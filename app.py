"""
AutoAssistGroup Support Ticket Management System

This Flask application provides a comprehensive support ticket management system with:
- User authentication and role-based access control
- Ticket creation, assignment, and tracking
- Email integration and automated processing
- File attachment handling with warranty detection
- Real-time dashboard with analytics
- MongoDB backend with optimized queries
- Serverless deployment support

CRITICAL FIX (2025-01-26): N8N Ticket ID Preservation
- Issue: N8N ticket IDs (e.g., GS5160) were being replaced with generated IDs (e.g., EO5267)
- Root Cause: Ticket ID extraction logic was not properly handling nested data structures
- Solution: Enhanced ticket ID preservation with multiple fallback extraction methods
- Added comprehensive debugging to identify data structure issues
- New debug endpoint: /api/tickets/debug-n8n for troubleshooting

Author: AutoAssistGroup Development Team
Version: 2.0
"""

from flask import Flask, render_template, jsonify, redirect, request, url_for, send_from_directory, session, flash, Response, make_response, render_template_string
from flask_cors import CORS
import os
import logging
from datetime import datetime, timedelta
import uuid
import re
import json
import requests
import atexit
import csv
import io
import smtplib
import threading
import time
import random
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from werkzeug.security import generate_password_hash, check_password_hash
from werkzeug.utils import secure_filename
from collections import defaultdict
from database import get_db
from bson.objectid import ObjectId
import base64
import mimetypes
import hashlib
from flask import send_file
import html

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # dotenv not available, skip loading
    pass

app = Flask(__name__)

# Enable CORS for all routes
CORS(app)

# Configure logging properly
is_production = os.environ.get('FLASK_ENV') == 'production'
log_level = logging.INFO if is_production else logging.DEBUG

logging.basicConfig(
    level=log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

# Disable all logging globally for performance (including third-party loggers)
logging.disable(logging.CRITICAL)

# Only add file handler in development
if not is_production:
    file_handler = logging.FileHandler('app.log')
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logging.getLogger().addHandler(file_handler)

# Ensure external libraries are fully silenced
try:
    logging.getLogger('werkzeug').disabled = True
    logging.getLogger('urllib3').disabled = True
except Exception:
    pass

app.logger.setLevel(logging.INFO)

# Disable all app.logger calls by replacing with a no-op logger
class _NoopLogger:
    def __getattr__(self, name):
        def _noop(*args, **kwargs):
            return None
        return _noop

app.logger = _NoopLogger()

# Security configuration
app.secret_key = os.environ.get('SECRET_KEY', os.urandom(32).hex())
if not os.environ.get('SECRET_KEY'):
    app.logger.warning("SECRET_KEY not set in environment, using generated key (not suitable for production)")

# Enhanced session configuration for better stability and longer sessions
app.config['SESSION_COOKIE_SECURE'] = False  # Set to True only in production with HTTPS
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
app.config['SESSION_REFRESH_EACH_REQUEST'] = True
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=30)  # 30 days - very permissive for better user experience
app.config['SESSION_COOKIE_MAX_AGE'] = 30 * 24 * 60 * 60  # 30 days in seconds

# Simple session configuration
# Minimal security headers - more permissive for better user experience
@app.after_request
def set_security_headers(response):
    """Add minimal security headers to all responses"""
    response.headers['X-Content-Type-Options'] = 'nosniff'
    # Removed strict security headers to prevent session issues
    return response

# Enhanced session timeout configuration
app.permanent_session_lifetime = timedelta(days=30)  # 30 days - very permissive for better user experience

def check_session_timeout():
    """No session timeout - sessions are permanent"""
    # Sessions never expire - always return False
    return False

def refresh_session():
    """Aggressive session refresh - force session to persist"""
    try:
        if 'member_id' in session:
            # Force session to be permanent and never expire
            session.permanent = True
            session.modified = True
            
            # Add persistence markers
            session['_last_refresh'] = datetime.now().isoformat()
            session['_refresh_count'] = session.get('_refresh_count', 0) + 1
            
            # Force session to be saved immediately
            session['_force_persist'] = True
            
            app.logger.info(f"Session aggressively refreshed for user {session.get('member_id', 'unknown')} - Refresh #{session['_refresh_count']}")
            return True
        else:
            app.logger.warning("Cannot refresh session - no member_id found")
            return False
    except Exception as e:
        app.logger.error(f"Error refreshing session: {e}")
        return False
        
def restore_user_session():
    """Simple session restoration - just try to get user_id from database"""
    try:
        # If session already has member_id, no need to restore
        if 'member_id' in session:
            return True
            
        app.logger.info(f"Attempting session restoration. Session keys: {list(session.keys())}")
        
        # Try to restore from user_id in session
        if 'user_id' in session:
            try:
                db = get_db()
                user = db.get_member_by_user_id(session['user_id'])
                if user:
                    # Simple restoration
                    session['member_id'] = str(user['_id'])
                    session['member_name'] = user.get('name', 'Unknown')
                    session['member_role'] = user.get('role', 'Member')
                    session.permanent = True
                    session.modified = True
                    
                    app.logger.info(f"Session restored for user {user.get('name', 'Unknown')}")
                    return True
                else:
                    app.logger.warning(f"User {session['user_id']} not found in database")
            except Exception as e:
                app.logger.error(f"Failed to restore session: {e}")
        
        return False
        
    except Exception as e:
        app.logger.error(f"Error in session restoration: {e}")
        return False

def check_and_restore_session():
    """Check if session is valid and try to restore if needed"""
    try:
        # If session has member_id, it's valid
        if 'member_id' in session:
            return True
            
        # Try to restore the session
        if restore_user_session():
            return True
            
        # If restoration failed, session is truly invalid
        return False
        
    except Exception as e:
        app.logger.error(f"Error checking/restoring session: {e}")
        return False

def safe_member_lookup():
    """Safely get member data with automatic session restoration"""
    try:
        if 'member_id' not in session:
            # Try to restore session first
            if check_and_restore_session():
                app.logger.info("Session restored during member lookup")
            else:
                return None
        
        # Now try to get member data
        db = get_db()
        current_member = db.get_member_by_id(session['member_id'])
        
        if not current_member:
            app.logger.warning(f"Member {session.get('member_id')} not found in database")
            return None
            
        return current_member
        
    except Exception as e:
        app.logger.error(f"Error in safe_member_lookup: {e}")
        return None

# Enhanced before_request with better session management
@app.before_request
def before_request():
    """Enhanced request preprocessing with better session handling"""
    protected_routes = ['dashboard', 'ticket_detail', 'create_ticket', 'admin', 'members', 'technicians']
    
    # Also check API routes that require authentication
    api_routes_requiring_auth = [
        'manage_members', 'manage_member', 'get_technicians', 'create_technician', 
        'update_technician', 'deactivate_technician', 'get_single_ticket',
        'delete_ticket', 'assign_ticket', 'update_ticket_status', 'send_reply',
        'dashboard_updates'  # Add this line to protect the dashboard updates API
    ]
    
    # Skip session checks for static files and non-protected routes
    if request.endpoint in ['static', 'favicon'] or request.path.startswith('/static/'):
        return None
    
    # Skip session checks for health check and session heartbeat endpoints
    if request.endpoint in ['health_check', 'session_heartbeat']:
        return None
    
    # Simple session management - always try to restore if needed
    if 'member_id' not in session:
        # Try to restore session without redirecting
        if check_and_restore_session():
            app.logger.info(f"Session restored for {request.endpoint}")
        else:
            app.logger.warning(f"Session restoration failed for {request.endpoint}")
            # Don't redirect - let the endpoint handle it
    
    # If we have member_id, just refresh it
    if 'member_id' in session:
        try:
            refresh_session()
            app.logger.debug(f"Session refreshed for user {session.get('member_id')}")
        except Exception as e:
            app.logger.error(f"Error refreshing session: {e}")
    
    # Sessions are permanent - no timeout checks
    # Users stay logged in forever

# Configuration
WEBHOOK_URL = os.environ.get('WEBHOOK_URL', 'https://ffxtrading.app.n8n.cloud/webhook/fb4af014-26e6-4477-821f-917fc9b3ee96')

# Email Configuration
EMAIL_HOST = os.environ.get('EMAIL_HOST', 'smtp.gmail.com')
EMAIL_PORT = int(os.environ.get('EMAIL_PORT', '587'))
EMAIL_USERNAME = os.environ.get('EMAIL_USERNAME', '')
EMAIL_PASSWORD = os.environ.get('EMAIL_PASSWORD', '')
EMAIL_USE_TLS = os.environ.get('EMAIL_USE_TLS', 'True').lower() == 'true'
EMAIL_FROM = os.environ.get('EMAIL_FROM', EMAIL_USERNAME)

# Input validation and sanitization helpers
def sanitize_input(text):
    """Sanitize user input to prevent XSS attacks"""
    if not text:
        return ""
    return html.escape(str(text).strip())

def validate_email(email):
    """Validate email format"""
    import re
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None

def validate_ticket_id(ticket_id):
    """Validate ticket ID format"""
    if not ticket_id or len(str(ticket_id)) > 50:
        return False
    return str(ticket_id).replace(' ', '') == str(ticket_id)  # No spaces allowed

def rate_limit_check(key, limit=10, window=60):
    """Simple in-memory rate limiting (for production, use Redis)"""
    import time
    current_time = time.time()
    
    # For simplicity, using a global dict (in production, use proper cache)
    if not hasattr(rate_limit_check, 'cache'):
        rate_limit_check.cache = {}
    
    if key not in rate_limit_check.cache:
        rate_limit_check.cache[key] = []
    
    # Remove old entries
    rate_limit_check.cache[key] = [
        timestamp for timestamp in rate_limit_check.cache[key] 
        if current_time - timestamp < window
    ]
    
    if len(rate_limit_check.cache[key]) >= limit:
        return False
    
    rate_limit_check.cache[key].append(current_time)
    return True

# Simple caching mechanism (in production, use Redis/Memcached)
def cache_get(key, default=None):
    """Get value from cache"""
    if not hasattr(cache_get, 'cache'):
        cache_get.cache = {}
    
    if key in cache_get.cache:
        value, expires = cache_get.cache[key]
        if time.time() < expires:
            return value
        else:
            del cache_get.cache[key]
    
    return default

def cache_set(key, value, expires_in=300):
    """Set value in cache with expiration (default 5 minutes)"""
    import time
    if not hasattr(cache_get, 'cache'):
        cache_get.cache = {}
    
    expires_at = time.time() + expires_in
    cache_get.cache[key] = (value, expires_at)

# File upload configuration for serverless environments
if is_production:
    # For serverless/production, use /tmp directory (ephemeral)
    UPLOAD_FOLDER = '/tmp/uploads'
    try:
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        logging.info(f"SUCCESS: Created upload directory: {UPLOAD_FOLDER}")
    except OSError as e:
        logging.warning(f"Could not create upload directory: {e}")
        # Fallback to /tmp if /tmp/uploads fails
        UPLOAD_FOLDER = '/tmp'
        logging.info(f" Fallback upload directory: {UPLOAD_FOLDER}")
else:
    # For development - use absolute path to avoid read-only issues
    UPLOAD_FOLDER = os.environ.get('UPLOAD_FOLDER', os.path.join(os.getcwd(), 'uploads'))
    try:
        os.makedirs('static', exist_ok=True)
        os.makedirs('templates', exist_ok=True)
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        logging.info(f"SUCCESS: Created directories including: {UPLOAD_FOLDER}")
    except OSError as e:
        logging.warning(f"Could not create directories: {e}")
        # Fallback to system temp directory if current directory is read-only
        import tempfile
        UPLOAD_FOLDER = os.path.join(tempfile.gettempdir(), 'autoassist_uploads')
        try:
            os.makedirs(UPLOAD_FOLDER, exist_ok=True)
            logging.info(f"SUCCESS: Created fallback upload directory: {UPLOAD_FOLDER}")
        except OSError as fallback_error:
            logging.error(f"CRITICAL: Could not create any upload directory: {fallback_error}")
            UPLOAD_FOLDER = None

# Log upload folder configuration
        logging.info(f"UPLOAD_FOLDER configured as: {UPLOAD_FOLDER}")
        logging.info(f"UPLOAD_FOLDER exists: {os.path.exists(UPLOAD_FOLDER) if UPLOAD_FOLDER else False}")

app.config['DEBUG'] = os.environ.get('FLASK_ENV') != 'production'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Add these constants after existing app configuration
ALLOWED_EXTENSIONS = {'pdf', 'doc', 'docx', 'jpg', 'jpeg', 'png', 'txt', 'csv'}

# Note: Upload directory creation is now handled above based on environment

# Email Service Class
class EmailService:
    """Email service for sending notifications"""
    
    def __init__(self):
        self.host = EMAIL_HOST
        self.port = EMAIL_PORT
        self.username = EMAIL_USERNAME
        self.password = EMAIL_PASSWORD
        self.use_tls = EMAIL_USE_TLS
        self.from_email = EMAIL_FROM
    
    def send_email(self, to_email, subject, body, html_body=None, attachments=None):
        """Send email with optional HTML body and attachments
        
        Args:
            to_email: Recipient email address
            subject: Email subject
            body: Email body text
            html_body: Optional HTML body
            attachments: List of attachments. Each attachment can be:
                - String (file path)
                - Dict with keys: 'filename', 'data' (base64), 'content_type' (optional)
        """
        try:
            # Skip sending if email is not configured
            if not self.username or not self.password:
                app.logger.warning("Email not configured - would send email:")
                app.logger.info(f"To: {to_email}")
                app.logger.info(f"Subject: {subject}")
                app.logger.info(f"Body: {body}")
                if attachments:
                    app.logger.info(f"Attachments: {len(attachments)} files")
                return True
            
            # Create message
            msg = MIMEMultipart('alternative')
            msg['From'] = self.from_email
            msg['To'] = to_email
            msg['Subject'] = subject
            
            # Add text body
            text_part = MIMEText(body, 'plain')
            msg.attach(text_part)
            
            # Add HTML body if provided
            if html_body:
                html_part = MIMEText(html_body, 'html')
                msg.attach(html_part)
            
            # Add attachments if provided
            if attachments:
                for attachment in attachments:
                    try:
                        if isinstance(attachment, str):
                            # Handle file path attachment (original behavior)
                            if os.path.exists(attachment):
                                with open(attachment, 'rb') as attachment_file:
                                    part = MIMEBase('application', 'octet-stream')
                                    part.set_payload(attachment_file.read())
                                
                                encoders.encode_base64(part)
                                part.add_header(
                                    'Content-Disposition',
                                            f'attachment; filename="{os.path.basename(attachment)}"'
                                )
                                msg.attach(part)
                                app.logger.info(f" Added file attachment: {os.path.basename(attachment)}")
                            else:
                                app.logger.warning(f" Attachment file not found: {attachment}")
                        
                        elif isinstance(attachment, dict):
                            # Handle base64 data attachment (new functionality)
                            filename = attachment.get('filename', attachment.get('fileName', 'attachment'))
                            file_data = attachment.get('data', attachment.get('fileData', ''))
                            content_type = attachment.get('content_type', 'application/octet-stream')
                            
                            if file_data:
                                # Decode base64 data
                                try:
                                    decoded_data = base64.b64decode(file_data)
                                    
                                    # Determine MIME type
                                    mime_type = content_type
                                    if mime_type == 'application/octet-stream':
                                        import mimetypes
                                        guessed_type, _ = mimetypes.guess_type(filename)
                                        if guessed_type:
                                            mime_type = guessed_type
                                    
                                    # Create attachment part
                                    maintype, subtype = mime_type.split('/', 1)
                                    part = MIMEBase(maintype, subtype)
                                    part.set_payload(decoded_data)
                                    encoders.encode_base64(part)
                                    part.add_header(
                                        'Content-Disposition',
                                        f'attachment; filename="{filename}"'
                                    )
                                    msg.attach(part)
                                    app.logger.info(f" Added base64 attachment: {filename} ({len(decoded_data)} bytes)")
                                    
                                except Exception as decode_error:
                                    app.logger.error(f" Failed to decode base64 attachment {filename}: {decode_error}")
                            else:
                                app.logger.warning(f" No data provided for attachment: {filename}")
                        
                        else:
                            app.logger.warning(f" Invalid attachment format: {type(attachment)}")
                            
                    except Exception as att_error:
                        app.logger.error(f" Error processing attachment: {att_error}")
                        continue
            
            # Send email
            server = smtplib.SMTP(self.host, self.port)
            if self.use_tls:
                server.starttls()
            server.login(self.username, self.password)
            server.send_message(msg)
            server.quit()
            
            app.logger.info(f"ðŸ“§ Email sent successfully to {to_email} with {len(attachments) if attachments else 0} attachments")
            return True
            
        except Exception as e:
            app.logger.error(f"ðŸ’¥ Failed to send email to {to_email}: {e}")
            return False

# Initialize email service
email_service = EmailService()

# Add function to check allowed file extensions
def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# Note: Manual ticket creation route removed - ticket numbers are auto-generated
# Tickets are created automatically through:
# 1. Email integration (/api/tickets)
# 2. Warranty form submissions (/api/warranty-form-submission)
# 3. Other automated processes

# Note: Manual ticket creation API removed since ticket numbers are auto-generated
# Tickets are created automatically through existing automated endpoints

# ===============================
# SMART DETECTION & PARSING UTILITIES
# ===============================
def detect_warranty_form(filename, file_data=None):
    """
    Intelligent warranty form detection based on filename and content
    Enhanced with comprehensive keyword matching and future content analysis capability
    """
    # Comprehensive warranty keywords including common misspellings
    warranty_keywords = [
        'warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante', 'garentee',
        'extended', 'protection', 'coverage', 'service_plan', 'service_contract',
        'maintenance_agreement', 'care_plan', 'support_plan', 'repair_coverage',
        'product_protection', 'extended_service', 'service_warranty', 
        'manufacturer_warranty', 'factory_warranty', 'vehicle_warranty',
        'bumper_to_bumper', 'powertrain', 'drivetrain', 'comprehensive_coverage'
    ]
    
    filename_lower = filename.lower()
    
    # Check filename for warranty keywords
    for keyword in warranty_keywords:
        if keyword in filename_lower:
            app.logger.info(f"Warranty form detected via filename keyword: {keyword} in {filename}")
            return True
    
    # Future enhancement: Content-based analysis
    if file_data:
        # Framework for content analysis (OCR, text extraction, etc.)
        # Can be extended to analyze file contents for warranty-related text
        pass
    
    return False

def get_enhanced_file_type_info(filename, file_size=0):
    """
    Advanced file type detection with comprehensive MIME type mapping
    Returns detailed file information including icons, colors, and capabilities
    """
    extension = filename.split('.').pop().lower()
    
    file_type_mapping = {
        # Document types
        'pdf': {
            'icon': 'fas fa-file-pdf', 
            'color': 'text-red-600', 
            'type': 'PDF Document',
            'mime': 'application/pdf',
            'viewable': True,
            'category': 'document'
        },
        'doc': {
            'icon': 'fas fa-file-word', 
            'color': 'text-blue-600', 
            'type': 'Word Document',
            'mime': 'application/msword',
            'viewable': False,
            'category': 'document'
        },
        'docx': {
            'icon': 'fas fa-file-word', 
            'color': 'text-blue-600', 
            'type': 'Word Document',
            'mime': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            'viewable': False,
            'category': 'document'
        },
        'xls': {
            'icon': 'fas fa-file-excel', 
            'color': 'text-green-600', 
            'type': 'Excel Spreadsheet',
            'mime': 'application/vnd.ms-excel',
            'viewable': False,
            'category': 'spreadsheet'
        },
        'xlsx': {
            'icon': 'fas fa-file-excel', 
            'color': 'text-green-600', 
            'type': 'Excel Spreadsheet',
            'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            'viewable': False,
            'category': 'spreadsheet'
        },
        'ppt': {
            'icon': 'fas fa-file-powerpoint', 
            'color': 'text-orange-600', 
            'type': 'PowerPoint Presentation',
            'mime': 'application/vnd.ms-powerpoint',
            'viewable': False,
            'category': 'presentation'
        },
        'pptx': {
            'icon': 'fas fa-file-powerpoint', 
            'color': 'text-orange-600', 
            'type': 'PowerPoint Presentation',
            'mime': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            'viewable': False,
            'category': 'presentation'
        },
        # Image types
        'jpg': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'JPEG Image',
            'mime': 'image/jpeg',
            'viewable': True,
            'category': 'image'
        },
        'jpeg': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'JPEG Image',
            'mime': 'image/jpeg',
            'viewable': True,
            'category': 'image'
        },
        'png': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'PNG Image',
            'mime': 'image/png',
            'viewable': True,
            'category': 'image'
        },
        'gif': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'GIF Image',
            'mime': 'image/gif',
            'viewable': True,
            'category': 'image'
        },
        'webp': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'WebP Image',
            'mime': 'image/webp',
            'viewable': True,
            'category': 'image'
        },
        # Archive types
        'zip': {
            'icon': 'fas fa-file-archive', 
            'color': 'text-yellow-600', 
            'type': 'ZIP Archive',
            'mime': 'application/zip',
            'viewable': False,
            'category': 'archive'
        },
        'rar': {
            'icon': 'fas fa-file-archive', 
            'color': 'text-yellow-600', 
            'type': 'RAR Archive',
            'mime': 'application/vnd.rar',
            'viewable': False,
            'category': 'archive'
        },
        '7z': {
            'icon': 'fas fa-file-archive', 
            'color': 'text-yellow-600', 
            'type': '7-Zip Archive',
            'mime': 'application/x-7z-compressed',
            'viewable': False,
            'category': 'archive'
        },
        # Text types
        'txt': {
            'icon': 'fas fa-file-alt', 
            'color': 'text-gray-600', 
            'type': 'Text File',
            'mime': 'text/plain',
            'viewable': True,
            'category': 'text'
        },
        'csv': {
            'icon': 'fas fa-file-csv', 
            'color': 'text-green-600', 
            'type': 'CSV File',
            'mime': 'text/csv',
            'viewable': True,
            'category': 'data'
        },
        'json': {
            'icon': 'fas fa-file-code', 
            'color': 'text-indigo-600', 
            'type': 'JSON File',
            'mime': 'application/json',
            'viewable': True,
            'category': 'data'
        },
        'xml': {
            'icon': 'fas fa-file-code', 
            'color': 'text-indigo-600', 
            'type': 'XML File',
            'mime': 'application/xml',
            'viewable': True,
            'category': 'data'
        }
    }
    
    file_info = file_type_mapping.get(extension, {
        'icon': 'fas fa-file', 
        'color': 'text-gray-600', 
        'type': 'File',
        'mime': 'application/octet-stream',
        'viewable': False,
        'category': 'unknown'
    })
    
    # Add file size information
    file_info['size'] = file_size
    file_info['extension'] = extension.upper()
    
    return file_info

# ===============================
# ENHANCED EMAIL PROCESSING FUNCTIONS
# ===============================

def enhanced_detect_warranty_form(filename, file_data=None):
    """
    Enhanced warranty form detection with comprehensive keyword matching
    Detects warranty forms based on filename patterns and content analysis
    """
    # Enhanced warranty keywords with common misspellings and variations
    warranty_keywords = [
        'warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante', 'warrantie',
        'dpf', 'diesel', 'emission', 'claim', 'form', 'customer',
        'repair', 'service', 'defect', 'malfunction', 'issue', 'fault',
        'warranty_form', 'warranty_claim', 'claim_form', 'service_form',
        'dpf_form', 'emission_form', 'diesel_form', 'repair_form',
        'customer_form', 'complaint_form', 'warranty_application'
    ]
    
    filename_lower = filename.lower()
    
    app.logger.info(f" CHECKING WARRANTY in filename: '{filename}' â†’ '{filename_lower}'")
    
    # Check filename for warranty keywords
    keyword_matches = 0
    detected_keywords = []
    
    for keyword in warranty_keywords:
        if keyword in filename_lower:
            keyword_matches += 1
            detected_keywords.append(keyword)
            app.logger.info(f"     FOUND KEYWORD: '{keyword}'")
    
    app.logger.info(f" Total keyword matches: {keyword_matches}, Keywords found: {detected_keywords}")
    
    # Higher confidence with multiple keyword matches
    if keyword_matches >= 2:
        app.logger.info(f" Multi-keyword warranty detection: {filename} - Keywords: {detected_keywords}")
        return True
    elif keyword_matches == 1:
        # Single keyword match - check for high-confidence patterns
        high_confidence_keywords = ['warranty_form', 'warranty_claim', 'claim_form', 'dpf_form']
        for keyword in high_confidence_keywords:
            if keyword in filename_lower:
                app.logger.info(f" High-confidence warranty detection: {filename} - Keyword: {keyword}")
                return True
        app.logger.info(f" Single keyword match but not high-confidence: {detected_keywords[0]}")
    
    # Check for common warranty file patterns
    warranty_patterns = [
        'warranty', 'claim', 'dpf', 'emission', 'diesel'
    ]
    
    for pattern in warranty_patterns:
        if pattern in filename_lower and ('form' in filename_lower or 'pdf' in filename_lower):
            app.logger.info(f"Pattern-based warranty detection: {filename} - Pattern: {pattern}")
            return True
    
    return False

def generate_email_draft_response(ticket_data):
    """
    Generate contextual draft response for email tickets
    Creates intelligent draft based on email content, warranty status, and classification
    """
    try:
        customer_name = ticket_data.get('name', '').strip()
        first_name = customer_name.split()[0] if customer_name else 'Customer'
        
        subject = ticket_data.get('subject', '').lower()
        body = ticket_data.get('body', '').lower()
        classification = ticket_data.get('classification', 'General').lower()
        has_warranty = ticket_data.get('has_warranty', False)
        has_attachments = ticket_data.get('has_attachments', False)
        
        # ðŸš€ SMART DRAFT GENERATION based on content analysis
        app.logger.info(f"ðŸ¤– GENERATING SMART DRAFT for ticket - Classification: {classification}, Warranty: {has_warranty}, Attachments: {has_attachments}")
        
        # Warranty-related responses
        if has_warranty or 'warranty' in subject or 'warranty' in body or 'claim' in subject or classification == 'warranty claim':
            app.logger.info(f" WARRANTY DRAFT - Generating warranty claim response")
            draft = """Dear {first_name},

Thank you for contacting Auto Assist Group regarding your warranty inquiry.

We have received your warranty claim and our Aftercare Team is reviewing the details. To process your claim efficiently, we may need some additional information:

â€¢ Vehicle registration number
â€¢ Current mileage reading (with dashboard photo)
â€¢ Any new fault codes or error messages
â€¢ Details of any recent services or repairs

Our warranty claim form is available at: https://autoassistgroup.com/report/claims

We will review your case within 2-3 business days and contact you with next steps. If your claim is approved, we will arrange the necessary remedial work at no cost to you.

If you have any questions in the meantime, please don't hesitate to contact us.

Best regards,
Auto Assist Group - Aftercare Team"""

        # DPF/Technical issues
        elif 'dpf' in subject or 'dpf' in body or 'filter' in subject or 'regen' in subject or classification == 'technical support':
            app.logger.info(f"ðŸ”§ TECHNICAL DRAFT - Generating DPF/technical support response")
            draft = """Dear {first_name},

Thank you for reaching out regarding your DPF/technical issue.

We've received your inquiry and our technical team is reviewing the details. Based on the information provided, we will:

1. Assess the technical requirements for your vehicle
2. Provide you with a detailed solution and quote
3. Schedule the work at your convenience

Our technical specialists will contact you within 24 hours to discuss:
â€¢ Diagnostic findings and recommendations
â€¢ Service options and pricing
â€¢ Appointment availability

In the meantime, if you experience any urgent issues with your vehicle, please contact us immediately at 01234 567890.

Best regards,
Auto Assist Group - Technical Support Team"""

        # Customer service/General inquiries
        elif classification == 'customer service' or 'service' in subject or 'appointment' in subject or 'booking' in subject:
            app.logger.info(f"ðŸ“ž SERVICE DRAFT - Generating customer service response")
            draft = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your inquiry and appreciate you choosing our services. Our customer service team is reviewing your request and will respond within 24 hours.

For immediate assistance, you can reach us at:
â€¢ Phone: 01234 567890 (Mon-Fri 8AM-6PM)
â€¢ Email: support@autoassistgroup.com

If you're looking to book a service, you can also use our online booking system at: https://autoassistgroup.com/book

We look forward to assisting you with your automotive needs.

Kind regards,
Auto Assist Group Customer Service Team"""

        # File/Document submissions
        elif has_attachments or 'document' in subject or 'file' in subject or 'upload' in body:
            app.logger.info(f"ðŸ“Ž DOCUMENT DRAFT - Generating file/document response")
            draft = """Dear {first_name},

Thank you for submitting your documentation to Auto Assist Group.

We have received your files and our team is currently reviewing them. You can expect:

â€¢ Document verification within 24-48 hours
â€¢ A follow-up call or email with next steps
â€¢ Any additional requirements if needed

If your submission is related to a warranty claim, our Aftercare Team will prioritize the review process.

Your reference number is: {ticket_data.get('ticket_id', 'N/A')}

Thank you for your patience. We will contact you soon with an update.

Best regards,
Auto Assist Group Support Team"""
        # General/Default response
        else:
            app.logger.info(f"ðŸ’¬ GENERAL DRAFT - Generating standard response")
            draft = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your message and our team is reviewing your inquiry. We aim to respond to all customer communications within 24 hours.

If your inquiry is urgent, please contact us directly at
â€¢ Email: support@autoassistgroup.com

Your reference number is: {ticket_data.get('ticket_id', 'N/A')}

We appreciate your business and look forward to assisting you.

Kind regards,
Auto Assist Group Support Team"""        
        app.logger.info(f" DRAFT GENERATED - Length: {len(draft)} characters for ticket {ticket_data.get('ticket_id', 'Unknown')}")
        return draft.strip()
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ DRAFT GENERATION FAILED: {e}")
        # Fallback draft
        customer_name = ticket_data.get('name', 'Customer')
        first_name = customer_name.split()[0] if customer_name else 'Customer'
        
        fallback_draft = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your message and will respond as soon as possible.

Best regards,
Auto Assist Group Support Team"""
        
        app.logger.info(f"ðŸ”„ USING FALLBACK DRAFT for ticket {ticket_data.get('ticket_id', 'Unknown')}")
        return fallback_draft.strip()

def enhanced_process_email_attachments(attachments_data):
    """
    Enhanced attachment processing with base64 handling and warranty detection
    Updated to handle complex n8n data structures properly
    """
    processed_attachments = []
    warranty_detected = False
    
    if not attachments_data:
        return processed_attachments, warranty_detected
    
    # Handle the complex n8n data structure
    app.logger.info(f"Processing {len(attachments_data)} attachment items")
    for i, att_data in enumerate(attachments_data):
        app.logger.info(f"Attachment item {i}: {type(att_data)} - Keys: {list(att_data.keys()) if isinstance(att_data, dict) else 'Not a dict'}")
        
        if isinstance(att_data, dict):
            # Case 1: Handle data array with nested attachments (n8n format)
            if 'data' in att_data and isinstance(att_data['data'], list):
                app.logger.info(f"Case 1: Found nested data array with {len(att_data['data'])} items")
                for j, nested_item in enumerate(att_data['data']):
                    app.logger.info(f"Nested item {j}: {type(nested_item)} - Keys: {list(nested_item.keys()) if isinstance(nested_item, dict) else 'Not a dict'}")
                    if isinstance(nested_item, dict):
                        # Handle nested JSON string data
                        if 'data' in nested_item and isinstance(nested_item['data'], str):
                            app.logger.info(f"Case 1a: Found JSON string data")
                            try:
                                parsed_att = json.loads(nested_item['data'])
                                app.logger.info(f"Parsed attachment data: {list(parsed_att.keys()) if isinstance(parsed_att, dict) else 'Not a dict'}")
                                attachment = process_single_attachment(parsed_att)
                                if attachment:
                                    app.logger.info(f"Created attachment: {attachment.get('filename', 'unknown')}")
                                    processed_attachments.append(attachment)
                                    if attachment.get('is_warranty', False):
                                        warranty_detected = True
                            except json.JSONDecodeError as e:
                                app.logger.error(f"JSON decode error: {e}")
                                continue
                        else:
                            # Direct nested attachment data
                            app.logger.info(f"Case 1b: Direct nested attachment data")
                            attachment = process_single_attachment(nested_item)
                            if attachment:
                                app.logger.info(f"Created attachment: {attachment.get('filename', 'unknown')}")
                                processed_attachments.append(attachment)
                                if attachment.get('is_warranty', False):
                                    warranty_detected = True
            
            # Case 2: Handle JSON string data
            elif 'data' in att_data and isinstance(att_data['data'], str):
                try:
                    parsed_att = json.loads(att_data['data'])
                    attachment = process_single_attachment(parsed_att)
                    if attachment:
                        processed_attachments.append(attachment)
                        if attachment.get('is_warranty', False):
                            warranty_detected = True
                except json.JSONDecodeError:
                    attachment = process_single_attachment(att_data)
                    if attachment:
                        processed_attachments.append(attachment)
                        if attachment.get('is_warranty', False):
                            warranty_detected = True
            
            # Case 3: Direct attachment data
            else:
                attachment = process_single_attachment(att_data)
            if attachment:
                processed_attachments.append(attachment)
                if attachment.get('is_warranty', False):
                    warranty_detected = True
    
    # Final debugging summary
    app.logger.info(f"[TARGET] Enhanced attachment processing complete:")
    app.logger.info(f"  - Input items: {len(attachments_data)}")
    app.logger.info(f"  - Processed attachments: {len(processed_attachments)}")
    app.logger.info(f"  - Warranty detected: {warranty_detected}")
    if processed_attachments:
        app.logger.info(f"  - Attachment filenames: {[att.get('filename', 'unknown') for att in processed_attachments]}")
    else:
        app.logger.warning(f"  - [WARNING]  NO ATTACHMENTS PROCESSED from {len(attachments_data)} input items!")
    
    return processed_attachments, warranty_detected

def process_single_attachment(att_data):
    """
    Process a single attachment with enhanced metadata
    """
    app.logger.info(f"Processing single attachment: {type(att_data)} - Keys: {list(att_data.keys()) if isinstance(att_data, dict) else 'Not a dict'}")
    
    if not isinstance(att_data, dict):
        app.logger.warning(f"Attachment data is not a dict: {type(att_data)}")
        return None
    
    # Handle different field name variations from n8n
    filename = (att_data.get('fileName') or 
                att_data.get('filename') or 
                att_data.get('name') or 
                'unknown_file')
    
    file_data = (att_data.get('fileData') or 
                 att_data.get('data') or 
                 att_data.get('content') or 
                 '')
    
    if not filename or filename == 'unknown_file':
        app.logger.warning(f"No valid filename found. Available keys: {list(att_data.keys())}")
        if not file_data:
            app.logger.warning(f"No file data either. Skipping this attachment.")
            return None
        else:
            filename = 'attachment_without_name'
    
    app.logger.info(f"[SUCCESS] Processing attachment: {filename} (has_data: {bool(file_data)})")
    
    # Calculate file size
    file_size = 0
    if file_data:
        try:
            file_size = len(base64.b64decode(file_data))
        except:
            file_size = 0
    
    # Enhanced warranty detection
    is_warranty = enhanced_detect_warranty_form(filename)
    
    # DEBUG: Log warranty detection result
    app.logger.info(f" WARRANTY CHECK: {filename} â†’ {' WARRANTY DETECTED' if is_warranty else ' No warranty detected'}")
    
    attachment = {
        'filename': filename,
        'data': file_data,
        'is_warranty': is_warranty,
        'size': file_size,
        'size_formatted': format_file_size(file_size),
        'from': att_data.get('from', ''),
        'ticket_no': att_data.get('ticketNo', att_data.get('ticket_id', '')),
        'index': att_data.get('index', 0),
        'processed_at': datetime.now().isoformat()
    }
    
    # Add file type analysis
    try:
        file_type_info = get_enhanced_file_type_info(filename, file_size)
        attachment.update({
        'file_type': file_type_info.get('type', 'unknown'),
        'file_category': file_type_info.get('category', 'unknown'),
        'file_extension': file_type_info.get('extension', ''),
        'type_confidence': file_type_info.get('confidence', 0)
        })
    except Exception as e:
        app.logger.error(f"Error analyzing file type for {filename}: {e}")
        attachment.update({
            'file_type': 'unknown',
            'file_category': 'unknown',
            'file_extension': os.path.splitext(filename)[1].lower() if filename else '',
            'type_confidence': 0
    })
    
    return attachment

def format_file_size(size_bytes):
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def enhanced_process_complex_email_data(raw_data):
    """
    Enhanced email processing combining Gmail frontend capabilities with AutoAssistGroup features
    """
    processed_tickets = []
    attachments_list = []
    main_ticket = None
    warranty_detected = False
    
    app.logger.info(f"Enhanced processing email data: {type(raw_data)}")
    
    try:
        # Handle case where data is a list (n8n often sends arrays)
        if isinstance(raw_data, list):
            app.logger.info(f"Processing array with {len(raw_data)} items")
            for i, item in enumerate(raw_data):
                app.logger.info(f"Processing list item {i}: {type(item)} - Keys: {list(item.keys()) if isinstance(item, dict) else 'Not a dict'}")
                
                if isinstance(item, dict):
                    # Check for attachment data with enhanced parsing
                    if 'data' in item and isinstance(item['data'], list):
                        app.logger.info(f"Found attachment data array with {len(item['data'])} items")
                        # Process attachments route data
                        processed_atts, warranty_found = enhanced_process_email_attachments(item['data'])
                        app.logger.info(f"Processed {len(processed_atts)} attachments, warranty found: {warranty_found}")
                        attachments_list.extend(processed_atts)
                        if warranty_found:
                            warranty_detected = True
                    
                    # Check if this is main ticket data (text route)
                    elif 'ticket_id' in item or 'threadI' in item or 'body' in item:
                        main_ticket = item
                        
                    # Check if item has direct data field with JSON
                    elif 'data' in item and isinstance(item['data'], str):
                        try:
                            parsed_data = json.loads(item['data'])
                            if 'fileName' in parsed_data:
                                attachment = process_single_attachment(parsed_data)
                                if attachment:
                                    attachments_list.append(attachment)
                                    if attachment.get('is_warranty', False):
                                        warranty_detected = True
                            else:
                                main_ticket = parsed_data
                        except json.JSONDecodeError:
                            pass
                    
                    # [FIX] CRITICAL FIX: Check for flat attachment structure BEFORE treating as main ticket
                    elif 'fileName' in item and 'fileData' in item:
                        # This is a flat attachment structure
                        attachment = process_single_attachment(item)
                        if attachment:
                            attachments_list.append(attachment)
                            if attachment.get('is_warranty', False):
                                warranty_detected = True
                                app.logger.info(f"Warranty detected in flat attachment: {item['fileName']}")
                        app.logger.info(f"Detected flat attachment: {item['fileName']}")
                            
                    # Direct ticket data without nesting (fallback)
                    else:
                        if not main_ticket:  # Only set if we don't have one yet
                            main_ticket = item
        else:
            # Single item case
            if isinstance(raw_data, dict):
                if 'ticket_id' in raw_data or 'threadI' in raw_data or 'body' in raw_data:
                    main_ticket = raw_data
                else:
                    processed_tickets.append(enhanced_process_single_email_item(raw_data))
        
        # Combine main ticket with attachments
        if main_ticket:
            combined_ticket = main_ticket.copy()
            combined_ticket['attachments'] = attachments_list
            combined_ticket['has_attachments'] = len(attachments_list) > 0
            combined_ticket['has_warranty'] = warranty_detected
            combined_ticket['warranty_forms_count'] = sum(1 for att in attachments_list if att.get('is_warranty', False))
            
            # Enhanced ticket metadata
            combined_ticket['processed_at'] = datetime.now().isoformat()
            combined_ticket['processing_method'] = 'enhanced_email_processor'
            combined_ticket['total_attachments'] = len(attachments_list)
            combined_ticket['attachment_total_size'] = sum(att.get('size', 0) for att in attachments_list)
            
            # Enhanced debugging
            app.logger.info(f"[DEBUG] Enhanced processing summary:")
            app.logger.info(f"  - Attachments found: {len(attachments_list)}")
            app.logger.info(f"  - Has attachments: {combined_ticket.get('has_attachments')}")
            app.logger.info(f"  - Total attachments: {combined_ticket.get('total_attachments')}")
            app.logger.info(f"  - Warranty detected: {warranty_detected}")
            if attachments_list:
                app.logger.info(f"  - Attachment details: {[att.get('filename', 'unknown') for att in attachments_list]}")
                for idx, att in enumerate(attachments_list):
                    app.logger.info(f"    ðŸ“Ž Attachment {idx}: {att.get('filename', 'no_name')} | Size: {att.get('size', 0)} | Warranty: {att.get('is_warranty', False)} | HasData: {bool(att.get('data'))}")
            else:
                app.logger.warning(f" NO ATTACHMENTS FOUND in email processing!")
            
            # Set priority based on warranty detection
            if warranty_detected:
                combined_ticket['priority'] = 'High'
                combined_ticket['classification'] = 'Warranty Claim'
                app.logger.info(f" WARRANTY CLASSIFICATION SET: Ticket {combined_ticket.get('ticket_id', 'UNKNOWN')} marked as High priority and 'Warranty Claim' classification due to warranty form detection")
            
            processed_tickets.append(combined_ticket)
        
        # If we have attachments but no main ticket, create tickets from attachments
        elif attachments_list:
            for att in attachments_list:
                # Enhanced collision-resistant ID generation for attachment-only tickets
                timestamp = datetime.now()
                ticket_id = att.get('ticket_no', 
                    f"ATTCH{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12])
                ticket = {
                    'ticket_id': ticket_id,
                    'name': 'Unknown',
                    'from': att.get('from', ''),
                    'subject': f"Attachment: {att.get('filename', 'unknown')}",
                    'body': f"Ticket created from attachment: {att.get('filename', 'unknown')}",
                    'date': datetime.now().isoformat(),
                    'Priority': 'High' if att.get('is_warranty') else 'Medium',
                    'Classification': 'Warranty Claim' if att.get('is_warranty') else 'General',
                    'draft': '',
                    'attachments': [att],
                    'has_attachments': True,
                    'has_warranty': att.get('is_warranty', False),
                    'warranty_forms_count': 1 if att.get('is_warranty') else 0,
                    'total_attachments': 1,  # Fix: Add missing total_attachments
                    'attachment_total_size': att.get('size', 0),  # Fix: Add missing attachment_total_size
                    'processed_at': datetime.now().isoformat(),
                    'processing_method': 'attachment_only_processor'
                }
                processed_tickets.append(ticket)
        
        app.logger.info(f"Enhanced processing completed: {len(processed_tickets)} tickets, {len(attachments_list)} attachments, warranty detected: {warranty_detected}")
        
    except Exception as e:
        app.logger.error(f"Enhanced email processing error: {str(e)}")
        return []
    
    return processed_tickets

def enhanced_process_single_email_item(item):
    """
    Enhanced processing of single email items with warranty detection
    """
    ticket = {}
    
    if isinstance(item, dict) and 'data' in item:
        # Parse the data field if it's a JSON string
        data_content = item['data']
        if isinstance(data_content, str):
            try:
                parsed_data = json.loads(data_content)
                ticket.update(parsed_data)
            except json.JSONDecodeError:
                ticket['raw_data'] = data_content
        else:
            ticket.update(data_content)
            
        # Add index if available
        if 'index' in item:
            ticket['attachment_index'] = item['index']
    else:
        ticket.update(item)
    
    # Enhanced attachment processing
    if 'fileName' in ticket and 'fileData' in ticket:
        attachment = process_single_attachment(ticket)
        if attachment:
            ticket['attachments'] = [attachment]
            ticket['has_attachments'] = True
            ticket['has_warranty'] = attachment.get('is_warranty', False)
            ticket['warranty_forms_count'] = 1 if attachment.get('is_warranty') else 0
    else:
        ticket['has_attachments'] = False
        ticket['has_warranty'] = False
        ticket['warranty_forms_count'] = 0
        ticket['attachments'] = []
    
    # Enhanced metadata with collision-resistant ID
    if 'ticket_id' not in ticket:
        timestamp = datetime.now()
        ticket['ticket_id'] = f"EPROC{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
    ticket.setdefault('date', datetime.now().isoformat())
    ticket.setdefault('Priority', 'High' if ticket.get('has_warranty') else 'Medium')
    ticket.setdefault('Classification', 'Warranty Claim' if ticket.get('has_warranty') else 'General')
    ticket.setdefault('processed_at', datetime.now().isoformat())
    ticket.setdefault('processing_method', 'single_item_processor')
    
    return ticket

def process_complex_email_data(raw_data):
    """
    Ultra-sophisticated email data parsing for complex nested n8n structures
    Handles multiple data formats, nested JSON, and fragmented information
    """
    processed_tickets = []
    attachments_list = []
    main_ticket = None
    warranty_detected = False
    
    app.logger.info(f"Processing complex email data: {type(raw_data)}")
    
    try:
        # Handle case where data is a list (n8n often sends arrays)
        if isinstance(raw_data, list):
            for item in raw_data:
                app.logger.info(f"Processing list item: {type(item)}")
                
                if isinstance(item, dict):
                    # Check for attachment data with nested structure
                    if 'data' in item and isinstance(item['data'], list):
                        # This is the attachments route data
                        for att_data in item['data']:
                            if isinstance(att_data, dict):
                                if 'data' in att_data and isinstance(att_data['data'], str):
                                    # Parse JSON string data
                                    try:
                                        parsed_att = json.loads(att_data['data'])
                                        if 'fileName' in parsed_att:
                                            attachments_list.append(parsed_att)
                                            # Check for warranty form
                                            if detect_warranty_form(parsed_att['fileName']):
                                                warranty_detected = True
                                                app.logger.info(f"Warranty detected in attachment: {parsed_att['fileName']}")
                                    except json.JSONDecodeError as e:
                                        app.logger.error(f"JSON decode error: {e}")
                                elif 'fileName' in att_data:
                                    # Direct attachment data
                                    attachments_list.append(att_data)
                                    if detect_warranty_form(att_data['fileName']):
                                        warranty_detected = True
                    
                    # Check if this is main ticket data
                    elif 'ticket_id' in item or 'threadI' in item or 'body' in item:
                        main_ticket = item
                        
                    # Check if item has direct data field with JSON
                    elif 'data' in item and isinstance(item['data'], str):
                        try:
                            parsed_data = json.loads(item['data'])
                            if 'fileName' in parsed_data:
                                attachments_list.append(parsed_data)
                                if detect_warranty_form(parsed_data['fileName']):
                                    warranty_detected = True
                            else:
                                main_ticket = parsed_data
                        except json.JSONDecodeError:
                            pass
                    
                    # [FIX] CRITICAL FIX: Check for flat attachment structure BEFORE treating as main ticket
                    elif 'fileName' in item and 'fileData' in item:
                        # This is a flat attachment structure
                        attachments_list.append(item)
                        if detect_warranty_form(item['fileName']):
                            warranty_detected = True
                            app.logger.info(f"Warranty detected in flat attachment: {item['fileName']}")
                        app.logger.info(f"Detected flat attachment: {item['fileName']}")
                            
                    # Direct ticket data without nesting (fallback)
                    else:
                        if not main_ticket:  # Only set if we don't have one yet
                            main_ticket = item
        else:
            # Single item case
            if isinstance(raw_data, dict):
                if 'ticket_id' in raw_data or 'threadI' in raw_data or 'body' in raw_data:
                    main_ticket = raw_data
                else:
                    processed_tickets.append(process_single_email_item(raw_data))
        
        # Combine main ticket with attachments
        if main_ticket:
            combined_ticket = main_ticket.copy()
            combined_ticket['attachments'] = []
            combined_ticket['has_attachments'] = len(attachments_list) > 0
            combined_ticket['has_warranty'] = warranty_detected
            
            for att in attachments_list:
                attachment = {
                    'filename': att.get('fileName', 'unknown_file'),
                    'data': att.get('fileData', ''),
                    'is_warranty': detect_warranty_form(att.get('fileName', '')),
                    'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0,
                    'file_type': get_enhanced_file_type_info(att.get('fileName', ''))
                }
                combined_ticket['attachments'].append(attachment)
            
            processed_tickets.append(combined_ticket)
        
        # If we have attachments but no main ticket, create a basic ticket
        elif attachments_list:
            for att in attachments_list:
                # Generate collision-resistant ID for attachment tickets
                timestamp = datetime.now()
                default_ticket_id = f"OATTCH{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                ticket = {
                    'ticket_id': att.get('ticketNo', att.get('ticket_id', default_ticket_id)),
                    'name': 'Unknown',
                    'from': att.get('from', ''),
                    'subject': att.get('subject', 'Attachment Only'),
                    'body': f"Ticket created from attachment: {att.get('fileName', 'unknown')}",
                    'date': datetime.now().isoformat(),
                    'Priority': 'Medium',
                    'Classification': 'General',
                    'draft': '',
                    'attachments': [{
                        'filename': att.get('fileName', 'unknown_file'),
                        'data': att.get('fileData', ''),
                        'is_warranty': detect_warranty_form(att.get('fileName', '')),
                        'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0,
                        'file_type': get_enhanced_file_type_info(att.get('fileName', ''))
                    }],
                    'has_attachments': True,
                    'has_warranty': detect_warranty_form(att.get('fileName', ''))
                }
                processed_tickets.append(ticket)
        
        app.logger.info(f"Processed {len(processed_tickets)} tickets, warranty detected: {warranty_detected}")
        return processed_tickets
        
    except Exception as e:
        app.logger.error(f"Error in complex email data processing: {str(e)}")
        return []

def process_single_email_item(item):
    """
    Process a single email item with intelligent content analysis
    """
    ticket = {}
    
    if isinstance(item, dict) and 'data' in item:
        # Parse the data field if it's a JSON string
        data_content = item['data']
        if isinstance(data_content, str):
            try:
                parsed_data = json.loads(data_content)
                ticket.update(parsed_data)
            except json.JSONDecodeError:
                ticket['raw_data'] = data_content
        else:
            ticket.update(data_content)
            
        # Add index if available
        if 'index' in item:
            ticket['attachment_index'] = item['index']
    else:
        ticket.update(item)
    
    # Process attachments if present
    if 'fileName' in ticket and 'fileData' in ticket:
        file_type_info = get_enhanced_file_type_info(ticket['fileName'])
        attachment = {
            'filename': ticket['fileName'],
            'data': ticket['fileData'],
            'is_warranty': detect_warranty_form(ticket['fileName']),
            'size': len(base64.b64decode(ticket['fileData'])) if ticket['fileData'] else 0,
            'file_type': file_type_info
        }
        ticket['attachments'] = [attachment]
        ticket['has_attachments'] = True
        ticket['has_warranty'] = attachment.get('is_warranty', False)
    else:
        ticket['has_attachments'] = False
        ticket['has_warranty'] = False
        ticket['attachments'] = []
    
    # Ensure required fields with collision-resistant ID
    if 'ticket_id' not in ticket:
        timestamp = datetime.now()
        ticket['ticket_id'] = f"OPROC{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
    ticket.setdefault('date', datetime.now().isoformat())
    ticket.setdefault('Priority', 'Medium')
    ticket.setdefault('Classification', 'General')
    
    return ticket

# ===============================
# API ENDPOINTS
# ===============================

# Add API endpoint for automatic ticket creation from warranty form submissions
@app.route('/api/n8n/email-tickets', methods=['POST'])
def n8n_email_tickets():
    """
    New endpoint specifically designed for n8n email data with proper attachment handling
    """
    try:
        # Get JSON data from request
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400
        
        app.logger.info(f"N8N Email Tickets endpoint received data: {type(data)}")
        
        # Process the email data using enhanced processing
        try:
            processed_tickets = enhanced_process_complex_email_data(data)
            app.logger.info(f"Enhanced processing returned {len(processed_tickets) if processed_tickets else 0} tickets")
            
            # Debug: Log the processed ticket structure
            for i, ticket in enumerate(processed_tickets or []):
                attachments = ticket.get('attachments', [])
                app.logger.info(f" [DEBUG] Processed ticket {i}:")
                app.logger.info(f"  - has_attachments: {ticket.get('has_attachments')}")
                app.logger.info(f"  - has_warranty: {ticket.get('has_warranty')}")
                app.logger.info(f"  - total_attachments: {ticket.get('total_attachments')} (type: {type(ticket.get('total_attachments'))})")
                app.logger.info(f"  - attachments_count: {len(attachments)}")
                app.logger.info(f"  - subject: {ticket.get('subject', 'No subject')}")
                app.logger.info(f"  - from: {ticket.get('from', 'No sender')}")
                if attachments:
                    for j, att in enumerate(attachments):
                        app.logger.info(f"    ðŸ“Ž Attachment {j}: {att.get('filename', 'unknown')} (warranty: {att.get('is_warranty', False)}) (data_length: {len(att.get('data', ''))})")
                else:
                    app.logger.warning(f"     NO ATTACHMENTS in this ticket!")
                
        except Exception as processing_error:
            app.logger.error(f"Error in enhanced_process_complex_email_data: {processing_error}")
            return jsonify({
                'status': 'error',
                'message': f'Error processing email data: {str(processing_error)}',
                'data_received': data
            }), 500
        
        if not processed_tickets:
            return jsonify({
                'status': 'error',
                'message': 'No valid ticket data found in request',
                'data_received': data,
                'debug_info': 'enhanced_process_complex_email_data returned empty list'
            }), 400
        
        db = get_db()
        created_tickets = []
        
        for ticket in processed_tickets:
            try:
                # [FIX] Use n8n provided ticket_id if available, otherwise generate one
                n8n_ticket_id = ticket.get('ticket_id', '').strip()
                
                if n8n_ticket_id:
                    # Use n8n ticket ID EXACTLY as provided (no formatting, no prefixes)
                    if not db.ticket_id_exists(n8n_ticket_id):
                        # Use n8n ticket ID exactly as-is
                        ticket_id = n8n_ticket_id
                        app.logger.info(f"[N8N_TICKET_ID] Using n8n ticket ID exactly as provided: {ticket_id}")
                    else:
                        app.logger.warning(f"[N8N_TICKET_ID] N8N ticket ID {n8n_ticket_id} already exists, using generated ID")
                        # Fall through to generate new ID
                        ticket_id = None
                if not ticket_id:
                    # Generate unique ticket ID with collision protection as fallback
                    max_attempts = 20
                    ticket_id = None
                    
                    for attempt in range(max_attempts):
                        # Generate unique ticket ID
                        timestamp = datetime.now()
                        potential_id = f"N8N{timestamp.strftime('%H%M%S')}{random.randint(1000, 9999)}"
                        
                        # Check if ID already exists
                        if not db.ticket_id_exists(potential_id):
                            ticket_id = potential_id
                            break
                        app.logger.debug(f"Ticket ID collision {potential_id}, retrying...")
                    
                    if n8n_ticket_id:
                        app.logger.warning(f"[N8N_TICKET_ID] N8N ticket ID {n8n_ticket_id} already exists, using generated ID: {ticket_id}")
                    else:
                        app.logger.info(f"[N8N_TICKET_ID] No n8n ticket ID provided, using generated ID: {ticket_id}")
                    
                    if not ticket_id:
                        app.logger.error(f"Failed to generate unique ticket ID after {max_attempts} attempts")
                        continue
                
                # Prepare ticket data for database (matching database schema)
                # Fix total_attachments calculation issue - always use actual attachment count
                total_attachments = ticket.get('total_attachments')
                attachments_array = ticket.get('attachments', [])
                
                # Always recalculate from actual attachments to fix inconsistency
                if attachments_array:
                    total_attachments = len(attachments_array)
                    app.logger.info(f"[FIX] Recalculated total_attachments from {ticket.get('total_attachments')} to {total_attachments}")
                elif total_attachments is None:
                    total_attachments = 0
                
                # Debug logging
                app.logger.info(f"[INFO] Ticket {ticket_id} - has_attachments: {ticket.get('has_attachments')}, total_attachments: {total_attachments}, attachments array length: {len(attachments_array)}")
                
                # Generate unique thread_id to avoid conflicts (never use incoming threadI data)
                thread_id = f"THREAD_{ticket_id}_{timestamp.strftime('%Y%m%d_%H%M%S')}_{random.randint(100, 999)}"
                
                # AUTO-CONFIRM WARRANTY: If warranty detected in email, set status directly to "Warranty Form Received"
                has_warranty = ticket.get('has_warranty', False)
                auto_confirmed_status = 'Warranty Form Received' if has_warranty else 'New'
                
                if has_warranty:
                    app.logger.info(f"ðŸŽ¯ AUTO-CONFIRMED WARRANTY: Ticket {ticket_id} status set to '{auto_confirmed_status}' (no manual confirmation needed)")
                else:
                    app.logger.info(f"â„¹ NO WARRANTY DETECTED: Ticket {ticket_id} status set to '{auto_confirmed_status}'")
                
                ticket_data = {
                    'ticket_id': ticket_id,
                    'thread_id': thread_id,  # Add unique thread_id
                    'name': ticket.get('name', 'Unknown'),
                    'email': ticket.get('from', ''),
                    'subject': ticket.get('subject', 'No Subject'),
                    'body': ticket.get('body', ''),
                    'status': auto_confirmed_status,  # Auto-confirm warranty, no manual confirmation needed
                    'priority': ticket.get('Priority', 'Medium'),
                    'classification': ticket.get('Classification', 'General'),
                    'is_important': False,
                    'has_unread_reply': False,
                    'has_warranty': has_warranty,
                    'has_attachments': total_attachments > 0,  # Fix: base this on actual attachment count
                    'warranty_forms_count': ticket.get('warranty_forms_count', 0) or 0,
                    'total_attachments': total_attachments or 0,
                    'attachment_total_size': ticket.get('attachment_total_size', 0) or 0,
                    'processing_method': 'n8n_email_processor'
                }
                
                # ðŸš€ FIX: Store N8N-provided draft in ticket data
                n8n_provided_draft = ticket.get('draft', '').strip()
                if n8n_provided_draft:
                    app.logger.info(f"ðŸ“ FOUND N8N PROVIDED DRAFT: {n8n_provided_draft[:200]}...")
                    ticket_data['draft'] = n8n_provided_draft
                    ticket_data['draft_body'] = n8n_provided_draft
                    ticket_data['n8n_draft'] = n8n_provided_draft
                    app.logger.info(f"ðŸ“ STORED N8N DRAFT in multiple fields for compatibility")
                else:
                    app.logger.info(f"ðŸ“ NO N8N DRAFT PROVIDED - will generate one")
                
                # Remove any conflicting threadI data from incoming ticket to avoid conflicts
                if 'threadI' in ticket:
                    app.logger.info(f"Removing incoming threadI data to avoid conflicts: {ticket['threadI']}")
                    ticket.pop('threadI', None)
                
                app.logger.info(f"Creating ticket {ticket_id} with thread_id {thread_id}")
                app.logger.info(f"Ticket data keys: {list(ticket_data.keys())}")
                app.logger.info(f"Total attachments: {ticket_data['total_attachments']}, Has attachments: {ticket_data['has_attachments']}")
                
                # ðŸš€ GENERATE DRAFT RESPONSE for email tickets (only if no N8N draft)
                if not n8n_provided_draft:
                    app.logger.info(f"ðŸ¤– GENERATING DRAFT for email ticket {ticket_id}")
                    app.logger.info(f"ðŸ” DEBUG: ticket_data['ticket_id'] = {ticket_data.get('ticket_id')} (should be formatted like EO980494)")
                    draft_response = generate_email_draft_response(ticket_data)
                    ticket_data['draft_body'] = draft_response
                    app.logger.info(f"ðŸ“ DRAFT GENERATED for ticket {ticket_id}: {draft_response[:200]}..." if len(draft_response) > 200 else f"ðŸ“ DRAFT GENERATED: {draft_response}")
                else:
                    app.logger.info(f"ðŸ“ USING N8N PROVIDED DRAFT - no need to generate new one")
                
                # Create ticket in database
                try:
                    created_id = db.create_ticket(ticket_data)
                    app.logger.info(f"[SUCCESS] Successfully created ticket {ticket_id} in database with ID: {created_id}")
                except ValueError as val_error:
                    app.logger.error(f"Validation error creating ticket {ticket_id}: {val_error}")
                    # Try with completely new ticket ID and thread ID
                    retry_timestamp = datetime.now()
                    retry_ticket_id = f"N8N{retry_timestamp.strftime('%H%M%S')}{random.randint(10000, 99999)}"
                    retry_thread_id = f"THREAD_{retry_ticket_id}_{retry_timestamp.strftime('%Y%m%d_%H%M%S')}"
                    
                    ticket_data['ticket_id'] = retry_ticket_id
                    ticket_data['thread_id'] = retry_thread_id
                    
                    try:
                        created_id = db.create_ticket(ticket_data)
                        ticket_id = retry_ticket_id  # Update ticket_id for later use
                        app.logger.info(f"Successfully created ticket {ticket_id} on retry with new thread_id")
                    except Exception as retry_error:
                        app.logger.error(f"Failed to create ticket even on retry: {retry_error}")
                        # Last resort: create without thread_id
                        ticket_data_no_thread = ticket_data.copy()
                        ticket_data_no_thread.pop('thread_id', None)
                        try:
                            created_id = db.create_ticket(ticket_data_no_thread)
                            app.logger.info(f"Successfully created ticket {ticket_id} without thread_id")
                        except Exception as final_error:
                            app.logger.error(f"Final attempt failed: {final_error}")
                            raise final_error
                except Exception as db_error:
                    app.logger.error(f"Database error creating ticket {ticket_id}: {db_error}")
                    app.logger.error(f"Ticket data causing error: {ticket_data}")
                    import traceback
                    app.logger.error(f"Full traceback: {traceback.format_exc()}")
                    raise db_error
                
                # Process and SAVE attachments to disk for proper download
                total_ticket_attachments = ticket.get('attachments', [])
                app.logger.info(f"FOLDER PROCESSING {len(total_ticket_attachments)} ATTACHMENTS for ticket {ticket_id}")
                
                if total_ticket_attachments:
                    for i, attachment in enumerate(total_ticket_attachments):
                        try:
                            filename = attachment.get('filename', f'attachment_{i}')
                            file_data = attachment.get('data', '')
                            is_warranty = attachment.get('is_warranty', False)
                            
                            app.logger.info(f"ðŸ’¾ PROCESSING ATTACHMENT {i+1}/{len(total_ticket_attachments)}: {filename} (warranty: {is_warranty})")
                            
                            # SAVE FILE TO DISK for download functionality
                            file_path = None
                            if file_data:
                                try:
                                    # Decode base64 and save to uploads directory
                                    decoded_data = base64.b64decode(file_data)
                                    safe_filename = secure_filename(filename)
                                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                    unique_filename = f"{timestamp}_{ticket_id}_{safe_filename}"
                                    
                                    file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                                    with open(file_path, 'wb') as f:
                                        f.write(decoded_data)
                                    
                                    app.logger.info(f" SAVED ATTACHMENT to disk: {file_path} ({len(decoded_data)} bytes)")
                                    
                                except Exception as save_error:
                                    app.logger.error(f" Failed to save attachment {filename}: {save_error}")
                                    file_path = None
                            else:
                                app.logger.warning(f" NO FILE DATA for attachment {filename}")
                            
                            # Store both metadata AND file path for download
                            attachment_metadata = {
                                'key': f'attachment_{i}',
                                'filename': filename,
                                'file_path': file_path,  # ADD: Path to saved file
                                'data': file_data,       # Keep base64 data as backup
                                'is_warranty': attachment.get('is_warranty', False),
                                'size': attachment.get('size', 0),
                                'file_type': attachment.get('file_type', 'unknown'),
                                'saved_to_disk': bool(file_path)  # Track if file was saved
                            }
                            db.add_ticket_metadata(ticket_id, f'attachment_{i}', json.dumps(attachment_metadata))
                            app.logger.info(f"COMPLETE: Saved attachment {filename} - disk:{bool(file_path)} metadata:âœ“")
                            
                        except Exception as att_error:
                            app.logger.error(f"Error processing attachment {i}: {att_error}")
                
                created_tickets.append({
                    'ticket_id': ticket_id,
                    'has_attachments': total_attachments > 0,  # Fix: use calculated value
                    'has_warranty': ticket.get('has_warranty', False),
                    'total_attachments': total_attachments,  # Fix: use calculated value
                    'warranty_forms_count': ticket.get('warranty_forms_count', 0),
                    'priority': ticket.get('Priority', 'Medium')
                })
                
                app.logger.info(f"Successfully processed ticket {ticket_id} with {total_attachments} attachments")
                
            except Exception as e:
                app.logger.error(f"Error creating ticket: {e}")
                continue
        
        if not created_tickets:
            # Enhanced error reporting
            error_details = []
            for i, ticket in enumerate(processed_tickets):
                error_details.append({
                    'ticket_index': i,
                    'ticket_data': {
                        'has_attachments': ticket.get('has_attachments'),
                        'total_attachments': ticket.get('total_attachments'),
                        'has_warranty': ticket.get('has_warranty'),
                        'subject': ticket.get('subject'),
                        'from': ticket.get('from')
                    }
                })
            
            return jsonify({
                'status': 'error',
                'message': 'Failed to create any tickets',
                'processed_data': processed_tickets,
                'error_details': error_details,
                'debug_info': f'Processed {len(processed_tickets)} ticket(s) but none were created successfully'
            }), 500
        
        return jsonify({
            'status': 'success',
            'message': f'Successfully created {len(created_tickets)} email ticket(s) with enhanced processing',
            'count': len(created_tickets),
            'tickets': created_tickets,
            'total_attachments': sum(t.get('total_attachments', 0) for t in created_tickets),
            'warranty_forms_detected': sum(t.get('warranty_forms_count', 0) for t in created_tickets)
        })
        
    except Exception as e:
        app.logger.error(f"N8N Email Tickets endpoint error: {e}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Server error: {str(e)}'
        }), 500

@app.route('/api/n8n/simple-test', methods=['POST'])
def n8n_simple_test():
    """
    Simple test endpoint to verify database connectivity and basic ticket creation
    """
    try:
        data = request.json
        app.logger.info(f"Simple test endpoint received: {data}")
        
        db = get_db()
        
        # Create a simple test ticket
        test_ticket_data = {
            'ticket_id': f"TEST{random.randint(100000, 999999)}",
            'name': 'Test User',
            'email': 'test@example.com',
            'subject': 'Test Ticket',
            'body': 'This is a test ticket',
            'status': 'New',
            'priority': 'Medium',
            'classification': 'General',
            'is_important': False,
            'has_unread_reply': False,
            'has_warranty': False,
            'has_attachments': False,
            'warranty_forms_count': 0,
            'total_attachments': 0,
            'attachment_total_size': 0,
            'processing_method': 'test_processor'
        }
        
        app.logger.info(f"Creating test ticket: {test_ticket_data}")
        created_id = db.create_ticket(test_ticket_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Test ticket created successfully',
            'ticket_id': test_ticket_data['ticket_id'],
            'created_id': str(created_id),
            'data_received': data
        })
        
    except Exception as e:
        app.logger.error(f"Simple test error: {e}")
        import traceback
        app.logger.error(f"Test traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Test failed: {str(e)}',
            'data_received': data
        }), 500

@app.route('/api/warranty-form-submission', methods=['POST'])
def warranty_form_submission():
    """Create a ticket automatically from a warranty form submission"""
    db = None
    try:
        # Get JSON data from request
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400
        
        # Extract required fields
        name = data.get('customer_name')
        email = data.get('customer_email')
        phone = data.get('customer_phone', '')
        registration = data.get('vehicle_registration', '')
        warranty_details = data.get('warranty_details', '')
        
        # Validate required fields
        if not all([name, email]):
            return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400
        
        # Create subject and body from warranty details
        subject = f"Warranty Claim - {registration}"
        body = warranty_details
        
        # Connect to database first
        db = get_db()
        
        # Create unique warranty ticket ID with race condition protection
        max_attempts = 50
        ticket_id = None
        # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
        thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
        
        for attempt in range(max_attempts):
            potential_id = f"W{str(uuid.uuid4())[:5].upper()}"
            
            try:
                # Try to create ticket with this ID - will fail if duplicate
                ticket_data = {
                    'ticket_id': potential_id,
                    'email': email,
                    'name': name,
                    'phone': phone,
                    'subject': subject,
                    'body': body,
                    'classification': 'Warranty Claim',
                    'priority': 'Medium',
                    'status': 'Open',
                    'thread_id': thread_id,
                    'creation_method': 'email'
                }
                
                # ðŸš€ GENERATE DRAFT RESPONSE for warranty email tickets  
                app.logger.info(f"ðŸ¤– GENERATING DRAFT for warranty email ticket {potential_id}")
                draft_response = generate_email_draft_response(ticket_data)
                ticket_data['draft_body'] = draft_response
                app.logger.info(f" DRAFT GENERATED for warranty ticket {potential_id} - Length: {len(draft_response)} chars")
                
                # This will throw ValueError if ticket ID already exists (race condition safe)
                db.create_ticket(ticket_data)
                ticket_id = potential_id
                app.logger.info(f"Successfully created warranty ticket with ID: {ticket_id} on attempt {attempt + 1}")
                break
                
            except ValueError as e:
                if "Ticket ID already exists" in str(e):
                    app.logger.debug(f"Warranty ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                    continue  # Try next ID
                else:
                    # Different error, re-raise
                    raise e
        
        if not ticket_id:
            return jsonify({'status': 'error', 'message': 'Failed to generate unique ticket ID. Please try again.'}), 500
        
        # Store vehicle registration
        if registration:
            db.add_ticket_metadata(ticket_id, 'vehicle_registration', registration)
        
        # Store any additional form fields as metadata
        for key, value in data.items():
            if key not in ['customer_name', 'customer_email', 'customer_phone', 'vehicle_registration', 'warranty_details']:
                db.add_ticket_metadata(ticket_id, key, str(value))
        
        # Create a reply indicating this was an automatic submission
        reply_data = {
            'ticket_id': ticket_id,
            'thread_id': thread_id,
            'message': "This ticket was created automatically from an online warranty form submission.",
            'sender': 'system'
        }
        db.create_reply(reply_data)
        
        return jsonify({
            'status': 'success',
            'message': f'Warranty claim created successfully! Your Customer Number is: {ticket_id}',
            'ticket_id': ticket_id,
            'customer_number': ticket_id,
            'reference_message': f'Please save Customer Number {ticket_id} for tracking your warranty claim.'
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


# Initialize database connection on startup (with error handling)
# Note: Skip database initialization in serverless to avoid import issues
if os.environ.get('FLASK_ENV') != 'production':
    try:
        # Test database connection early to catch configuration issues
        if os.environ.get('MONGODB_URI'):
            db_test = get_db()
            app.logger.info("Database connection established successfully")
            
            # [FIX] Run consistency check on startup in development
            try:
                fixed_count = fix_ticket_status_consistency()
                if fixed_count > 0:
                    app.logger.info(f"[FIX] STARTUP CONSISTENCY CHECK - Fixed {fixed_count} tickets")
                else:
                    app.logger.info("[SUCCESS] STARTUP CONSISTENCY CHECK - No issues found")
            except Exception as consistency_error:
                app.logger.warning(f"Startup consistency check failed: {consistency_error}")
        else:
            app.logger.warning("MONGODB_URI not set - database features will not work")
    except Exception as e:
        app.logger.error(f"Database initialization failed: {e}")
        # Continue running to allow health checks and debugging
else:
    app.logger.info("Production mode - database will be initialized on first request")

def cleanup():
    """Cleanup function for application exit"""
    # Application shutting down
    pass

atexit.register(cleanup)

# Add a health check route for debugging
@app.route('/health')
def health_check():
    """Health check endpoint for debugging serverless deployment"""
    try:
        # Test database connection
        db = get_db()
        db.client.admin.command('ping')
        
        return jsonify({
            'status': 'ok',
            'message': 'Application is running',
            'environment': os.environ.get('FLASK_ENV', 'development'),
            'database': 'connected',
            'upload_folder': UPLOAD_FOLDER,
            'version': 'v2.0-comprehensive-assignment',  # Added version tag
            'last_updated': '2025-07-26'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e),
            'environment': os.environ.get('FLASK_ENV', 'development'),
            'database': 'disconnected'
        }), 500

# Enhanced session heartbeat endpoint to prevent timeouts
@app.route('/api/session/heartbeat', methods=['POST'])
def session_heartbeat():
    """Enhanced session heartbeat with better error handling and session validation"""
    try:
        if 'member_id' not in session:
            app.logger.warning("Session heartbeat failed - no member_id in session")
            return jsonify({'status': 'error', 'message': 'No active session'}), 401
        
        # Validate session data integrity
        member_id = session.get('member_id')
        member_name = session.get('member_name')
        member_role = session.get('member_role')
        
        if not all([member_id, member_name, member_role]):
            app.logger.warning(f"Session heartbeat failed - incomplete session data for user {member_id}")
            session.clear()
            return jsonify({'status': 'error', 'message': 'Invalid session data'}), 401
        
        # Refresh session with enhanced error handling
        if refresh_session():
            app.logger.debug(f"Session heartbeat successful for user {member_id}")
            return jsonify({
                'status': 'success', 
                'message': 'Session refreshed',
                'user_id': member_id,
                'user_name': member_name,
                'user_role': member_role,
                'session_lifetime': app.permanent_session_lifetime.total_seconds()
            })
        else:
            app.logger.error(f"Session heartbeat failed - refresh_session returned False for user {member_id}")
            return jsonify({'status': 'error', 'message': 'Failed to refresh session'}), 500
            
    except Exception as e:
        app.logger.error(f"Session heartbeat error: {e}")
        # Clear corrupted session
        session.clear()
        return jsonify({'status': 'error', 'message': 'Session error occurred'}), 500

# Session refresh endpoint
@app.route('/api/session/refresh', methods=['POST'])
def session_refresh():
    """Proactively refresh the current session to prevent timeouts"""
    try:
        if 'member_id' not in session:
            app.logger.warning("Session refresh failed - no member_id in session")
            return jsonify({'status': 'error', 'message': 'No active session'}), 401
        
        # Validate session data integrity
        member_id = session.get('member_id')
        member_name = session.get('member_name')
        member_role = session.get('member_role')
        
        if not all([member_id, member_name, member_role]):
            app.logger.warning(f"Session refresh failed - incomplete session data for user {member_id}")
            session.clear()
            return jsonify({'status': 'error', 'message': 'Invalid session data'}), 401
        
        # Refresh session
        if refresh_session():
            app.logger.info(f"Session refreshed successfully for user {member_id}")
            return jsonify({
                'status': 'success', 
                'message': 'Session refreshed successfully',
                'user_id': member_id,
                'user_name': member_name,
                'user_role': member_role,
                'session_lifetime': app.permanent_session_lifetime.total_seconds()
            })
        else:
            app.logger.error(f"Session refresh failed for user {member_id}")
            return jsonify({'status': 'error', 'message': 'Failed to refresh session'}), 500
            
    except Exception as e:
        app.logger.error(f"Session refresh error: {e}")
        # Clear corrupted session
        session.clear()
        return jsonify({'status': 'error', 'message': 'Session error occurred'}), 500

# Session status check endpoint
@app.route('/api/session/status', methods=['GET'])
def session_status():
    """Check current session status and health with enhanced information"""
    try:
        # Debug: Log all session data
        app.logger.info(f"Session status check - Session keys: {list(session.keys())}")
        app.logger.info(f"Session data: {dict(session)}")
        
        if 'member_id' not in session:
            return jsonify({
                'status': 'error',
                'message': 'No active session',
                'authenticated': False,
                'session_keys': list(session.keys()),
                'debug_info': 'Session restoration may be needed'
            }), 401
        
        # Get session info
        member_id = session.get('member_id')
        member_name = session.get('member_name')
        member_role = session.get('member_role')
        last_activity = session.get('last_activity')
        
        # Calculate session age
        session_age = 0
        if last_activity:
            try:
                last_activity_dt = datetime.fromisoformat(last_activity)
                session_age = (datetime.now() - last_activity_dt).total_seconds()
            except:
                session_age = 0
        
        # Calculate remaining time
        max_lifetime = app.permanent_session_lifetime.total_seconds()
        remaining_time = max(0, max_lifetime - session_age)
        
        # Enhanced session health calculation
        hours_remaining = remaining_time / 3600
        if hours_remaining > 12:
            health = 'excellent'
        elif hours_remaining > 6:
            health = 'good'
        elif hours_remaining > 2:
            health = 'warning'
        elif hours_remaining > 0.5:  # 30 minutes
            health = 'critical'
        else:
            health = 'expired'
        
        # Activity-based session extension info
        activity_extension = False
        if session_age < 21600:  # 6 hours
            activity_extension = True
        
        return jsonify({
            'status': 'success',
            'authenticated': True,
            'user_id': member_id,
            'user_name': member_name,
            'user_role': member_role,
            'session_age_seconds': session_age,
            'remaining_time_seconds': remaining_time,
            'max_lifetime_seconds': max_lifetime,
            'hours_remaining': round(hours_remaining, 2),
            'session_health': health,
            'activity_extension_active': activity_extension,
            'session_lifetime_hours': 24,
            'auto_extend_threshold_hours': 6
        })
        
    except Exception as e:
        app.logger.error(f"Session status check error: {e}")
        return jsonify({
            'status': 'error',
            'message': 'Error checking session status',
            'authenticated': False
        }), 500

# Session test endpoint for debugging
@app.route('/api/session/test', methods=['GET'])
def session_test():
    """Simple session test endpoint for debugging session issues"""
    try:
        app.logger.info(f"Session test endpoint called - Session keys: {list(session.keys())}")
        app.logger.info(f"Session data: {dict(session)}")
        app.logger.info(f"Request endpoint: {request.endpoint}")
        app.logger.info(f"Request path: {request.path}")
        
        # Check session health
        session_health = {
            'has_member_id': 'member_id' in session,
            'is_permanent': session.permanent,
            'refresh_count': session.get('_refresh_count', 0),
            'restore_count': session.get('_restore_count', 0),
            'request_count': session.get('_request_count', 0),
            'last_refresh': session.get('_last_refresh'),
            'last_restored': session.get('_last_restored'),
            'last_request': session.get('_last_request')
        }
        
        return jsonify({
            'status': 'success',
            'message': 'Session test completed',
            'session_keys': list(session.keys()),
            'session_data': dict(session),
            'session_health': session_health,
            'request_endpoint': request.endpoint,
            'request_path': request.path,
            'debug_info': 'Check logs for detailed session information'
        })
        
    except Exception as e:
        app.logger.error(f"Session test error: {e}")
        return jsonify({
            'status': 'error',
            'message': f'Session test failed: {str(e)}',
            'debug_info': 'Check server logs for details'
        }), 500

# Session extension endpoint
@app.route('/api/session/extend', methods=['POST'])
def extend_session():
    """Extend user session by refreshing activity timestamp"""
    try:
        if 'member_id' not in session:
            return jsonify({
                'status': 'error',
                'message': 'No active session'
            }), 401
        
        # Refresh session
        if refresh_session():
            member_id = session.get('member_id')
            member_name = session.get('member_name')
            
            app.logger.info(f"Session extended for user {member_name} ({member_id})")
            
            return jsonify({
                'status': 'success',
                'message': 'Session extended successfully',
                'user_id': member_id,
                'user_name': member_name,
                'extended_at': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'Failed to extend session'
            }), 500
            
    except Exception as e:
        app.logger.error(f"Session extension error: {e}")
        return jsonify({
            'status': 'error',
            'message': 'Error extending session'
        }), 500



# Add a simple test route
@app.route('/test')
def test_route():
    """Simple test route"""
    return jsonify({
        'message': 'Flask app is working!',
        'environment': os.environ.get('FLASK_ENV', 'development')
    })

@app.route('/test', methods=['POST'])
def add_test_data():
    """Add sample test data"""
    try:
        # Create a sample PDF content (minimal PDF)
        sample_pdf_base64 = "JVBERi0xLjQKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUgo+PgplbmRvYmoKMiAwIG9iago8PAovQmFzZUZ4Kc3RhcnR4cmVmCjIyNDcKJSVFT0YK"
        
        # Sample ticket data
        sample_tickets = [
            {
                'id': str(uuid.uuid4())[:8],
                'threadId': 'sample-thread-123',
                'name': 'John Doe',
                'email': 'john.doe@example.com',
                'subject': 'Sample Ticket - System Issue',
                'body': 'I am experiencing issues with the dashboard loading slowly. Could you please help?',
                'draft': 'Dear John Doe,\n\nThank you for contacting us regarding the dashboard performance issue. We are looking into this matter and will provide an update soon.\n\nBest regards,\nSupport Team',
                'classification': 'Technical Support',
                'priority': 'High',
                'date': datetime.now().isoformat(),
                'messageId': 'msg-sample-123',
                'attachments': [{
                    'fileName': 'sample_report.pdf',
                    'fileData': sample_pdf_base64,
                    'id': str(uuid.uuid4())
                }],
                'created_at': datetime.now().isoformat()
            },
            {
                'id': str(uuid.uuid4())[:8],
                'threadId': 'sample-thread-456',
                'name': 'Jane Smith',
                'email': 'jane.smith@company.com',
                'subject': 'Billing Inquiry',
                'body': 'I have a question about my recent invoice. The amount seems incorrect.',
                'draft': 'Dear Jane Smith,\n\nThank you for your billing inquiry. We will review your account and get back to you within 24 hours with a detailed explanation.\n\nBest regards,\nBilling Department',
                'classification': 'Billing',
                'priority': 'Medium',
                'date': datetime.now().isoformat(),
                'messageId': 'msg-sample-456',
                'attachments': [],
                'created_at': datetime.now().isoformat()
            }
        ]
        
        # Add to database
        db = get_db()
        created_count = 0
        
        for ticket in sample_tickets:
            try:
                # Convert to database format
                ticket_data = {
                    'ticket_id': ticket['id'],
                    'threadId': ticket['threadId'],
                    'from': ticket['email'],
                    'name': ticket['name'],
                    'subject': ticket['subject'],
                    'body': ticket['body'],
                    'draft': ticket['draft'],
                    'classification': ticket['classification'],
                    'priority': ticket['priority'],
                    'date': ticket['date'],
                    'messageid': ticket['messageId'],
                    'attachments': [att['fileData'] for att in ticket['attachments']],
                    'attachment_names': [att['fileName'] for att in ticket['attachments']],
                    'has_attachment': len(ticket['attachments']) > 0
                }
                
                created_id = db.create_ticket(ticket_data)
                if created_id:
                    created_count += 1
                    # Add attachment metadata if present
                    if ticket_data['has_attachment']:
                        for i, attachment in enumerate(ticket['attachments']):
                            attachment_metadata = {
                                'filename': attachment['fileName'],
                                'data': attachment['fileData'],
                                'type': 'email_attachment',
                                'id': attachment['id']
                            }
                            db.add_ticket_metadata(ticket_data['ticket_id'], f'attachment_{i}', json.dumps(attachment_metadata))
                            
            except Exception as e:
                app.logger.error(f"Error creating ticket: {str(e)}")
        
        return jsonify({
            'success': True,
            'message': f'Added {created_count} test tickets to database',
            'tickets_added': created_count
        }), 200
        
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error adding test data: {str(e)}'
        }), 500

@app.route('/api/attachment/<attachment_id>')
def get_attachment(attachment_id):
    """Serve attachment file"""
    try:
        # Find attachment in all tickets
        attachment = None
        for ticket in tickets_storage:
            for att in ticket['attachments']:
                if att['id'] == attachment_id:
                    attachment = att
                    break
            if attachment:
                break
        
        if not attachment:
            return jsonify({'error': 'Attachment not found'}), 404
        
        # Decode base64 data
        file_data = base64.b64decode(attachment['fileData'])
        
        # Create a BytesIO object
        file_stream = io.BytesIO(file_data)
        
        # Guess MIME type
        mime_type, _ = mimetypes.guess_type(attachment['fileName'])
        if not mime_type:
            mime_type = 'application/octet-stream'
        
        return send_file(
            file_stream,
            mimetype=mime_type
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/add-real-data', methods=['POST'])
def add_real_data():
    """Add the real JSON data from your n8n workflow"""
    try:
        # Your real JSON data
        real_data = [
            {
                "complete": "{\"result\":false,\"fileName\":\"warranty_dashboard_report_20250726_112229.pdf\",\"fileData\":\"JVBERi0xLjQKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUgo+PgplbmRvYmoKMiAwIG9iago8PAovQmFzZUZ4Kc3RhcnR4cmVmCjIyNDcKJSVFT0YK\"}"
            },
            {
                "complete": "{\"threadId\":\"AQQkADAwATM3ZmYBLTljMmQtMmQ5ZS0wMAItMDAKABAA62jpB7tOGUO0IrhdiiKqQg==\",\"name\":\"muhammad zeeshan liaqat\",\"body\":\"The mails\",\"Classification\":\"Others\",\"Priority\":\"Low\",\"ticket_id\":\"706393\",\"from\":\"fa22-bse-061@outlook.com\",\"date\":\"2025-08-07T20:52:53Z\",\"draft\":\"Dear muhammad zeeshan liaqat,\\n\\nThank you for your message regarding the test emails. We have noted your communication and will keep it on record.\\n\\nIf you have any specific inquiries or need further assistance, please feel free to reach out.\\n\\n(Ticket ID: 706393)\\n\\nSincerely,\\nCustomer Services\",\"messageid\":\"AQMkADAwATM3AAAADdI5CgAAAA==\",\"\":\"\"}"
            }
        ]
        
        # Parse the JSON data
        attachments = []
        ticket_info = None
        
        for item in real_data:
            if 'complete' in item:
                # Clean JSON before parsing
                clean_json = item['complete'].strip()
                if clean_json.endswith(',}'):
                    clean_json = clean_json[:-2] + '}'
                elif clean_json.endswith(',]'):
                    clean_json = clean_json[:-2] + ']'
                parsed_data = json.loads(clean_json)
                
                # Check if this is attachment data
                if 'fileName' in parsed_data and 'fileData' in parsed_data:
                    attachments.append({
                        'fileName': parsed_data['fileName'],
                        'fileData': parsed_data['fileData'],
                        'id': str(uuid.uuid4())
                    })
                # Check if this is ticket info
                elif 'ticket_id' in parsed_data:
                    ticket_info = parsed_data
        
        if ticket_info:
            # Create complete ticket with attachment
            ticket = {
                'id': ticket_info['ticket_id'],
                'threadId': ticket_info.get('threadId', ''),
                'name': ticket_info.get('name', 'Unknown'),
                'email': ticket_info.get('from', 'unknown@example.com'),
                'subject': f"Ticket #{ticket_info['ticket_id']} - {ticket_info.get('body', 'No subject')}",
                'body': ticket_info.get('body', ''),
                'draft': ticket_info.get('draft', '').replace('\\n', '\n'),  # Fix newlines
                'classification': ticket_info.get('Classification', 'General'),
                'priority': ticket_info.get('Priority', 'Medium'),
                'date': ticket_info.get('date', datetime.now().isoformat()),
                'messageId': ticket_info.get('messageid', ''),
                'attachments': attachments,
                'created_at': datetime.now().isoformat()
            }
            
            # Add to database
            db = get_db()
            created_id = db.create_ticket(ticket)
            if created_id and attachments:
                # Add attachment metadata
                for i, attachment in enumerate(attachments):
                    db.add_ticket_metadata(ticket['id'], f'attachment_{i}', json.dumps(attachment))
            
            return jsonify({
                'success': True,
                'message': f'Added real ticket {ticket_info["ticket_id"]} with {len(attachments)} attachments',
                'ticket_id': ticket_info['ticket_id'],
                'attachments_count': len(attachments)
            }), 200
        else:
            return jsonify({
                'success': False,
                'message': 'No valid ticket information found in data'
            }), 400
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error adding real data: {str(e)}'
        }), 500

@app.route('/api/test/action-buttons', methods=['GET', 'POST'])
def test_action_buttons():
    """Test endpoint for action button functionality"""
    return jsonify({
        'status': 'success',
        'message': 'Action buttons backend is working!',
        'session_valid': 'member_id' in session,
        'member_id': session.get('member_id', 'None'),
        'member_name': session.get('member_name', 'None'),
        'timestamp': datetime.now().isoformat(),
        'available_endpoints': [
            '/api/tickets/{ticket_id}/assign',
            '/api/tickets/{ticket_id}/tech-director',
            '/api/tickets/{ticket_id}/close'
        ]
    })

# ===============================
# ADVANCED N8N INTEGRATION ENDPOINTS
# ===============================

@app.route('/api/n8n/quick', methods=['POST'])
def n8n_quick_response():
    """
    Quick response endpoint for n8n - responds immediately to prevent timeouts
    Processes data in background to avoid hanging n8n workflows
    """
    try:
        # Send immediate response to prevent n8n timeout
        response_data = {
            'success': True,
            'message': 'Data received and queued for processing',
            'timestamp': datetime.now().isoformat(),
            'status': 'accepted'
        }
        
        # Get data quickly
        raw_data = request.get_data()
        
        # Create immediate response
        response = jsonify(response_data)
        response.headers['Content-Type'] = 'application/json'
        response.headers['Access-Control-Allow-Origin'] = '*'
        
        # Background processing after sending response
        try:
            if raw_data:
                if request.is_json:
                    data = request.get_json(force=True)
                else:
                    data = json.loads(raw_data.decode('utf-8'))
                
                # Process with enhanced sophisticated parsing
                processed_tickets = enhanced_process_complex_email_data(data)
                
                if processed_tickets:
                    db = get_db()
                    
                    for ticket_data in processed_tickets:
                        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
                        n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
                        
                        if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                            # Use n8n provided ticket ID if it doesn't exist in database
                            ticket_id = n8n_ticket_id
                            app.logger.info(f"[N8N_QUICK] Using n8n provided ticket ID: {ticket_id}")
                            
                            # Prepare ticket data
                            ticket = {
                                'ticket_id': ticket_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                # Add to database
                                db.create_ticket(ticket)
                                app.logger.info(f"N8N quick processing created ticket {ticket_id} using n8n ID, warranty: {ticket.get('has_warranty')}")
                            except ValueError as e:
                                app.logger.error(f"Failed to create ticket with n8n ID {ticket_id}: {e}")
                        else:
                            # Create ticket in database with warranty detection and collision protection  
                            timestamp = datetime.now()
                            base_ticket_id = f"N8NQ{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                            
                            # Collision-resistant ticket creation (similar to warranty tickets)
                            max_attempts = 10
                            ticket_id = None
                            
                            if n8n_ticket_id:
                                app.logger.warning(f"[N8N_QUICK] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                            else:
                                app.logger.info(f"[N8N_QUICK] No n8n ticket ID provided, generating new ID")
                            
                            for attempt in range(max_attempts):
                                # Generate unique ID with attempt suffix if needed
                                potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                                
                                # Prepare ticket data
                                ticket = {
                                    'ticket_id': potential_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                # Add to database - will throw ValueError if ID exists
                                db.create_ticket(ticket)
                                ticket_id = potential_id
                                app.logger.info(f"N8N quick processing created ticket {ticket_id} (attempt {attempt + 1}), warranty: {ticket.get('has_warranty')}")
                                break
                                
                            except ValueError as e:
                                if "Ticket ID already exists" in str(e):
                                    app.logger.debug(f"N8N ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                                    continue  # Try next ID
                                else:
                                    raise e  # Re-raise unexpected errors
                        
        except Exception as bg_error:
            app.logger.error(f"Background processing error (non-critical): {bg_error}")
        
        return response
        
    except Exception as e:
        app.logger.error(f"Quick endpoint error: {str(e)}")
        # Still return immediate response even on error to prevent hanging
        return jsonify({
            'success': False,
            'message': 'Error occurred but request acknowledged',
            'timestamp': datetime.now().isoformat(),
            'status': 'error_acknowledged'
        })

@app.route('/api/n8n/minimal', methods=['POST'])
def n8n_minimal_response():
    """
    Minimal acknowledgment endpoint - ultra-fast response for slow n8n scenarios
    Returns acknowledgment immediately, processes data separately
    """
    try:
        # Ultra-fast acknowledgment
        timestamp = datetime.now().isoformat()
        
        # Store raw data for background processing
        raw_data = request.get_data()
        
        # Process data if available (but don't wait for completion)
        if raw_data:
            try:
                if request.is_json:
                    data = request.get_json(force=True)
                else:
                    data = json.loads(raw_data.decode('utf-8'))
                
                # Quick background processing with enhanced sophisticated parsing
                processed_tickets = enhanced_process_complex_email_data(data)
                
                if processed_tickets:
                    db = get_db()
                    
                    for ticket_data in processed_tickets:
                        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
                        n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
                        
                        if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                            # Use n8n provided ticket ID if it doesn't exist in database
                            ticket_id = n8n_ticket_id
                            app.logger.info(f"[N8N_MINIMAL] Using n8n provided ticket ID: {ticket_id}")
                            
                            ticket = {
                                'ticket_id': ticket_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                # Add to database
                                db.create_ticket(ticket)
                                app.logger.info(f"N8N minimal processing created ticket {ticket_id} using n8n ID, warranty: {ticket.get('has_warranty')}")
                            except ValueError as e:
                                app.logger.error(f"Failed to create ticket with n8n ID {ticket_id}: {e}")
                        else:
                            # Create ticket with collision protection as fallback
                            timestamp = datetime.now()
                            base_ticket_id = f"N8NM{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                            
                            # Collision-resistant ticket creation
                            max_attempts = 10
                            ticket_id = None
                            
                            if n8n_ticket_id:
                                app.logger.warning(f"[N8N_MINIMAL] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                            else:
                                app.logger.info(f"[N8N_MINIMAL] No n8n ticket ID provided, generating new ID")
                            
                            for attempt in range(max_attempts):
                                # Generate unique ID with attempt suffix if needed
                                potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                                
                                ticket = {
                                    'ticket_id': potential_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                db.create_ticket(ticket)
                                ticket_id = potential_id
                                app.logger.info(f"N8N minimal processing created ticket {ticket_id} (attempt {attempt + 1})")
                                break
                                
                            except ValueError as e:
                                if "Ticket ID already exists" in str(e):
                                    app.logger.debug(f"N8N minimal ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                                    continue  # Try next ID
                                else:
                                    raise e  # Re-raise unexpected errors
                        
            except Exception as process_error:
                app.logger.error(f"Minimal endpoint processing error: {process_error}")
        
        # Return minimal response immediately
        return jsonify({'ok': True, 'timestamp': timestamp})
        
    except Exception as e:
        app.logger.error(f"Minimal endpoint error: {str(e)}")
        return jsonify({'ok': False, 'error': str(e), 'timestamp': datetime.now().isoformat()})

@app.route('/api/n8n/status', methods=['GET'])
def n8n_processing_status():
    """
    Check processing status and system health for n8n integration monitoring
    """
    try:
        db = get_db()
        
        # Get recent tickets count
        recent_tickets = db.get_tickets_with_assignments()[:10] if hasattr(db, 'get_tickets_with_assignments') else []
        warranty_count = sum(1 for ticket in recent_tickets if ticket.get('has_warranty', False))
        
        return jsonify({
            'status': 'operational',
            'timestamp': datetime.now().isoformat(),
            'recent_tickets_count': len(recent_tickets),
            'warranty_forms_detected': warranty_count,
            'system_health': 'good',
            'endpoints': {
                'standard': '/api/tickets',
                'quick': '/api/n8n/quick', 
                'minimal': '/api/n8n/minimal'
            }
        })
        
    except Exception as e:
        app.logger.error(f"Status check error: {str(e)}")
        return jsonify({
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }), 500

@app.route('/api/email/process', methods=['POST'])
def process_email_integration():
    """
    Advanced email processing endpoint with sophisticated parsing and warranty detection
    Handles complex n8n data structures and automatically detects warranty forms
    """
    try:
        # Get raw email data
        raw_data = request.get_data()
        
        if request.is_json:
            data = request.get_json(force=True)
        else:
            data = json.loads(raw_data.decode('utf-8'))
        
        app.logger.info(f"Processing email integration data: {type(data)}")
        
        # Use sophisticated email parsing
        processed_tickets = process_complex_email_data(data)
        
        if not processed_tickets:
            return jsonify({
                'success': False,
                'message': 'No valid ticket data found',
                'count': 0
            }), 400
        
        db = get_db()
        created_tickets = []
        
        for ticket_data in processed_tickets:
            # [FIX] Use n8n provided ticket_id if available, otherwise generate one
            n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
            customer_email = ticket_data.get('from', '')
            customer_name = ticket_data.get('name', 'Unknown')
            
            if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                # Use n8n provided ticket ID if it doesn't exist in database
                ticket_id = n8n_ticket_id
                app.logger.info(f"[EMAIL_PROCESS] Using n8n provided ticket ID: {ticket_id}")
                
                # Prepare comprehensive ticket data
                ticket = {
                    'ticket_id': ticket_id,
                    'name': customer_name,
                    'email': customer_email,
                    'phone': '',
                    'vin': '',
                    'description': ticket_data.get('body', ''),
                    'priority': ticket_data.get('Priority', 'Medium'),
                    'classification': ticket_data.get('Classification', 'General'),
                    'date_created': datetime.now().isoformat(),
                    'status': 'Open',
                    'has_warranty': ticket_data.get('has_warranty', False),
                    'has_attachments': ticket_data.get('has_attachments', False),
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                    'message_id': ticket_data.get('messageid', ''),
                    'draft_body': ticket_data.get('draft', '')
                }
                
                try:
                    # Add to database
                    db.create_ticket(ticket)
                    app.logger.info(f"Email processing created ticket {ticket_id} using n8n ID")
                except ValueError as e:
                    app.logger.error(f"Failed to create ticket with n8n ID {ticket_id}: {e}")
                    continue
            else:
                # Generate ticket ID with collision protection as fallback
                timestamp = datetime.now()
                base_ticket_id = f"EMAPI{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                
                # Collision-resistant ticket creation
                max_attempts = 10
                ticket_id = None
                
                if n8n_ticket_id:
                    app.logger.warning(f"[EMAIL_PROCESS] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                else:
                    app.logger.info(f"[EMAIL_PROCESS] No n8n ticket ID provided, generating new ID")
                
                for attempt in range(max_attempts):
                    # Generate unique ID with attempt suffix if needed
                    potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                    
                    # Prepare comprehensive ticket data
                    ticket = {
                        'ticket_id': potential_id,
                    'name': customer_name,
                    'email': customer_email,
                    'phone': '',
                    'vin': '',
                    'description': ticket_data.get('body', ''),
                    'priority': ticket_data.get('Priority', 'Medium'),
                    'classification': ticket_data.get('Classification', 'General'),
                    'date_created': datetime.now().isoformat(),
                    'status': 'Open',
                    'has_warranty': ticket_data.get('has_warranty', False),
                    'has_attachments': ticket_data.get('has_attachments', False),
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                    'message_id': ticket_data.get('messageid', ''),
                    'draft_body': ticket_data.get('draft', '')
                }
                
                try:
                    # Add to database - will throw ValueError if ID exists
                    db.create_ticket(ticket)
                    ticket_id = potential_id
                    app.logger.info(f"Email processing created ticket {ticket_id} (attempt {attempt + 1})")
                    break
                    
                except ValueError as e:
                    if "Ticket ID already exists" in str(e):
                        app.logger.debug(f"Email ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                        continue  # Try next ID
                    else:
                        raise e  # Re-raise unexpected errors
            
            # Process attachments if present
            if ticket_data.get('attachments'):
                for i, attachment in enumerate(ticket_data['attachments']):
                    # Handle base64 attachments from email
                    if attachment.get('data'):
                        # Save base64 data as file
                        try:
                            file_data = base64.b64decode(attachment.get('data', ''))
                            filename = attachment.get('filename', 'unknown_file')
                            safe_filename = secure_filename(filename)
                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                            unique_filename = f"{timestamp}_{safe_filename}"
                            
                            # Save to uploads directory
                            file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                            with open(file_path, 'wb') as f:
                                f.write(file_data)
                            
                            # Add attachment metadata
                            attachment_key = 'warranty_form' if attachment.get('is_warranty') else f'other_file_{i+1}'
                            attachment_metadata = {
                                'key': attachment_key,
                                'file_path': unique_filename,
                                'original_name': filename,
                                'size': attachment.get('size', len(file_data)),
                                'is_warranty': attachment.get('is_warranty', False),
                                'file_type': attachment.get('file_type', {})
                            }
                            
                            db.add_ticket_metadata(ticket_id, attachment_key, json.dumps(attachment_metadata))
                            
                            app.logger.info(f"Saved email attachment: {filename} ({'warranty' if attachment.get('is_warranty') else 'regular'} file)")
                            
                        except Exception as att_error:
                            app.logger.error(f"Error saving attachment {attachment.get('filename', 'unknown')}: {att_error}")
            
            created_tickets.append({
                'ticket_id': ticket_id,
                'has_warranty': ticket.get('has_warranty'),
                'has_attachments': ticket.get('has_attachments'),
                'customer': customer_name,
                'email': customer_email
            })
            
            app.logger.info(f"Email integration created ticket {ticket_id} - Warranty: {ticket.get('has_warranty')}, Attachments: {ticket.get('has_attachments')}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully processed {len(created_tickets)} tickets',
            'count': len(created_tickets),
            'tickets': created_tickets,
            'warranty_detected': sum(1 for t in created_tickets if t['has_warranty']),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Email integration processing error: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': f'Email processing failed: {str(e)}',
            'timestamp': datetime.now().isoformat()
        }), 500

# Add webhook debug endpoint
@app.route('/debug/webhook-test')
def debug_webhook_test():
    """Debug endpoint to test webhook configuration"""
    try:
        webhook_url = os.environ.get('TECH_DIRECTOR_REMINDER_WEBHOOK', 'NOT_SET')
        
        # Test payload
        test_payload = {
            'ticket_id': 'DEBUG123',
            'subject': 'Debug Test',
            'customer_name': 'Test Customer',
            'priority': 'Medium',
            'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
            'reminder_context': 'This is a debug test from the webhook system'
        }
        
        if webhook_url == 'NOT_SET':
            return jsonify({
                'status': 'error',
                'message': 'TECH_DIRECTOR_REMINDER_WEBHOOK environment variable is not set',
                'webhook_url': webhook_url
            })
        
        # Try to send test webhook
        response = requests.post(webhook_url, json=test_payload, timeout=10)
        response.raise_for_status()
        
        return jsonify({
            'status': 'success',
            'message': 'Test webhook sent successfully!',
            'webhook_url': webhook_url,
            'response_status': response.status_code,
            'test_payload': test_payload
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'status': 'error',
            'message': f'Webhook request failed: {str(e)}',
            'webhook_url': webhook_url,
            'error_details': str(e)
        }), 500
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Debug test failed: {str(e)}',
            'webhook_url': webhook_url
        }), 500



# Add debug endpoint for session data
@app.route('/debug/session')
def debug_session():
    """Debug endpoint to check session data"""
    try:
        session_info = {
            'session_exists': bool(session),
            'session_keys': list(session.keys()) if session else [],
            'member_id': session.get('member_id'),
            'member_name': session.get('member_name'),
            'member_role': session.get('member_role'),
            'selected_portal': session.get('selected_portal'),
            'last_activity': session.get('last_activity'),
            'session_permanent': session.get('_permanent', False),
            'session_modified': session.get('_modified', False),
            'session_new': session.get('_new', False),
            'session_id': session.get('_id', None),
            'current_time': datetime.now().isoformat(),
            'session_lifetime': str(app.permanent_session_lifetime),
            'is_production': is_production
        }
        
        # Sessions are permanent - no timeout checks needed
        if 'member_id' in session:
            session_info['session_timeout_check'] = False  # Never timeout
            session_info['session_refresh_result'] = refresh_session()
        
        return jsonify(session_info)
    except Exception as e:
        return jsonify({'error': str(e), 'session_exists': bool(session)})

# Add ticket inspection endpoint
@app.route('/debug/inspect-referred-tickets')
def debug_inspect_referred_tickets():
    """Debug endpoint to inspect all tickets referred to Tech Director"""
    try:
        db = get_db()
        
        # Get all tickets with "Referred to Tech Director" status
        referred_tickets = db.get_tickets_by_status("Referred to Tech Director")
        
        inspection_results = []
        for ticket in referred_tickets:
            ticket_id = ticket['ticket_id']
            assignment = db.get_assignment_by_ticket(ticket_id)
            
            result = {
                'ticket_id': ticket_id,
                'status': ticket.get('status'),
                'priority': ticket.get('priority'),
                'created_at': str(ticket.get('created_at')),
                'has_assignment': assignment is not None
            }
            
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    result.update({
                        'assigned_member_name': assigned_member.get('name', 'Unknown') if assigned_member else 'None',
                        'assigned_member_role': assigned_member.get('role', 'Unknown') if assigned_member else 'None',
                        'is_forwarded': assignment.get('is_forwarded', False),
                        'assignment_created_at': str(assignment.get('created_at', 'Unknown'))
                    })
                else:
                    result.update({
                        'assigned_member_name': 'Error: No member_id',
                        'assigned_member_role': 'Error: No member_id',
                        'is_forwarded': False,
                        'assignment_created_at': 'Error: No member_id'
                    })
            else:
                result.update({
                    'assigned_member_name': None,
                    'assigned_member_role': None,
                    'is_forwarded': False,
                    'assignment_created_at': None
                })
            
            inspection_results.append(result)
        
        return jsonify({
            'status': 'success',
            'total_referred_tickets': len(referred_tickets),
            'tickets': inspection_results
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Inspection failed: {str(e)}'
        }), 500

# Add consistency check endpoint
@app.route('/debug/fix-status-consistency')
def debug_fix_status_consistency():
    """Debug endpoint to fix status consistency issues"""
    try:
        fixed_count = fix_ticket_status_consistency()
        return jsonify({
            'status': 'success',
            'message': f'Consistency check completed',
            'fixed_tickets': fixed_count,
            'details': f'Fixed {fixed_count} tickets with inconsistent status/assignment'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Consistency check failed: {str(e)}'
        }), 500

# Add specific ticket fix endpoint  
@app.route('/debug/fix-ticket/<ticket_id>')
def debug_fix_specific_ticket(ticket_id):
    """Debug endpoint to fix a specific ticket's consistency"""
    try:
        db = get_db()
        
        # Get ticket and assignment
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        current_status = ticket.get('status')
        fix_applied = False
        
        if assignment:
            # [FIX] Ensure member_id is valid before calling get_member_by_id
            member_id = assignment.get('member_id')
            if member_id:
                assigned_member = db.get_member_by_id(member_id)
                
                if assigned_member:
                    # Check for inconsistency
                    if (current_status == 'Referred to Tech Director' and 
                        assigned_member.get('role') != 'Technical Director'):
                        
                        # Fix the status
                        target_role = assigned_member.get('role', 'Support')
                        if target_role == 'Administrator':
                            corrected_status = 'Open'
                        elif target_role in ['Support', 'Engineer', 'IT']:
                            corrected_status = 'Under Review'
                        else:
                            corrected_status = 'Open'
                        
                        db.update_ticket(ticket_id, {
                            'status': corrected_status,
                            'updated_at': datetime.now(),
                            'status_manually_fixed': f'Debug fix - assigned to {assigned_member.get("name", "Unknown")}',
                            'previous_inconsistent_status': current_status
                        })
                        
                        fix_applied = True
                        
                        return jsonify({
                            'status': 'success',
                            'message': f'Ticket {ticket_id} fixed',
                            'old_status': current_status,
                            'new_status': corrected_status,
                            'assigned_to': assigned_member.get('name'),
                            'assigned_role': target_role
                        })
            else:
                app.logger.error(f"[ERROR] TICKET {ticket_id} has assignment but no member_id")
        
        if not fix_applied:
            return jsonify({
                'status': 'info',
                'message': f'Ticket {ticket_id} appears consistent',
                'current_status': current_status,
                'assignment_info': {
                    'assigned_to': assigned_member.get('name') if assignment and assigned_member else 'None',
                    'assigned_role': assigned_member.get('role') if assignment and assigned_member else 'None',
                    'is_forwarded': assignment.get('is_forwarded') if assignment else False
                } if assignment else None
            })
            
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Failed to fix ticket {ticket_id}: {str(e)}'
        }), 500

# Error handlers
@app.errorhandler(404)
def not_found_error(error):
    if request.path.startswith('/api/'):
        return jsonify({'error': 'Endpoint not found'}), 404
    try:
        return render_template('error.html', error="Page not found"), 404
    except:
        return f"404 - Page not found: {request.path}", 404

@app.errorhandler(500)
def internal_error(error):
    app.logger.error(f"Internal server error: {error}")
    if request.path.startswith('/api/'):
        return jsonify({'error': 'Internal server error'}), 500
    try:
        return render_template('error.html', error="Internal server error"), 500
    except:
        return "500 - Internal server error", 500

@app.errorhandler(Exception)
def handle_exception(e):
    """Handle all unhandled exceptions"""
    app.logger.error(f"Unhandled exception: {e}", exc_info=True)
    if request.path.startswith('/api/'):
        return jsonify({'error': 'An unexpected error occurred'}), 500
    try:
        return render_template('error.html', error="An unexpected error occurred"), 500
    except:
        return f"Error: {str(e)}", 500

def extract_email(raw_email):
    """Extract email address from possible formatted string"""
    match = re.search(r'<([^>]+)>', raw_email)
    return match.group(1) if match else raw_email

def get_classification_code(classification):
    """Get single-letter code for email ticket classifications"""
    mapping = {
        'Technical Issue': 'T',
        'Technical': 'T',
        'Payment': 'P', 
        'Support': 'S',
        'Account': 'A',
        'Spam': 'X',  # Changed from 'S' to 'X' to avoid conflict with Support
        'Warranty Claim': 'W',
        'General': 'G',
        'Other': 'O'
    }
    return mapping.get(classification, 'G')  # Default to 'G' for General

def get_priority_code(priority):
    """Get single-letter code for email ticket priorities"""
    mapping = {
        'Urgent': 'U',
        'Fast': 'F', 
        'Medium': 'M',
        'Low': 'L'
    }
    return mapping.get(priority, 'M')  # Default to 'M' for Medium

def get_email_classification_code(classification):
    """
    Get classification code for EMAIL tickets (similar to manual ticket type codes)
    Format: E{classification_code}{4 digits} - matches manual ticket format M{type_code}{4 digits}
    """
    classification_mapping = {
        'Technical Support': 'T',
        'Technical': 'T',
        'Billing': 'B', 
        'General': 'G',
        'Others': 'O',
        'Other': 'O',
        'Warranty': 'W',
        'DPF Related': 'D',
        'Parts': 'P',
        'Complaint': 'C',
        'Inquiry': 'I',
        'Installation': 'N',
        'Support': 'S'
    }
    return classification_mapping.get(classification, 'G')  # Default to General

def generate_email_ticket_id(email, name, classification, db):
    """
    [TARGET] Generate email ticket ID in SAME format as manual tickets: E{type_code}{4 digits}
    Uses identical deterministic calculation as manual tickets for consistency
    """
    # Get classification code (similar to manual ticket type codes)
    type_code = get_email_classification_code(classification)
    
    max_attempts = 100
    ticket_id = None
    
    app.logger.info(f"[TARGET] Generating email ticket ID for: {email}, classification: {classification} -> {type_code}")
    
    for attempt in range(max_attempts):
        # Generate 4-digit code using SAME logic as manual tickets
        seed_string = f"{email}{name}{datetime.now().isoformat()}"
        
        # Calculate sum of character codes (identical to manual ticket logic)
        sum_chars = 0
        for char in seed_string:
            sum_chars += ord(char)
        
        # Generate 4-digit number (same as manual: sum % 10000)
        four_digit_code = sum_chars % 10000
        four_digit_str = f"{four_digit_code:04d}"  # Ensure 4 digits with leading zeros
        
        potential_id = f"E{type_code}{four_digit_str}"  # Exactly 6 chars: E + 1 + 4 digits
        
        app.logger.info(f"? Attempting email ticket ID: {potential_id} (attempt {attempt + 1}/{max_attempts})")
        app.logger.debug(f"? Email calculation: seed='{seed_string[:50]}...', sum_chars={sum_chars}, 4-digit={four_digit_code}")
        
        # Check if ID already exists (same check as manual tickets)
        if not db.ticket_id_exists(potential_id):
            ticket_id = potential_id
            app.logger.info(f"[SUCCESS] Generated unique email ticket ID: {ticket_id}")
            break
        else:
            app.logger.debug(f"[RETRY] Email ticket ID collision: {potential_id}, retrying...")
            # Add small random variation to avoid infinite loops with same data
            import time
            time.sleep(0.001)  # 1ms delay to change timestamp
    
    if not ticket_id:
        app.logger.error(f"[ERROR] Failed to generate unique email ticket ID after {max_attempts} attempts")
        raise Exception(f"Failed to generate unique email ticket ID after {max_attempts} attempts")
    
    return ticket_id

def fix_ticket_status_consistency():
    """Fix any existing tickets with inconsistent status vs assignment"""
    try:
        db = get_db()
        
        # Find tickets with "Referred to Tech Director" status
        referred_tickets = list(db.tickets.find({"status": "Referred to Tech Director"}))
        
        fixed_count = 0
        for ticket in referred_tickets:
            ticket_id = ticket['ticket_id']
            
            # Check current assignment
            assignment = db.get_assignment_by_ticket(ticket_id)
            
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    
                    # If assigned to non-TD member but status still shows "Referred to Tech Director"
                    if (assigned_member and 
                        assigned_member.get('role') != 'Technical Director' and 
                        assignment.get('is_forwarded', False)):
                        
                        # Fix the status based on assigned member's role
                        target_role = assigned_member.get('role', 'Support')
                        if target_role == 'Administrator':
                            new_status = 'Open'
                        elif target_role in ['Support', 'Engineer', 'IT']:
                            new_status = 'Under Review'
                        else:
                            new_status = 'Open'
                        
                        # Update the ticket status
                        db.update_ticket(ticket_id, {
                            'status': new_status,
                            'updated_at': datetime.now(),
                            'status_auto_fixed': f'Corrected inconsistency - assigned to {assigned_member.get("name", "Unknown")} ({target_role})',
                            'previous_inconsistent_status': 'Referred to Tech Director'
                        })
                        
                        app.logger.info(f"[FIX] FIXED INCONSISTENCY - Ticket {ticket_id}: status changed from 'Referred to Tech Director' to '{new_status}' (assigned to {assigned_member.get('name')})")
                        fixed_count += 1
                else:
                    app.logger.error(f"[ERROR] TICKET {ticket_id} has assignment but no member_id")
        
        if fixed_count > 0:
            app.logger.info(f"[SUCCESS] CONSISTENCY CHECK COMPLETE - Fixed {fixed_count} inconsistent tickets")
        else:
            app.logger.info(f"[SUCCESS] CONSISTENCY CHECK COMPLETE - No inconsistencies found")
            
        return fixed_count
        
    except Exception as e:
        app.logger.error(f"Error in consistency check: {e}")
        return 0

def identify_ticket_origin(ticket):
    """Identify ticket origin and format information for display"""
    ticket_id = ticket.get('ticket_id', '')
    creation_method = ticket.get('creation_method', 'unknown')
    
    if creation_method == 'manual':
        # Manual tickets: M{type_code}{4_digits}
        if ticket_id.startswith('M'):
            type_code = ticket_id[1:2] if len(ticket_id) > 1 else 'Unknown'
            four_digits = ticket_id[2:6] if len(ticket_id) >= 6 else 'Unknown'
            
            type_mapping = {
                'P': 'DPF Clean - Premium',
                'S': 'DPF Clean - Standard', 
                'J': 'Part Job',
                'O': 'Other',
                'K': 'Workshop Job'
            }
            
            return {
                'origin': 'Manual',
                'origin_icon': 'fas fa-user-edit',
                'origin_color': 'blue',
                'type': type_mapping.get(type_code, 'Unknown'),
                'format': f'M{type_code}{four_digits}',
                'description': f'Manual ticket created for {type_mapping.get(type_code, "Unknown")} (Code: {four_digits})'
            }
    
    elif creation_method == 'email':
        # Email tickets: {class_code}{priority_code}{4_digits}
        if len(ticket_id) >= 6:
            class_code = ticket_id[0:1]
            priority_code = ticket_id[1:2] 
            four_digits = ticket_id[2:6]
            
            class_mapping = {
                'T': 'Technical Issue',
                'P': 'Payment', 
                'S': 'Support',
                'A': 'Account',
                'X': 'Spam',
                'W': 'Warranty Claim',
                'G': 'General',
                'O': 'Other'
            }
            
            priority_mapping = {
                'U': 'Urgent',
                'F': 'Fast',
                'M': 'Medium', 
                'L': 'Low'
            }
            
            return {
                'origin': 'Email',
                'origin_icon': 'fas fa-envelope',
                'origin_color': 'green',
                'classification': class_mapping.get(class_code, 'Unknown'),
                'priority': priority_mapping.get(priority_code, 'Unknown'),
                'format': f'{class_code}{priority_code}{four_digits}',
                'description': f'Email ticket - {class_mapping.get(class_code, "Unknown")} / {priority_mapping.get(priority_code, "Unknown")} (Code: {four_digits})'
            }
    
    elif creation_method == 'warranty' or ticket_id.startswith('W'):
        # Warranty tickets: W{5_digits}
        return {
            'origin': 'Warranty',
            'origin_icon': 'fas fa-shield-alt',
            'origin_color': 'purple',
            'format': ticket_id,
            'description': f'Warranty claim ticket (ID: {ticket_id})'
        }
    
    # Fallback for unknown tickets
    return {
        'origin': 'Unknown',
        'origin_icon': 'fas fa-question-circle',
        'origin_color': 'gray',
        'format': ticket_id,
        'description': f'Unknown ticket type (ID: {ticket_id})'
    }



def safe_datetime_parse(value):
    """Safely parse datetime from either datetime object or string"""
    if isinstance(value, datetime):
        return value
    elif value:
        try:
            return datetime.strptime(str(value), "%Y-%m-%d %H:%M:%S")
        except:
            try:
                # Try alternative format
                return datetime.fromisoformat(str(value).replace('Z', '+00:00'))
            except:
                return None
    return None

def safe_date_format(value, format_str="%b %d, %I:%M %p"):
    """Safely format datetime to string"""
    parsed_date = safe_datetime_parse(value)
    if parsed_date:
        return parsed_date.strftime(format_str)
    return str(value) if value else ""

def group_tickets_by_date(tickets):
    """Group tickets by date categories (Today, Yesterday, etc.)"""
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)
    this_week_start = today - timedelta(days=today.weekday())
    
    tickets_grouped = defaultdict(list)
    
    for ticket in tickets:
        # Handle both datetime objects (from MongoDB) and string dates
        if isinstance(ticket['created_at'], datetime):
            ticket_date = ticket['created_at'].date()
        else:
            try:
                ticket_date = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S").date()
            except:
                # If we can't parse the date, put it in a default group
                tickets_grouped["Unknown Date"].append(ticket)
                continue
        
        if ticket_date == today:
            date_group = "Today"
        elif ticket_date == yesterday:
            date_group = "Yesterday"
        elif ticket_date >= this_week_start:
            date_group = "This Week"
        else:
            date_group = ticket_date.strftime("%B %d, %Y")
            
        tickets_grouped[date_group].append(ticket)
    

    
    return tickets_grouped



@app.route('/')
def dashboard():
    """Main dashboard showing all tickets"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get current user's role
        current_member = db.get_member_by_id(session['member_id'])
        if not current_member:
            return redirect(url_for('portal'))
        current_user_role = current_member['role']
        
        # Redirect Technical Director to their specific dashboard
        if current_user_role == 'Technical Director':
            return redirect(url_for('tech_director_dashboard'))
        
        # CRITICAL FIX: Ensure all tickets have has_unread_reply field before processing
        try:
            db.migrate_has_unread_reply_field()
            app.logger.info("[DASHBOARD] has_unread_reply field migration completed")
        except Exception as migration_error:
            app.logger.warning(f"[DASHBOARD] has_unread_reply migration failed: {migration_error}")
        
        # Get pagination parameters
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status_filter = request.args.get('status', 'All')
        priority_filter = request.args.get('priority', 'All')
        search_query = request.args.get('search', '')
        
        # Get paginated tickets with assignment info
        tickets = db.get_tickets_with_assignments(
            page=page, 
            per_page=per_page, 
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # Get total count for pagination
        total_tickets = db.get_tickets_count(
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # DEBUG: Check important ticket sorting
        important_count = sum(1 for t in tickets if t.get('is_important', False))
        app.logger.info(f"[DASHBOARD] Total tickets: {len(tickets)}, Important tickets: {important_count}")
        if important_count > 0:
            first_five = tickets[:5]
            for i, t in enumerate(first_five):
                app.logger.info(f"[DASHBOARD] Position {i+1}: Ticket {t.get('ticket_id')} - Important: {t.get('is_important', False)}, Classification: {t.get('classification', 'None')}")
        
        # Separate forwarded tickets for current user
        forwarded_tickets = []
        regular_tickets = []
        
        # Convert to dict format and format dates
        formatted_tickets = []
        for ticket in tickets:
            # Convert ObjectId to string for template compatibility
            ticket['_id'] = str(ticket['_id'])
            
            # Handle assignment info - ENHANCED DEBUGGING
            ticket_id = ticket.get('ticket_id')
            assignment_data = ticket.get('assignment', [])
            assigned_member_data = ticket.get('assigned_member', [])
            
            app.logger.info(f"[DASHBOARD] Processing ticket {ticket_id}: assignment_count={len(assignment_data)}, member_count={len(assigned_member_data)}")
            
            if assignment_data and len(assignment_data) > 0:
                assignment = assignment_data[0]
                app.logger.info(f"[DASHBOARD] Ticket {ticket_id} has assignment: member_id={assignment.get('member_id')}, is_forwarded={assignment.get('is_forwarded', False)}")
                
                if assigned_member_data and len(assigned_member_data) > 0:
                    member = assigned_member_data[0]
                    ticket['assigned_to'] = member.get('name')
                    ticket['assigned_to_gender'] = member.get('gender')
                    app.logger.info(f"[DASHBOARD] Ticket {ticket_id}: ASSIGNED TO {ticket['assigned_to']} (member_id={member.get('_id')})")
                else:
                    app.logger.error(f"[BADGE_ISSUE] Ticket {ticket_id}: Has assignment (member_id={assignment.get('member_id')}) but no member data found in aggregation!")
                    app.logger.error(f"[BADGE_ISSUE] Assignment data: {assignment}")
                    
                    # ENHANCED FALLBACK: Handle ObjectId conversion properly
                    try:
                        member_id = assignment.get('member_id')
                        app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: member_id={member_id}, type={type(member_id).__name__}")
                        
                        if member_id:
                            # Convert to string if it's ObjectId
                            member_id_str = str(member_id)
                            app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: Converted to string: {member_id_str}")
                            
                            member = db.get_member_by_id(member_id_str)
                            if member:
                                ticket['assigned_to'] = member.get('name')
                                ticket['assigned_to_gender'] = member.get('gender')
                                app.logger.info(f"[BADGE_FALLBACK] Ticket {ticket_id}: Found member via direct lookup: {ticket['assigned_to']}")
                            else:
                                app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: Member {member_id_str} not found in database!")
                                # DEBUG: Check what members exist
                                all_members = list(db.members.find({}, {'_id': 1, 'name': 1}).limit(5))
                                app.logger.error(f"[BADGE_FALLBACK] Available members: {[(str(m['_id']), m.get('name')) for m in all_members]}")
                                ticket['assigned_to'] = None
                        else:
                            app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: member_id is None or empty")
                            ticket['assigned_to'] = None
                    except Exception as fallback_error:
                        app.logger.error(f"[BADGE_FALLBACK] Error during fallback lookup: {fallback_error}")
                        ticket['assigned_to'] = None
                
                # Handle forwarding information
                ticket['assigned_at'] = assignment.get('assigned_at')
                ticket['is_forwarded'] = assignment.get('is_forwarded', False)
                
                # Get forwarded from member info
                if ticket['is_forwarded'] and ticket.get('forwarded_from_member') and len(ticket['forwarded_from_member']) > 0:
                    forwarded_member = ticket['forwarded_from_member'][0]
                    ticket['forwarded_from_name'] = forwarded_member.get('name')
                    app.logger.debug(f"[DASHBOARD] Ticket {ticket_id}: Forwarded from {ticket['forwarded_from_name']}")
                else:
                    ticket['forwarded_from_name'] = 'Unknown'
                    app.logger.debug(f"[DASHBOARD] Ticket {ticket_id}: No forwarded_from_member data, setting to Unknown")
            else:
                app.logger.debug(f"[DASHBOARD] Ticket {ticket_id}: No assignment data")
                ticket['assigned_to'] = None
                ticket['is_forwarded'] = False

            
            # Format date
            if 'created_at' in ticket and ticket['created_at']:
                if isinstance(ticket['created_at'], datetime):
                    ticket['formatted_date'] = ticket['created_at'].strftime("%b %d, %I:%M %p")
                else:
                    try:
                        created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                    except:
                        ticket['formatted_date'] = str(ticket['created_at'])
            
            # Get technician information for this ticket
            ticket_id = ticket.get('ticket_id')
            if ticket_id:
                try:
                    # Check if database is actually working
                    if not hasattr(db, 'ticket_metadata') or not db.ticket_metadata:
                        app.logger.warning(f"Database not properly initialized for ticket {ticket_id}")
                        ticket['technician_name'] = None
                        ticket['technician_id'] = None
                    else:
                        metadata = db.get_ticket_metadata(ticket_id)
                        app.logger.info(f" Retrieved metadata for ticket {ticket_id}: {metadata}")
                        if metadata:
                            app.logger.info(f"Found {len(metadata)} metadata entries for ticket {ticket_id}")
                            for meta in metadata:
                                app.logger.info(f"  - Key: '{meta.get('key')}', Value: '{meta.get('value')}'")
                                if meta.get('key') == 'technician_name':
                                    ticket['technician_name'] = meta.get('value')
                                    app.logger.info(f" Set technician_name to: {meta.get('value')}")
                                    break
                                elif meta.get('key') == 'technician_id':
                                    ticket['technician_id'] = meta.get('value')
                                    app.logger.info(f" Set technician_id to: {meta.get('value')}")
                                    break
                        else:
                            app.logger.info(f" No metadata found for ticket {ticket_id}")
                            ticket['technician_name'] = None
                            ticket['technician_id'] = None
                        
                        # Ensure technician fields are explicitly set to None if not found
                        if 'technician_name' not in ticket or ticket['technician_name'] is None:
                            ticket['technician_name'] = None
                            app.logger.info(f"ðŸ”§ Explicitly set technician_name to None for ticket {ticket_id}")
                        if 'technician_id' not in ticket or ticket['technician_id'] is None:
                            ticket['technician_id'] = None
                            app.logger.info(f"ðŸ”§ Explicitly set technician_id to None for ticket {ticket_id}")
                except Exception as e:
                    app.logger.debug(f"Error getting technician info for ticket {ticket_id}: {e}")
                    ticket['technician_name'] = None
                    ticket['technician_id'] = None
                
                # Final fallback: ensure technician fields are always set
                if 'technician_name' not in ticket:
                    ticket['technician_name'] = None
                if 'technician_id' not in ticket:
                    ticket['technician_id'] = None
            
            # Check if this ticket is forwarded to current user
            is_forwarded_to_current_user = (
                ticket.get('is_forwarded', False) and 
                ticket.get('assigned_to') == current_member['name']
            )
            
            if is_forwarded_to_current_user:
                forwarded_tickets.append(ticket)
            else:
                regular_tickets.append(ticket)
            
            formatted_tickets.append(ticket)
            
            # CRITICAL FIX: Validate has_unread_reply field for each ticket
            if 'has_unread_reply' not in ticket:
                ticket['has_unread_reply'] = False
                app.logger.warning(f"[DASHBOARD] Ticket {ticket_id} missing has_unread_reply field, setting to False")
            elif not isinstance(ticket['has_unread_reply'], bool):
                ticket['has_unread_reply'] = bool(ticket['has_unread_reply'])
                app.logger.warning(f"[DASHBOARD] Ticket {ticket_id} has invalid has_unread_reply type, converted to {ticket['has_unread_reply']}")
            
            # Log unread reply status for debugging
            if ticket.get('has_unread_reply'):
                app.logger.info(f"[DASHBOARD] ðŸš¨ Ticket {ticket_id} has UNREAD REPLY - will show red dot alert")
            else:
                app.logger.debug(f"[DASHBOARD] Ticket {ticket_id} has no unread replies")
            
            # Log final ticket data for debugging
            if ticket.get('technician_name'):
                app.logger.info(f" Ticket {ticket_id} has technician: {ticket['technician_name']}")
            else:
                app.logger.info(f" Ticket {ticket_id} has NO technician assigned")
            
            # Additional debugging for technician fields
            app.logger.info(f" Final technician data for ticket {ticket_id}: technician_name='{ticket.get('technician_name')}', technician_id='{ticket.get('technician_id')}'")
            app.logger.info(f" Ticket {ticket_id} keys: {list(ticket.keys())}")
            
            # Double-check: if we still don't have technician data, try one more time
            if not ticket.get('technician_name') and not ticket.get('technician_id'):
                app.logger.warning(f" Ticket {ticket_id} still missing technician data, trying one more retrieval...")
                try:
                    final_metadata = db.get_ticket_metadata(ticket_id)
                    for meta in final_metadata:
                        if meta.get('key') == 'technician_name':
                            ticket['technician_name'] = meta.get('value')
                            app.logger.info(f"ðŸ”„ Final attempt: Set technician_name to: {meta.get('value')}")
                            break
                except Exception as e:
                    app.logger.error(f" Final attempt failed for ticket {ticket_id}: {e}")
        
        #  DYNAMIC WARRANTY CLASSIFICATION: Update classification for tickets with warranty attachments
        for ticket_dict in formatted_tickets:
            ticket_id = ticket_dict.get('ticket_id')
            if ticket_id:
                try:
                    # Check if ticket has warranty attachments
                    metadata = db.get_ticket_metadata(ticket_id)
                    has_warranty_attachment = False
                    
                    if metadata:
                        for meta in metadata:
                            try:
                                # Ensure meta is a dictionary
                                if not isinstance(meta, dict):
                                    continue
                                
                                meta_value = meta.get('value')
                                if isinstance(meta_value, str):
                                    # Handle potential malformed JSON
                                    if meta_value.strip() and meta_value.strip() not in ['{}', '']:
                                        try:
                                            # Clean JSON before parsing
                                            clean_json = meta_value.strip()
                                            # Remove trailing commas and fix common JSON issues
                                            if clean_json.endswith(',}'):
                                                clean_json = clean_json[:-2] + '}'
                                            elif clean_json.endswith(',]'):
                                                clean_json = clean_json[:-2] + ']'
                                            # Remove any leading/trailing whitespace and quotes
                                            clean_json = clean_json.strip().strip('"\'')
                                            # Skip if still empty after cleaning
                                            if not clean_json or clean_json in ['{}', '[]', 'null', 'undefined']:
                                                meta_data = {}
                                            else:
                                                meta_data = json.loads(clean_json)
                                        except json.JSONDecodeError as json_err:
                                            # Only log if it's actually malformed, not just empty
                                            if meta_value.strip() and meta_value.strip() not in ['{}', '[]', 'null', 'undefined', '']:
                                                app.logger.debug(f"Skipping malformed JSON in metadata: {json_err} - Value: {meta_value[:50]}")
                                            meta_data = {}
                                    else:
                                        meta_data = {}
                                elif isinstance(meta_value, dict):
                                    meta_data = meta_value
                                else:
                                    meta_data = {}
                                
                                # Check if this attachment is warranty-related
                                if isinstance(meta_data, dict):
                                    is_warranty = meta_data.get('is_warranty', False)
                                    if is_warranty:
                                        has_warranty_attachment = True
                                        break
                            except (json.JSONDecodeError, TypeError, AttributeError) as e:
                                app.logger.warning(f"Error processing metadata for ticket {ticket_id}: {e}")
                                continue
                    
                    # Also check direct has_warranty flag on ticket
                    has_warranty_flag = ticket_dict.get('has_warranty', False)
                    
                    # If ticket has warranty attachments or warranty flag, ensure classification is "Warranty Claim"
                    if has_warranty_attachment or has_warranty_flag:
                        original_classification = ticket_dict.get('classification')
                        ticket_dict['classification'] = 'Warranty Claim'
                        
                        if original_classification != 'Warranty Claim':
                            app.logger.info(f" DYNAMIC WARRANTY CLASSIFICATION: Ticket {ticket_id} updated from '{original_classification}' to 'Warranty Claim' (warranty_attachment: {has_warranty_attachment}, warranty_flag: {has_warranty_flag})")
                
                except Exception as e:
                    app.logger.error(f"Error checking warranty status for ticket {ticket_id}: {e}")
        
        # Group tickets by date
        tickets_grouped = group_tickets_by_date(formatted_tickets)
        
        # Get counts for stats - FIXED: Use database total, not paginated count
        # total_tickets is already set correctly from database.get_tickets_count()
        open_tickets = len([t for t in formatted_tickets if t.get('status') == 'Open'])
        resolved_tickets = len([t for t in formatted_tickets if t.get('status') == 'Resolved'])
        waiting_tickets = len([t for t in formatted_tickets if t.get('status') == 'Waiting for Response'])
        
        # CRITICAL FIX: Count tickets with unread replies for debugging
        unread_reply_count = sum(1 for t in formatted_tickets if t.get('has_unread_reply'))
        app.logger.info(f"[DASHBOARD] FINAL SUMMARY: {unread_reply_count} tickets have unread replies out of {len(formatted_tickets)} total tickets")
        
        # Get priority and type breakdowns
        priorities = {
            'Urgent': len([t for t in formatted_tickets if t.get('priority') == 'Urgent']),
            'Fast': len([t for t in formatted_tickets if t.get('priority') == 'Fast']),
            'Medium': len([t for t in formatted_tickets if t.get('priority') == 'Medium']),
            'Low': len([t for t in formatted_tickets if t.get('priority') == 'Low'])
        }
        
        classifications = {}
        for ticket in formatted_tickets:
            cls = ticket.get('classification')
            if cls:
                classifications[cls] = classifications.get(cls, 0) + 1
        
        # Calculate pagination info
        total_pages = (total_tickets + per_page - 1) // per_page
        has_prev = page > 1
        has_next = page < total_pages
        prev_page = page - 1 if has_prev else None
        next_page = page + 1 if has_next else None
        
        pagination_info = {
            'current_page': page,
            'per_page': per_page,
            'total_tickets': total_tickets,
            'total_pages': total_pages,
            'has_prev': has_prev,
            'has_next': has_next,
            'prev_page': prev_page,
            'next_page': next_page,
            'status_filter': status_filter,
            'priority_filter': priority_filter,
            'search_query': search_query
        }
        
        return render_template('index.html', 
                            tickets_grouped=tickets_grouped,
                            tickets=formatted_tickets,  # Add this line for template compatibility
                            forwarded_tickets=forwarded_tickets,
                            total_tickets=total_tickets,
                            open_tickets=open_tickets,
                            resolved_tickets=resolved_tickets,
                            waiting_tickets=waiting_tickets,
                            priorities=priorities,
                            classifications=classifications,
                            current_user=session.get('member_name'),
                            current_user_role=current_user_role,
                            pagination=pagination_info)
    except Exception as e:
        return render_template('error.html', error=f"Database error: {e}"), 500





@app.route('/portal')
def portal():
    return render_template('portal.html')



@app.route('/login', methods=['GET', 'POST'])
def login():
    # Get role parameter from URL
    selected_role = request.args.get('role', 'general')
    
    # Get filtered members based on selected portal
    db = get_db()
    all_members = db.get_all_members()
    
    # Filter members based on selected portal
    filtered_members = []
    if selected_role == 'admin':
        filtered_members = [m for m in all_members if m.get('role') == 'Administrator']
    elif selected_role == 'tech-director':
        filtered_members = [m for m in all_members if m.get('role') == 'Technical Director']
    elif selected_role == 'user':
        # User portal accessible by all roles except Administrator and Technical Director
        filtered_members = [m for m in all_members if m.get('role') not in ['Administrator', 'Technical Director']]
    else:
        filtered_members = all_members
    
    # Convert ObjectIds to strings for template
    for member in filtered_members:
        member['_id'] = str(member['_id'])
    
    if request.method == 'POST':
        try:
            # Check if using member selection or manual input
            member_id = request.form.get('member_id')
            user_id = request.form.get('user_id', '').strip()
            password = request.form.get('password', '')
            
            # Basic input validation
            if not password:
                flash('Please enter password', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            if len(password) > 100:  # Reasonable limits
                flash('Invalid credentials', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            # Get member either by selection or user_id
            member = None
            if member_id and member_id != '':
                member = db.get_member_by_id(member_id)
            elif user_id:
                member = db.get_member_by_user_id(user_id)
            
            # Check if user exists
            if not member:
                flash('User ID not found. Please check your User ID or select an account from the list above.', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            # Check password
            if not check_password_hash(member.get('password_hash', ''), password):
                flash('Incorrect password. Please try again.', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            # Validate role access
            user_role = member.get('role', 'User')
            
            # Role validation based on portal selection
            role_access_valid = True
            if selected_role == 'admin' and user_role != 'Administrator':
                role_access_valid = False
                flash('Access denied. Administrator credentials required.', 'error')
            elif selected_role == 'tech-director' and user_role != 'Technical Director':
                role_access_valid = False
                flash('Access denied. Technical Director credentials required.', 'error')
            elif selected_role == 'user' and user_role in ['Administrator', 'Technical Director']:
                role_access_valid = False
                flash('Access denied. This portal is for users only.', 'error')
            
            if role_access_valid:
                # Make session permanent and set initial activity
                session.permanent = True
                session['member_id'] = str(member['_id'])
                session['member_name'] = member['name']
                session['member_role'] = user_role
                session['selected_portal'] = selected_role
                session['last_activity'] = datetime.now().isoformat()
                
                # Store additional data for session restoration
                session['user_id'] = member.get('user_id', '')
                session['login_timestamp'] = datetime.now().isoformat()
                session['client_ip'] = request.remote_addr
                
                app.logger.info(f"Successful login for user: {member.get('user_id', 'unknown')}, role: {user_role}, portal: {selected_role}")
                
                # Redirect based on role
                if user_role == 'Technical Director':
                    return redirect(url_for('tech_director_dashboard'))
                else:
                    return redirect(url_for('dashboard'))
        except Exception as e:
            app.logger.warning(f"Failed login attempt for portal: {selected_role}")
            flash('Invalid credentials', 'error')
    
    return render_template('login.html', selected_role=selected_role, members=filtered_members)

@app.route('/logout')
def logout():
    """Enhanced logout with proper session cleanup and logging"""
    try:
        user_id = session.get('member_id', 'unknown')
        user_name = session.get('member_name', 'unknown')
        app.logger.info(f"User {user_name} ({user_id}) logging out")
        
        # Clear all session data
        session.clear()
        
        # Show success message and redirect to portal
        flash('You have been successfully logged out.', 'success')
        return redirect(url_for('portal'))
        
    except Exception as e:
        app.logger.error(f"Error during logout: {e}")
        # Clear session anyway and redirect
        session.clear()
        return redirect(url_for('portal'))



@app.route('/favicon.ico')
@app.route('/favicon.png')  
def favicon():
    """Handle favicon requests to prevent 404 errors"""
    try:
        return send_from_directory('static', 'logo.png')
    except:
        return '', 404

@app.route('/members')
def member_management():
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    db = get_db()
    # Check if current user is admin - Technical Director NOT allowed
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        # Redirect Technical Director to their dashboard
        if current_member and current_member['role'] == 'Technical Director':
            return redirect(url_for('tech_director_dashboard'))
        return redirect(url_for('dashboard'))
    
    members = db.get_all_members()
    # Convert ObjectIds to strings for template
    for member in members:
        member['_id'] = str(member['_id'])
    
    return render_template('members.html', 
                         members=members,
                         current_user=session.get('member_name'),
                         current_user_role=current_member['role'])

@app.route('/admin')
def admin_panel():
    """Admin panel for managing technicians and system settings"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if current user is admin - Technical Director NOT allowed
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return render_template('error.html', error="Access denied. Administrator access required."), 403
    
    try:
        db = get_db()
        
        # Initialize default statuses if needed
        db.initialize_default_statuses()
        
        tickets = db.get_all_tickets()
        members = db.get_all_members()
        statuses = db.get_all_ticket_statuses()
        technicians = db.get_all_technicians()
        all_roles = db.get_all_roles()
        
        #  FILTER TO ONLY 3 CORE ROLES FOR ADMIN PANEL
        allowed_role_names = ['Administrator', 'Technical Director', 'User']
        roles = [role for role in all_roles if role.get('name') in allowed_role_names]
        
        # Convert ObjectId to string for JSON serialization
        for ticket in tickets:
            ticket['_id'] = str(ticket['_id'])
        
        for member in members:
            member['_id'] = str(member['_id'])
        
        for status in statuses:
            status['_id'] = str(status['_id'])
            
        for tech in technicians:
            tech['_id'] = str(tech['_id'])
            
        for role in roles:
            role['_id'] = str(role['_id'])
        
        # Calculate stats - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(tickets)
        total_tickets = db.get_tickets_count()
        open_tickets = len([t for t in tickets if t.get('status') == 'Open'])
        resolved_tickets = len([t for t in tickets if t.get('status') == 'Resolved'])
        
        # Priority breakdown
        priorities = {}
        for ticket in tickets:
            priority = ticket.get('priority', 'Medium')
            priorities[priority] = priorities.get(priority, 0) + 1
        
        # Classification breakdown
        classifications = {}
        for ticket in tickets:
            classification = ticket.get('classification', 'General')
            classifications[classification] = classifications.get(classification, 0) + 1
        
        return render_template('admin.html',
                             tickets=tickets,
                             members=members,
                             statuses=statuses,
                             technicians=technicians,
                             roles=roles,
                             total_tickets=total_tickets,
                             open_tickets=open_tickets,
                             resolved_tickets=resolved_tickets,
                             priorities=priorities,
                             classifications=classifications,
                             current_user=session.get('member_name', 'Unknown'),
                             current_user_role=member_role)
    except Exception as e:
        app.logger.error(f"Error loading admin panel: {e}")
        return render_template('error.html', error="Failed to load admin panel"), 500

@app.route('/api/members', methods=['GET', 'POST'])
def manage_members():
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 403
    
    if request.method == 'GET':
        # Fetch all members for admin panel
        try:
            members = db.get_all_members()
            # Convert ObjectIds to strings for JSON serialization
            for member in members:
                member['_id'] = str(member['_id'])
            return jsonify({
                'status': 'success',
                'members': members
            })
        except Exception as e:
            app.logger.error(f"Error fetching members: {e}")
            return jsonify({'status': 'error', 'message': 'Failed to fetch members'}), 500
    
    elif request.method == 'POST':
        # Add new member
        data = request.json
        required_fields = ['name', 'role', 'gender', 'user_id', 'password']
        
        if not all(field in data for field in required_fields):
            return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400
            
        if data['password'] != data.get('confirm_password', ''):
            return jsonify({'status': 'error', 'message': 'Passwords do not match'}), 400
            
        try:
            # Check if user_id already exists
            existing_member = db.get_member_by_user_id(data['user_id'])
            if existing_member:
                return jsonify({'status': 'error', 'message': 'User ID already exists'}), 400
            
            member_data = {
                'name': data['name'],
                'role': data['role'],
                'gender': data['gender'],
                'user_id': data['user_id'],
                'password_hash': generate_password_hash(data['password'])
            }
            
            db.create_member(member_data)
            return jsonify({'status': 'success'})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/members/<member_id>', methods=['PUT', 'DELETE'])
def manage_member(member_id):
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    # Check admin permissions using session role (consistent with admin panel)
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    # Get database connection
    db = get_db()
    
    if request.method == 'PUT':
        data = request.json
        try:
            update_data = {
                'name': data['name'],
                'role': data['role'],
                'gender': data['gender']
            }
            
            if 'password' in data and data['password']:
                if data['password'] != data.get('confirm_password', ''):
                    return jsonify({'status': 'error', 'message': 'Passwords do not match'}), 400
                update_data['password_hash'] = generate_password_hash(data['password'])
            
            db.members.update_one(
                {'_id': ObjectId(member_id)},
                {'$set': update_data}
            )
            return jsonify({'status': 'success'})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500
            
    elif request.method == 'DELETE':
        try:
            app.logger.info(f"[DELETE] Attempting to delete member {member_id}")
            app.logger.info(f"[DELETE] Current user role: {member_role}")
            app.logger.info(f"[DELETE] Database connection: {db is not None}")
            
            # Validate member_id format
            try:
                ObjectId(member_id)
            except Exception as e:
                app.logger.error(f"[DELETE] Invalid ObjectId format: {member_id}")
                return jsonify({'status': 'error', 'message': 'Invalid member ID format'}), 400
            
            # Check if this is a protected user (additional backend protection)
            member_to_delete = db.members.find_one({'_id': ObjectId(member_id)})
            if member_to_delete and member_to_delete.get('user_id') in ['admin001', 'marc001']:
                app.logger.warning(f"[DELETE] Attempted to delete protected user: {member_to_delete.get('user_id')}")
                return jsonify({'status': 'error', 'message': 'Cannot delete protected administrator or technical director accounts'}), 403
            
            result = db.members.delete_one({'_id': ObjectId(member_id)})
            if result.deleted_count > 0:
                app.logger.info(f"[DELETE] Successfully deleted member {member_id}")
                return jsonify({'status': 'success', 'message': 'Member deleted successfully'})
            else:
                app.logger.warning(f"[DELETE] No member found with ID {member_id}")
                return jsonify({'status': 'error', 'message': 'Member not found'}), 404
        except Exception as e:
            app.logger.error(f"[DELETE] Error deleting member {member_id}: {e}")
            app.logger.error(f"[DELETE] Error type: {type(e).__name__}")
            import traceback
            app.logger.error(f"[DELETE] Traceback: {traceback.format_exc()}")
            return jsonify({'status': 'error', 'message': str(e)}), 500

# Add API endpoint to get technicians dynamically
@app.route('/api/technicians', methods=['GET'])
def get_technicians():
    """Get all active technicians from standalone technician collection"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        all_technicians = db.get_all_technicians()
        
        # Convert ObjectIds to strings and format response
        technicians = []
        for technician in all_technicians:
            technicians.append({
                'id': str(technician['_id']),
                'name': technician['name'],
                'is_active': technician.get('is_active', True),
                'created_at': technician.get('created_at', '')
            })
        
        return jsonify({
            'status': 'success',
            'technicians': technicians
        })
    except Exception as e:
        app.logger.error(f"Error getting technicians: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Add API endpoints for technician management
@app.route('/api/admin/technicians', methods=['POST'])
def create_technician():
    """Create a new technician (Admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin permissions
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    try:
        data = request.json
        name = data.get('name', '').strip()
        role = data.get('role', '').strip()
        email = data.get('email', '').strip()
        
        # Validate required fields
        if not name:
            return jsonify({'status': 'error', 'message': 'Technician name is required'}), 400
        if not role:
            return jsonify({'status': 'error', 'message': 'Technician role is required'}), 400
        if not email:
            return jsonify({'status': 'error', 'message': 'Technician email is required'}), 400
            
        # Validate email format
        import re
        if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
            return jsonify({'status': 'error', 'message': 'Invalid email format'}), 400
        
        db = get_db()
        technician_data = {
            'name': name,
            'role': role, 
            'email': email
        }
        technician_id = db.create_technician(technician_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Technician created successfully',
            'technician_id': str(technician_id)
        })
    except Exception as e:
        app.logger.error(f"Error creating technician: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/technicians/<technician_id>', methods=['PUT'])
def update_technician(technician_id):
    """Update a technician (Admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin permissions
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    try:
        data = request.json
        name = data.get('name', '').strip()
        role = data.get('role', '').strip()
        email = data.get('email', '').strip()
        is_active = data.get('is_active')
        
        db = get_db()
        update_data = {}
        
        # Handle field updates
        if name:
            update_data['name'] = name
        if role:
            update_data['role'] = role
        if email:
            # Validate email format if provided
            import re
            if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
                return jsonify({'status': 'error', 'message': 'Invalid email format'}), 400
            
            # Check for duplicate email (excluding current technician)
            from bson.objectid import ObjectId
            existing = db.technicians.find_one({"email": email, "_id": {"$ne": ObjectId(technician_id)}})
            if existing:
                return jsonify({'status': 'error', 'message': 'A technician with this email already exists'}), 400
                
            update_data['email'] = email
        
        # Handle activation/deactivation
        if is_active is not None:
            update_data['is_active'] = is_active
        
        if not update_data:
            return jsonify({'status': 'error', 'message': 'No data to update'}), 400
        
        result = db.update_technician(technician_id, update_data)
        
        if result.matched_count == 0:
            return jsonify({'status': 'error', 'message': 'Technician not found'}), 404
        
        action = 'activated' if is_active else 'updated'
        return jsonify({
            'status': 'success',
            'message': f'Technician {action} successfully'
        })
    except Exception as e:
        app.logger.error(f"Error updating technician {technician_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/technicians/<technician_id>/deactivate', methods=['POST'])
def deactivate_technician(technician_id):
    """Deactivate a technician (Admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin permissions
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    try:
        db = get_db()
        result = db.deactivate_technician(technician_id)
        
        if result.matched_count == 0:
            return jsonify({'status': 'error', 'message': 'Technician not found'}), 404
        
        return jsonify({
            'status': 'success',
            'message': 'Technician deactivated successfully'
        })
    except Exception as e:
        app.logger.error(f"Error deactivating technician {technician_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500



# Add AI-based warranty form detection
@app.route('/api/detect-warranty-form', methods=['POST'])
def detect_warranty_form():
    """AI-based warranty form detection with manual confirmation"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        # This is a placeholder implementation
        # In production, you would integrate with an AI service or use ML models
        
        data = request.json
        file_content = data.get('file_content', '')
        file_name = data.get('file_name', '')
        ticket_id = data.get('ticket_id', '')
        
        # Simple keyword-based detection (placeholder for AI)
        warranty_keywords = [
            'warranty', 'claim', 'dpf', 'diesel particulate filter',
            'vehicle registration', 'mileage', 'fault codes',
            'auto assist group', 'aftercare'
        ]
        
        keyword_matches = 0
        for keyword in warranty_keywords:
            if keyword.lower() in file_content.lower():
                keyword_matches += 1
        
        # Calculate confidence score
        confidence = min((keyword_matches / len(warranty_keywords)) * 100, 95)
        
        is_warranty_form = confidence > 30  # Threshold for detection
        
        if is_warranty_form:
            # Log the detection for manual review
            app.logger.info(f"Potential warranty form detected for ticket {ticket_id}: {file_name} (confidence: {confidence}%)")
            
            return jsonify({
                'status': 'success',
                'detected': True,
                'confidence': confidence,
                'message': f'Potential warranty form detected with {confidence:.1f}% confidence',
                'requires_manual_confirmation': True,
                'detected_keywords': [kw for kw in warranty_keywords if kw.lower() in file_content.lower()]
            })
        else:
            return jsonify({
                'status': 'success',
                'detected': False,
                'confidence': confidence,
                'message': 'This does not appear to be a warranty form',
                'requires_manual_confirmation': False
            })
            
    except Exception as e:
        app.logger.error(f"Error in warranty form detection: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Async webhook function for real-time behavior
def trigger_tech_director_webhook_async(ticket_id, ticket_data, assignment_method='referral', referred_by=None):
    """
    Asynchronous webhook trigger - runs in background thread for real-time behavior
    Does not block user interface - fires and forgets with retry logic
    """
    def webhook_worker():
        """Background worker for webhook call with retry logic"""
        max_retries = 3
        retry_delay = 1  # seconds
        
        for attempt in range(max_retries):
            try:
                # Prepare webhook payload
                db = get_db()
                metadata = db.get_ticket_metadata(ticket_id)
                vehicle_registration = 'Not specified'
                for meta in metadata:
                    if meta['key'] == 'vehicle_registration':
                        vehicle_registration = meta['value']
                        break
                
                app_domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
                if not app_domain.startswith('http'):
                    app_domain = f"https://{app_domain}"
                
                webhook_payload = {
                    'ticket_id': ticket_id,
                    'action': 'schedule_reminder',
                    'subject': ticket_data.get('subject', 'No Subject'),
                    'customer_name': ticket_data.get('name', 'Unknown Customer'),
                    'customer_email': ticket_data.get('email', ''),
                    'vehicle_registration': vehicle_registration,
                    'priority': ticket_data.get('priority', 'Medium'),
                    'classification': ticket_data.get('classification', 'General'),
                    'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
                    'app_domain': app_domain,
                    'ticket_url': f"{app_domain}/ticket/{ticket_id}",
                    'dashboard_url': f"{app_domain}/tech-director",
                    'referral_date': datetime.now().strftime('%B %d, %Y at %I:%M %p'),
                    'referred_by': referred_by or 'Support Team',
                    'assignment_method': assignment_method,
                    'reminder_context': f"This ticket requires your technical expertise and assessment. Please review ticket #{ticket_id} for {ticket_data.get('name', 'customer')} regarding '{ticket_data.get('subject', 'technical issue')}' (Vehicle: {vehicle_registration}). Priority: {ticket_data.get('priority', 'Medium')}"
                }
                
                WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
                
                app.logger.error(f"[LAUNCH] ASYNC WEBHOOK (Attempt {attempt + 1}/{max_retries}) - Ticket {ticket_id}")
                app.logger.error(f"[WEBHOOK] WEBHOOK URL: {WEBHOOK_URL}")
                app.logger.error(f"[PAYLOAD] WEBHOOK PAYLOAD: {webhook_payload}")
                
                # Fast webhook call optimized for production
                response = requests.post(
                    WEBHOOK_URL, 
                    json=webhook_payload, 
                    timeout=5,  # Reduced timeout for faster response
                    headers={'Content-Type': 'application/json'},
                    verify=True
                )
                
                response.raise_for_status()
                
                app.logger.info(f"[SUCCESS] ASYNC WEBHOOK SUCCESS - Ticket {ticket_id} (Attempt {attempt + 1})")
                app.logger.info(f"[SUCCESS] Response: {response.status_code} - {response.text[:100]}...")
                
                # Store success metadata
                db.add_ticket_metadata(ticket_id, 'async_webhook_triggered', datetime.now().isoformat())
                db.add_ticket_metadata(ticket_id, 'webhook_attempts', str(attempt + 1))
                db.add_ticket_metadata(ticket_id, 'webhook_method', assignment_method)
                
                return  # Success - exit retry loop
                
            except Exception as e:
                app.logger.warning(f"[WARNING] ASYNC WEBHOOK ATTEMPT {attempt + 1} FAILED - Ticket {ticket_id}: {e}")
                
                if attempt < max_retries - 1:  # Not the last attempt
                    app.logger.info(f"[RETRY] RETRYING in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    # Final attempt failed
                    app.logger.error(f"[ERROR] ASYNC WEBHOOK FINAL FAILURE - Ticket {ticket_id} after {max_retries} attempts")
                    try:
                        db.add_ticket_metadata(ticket_id, 'async_webhook_failed', datetime.now().isoformat())
                        db.add_ticket_metadata(ticket_id, 'webhook_attempts', str(max_retries))
                        db.add_ticket_metadata(ticket_id, 'webhook_error', str(e))
                    except:
                        pass  # Don't fail if metadata storage fails
    
    # Start background thread for async webhook
    webhook_thread = threading.Thread(target=webhook_worker, daemon=True)
    webhook_thread.start()
    
    app.logger.info(f"[LAUNCH] ASYNC WEBHOOK QUEUED - Ticket {ticket_id} (Background thread started)")
    return True  # Always return True for async - actual result happens in background


# Check if reminder is already scheduled for a ticket
def is_reminder_already_scheduled(ticket_id):
    """
    Check if a Tech Director reminder is already scheduled for this ticket
    Prevents duplicate webhooks and automatic replies
    """
    try:
        app.logger.info(f"[DEBUG] Checking reminder status for ticket {ticket_id}")
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        
        app.logger.info(f"[DEBUG] Found {len(metadata)} metadata entries for ticket {ticket_id}")
        
        for meta in metadata:
            app.logger.info(f"[DEBUG] Checking metadata key: {meta.get('key')} = {meta.get('value')}")
            if meta['key'] == 'webhook_triggered':
                # Check if webhook was triggered recently (within last 24 hours)
                try:
                    webhook_time = datetime.fromisoformat(meta['value'])
                    time_diff = datetime.now() - webhook_time
                    
                    app.logger.info(f"[DEBUG] Webhook was triggered at {webhook_time}, {time_diff.total_seconds()} seconds ago")
                    
                    # If webhook was triggered within 24 hours, don't send another
                    if time_diff.total_seconds() < 86400:  # 24 hours in seconds
                        app.logger.info(f"[WEBHOOK] Reminder already scheduled for ticket {ticket_id} within 24 hours")
                        return True
                    else:
                        app.logger.info(f"[DEBUG] Webhook was triggered more than 24 hours ago, allowing new webhook")
                except ValueError:
                    # If timestamp parsing fails, assume it's old and allow new webhook
                    app.logger.warning(f"[WEBHOOK] Failed to parse webhook timestamp for ticket {ticket_id}")
                    pass
        
        app.logger.info(f"[DEBUG] No existing webhook found for ticket {ticket_id}, allowing new webhook")
        return False
        
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to check reminder status for ticket {ticket_id}: {e}")
        # If we can't check, allow the webhook to proceed
        return False

# Centralized webhook trigger for Tech Director referrals (Synchronous for immediate feedback)
def trigger_tech_director_webhook(ticket_id, ticket_data, assignment_method='referral', referred_by=None):
    """
    Centralized function to trigger n8n webhook when ticket is referred to Tech Director
    
    Args:
        ticket_id: The ticket ID
        ticket_data: Complete ticket data
        assignment_method: How the ticket was referred ('referral', 'status_change', 'assignment')
        referred_by: Who referred the ticket
    """
    try:
        # Get database connection
        db = get_db()
        
        # Get vehicle registration from metadata if available
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Prepare app domain
        app_domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not app_domain.startswith('http'):
            app_domain = f"https://{app_domain}"
        
        # Prepare webhook payload for n8n
        webhook_payload = {
            'ticket_id': ticket_id,
            'action': 'schedule_reminder',
            'subject': ticket_data.get('subject', 'No Subject'),
            'customer_name': ticket_data.get('name', 'Unknown Customer'),
            'customer_email': ticket_data.get('email', ''),
            'vehicle_registration': vehicle_registration,
            'priority': ticket_data.get('priority', 'Medium'),
            'classification': ticket_data.get('classification', 'General'),
            'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
            'app_domain': app_domain,
            'ticket_url': f"{app_domain}/ticket/{ticket_id}",
            'dashboard_url': f"{app_domain}/tech-director",
            'referral_date': datetime.now().strftime('%B %d, %Y at %I:%M %p'),
            'referred_by': referred_by or session.get('member_name', 'Support Team'),
            'assignment_method': assignment_method,
            'reminder_context': f"This ticket requires your technical expertise and assessment. Please review ticket #{ticket_id} for {ticket_data.get('name', 'customer')} regarding '{ticket_data.get('subject', 'technical issue')}' (Vehicle: {vehicle_registration}). Priority: {ticket_data.get('priority', 'Medium')}"
        }
        
        # Check if reminder is already scheduled to prevent duplicates
        app.logger.info(f"[DEBUG] Checking if reminder already scheduled for ticket {ticket_id}")
        if is_reminder_already_scheduled(ticket_id):
            app.logger.info(f"[WEBHOOK] Skipping webhook for ticket {ticket_id} - reminder already scheduled")
            return True
        
        app.logger.info(f"[DEBUG] No existing reminder found - proceeding with webhook for ticket {ticket_id}")
        
        # n8n webhook URL - using the working production URL
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.info(f"[LAUNCH] TRIGGERING TECH DIRECTOR WEBHOOK for ticket {ticket_id}")
        app.logger.info(f"[WEBHOOK] Webhook URL: {WEBHOOK_URL}")
        app.logger.info(f"[WEBHOOK] Payload: {webhook_payload}")
        
        # Send webhook request to n8n with production-optimized configuration
        app.logger.info(f"[DEBUG] Sending webhook request to {WEBHOOK_URL}")
        response = requests.post(
            WEBHOOK_URL, 
            json=webhook_payload, 
            timeout=8,  # Reduced timeout for production
            headers={'Content-Type': 'application/json'},
            verify=True
        )
        
        app.logger.info(f"[DEBUG] Webhook request completed with status {response.status_code}")
        
        # Log detailed response info before raising for status
        app.logger.info(f"[WEBHOOK] WEBHOOK RESPONSE STATUS: {response.status_code}")
        app.logger.info(f"[WEBHOOK] WEBHOOK RESPONSE HEADERS: {dict(response.headers)}")
        app.logger.info(f"[WEBHOOK] WEBHOOK RESPONSE CONTENT: {response.text[:500]}...")  # First 500 chars
        
        response.raise_for_status()
        
        # Log success
        app.logger.info(f"[SUCCESS] WEBHOOK SUCCESS: Tech Director reminder scheduled for ticket {ticket_id}")
        app.logger.info(f"[SUCCESS] n8n Response: {response.status_code} - {response.text[:200]}")
        
        # Store webhook metadata
        app.logger.info(f"[DEBUG] Storing webhook metadata for ticket {ticket_id}")
        db.add_ticket_metadata(ticket_id, 'webhook_triggered', datetime.now().isoformat())
        db.add_ticket_metadata(ticket_id, 'webhook_url', WEBHOOK_URL)
        db.add_ticket_metadata(ticket_id, 'webhook_method', assignment_method)
        db.add_ticket_metadata(ticket_id, 'referred_by', webhook_payload['referred_by'])
        
        app.logger.info(f"[DEBUG] Webhook metadata stored successfully for ticket {ticket_id}")
        return True
        
    except requests.exceptions.RequestException as e:
        app.logger.error(f"[ERROR] WEBHOOK REQUEST FAILED for ticket {ticket_id}: {e}")
        app.logger.error(f"[ERROR] WEBHOOK URL: {WEBHOOK_URL}")
        app.logger.error(f"[ERROR] WEBHOOK PAYLOAD: {webhook_payload}")
        if hasattr(e, 'response') and e.response is not None:
            app.logger.error(f"[ERROR] Response status: {e.response.status_code}")
            app.logger.error(f"[ERROR] Response content: {e.response.text}")
            app.logger.error(f"[ERROR] Response headers: {dict(e.response.headers)}")
        else:
            app.logger.error(f"[ERROR] No response received - connection/timeout error")
        return False
        
    except Exception as e:
        app.logger.error(f"[ERROR] WEBHOOK UNEXPECTED ERROR for ticket {ticket_id}: {e}")
        app.logger.error(f"[ERROR] Error type: {type(e).__name__}")
        import traceback
        app.logger.error(f"[ERROR] Traceback: {traceback.format_exc()}")
        return False


# Cancel Tech Director reminder when ticket is no longer referred
def cancel_tech_director_reminder(ticket_id):
    """
    Cancel Tech Director reminder when ticket status changes away from 'Referred to Tech Director'
    Prevents unnecessary reminders for resolved tickets
    """
    try:
        # Prepare cancellation payload
        cancellation_payload = {
            'ticket_id': ticket_id,
            'action': 'cancel_reminder',
            'reason': 'Ticket status changed',
            'responded_by': 'System',
            'cancelled_at': datetime.now().isoformat()
        }
        
        # n8n webhook URL for cancellation
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.info(f"[CANCEL] Cancelling Tech Director reminder for ticket {ticket_id}")
        
        # Send cancellation webhook
        response = requests.post(
            WEBHOOK_URL,
            json=cancellation_payload,
            timeout=5,
            headers={'Content-Type': 'application/json'},
            verify=True
        )
        
        if response.ok:
            app.logger.info(f"[SUCCESS] Reminder cancelled for ticket {ticket_id}")
            # Update metadata to indicate cancellation
            db = get_db()
            db.add_ticket_metadata(ticket_id, 'reminder_cancelled', datetime.now().isoformat())
            return True
        else:
            app.logger.warning(f"[WARNING] Failed to cancel reminder for ticket {ticket_id}: {response.status_code}")
            return False
            
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to cancel reminder for ticket {ticket_id}: {e}")
        return False


# Add Technical Director referral email notification
def send_tech_director_referral_email(ticket_id, ticket_data):
    """Send email notification to Technical Director when ticket is referred"""
    try:
        # Technical Director email
        tech_director_email = os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com')
        
        # Get domain for links (fallback for local development)
        domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not domain.startswith('http'):
            domain = f"https://{domain}"
        
        subject = f"? URGENT: Technical Review Required - Ticket #{ticket_id}"
        
        # Get vehicle registration from metadata if available
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Plain text body
        body = """Dear Marc,

A support ticket has been escalated and requires your immediate technical review.

? TICKET DETAILS:
???????????????????
? Ticket ID: #{ticket_id}
? Subject: {ticket_data.get('subject', 'No Subject')}
? Customer: {ticket_data.get('name', 'Unknown')}
? Email: {ticket_data.get('email', 'Not provided')}
? Vehicle Registration: {vehicle_registration}
? Priority: {ticket_data.get('priority', 'Medium')}
? Classification: {ticket_data.get('classification', 'General')}

? QUICK ACTIONS:
???????????????????
? Review Ticket: {domain}/ticket/{ticket_id}
? Tech Director Portal: {domain}/tech-director

? This ticket requires your technical expertise and assessment.
Please review and provide your recommendations as soon as possible.

Best regards,
AutoAssistGroup Support System
        """

        # HTML body for better formatting
        html_body = """
        <html>
        <body style="font-family: Arial, sans-serif; line-height: 1.6; color: #333;">
            <div style="max-width: 600px; margin: 0 auto; padding: 20px;">
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px 10px 0 0;">
                    <h1 style="margin: 0; font-size: 24px;">? Technical Review Required</h1>
                    <p style="margin: 5px 0 0 0; opacity: 0.9;">Ticket #{ticket_id} needs your expertise</p>
                </div>
                
                <div style="background: #f8f9fa; padding: 25px; border-radius: 0 0 10px 10px; border: 1px solid #e9ecef;">
                    <div style="background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h2 style="color: #495057; margin-top: 0;">? Ticket Information</h2>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Ticket ID:</td><td style="padding: 8px 0;">#{ticket_id}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Subject:</td><td style="padding: 8px 0;">{ticket_data.get('subject', 'No Subject')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Customer:</td><td style="padding: 8px 0;">{ticket_data.get('name', 'Unknown')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Email:</td><td style="padding: 8px 0;">{ticket_data.get('email', 'Not provided')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Vehicle Reg:</td><td style="padding: 8px 0;">{vehicle_registration}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Priority:</td><td style="padding: 8px 0;"><span style="background: #ff6b6b; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px;">{ticket_data.get('priority', 'Medium')}</span></td></tr>
                        </table>
                    </div>
                    
                    <div style="text-align: center; margin: 25px 0;">
                        <a href="{domain}/ticket/{ticket_id}" style="background: #28a745; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">? Review Ticket</a>
                        <a href="{domain}/tech-director" style="background: #17a2b8; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">?? Dashboard</a>
                    </div>
                    
                    <div style="background: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 6px; margin-top: 20px;">
                        <p style="margin: 0; color: #856404;"><strong>? Action Required:</strong> This ticket requires your immediate technical assessment and recommendations.</p>
                    </div>
                </div>
                
                <div style="text-align: center; margin-top: 20px; color: #6c757d; font-size: 12px;">
                    <p>AutoAssistGroup Support System | Automated Notification</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Send the email using our email service
        success = email_service.send_email(
            to_email=tech_director_email,
            subject=subject,
            body=body,
            html_body=html_body
        )
        
        if success:
            app.logger.info(f"Tech Director referral email sent successfully to {tech_director_email} for ticket {ticket_id}")
            
            # [LAUNCH] NEW: Trigger async webhook for real-time reminder scheduling
            # ðŸš¨ TEMPORARILY DISABLED: Tech Director webhook causing automatic replies
            # webhook_queued = trigger_tech_director_webhook_async(ticket_id, ticket_data, 'email_referral')
            webhook_queued = False
            app.logger.warning(f"ðŸš¨ TECH DIRECTOR WEBHOOK DISABLED - Ticket {ticket_id} to prevent automatic replies")
            app.logger.info(f"[SUCCESS] Tech Director async webhook queued for ticket {ticket_id}")
            
        else:
            app.logger.error(f"Failed to send tech director referral email for ticket {ticket_id}")
        
        return success
    except Exception as e:
        app.logger.error(f"Failed to send tech director referral email: {e}")
        return False


# New API endpoint for Tech Director referral button
@app.route('/api/tickets/<ticket_id>/tech-director', methods=['POST'])
def refer_to_tech_director(ticket_id):
    """Dedicated endpoint to refer ticket to Tech Director and trigger webhook"""
    
    # Enhanced error handling and debugging
    app.logger.info(f"[TARGET] TECH DIRECTOR REFERRAL - Ticket: {ticket_id}")
    
    if 'member_id' not in session:
        app.logger.warning(f"[ERROR] UNAUTHORIZED - No session for tech director referral {ticket_id}")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in'}), 401
    
    try:
        db = get_db()
        
        # Get the ticket
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Enhanced validation for referral with consistency check
        current_status = ticket.get('status')
        
        # Check if ticket is already referred to tech director
        if current_status == 'Referred to Tech Director':
            # Check if it's truly with tech director or has assignment conflicts
            assignment = db.get_assignment_by_ticket(ticket_id)
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    if (assigned_member and 
                        assigned_member.get('role') != 'Technical Director' and 
                        assignment.get('is_forwarded', False)):
                        # Status is wrong - this ticket was forwarded back but status not updated
                        app.logger.warning(f"[FIX] FIXING STATUS INCONSISTENCY - Ticket {ticket_id} shows 'Referred to Tech Director' but is assigned to {assigned_member.get('name', 'Unknown')}")
                        
                        # Fix the status automatically based on assigned member role
                        target_role = assigned_member.get('role', 'Support')
                        if target_role == 'Administrator':
                            corrected_status = 'Open'
                        elif target_role in ['Support', 'Engineer', 'IT']:
                            corrected_status = 'Under Review'
                        else:
                            corrected_status = 'Open'
                        
                        db.update_ticket(ticket_id, {
                            'status': corrected_status,
                            'updated_at': datetime.now(),
                            'status_auto_fixed': f'Corrected from forwarded state - assigned to {assigned_member.get("name", "Unknown")}',
                            'previous_inconsistent_status': 'Referred to Tech Director'
                        })
                        
                        app.logger.info(f"[SUCCESS] AUTO-FIXED INCONSISTENCY - Ticket {ticket_id} status corrected to '{corrected_status}' (assigned to {assigned_member.get('name')})")
                        
                        # Now proceed with the referral since status is fixed
                    else:
                        # Ticket is genuinely with tech director
                        return jsonify({'status': 'error', 'message': 'Ticket is already referred to Tech Director'}), 400
                else:
                    app.logger.error(f"[ERROR] TICKET {ticket_id} has assignment but no member_id")
            else:
                # No assignment but status shows referred - this is also inconsistent
                app.logger.warning(f"[FIX] FIXING ORPHANED STATUS - Ticket {ticket_id} shows 'Referred to Tech Director' but has no assignment")
                # Allow the referral to proceed and fix the issue
        
        # Get referrer information
        referrer_name = session.get('member_name', 'Support Team')
        referrer_id = session.get('member_id')
        
        # [FIX] CRITICAL FIX: Clear any existing assignments when making direct referral
        # FIXED: Preserve assignments when referring to Tech Director
        existing_assignment = db.get_assignment_by_ticket(ticket_id)
        if existing_assignment:
            assigned_member_id = existing_assignment.get('member_id')
            app.logger.info(f"[PRESERVE] KEEPING ASSIGNMENT - Ticket {ticket_id} has assignment, preserving during Tech Director referral")
            # DON'T remove assignment - user can still work on it while Tech Director reviews
        
        # Update ticket status to "Referred to Tech Director"
        db.update_ticket(ticket_id, {
            'status': 'Referred to Tech Director',
            'updated_at': datetime.now(),
            'referred_to_tech_director_by': referrer_name,
            'referred_to_tech_director_at': datetime.now(),
            'referral_method': 'direct_button',
            'old_assignment_cleared': existing_assignment is not None
        })
        
        app.logger.info(f"[TARGET] MANUAL TECH DIRECTOR REFERRAL - Ticket {ticket_id} referred by {referrer_name}")
        
        # Send email notification to Tech Director
        email_success = send_tech_director_referral_email(ticket_id, ticket)
        if email_success:
            app.logger.info(f"[SUCCESS] Tech Director referral email sent for ticket {ticket_id}")
        else:
            app.logger.warning(f"[WARNING] Tech Director referral email failed for ticket {ticket_id}")
        
        # âœ… RE-ENABLED: Tech Director webhook with duplicate prevention
        webhook_queued = trigger_tech_director_webhook(ticket_id, ticket, 'manual_referral', referrer_name)
        if webhook_queued:
            app.logger.info(f"âœ… TECH DIRECTOR WEBHOOK ENABLED - Reminder scheduled for ticket {ticket_id}")
        else:
            app.logger.info(f"â„¹ï¸ TECH DIRECTOR WEBHOOK SKIPPED - Reminder already exists for ticket {ticket_id}")
        
        # Note: webhook_queued is always True for async - actual result happens in background
        
        # Add metadata to track the referral
        db.add_ticket_metadata(ticket_id, 'referred_by_manual_button', referrer_name)
        db.add_ticket_metadata(ticket_id, 'referral_method', 'manual_button')
        db.add_ticket_metadata(ticket_id, 'referral_timestamp', datetime.now().isoformat())
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket successfully referred to Tech Director',
            'ticket_id': ticket_id,
            'referred_by': referrer_name,
            'email_sent': email_success,
            'webhook_queued': webhook_queued,
            'real_time_mode': True,
            'note': 'Webhook running in background - check logs for completion status'
        })
        
    except Exception as e:
        app.logger.error(f"Error referring ticket {ticket_id} to Tech Director: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to refer ticket to Tech Director'}), 500


# Real-time webhook status endpoint
@app.route('/api/tickets/<ticket_id>/webhook-status', methods=['GET'])
def get_webhook_status(ticket_id):
    """Get real-time status of async webhook for a ticket"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get webhook-related metadata
        metadata = db.get_ticket_metadata(ticket_id)
        webhook_data = {}
        
        for meta in metadata:
            if meta['key'] in ['async_webhook_triggered', 'async_webhook_failed', 'webhook_attempts', 'webhook_method', 'webhook_error']:
                webhook_data[meta['key']] = meta['value']
        
        # Determine status
        if 'async_webhook_triggered' in webhook_data:
            status = 'completed'
            message = 'Webhook completed successfully'
        elif 'async_webhook_failed' in webhook_data:
            status = 'failed'
            message = f"Webhook failed: {webhook_data.get('webhook_error', 'Unknown error')}"
        else:
            status = 'pending'
            message = 'Webhook still processing in background'
        
        return jsonify({
            'status': 'success',
            'webhook_status': status,
            'message': message,
            'attempts': webhook_data.get('webhook_attempts', '0'),
            'method': webhook_data.get('webhook_method', 'unknown'),
            'details': webhook_data
        })
        
    except Exception as e:
        app.logger.error(f"Error getting webhook status for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to get webhook status'}), 500


# Webhook health monitoring endpoint
@app.route('/api/webhook/health', methods=['GET'])
def webhook_health():
    """Get overall health status of the webhook system"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        health_status = get_webhook_health_status()
        
        return jsonify({
            'status': 'success',
            'webhook_health': health_status,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error getting webhook health: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to get webhook health'}), 500


# Webhook cleanup endpoint (admin only)
@app.route('/api/webhook/cleanup', methods=['POST'])
def webhook_cleanup():
    """Clean up old webhook metadata (admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        # Check if user is admin
        db = get_db()
        member = db.get_member_by_id(session['member_id'])
        if not member or member.get('role') != 'Administrator':
            return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
        
        cleaned_count = cleanup_old_webhook_metadata()
        
        return jsonify({
            'status': 'success',
            'message': f'Cleaned up {cleaned_count} old webhook metadata records',
            'cleanup_count': cleaned_count,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error in webhook cleanup: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to cleanup webhook metadata'}), 500


# Debug endpoint for Tech Director referral issues
@app.route('/api/debug/tech-director-tickets', methods=['GET'])
def debug_tech_director_tickets():
    """Debug endpoint to check Tech Director ticket filtering"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get all tickets with "Referred to Tech Director" status
        all_referred = db.get_tickets_by_status("Referred to Tech Director")
        
        # Get tickets with assignments
        tickets_with_assignments = db.get_tickets_with_assignments()
        referred_with_assignments = [t for t in tickets_with_assignments if t.get('status') == "Referred to Tech Director"]
        
        debug_info = {
            'total_referred_tickets': len(all_referred),
            'referred_with_assignments': len(referred_with_assignments),
            'tickets': []
        }
        
        for ticket in all_referred:
            ticket_info = {
                'ticket_id': ticket.get('ticket_id'),
                'status': ticket.get('status'),
                'subject': ticket.get('subject'),
                'created_at': str(ticket.get('created_at')),
                'has_assignment': bool(db.get_assignment_by_ticket(ticket.get('ticket_id')))
            }
            debug_info['tickets'].append(ticket_info)
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info
        })
        
    except Exception as e:
        app.logger.error(f"Error in debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Debug endpoint for testing re-referral functionality
@app.route('/api/debug/re-referral-test/<ticket_id>', methods=['GET'])
def debug_re_referral_test(ticket_id):
    """Debug endpoint to test re-referral to Tech Director functionality"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get current user info
        current_user = session.get('member_name', 'Unknown')
        current_role = session.get('member_role', 'Unknown')
        
        # Get ticket info
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Get assignment info
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        # Check if ticket was forwarded back from Tech Director
        was_forwarded_back = False
        if assignment and assignment.get('is_forwarded', False) and assignment.get('forwarded_from_tech_director', False):
            was_forwarded_back = True
        
        # Check if ticket can be re-referred
        can_re_refer = (ticket.get('status') != 'Referred to Tech Director' and 
                       ticket.get('status') != 'Closed' and 
                       ticket.get('status') != 'Resolved')
        
        debug_info = {
            'ticket_id': ticket_id,
            'ticket_status': ticket.get('status'),
            'current_user': current_user,
            'current_role': current_role,
            'assignment': assignment,
            'was_forwarded_back': was_forwarded_back,
            'can_re_refer': can_re_refer,
            'referred_to_tech_director_by': ticket.get('referred_to_tech_director_by'),
            'referred_to_tech_director_at': str(ticket.get('referred_to_tech_director_at')) if ticket.get('referred_to_tech_director_at') else None,
            'forwarded_from_tech_director': ticket.get('forwarded_from_tech_director'),
            'forwarded_from_tech_director_to': ticket.get('forwarded_from_tech_director_to')
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info,
            'message': f'Re-referral test data for ticket {ticket_id}'
        })
        
    except Exception as e:
        app.logger.error(f"Error in re-referral test debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Debug endpoint for testing forward functionality
@app.route('/api/debug/forward-test/<ticket_id>', methods=['GET'])
def debug_forward_test(ticket_id):
    """Debug endpoint to test forward functionality"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get current user info
        current_user = session.get('member_name', 'Unknown')
        current_role = session.get('member_role', 'Unknown')
        
        # Get ticket assignment info
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        # Get all members for testing
        all_members = db.get_all_members()
        
        debug_info = {
            'ticket_id': ticket_id,
            'current_user': current_user,
            'current_role': current_role,
            'current_assignment': assignment,
            'available_members': [
                {
                    'id': str(member.get('_id')),
                    'name': member.get('name'),
                    'role': member.get('role')
                } for member in all_members
            ]
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info,
            'message': f'Forward test data for ticket {ticket_id}'
        })
        
    except Exception as e:
        app.logger.error(f"Error in forward test debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Debug endpoint specifically for user referral testing
@app.route('/api/debug/user-referral-test', methods=['GET'])
def debug_it_member_referral_test():
    """Debug endpoint to test user referral functionality"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get current user info
        current_user = session.get('member_name', 'Unknown')
        current_role = session.get('member_role', 'Unknown')
        
        # Get all tickets with "Referred to Tech Director" status
        all_referred = db.get_tickets_by_status("Referred to Tech Director")
        
        # Check which tickets were referred by users
        it_member_referrals = []
        for ticket in all_referred:
            # Check if ticket has referral metadata
            metadata = db.get_ticket_metadata(ticket.get('ticket_id'))
            referred_by = None
            for meta in metadata:
                if isinstance(meta, dict) and meta.get('key') == 'referred_by_manual_button':
                    referred_by = meta.get('value')
                    break
            
            if referred_by:
                it_member_referrals.append({
                    'ticket_id': ticket.get('ticket_id'),
                    'subject': ticket.get('subject'),
                    'referred_by': referred_by,
                    'status': ticket.get('status'),
                    'created_at': str(ticket.get('created_at'))
                })
        
        debug_info = {
            'current_user': current_user,
            'current_role': current_role,
            'total_referred_tickets': len(all_referred),
            'it_member_referrals': it_member_referrals,
            'it_member_referral_count': len(it_member_referrals)
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info,
            'message': f'Found {len(it_member_referrals)} tickets referred by users'
        })
        
    except Exception as e:
        app.logger.error(f"Error in user referral debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Test endpoint for n8n webhook connection
@app.route('/api/test-webhook', methods=['POST', 'GET'])
def test_webhook():
    """Test the n8n webhook connection directly"""
    
    # Check if user is authenticated
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    # Check if user has permission (admin or support team)
    try:
        db = get_db()
        member = db.get_member_by_id(session['member_id'])
        if not member or member.get('role') not in ['Administrator', 'Support Team', 'Technical Director']:
            return jsonify({'status': 'error', 'message': 'Insufficient permissions'}), 403
    except Exception as e:
        app.logger.error(f"Error checking user permissions: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to verify permissions'}), 500
    try:
        # Test payload
        test_payload = {
            'ticket_id': 'TEST123',
            'action': 'test_connection',
            'test_timestamp': datetime.now().isoformat(),
            'message': 'This is a test webhook call from the AutoAssist system',
            'customer_name': 'Test Customer',
            'customer_email': 'test@example.com',
            'subject': 'Test Webhook Connection',
            'priority': 'Medium',
            'classification': 'Test',
            'referred_by': 'System Test',
            'assignment_method': 'webhook_test'
        }
        
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.info(f"? TESTING WEBHOOK CONNECTION")
        app.logger.info(f"[WEBHOOK] URL: {WEBHOOK_URL}")
        app.logger.info(f"[PAYLOAD] Test Payload: {test_payload}")
        
        # Send test webhook request
        response = requests.post(WEBHOOK_URL, json=test_payload, timeout=15)
        
        app.logger.info(f"[SUCCESS] Webhook Response Status: {response.status_code}")
        app.logger.info(f"[SUCCESS] Webhook Response Content: {response.text}")
        app.logger.info(f"[SUCCESS] Webhook Response Headers: {dict(response.headers)}")
        
        response.raise_for_status()
        
        # Test the duplicate prevention system
        test_ticket_id = 'TEST_WEBHOOK_123'
        
        # First call should succeed
        first_call = trigger_tech_director_webhook(test_ticket_id, {
            'subject': 'Test Webhook Duplicate Prevention',
            'name': 'Test Customer',
            'email': 'test@example.com',
            'priority': 'High',
            'classification': 'Test'
        }, 'webhook_test', 'System Test')
        
        # Second call should be prevented (duplicate)
        second_call = trigger_tech_director_webhook(test_ticket_id, {
            'subject': 'Test Webhook Duplicate Prevention - Second Call',
            'name': 'Test Customer',
            'email': 'test@example.com',
            'priority': 'High',
            'classification': 'Test'
        }, 'webhook_test', 'System Test')
        
        # Clean up test metadata
        try:
            db = get_db()
            db.remove_ticket_metadata(test_ticket_id, 'webhook_triggered')
            db.remove_ticket_metadata(test_ticket_id, 'webhook_url')
            db.remove_ticket_metadata(test_ticket_id, 'webhook_method')
            db.remove_ticket_metadata(test_ticket_id, 'referred_by')
        except Exception as cleanup_error:
            app.logger.warning(f"Failed to cleanup test metadata: {cleanup_error}")
        
        return jsonify({
            'status': 'success',
            'message': 'Webhook test successful with duplicate prevention',
            'webhook_url': WEBHOOK_URL,
            'response_status': response.status_code,
            'response_content': response.text,
            'payload_sent': test_payload,
            'duplicate_prevention_test': {
                'first_call_success': first_call,
                'second_call_prevented': not second_call,
                'duplicate_prevention_working': first_call and not second_call
            }
        })
        
    except requests.exceptions.RequestException as e:
        error_details = {
            'error_type': 'RequestException',
            'error_message': str(e),
            'webhook_url': WEBHOOK_URL
        }
        
        if hasattr(e, 'response') and e.response is not None:
            error_details.update({
                'response_status': e.response.status_code,
                'response_content': e.response.text,
                'response_headers': dict(e.response.headers)
            })
            app.logger.error(f"[ERROR] WEBHOOK TEST FAILED - Status: {e.response.status_code}, Content: {e.response.text}")
        else:
            error_details['connection_error'] = 'No response received - connection/timeout error'
            app.logger.error(f"[ERROR] WEBHOOK TEST FAILED - Connection error")
        
        app.logger.error(f"[ERROR] WEBHOOK TEST ERROR: {e}")
        
        return jsonify({
            'status': 'error',
            'message': 'Webhook test failed',
            'error_details': error_details
        }), 500
        
    except Exception as e:
        app.logger.error(f"[ERROR] WEBHOOK TEST UNEXPECTED ERROR: {e}")
        import traceback
        app.logger.error(f"[ERROR] Traceback: {traceback.format_exc()}")
        
        return jsonify({
            'status': 'error',
            'message': 'Webhook test failed with unexpected error',
            'error_type': type(e).__name__,
            'error_message': str(e)
        }), 500

# Add Support team notification when Tech Director responds
def send_support_team_notification(ticket_id, ticket_data, feedback_data):
    """Send email notification to Support team when Tech Director provides feedback"""
    try:
        # Support team email (can be multiple recipients)
        support_emails = os.environ.get('SUPPORT_TEAM_EMAILS', 'support@autoassistgroup.com').split(',')
        
        # Get domain for links
        domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not domain.startswith('http'):
            domain = f"https://{domain}"
        
        subject = f"[SUCCESS] Technical Assessment Complete - Ticket #{ticket_id}"
        
        # Get vehicle registration from metadata if available
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Plain text body
        body = """Support Team,

The Technical Director has completed their assessment for ticket #{ticket_id}.

? TICKET DETAILS:
???????????????????
? Ticket ID: #{ticket_id}
? Subject: {ticket_data.get('subject', 'No Subject')}
? Customer: {ticket_data.get('name', 'Unknown')}
? Vehicle Registration: {vehicle_registration}

? TECHNICAL ASSESSMENT:
???????????????????????
? Assessment Category: {feedback_data.get('assessment_category', 'Not specified')}
? Reviewed by: {feedback_data.get('reviewer', 'Technical Director')}
? Date: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}

[NOTE] TECHNICAL NOTES:
???????????????????
{feedback_data.get('tech_director_notes', 'No notes provided')}

{f"[FIX] RECOMMENDED ACTION:\n{feedback_data.get('recommended_action')}\n" if feedback_data.get('recommended_action') else ''}

? NEXT STEPS:
???????????????????
? Review the assessment: {domain}/ticket/{ticket_id}
? Follow up with customer as needed
? Implement recommended actions

This ticket is now ready for Support team follow-up action.

Best regards,
AutoAssistGroup Support System
"""

        # HTML body for better formatting
        html_body = """
        <html>
        <body style="font-family: Arial, sans-serif; line-height: 1.6; color: #333;">
            <div style="max-width: 600px; margin: 0 auto; padding: 20px;">
                <div style="background: linear-gradient(135deg, #28a745 0%, #20c997 100%); color: white; padding: 20px; border-radius: 10px 10px 0 0;">
                    <h1 style="margin: 0; font-size: 24px;">[SUCCESS] Technical Assessment Complete</h1>
                    <p style="margin: 5px 0 0 0; opacity: 0.9;">Ticket #{ticket_id} ready for follow-up</p>
                </div>
                
                <div style="background: #f8f9fa; padding: 25px; border-radius: 0 0 10px 10px; border: 1px solid #e9ecef;">
                    <div style="background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h2 style="color: #495057; margin-top: 0;">? Ticket Information</h2>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Ticket ID:</td><td style="padding: 8px 0;">#{ticket_id}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Subject:</td><td style="padding: 8px 0;">{ticket_data.get('subject', 'No Subject')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Customer:</td><td style="padding: 8px 0;">{ticket_data.get('name', 'Unknown')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Vehicle Reg:</td><td style="padding: 8px 0;">{vehicle_registration}</td></tr>
                        </table>
                    </div>
                    
                    <div style="background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h2 style="color: #495057; margin-top: 0;">? Technical Assessment</h2>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Category:</td><td style="padding: 8px 0;"><span style="background: #17a2b8; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px;">{feedback_data.get('assessment_category', 'Not specified')}</span></td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Reviewed by:</td><td style="padding: 8px 0;">{feedback_data.get('reviewer', 'Technical Director')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Date:</td><td style="padding: 8px 0;">{datetime.now().strftime('%B %d, %Y at %I:%M %p')}</td></tr>
                        </table>
                        
                        <div style="margin-top: 15px;">
                            <h3 style="color: #495057; margin-bottom: 10px;">[NOTE] Technical Notes:</h3>
                            <div style="background: #f8f9fa; padding: 15px; border-radius: 6px; border-left: 4px solid #17a2b8;">
                                <p style="margin: 0; white-space: pre-wrap;">{feedback_data.get('tech_director_notes', 'No notes provided')}</p>
                            </div>
                        </div>
                        
                        {f'''<div style="margin-top: 15px;">
                            <h3 style="color: #495057; margin-bottom: 10px;">[FIX] Recommended Action:</h3>
                            <div style="background: #fff3cd; padding: 15px; border-radius: 6px; border-left: 4px solid #ffc107;">
                                <p style="margin: 0; white-space: pre-wrap; color: #856404;">{feedback_data.get('recommended_action')}</p>
                            </div>
                        </div>''' if feedback_data.get('recommended_action') else ''}
                    </div>
                    
                    <div style="text-align: center; margin: 25px 0;">
                        <a href="{domain}/ticket/{ticket_id}" style="background: #28a745; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">? Review Ticket</a>
                        <a href="{domain}/" style="background: #6f42c1; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">?? Dashboard</a>
                    </div>
                    
                    <div style="background: #d1ecf1; border: 1px solid #bee5eb; padding: 15px; border-radius: 6px; margin-top: 20px;">
                        <p style="margin: 0; color: #0c5460;"><strong>[SUCCESS] Ready for Action:</strong> This ticket has been assessed and is ready for your follow-up action.</p>
                    </div>
                </div>
                
                <div style="text-align: center; margin-top: 20px; color: #6c757d; font-size: 12px;">
                    <p>AutoAssistGroup Support System | Technical Assessment Notification</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Send emails to all support team members
        success_count = 0
        for email in support_emails:
            email = email.strip()
            if email:
                success = email_service.send_email(
                    to_email=email,
                    subject=subject,
                    body=body,
                    html_body=html_body
                )
                if success:
                    success_count += 1
        
        if success_count > 0:
            app.logger.info(f"Support team notification sent successfully to {success_count} recipients for ticket {ticket_id}")
            return True
        else:
            app.logger.error(f"Failed to send support team notification for ticket {ticket_id}")
            return False
        
    except Exception as e:
        app.logger.error(f"Failed to send support team notification: {e}")
        return False

# Add ticket status update API endpoint
@app.route('/api/tickets/<ticket_id>/status', methods=['POST'])
def update_ticket_status(ticket_id):
    """Update ticket status - Available for ALL users including Technical Director"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401

    
    try:
        data = request.json
        new_status = data.get('status')
        
        if not new_status:
            return jsonify({'status': 'error', 'message': 'Status is required'}), 400
        
        db = get_db()
        
        # Get current ticket data for email notification
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Prepare update data
        update_data = {'status': new_status}
        
        # Handle technical director assessment data
        tech_director_notes = data.get('tech_director_notes')
        assessment_category = data.get('assessment_category')
        
        if tech_director_notes:
            update_data['tech_director_notes'] = tech_director_notes
        
        if assessment_category:
            update_data['assessment_category'] = assessment_category
            # Also store as metadata for better tracking
            db.add_ticket_metadata(ticket_id, 'tech_director_assessment', assessment_category)
            if tech_director_notes:
                db.add_ticket_metadata(ticket_id, 'tech_director_notes', tech_director_notes)
        
        # Update the ticket with all data
        db.update_ticket(ticket_id, update_data)
        
        # [LAUNCH] WEBHOOK TRIGGER: Special handling for Technical Director referral
        if new_status == "Referred to Tech Director":
            app.logger.info(f"[TARGET] STATUS CHANGE TO TECH DIRECTOR - Processing referral for ticket {ticket_id}")
            
            # Send email notification (existing functionality)
            send_tech_director_referral_email(ticket_id, ticket)
            
            # âœ… RE-ENABLED: Tech Director webhook with duplicate prevention
            webhook_queued = trigger_tech_director_webhook(ticket_id, ticket, 'status_change', session.get('member_name', 'Support Team'))
            if webhook_queued:
                app.logger.info(f"âœ… STATUS CHANGE WEBHOOK ENABLED - Reminder scheduled for ticket {ticket_id}")
            else:
                app.logger.info(f"â„¹ï¸ STATUS CHANGE WEBHOOK SKIPPED - Reminder already exists for ticket {ticket_id}")
        
        # [CANCEL] Cancel Tech Director reminder when status changes away from referral
        elif new_status != "Referred to Tech Director":
            # Check if ticket was previously referred to Tech Director
            db = get_db()
            metadata = db.get_ticket_metadata(ticket_id)
            was_referred = any(meta['key'] == 'webhook_triggered' for meta in metadata)
            
            if was_referred:
                app.logger.info(f"[CANCEL] Status changed from 'Referred to Tech Director' - Cancelling reminder for ticket {ticket_id}")
                cancel_tech_director_reminder(ticket_id)
        
        return jsonify({'status': 'success', 'message': f'Status updated to: {new_status}'})
        
    except Exception as e:
        app.logger.error(f"Error updating ticket status: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to update status'}), 500

# Quick webhook test endpoint
@app.route('/api/urgent-webhook-test/<ticket_id>')
def urgent_webhook_test(ticket_id):
    """URGENT: Quick webhook test"""
    try:
        test_payload = {
            'ticket_id': ticket_id,
            'action': 'test_reminder',
            'subject': 'TEST - Webhook Verification',
            'customer_name': 'Test Customer',
            'priority': 'High',
            'test': True,
            'timestamp': datetime.now().isoformat()
        }
        
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.error(f"[ALERT] TESTING WEBHOOK NOW - Ticket: {ticket_id}")
        app.logger.error(f"[WEBHOOK] URL: {WEBHOOK_URL}")
        app.logger.error(f"[PAYLOAD] PAYLOAD: {test_payload}")
        
        response = requests.post(
            WEBHOOK_URL, 
            json=test_payload, 
            timeout=10,
            headers={'Content-Type': 'application/json'}
        )
        
        app.logger.error(f"[WEBHOOK] TEST RESPONSE: {response.status_code}")
        app.logger.error(f"[WEBHOOK] TEST CONTENT: {response.text}")
        
        return jsonify({
            'status': 'success' if response.status_code == 200 else 'error',
            'webhook_status': response.status_code,
            'webhook_response': response.text,
            'message': f'Webhook test complete for {ticket_id}'
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] WEBHOOK TEST ERROR: {e}")
        return jsonify({'status': 'error', 'error': str(e)})

# Add Technical Director dashboard
@app.route('/tech-director')
def tech_director_dashboard():
    """Special dashboard for Technical Director to view referred tickets"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if user has permission - only Technical Director (not Admin)
    member_role = session.get('member_role', '')
    if member_role != 'Technical Director':
        return render_template('error.html', error="Access denied. Technical Director access required."), 403
    
    try:
        db = get_db()
        
        # [FIX] Use direct status query instead of complex aggregation
        all_referred_tickets = db.get_tickets_by_status("Referred to Tech Director")
        
        # [ALERT] CRITICAL DEBUG - Log exactly what we found
        try:
            count_referred = len(all_referred_tickets)
        except Exception:
            count_referred = 0
        app.logger.error(f"[ALERT] TD DASHBOARD DEBUG - Found {count_referred} tickets with status 'Referred to Tech Director'")
        
        # Ensure iterable type
        if not isinstance(all_referred_tickets, list):
            try:
                all_referred_tickets = list(all_referred_tickets) if all_referred_tickets else []
            except Exception:
                all_referred_tickets = []
        
        # Debug each ticket found safely
        for i, ticket in enumerate(all_referred_tickets):
            if isinstance(ticket, dict):
                app.logger.error(f"[ALERT] TICKET {i+1}: ID={ticket.get('ticket_id')}, Status='{ticket.get('status')}', Priority={ticket.get('priority')}")
            else:
                app.logger.error(f"[ALERT] TICKET {i+1}: Invalid ticket type {type(ticket).__name__}")
        
        # [FIX] REMOVED AUTO-FIX LOGIC - Don't change ticket statuses automatically
        # This was causing issues with tickets referred by users
        app.logger.info(f"[INFO] TD DASHBOARD - No auto-fixing applied, showing all referred tickets as-is")
        
        # [FIX] ULTRA-SIMPLIFIED: Show ALL tickets with "Referred to Tech Director" status - NO FILTERING
        active_referred_tickets = []
        app.logger.info(f"[INFO] TD DASHBOARD - Processing {len(all_referred_tickets)} tickets with 'Referred to Tech Director' status")
        
        for ticket in all_referred_tickets:
            if not isinstance(ticket, dict):
                app.logger.warning(f"[SKIP] Non-dict ticket encountered: type={type(ticket).__name__}")
                continue
                
            ticket_dict = dict(ticket)
            ticket_id = ticket_dict.get('ticket_id', 'Unknown')
            
            # [FIX] INCLUDE ALL TICKETS - No assignment checking, no filtering
            # This ensures tickets referred by users (like zeeshan) are always shown
            active_referred_tickets.append(ticket_dict)
            app.logger.info(f"[INCLUDE] Ticket {ticket_id}: Added to Tech Director dashboard (no filtering applied)")
        
        app.logger.info(f"[SUCCESS] TD DASHBOARD - {len(active_referred_tickets)} tickets will be shown to Tech Director (ALL included)")
        
        # Format tickets for display
        formatted_tickets = []
        for ticket_dict in active_referred_tickets:
            if not isinstance(ticket_dict, dict):
                app.logger.error(f"[SKIP] Non-dict ticket in active list: type={type(ticket_dict).__name__}")
                continue
            # Format created_at
            created_at_value = ticket_dict.get('created_at')
            if isinstance(created_at_value, datetime):
                ticket_dict['formatted_date'] = created_at_value.strftime("%b %d, %Y %I:%M %p")
            else:
                try:
                    created_at = datetime.strptime(str(created_at_value), "%Y-%m-%d %H:%M:%S")
                    ticket_dict['formatted_date'] = created_at.strftime("%b %d, %Y %I:%M %p")
                except Exception:
                    ticket_dict['formatted_date'] = str(created_at_value)
            
            # Get vehicle registration from metadata
            metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
            ticket_dict['vehicle_registration'] = 'Not specified'
            has_warranty_attachment = False
            
            for meta in metadata:
                try:
                    if isinstance(meta, dict):
                        meta_key = meta.get('key')
                        meta_value = meta.get('value')
                    else:
                        meta_key = None
                        meta_value = None
                except (AttributeError, TypeError):
                    meta_key = None
                    meta_value = None

                if meta_key == 'vehicle_registration':
                    ticket_dict['vehicle_registration'] = meta_value if isinstance(meta_value, str) else str(meta_value)
                
                #  DYNAMIC WARRANTY CLASSIFICATION: Check for warranty attachments
                try:
                    if isinstance(meta_value, str):
                        # Clean JSON before parsing
                        clean_json = meta_value.strip()
                        # Remove trailing commas and fix common JSON issues
                        if clean_json.endswith(',}'):
                            clean_json = clean_json[:-2] + '}'
                        elif clean_json.endswith(',]'):
                            clean_json = clean_json[:-2] + ']'
                        # Remove any leading/trailing whitespace and quotes
                        clean_json = clean_json.strip().strip('"\'')
                        # Skip if still empty after cleaning
                        if not clean_json or clean_json in ['{}', '[]', 'null', 'undefined']:
                            meta_data = {}
                        else:
                            meta_data = json.loads(clean_json)
                    elif isinstance(meta_value, dict):
                        meta_data = meta_value
                    else:
                        meta_data = {}
                    
                    # Check if this attachment is warranty-related
                    is_warranty = meta_data.get('is_warranty', False) if isinstance(meta_data, dict) else False
                    if is_warranty:
                        has_warranty_attachment = True
                except (json.JSONDecodeError, TypeError, ValueError) as e:
                    # Only log if it's actually malformed, not just empty
                    if isinstance(meta_value, str) and meta_value.strip() and meta_value.strip() not in ['{}', '[]', 'null', 'undefined', '']:
                        app.logger.debug(f"JSON parse error in TD dashboard: {e} - Value: {meta_value[:50]}")
                    meta_data = {}
            
            # Update classification if warranty attachment found
            if has_warranty_attachment or ticket_dict.get('has_warranty', False):
                original_classification = ticket_dict.get('classification')
                ticket_dict['classification'] = 'Warranty Claim'
                
                if original_classification != 'Warranty Claim':
                    app.logger.info(f" TD DASHBOARD WARRANTY CLASSIFICATION: Ticket {ticket_dict['ticket_id']} updated from '{original_classification}' to 'Warranty Claim'")
            
            # Get assignment info for display
            assignment = db.get_assignment_by_ticket(ticket_dict['ticket_id'])
            if assignment is not None and not isinstance(assignment, dict):
                app.logger.error(f"[WARN] Non-dict assignment for ticket {ticket_dict.get('ticket_id')} during formatting: type={type(assignment).__name__}")
                assignment = None
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    if assigned_member:
                        ticket_dict['assignment_info'] = {
                            'assigned_to': assigned_member.get('name', 'Unknown'),
                            'assigned_at': assignment.get('assigned_at'),
                            'is_forwarded': assignment.get('is_forwarded', False),
                            'notes': assignment.get('notes', '')
                        }
            
            # Get forwarded_from information for "Referred from [Username]" display
            # First check if this is a direct referral to tech director (stored in ticket document)
            if ticket_dict.get('referred_to_tech_director_by'):
                ticket_dict['forwarded_from_name'] = ticket_dict['referred_to_tech_director_by']
            elif ticket_dict.get('is_forwarded') and ticket_dict.get('forwarded_from_member') and len(ticket_dict['forwarded_from_member']) > 0:
                # For forwarded tickets, use the forwarded_from_member data
                forwarded_member = ticket_dict['forwarded_from_member'][0]
                ticket_dict['forwarded_from_name'] = forwarded_member.get('name', 'Unknown')
            else:
                # For direct referrals (not forwarded), try to get the referring user from assignment
                if assignment and assignment.get('forwarded_from'):
                    try:
                        from bson.objectid import ObjectId
                        forwarded_from_id = assignment.get('forwarded_from')
                        if ObjectId.is_valid(str(forwarded_from_id)):
                            forwarded_member = db.get_member_by_id(forwarded_from_id)
                            if forwarded_member:
                                ticket_dict['forwarded_from_name'] = forwarded_member.get('name', 'Unknown')
                            else:
                                ticket_dict['forwarded_from_name'] = 'Unknown'
                        else:
                            ticket_dict['forwarded_from_name'] = 'Unknown'
                    except Exception as e:
                        app.logger.error(f"Error getting forwarded_from member for ticket {ticket_dict['ticket_id']}: {e}")
                        ticket_dict['forwarded_from_name'] = 'Unknown'
                else:
                    ticket_dict['forwarded_from_name'] = 'Unknown'
            
            formatted_tickets.append(ticket_dict)
        
        # Calculate statistics for dashboard
        total_referred_count = len(all_referred_tickets)
        active_tickets_count = len(formatted_tickets) 
        forwarded_count = total_referred_count - active_tickets_count
        
        app.logger.info(f"Tech Director Dashboard: {total_referred_count} total referred, {active_tickets_count} active, {forwarded_count} forwarded to others")
        
        return render_template('tech_director_dashboard.html', 
                             tickets=formatted_tickets,
                             total_referred=active_tickets_count,
                             total_originally_referred=total_referred_count,
                             forwarded_to_others=forwarded_count,
                             current_user=session.get('member_name'),
                             current_user_role=session.get('member_role'))
        
    except Exception as e:
        app.logger.error(f"Error loading tech director dashboard: {e}")
        return render_template('error.html', error="Failed to load dashboard"), 500

# Add Technical Director reminder scheduling endpoint
@app.route('/api/tech-director/schedule-reminder/<ticket_id>', methods=['POST'])
def schedule_tech_director_reminder(ticket_id):
    """Schedule reminder for Technical Director referral via n8n webhook"""
    try:
        # Get ticket data
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket or ticket.get('status') != 'Referred to Tech Director':
            return jsonify({'status': 'error', 'message': 'Invalid ticket for reminder scheduling'}), 400
        
        # Get vehicle registration from metadata if available
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Prepare reminder payload for your n8n workflow  
        app_domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not app_domain.startswith('http'):
            app_domain = f"https://{app_domain}"
            
        reminder_payload = {
            'ticket_id': ticket_id,
            'subject': ticket.get('subject', 'No Subject'),
            'customer_name': ticket.get('name', 'Unknown Customer'),
            'customer_email': ticket.get('email', ''),
            'vehicle_registration': vehicle_registration,
            'priority': ticket.get('priority', 'Medium'),
            'classification': ticket.get('classification', 'General'),
            'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
            'app_domain': app_domain,
            'ticket_url': f"{app_domain}/ticket/{ticket_id}",
            'dashboard_url': f"{app_domain}/tech-director",
            'referral_date': datetime.now().strftime('%B %d, %Y at %I:%M %p'),
            'reminder_context': f"This ticket requires your technical expertise and assessment. Please review ticket #{ticket_id} for {ticket.get('name', 'customer')} regarding '{ticket.get('subject', 'technical issue')}' (Vehicle: {vehicle_registration}). Priority: {ticket.get('priority', 'Medium')}"
        }
        
        # Send to n8n reminder webhook
        REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        response = requests.post(REMINDER_WEBHOOK_URL, json=reminder_payload, timeout=10)
        response.raise_for_status()
        
        # Log successful scheduling
        app.logger.info(f"Reminder scheduled for Technical Director - Ticket: {ticket_id}, Webhook: {REMINDER_WEBHOOK_URL}")
        
        # Store reminder scheduling info as metadata
        db.add_ticket_metadata(ticket_id, 'reminder_scheduled', datetime.now().isoformat())
        db.add_ticket_metadata(ticket_id, 'reminder_webhook_url', REMINDER_WEBHOOK_URL)
        
        return jsonify({
            'status': 'success',
            'message': 'Technical Director reminder sent to n8n workflow successfully',
            'ticket_id': ticket_id
        })
        
    except requests.exceptions.RequestException as e:
        app.logger.error(f"Failed to send reminder webhook for ticket {ticket_id}: {e}")
        if hasattr(e, 'response') and e.response is not None:
            app.logger.error(f"Webhook response status: {e.response.status_code}, content: {e.response.text}")
        return jsonify({'status': 'error', 'message': f'Failed to schedule reminder: {str(e)}'}), 500
        
    except Exception as e:
        app.logger.error(f"Unexpected error scheduling reminder for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tech-director/cancel-reminder/<ticket_id>', methods=['POST'])
def cancel_tech_director_reminder(ticket_id):
    """Cancel Technical Director reminder when feedback is submitted"""
    try:
        db = get_db()
        
        # Check if ticket exists
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Prepare cancellation payload for n8n
        cancellation_payload = {
            'ticket_id': ticket_id,
            'action': 'cancel_reminder',
            'reason': 'technical_director_responded',
            'cancelled_at': datetime.now().isoformat()
        }
        
        # Send cancellation to n8n reminder webhook
        REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        try:
            response = requests.post(REMINDER_WEBHOOK_URL, json=cancellation_payload, timeout=5)
            response.raise_for_status()
            app.logger.info(f"Reminder cancellation sent for ticket {ticket_id}")
        except Exception as e:
            app.logger.warning(f"Failed to send reminder cancellation for ticket {ticket_id}: {e}")
            # Don't fail the whole operation if cancellation fails
        
        # Update metadata to mark reminder as cancelled
        db.add_ticket_metadata(ticket_id, 'reminder_cancelled', datetime.now().isoformat())
        
        return jsonify({
            'status': 'success',
            'message': 'Reminder cancellation processed'
        })
        
    except Exception as e:
        app.logger.error(f"Error cancelling reminder for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Add Technical Director feedback API endpoint
@app.route('/api/tech-director/feedback/<ticket_id>', methods=['POST'])
def submit_tech_director_feedback(ticket_id):
    """Submit Technical Director feedback and notify Support team"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check if user has Tech Director permission - only Technical Director (not Admin)
    member_role = session.get('member_role', '')
    if member_role != 'Technical Director':
        return jsonify({'status': 'error', 'message': 'Tech Director access required'}), 403
    
    try:
        data = request.json
        assessment_category = data.get('assessment_category', '')
        tech_director_notes = data.get('tech_director_notes', '')
        recommended_action = data.get('recommended_action', '')
        new_status = data.get('new_status', '')
        
        if not assessment_category or not tech_director_notes:
            return jsonify({'status': 'error', 'message': 'Assessment category and notes are required'}), 400
        
        db = get_db()
        
        # Get ticket data for notifications
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Update ticket with Tech Director assessment
        update_data = {
            'status': new_status if new_status else ticket.get('status'),
            'tech_director_assessment': assessment_category,
            'tech_director_notes': tech_director_notes,
            'tech_director_feedback_date': datetime.now(),
            'tech_director_reviewer': session.get('member_name', 'Technical Director')
        }
        
        if recommended_action:
            update_data['recommended_action'] = recommended_action
        
        db.update_ticket(ticket_id, update_data)
        
        # Store as metadata for better tracking
        metadata_updates = [
            ('tech_director_assessment', assessment_category),
            ('tech_director_notes', tech_director_notes),
            ('tech_director_feedback_date', datetime.now().isoformat()),
            ('tech_director_reviewer', session.get('member_name', 'Technical Director'))
        ]
        
        if recommended_action:
            metadata_updates.append(('recommended_action', recommended_action))
        
        for key, value in metadata_updates:
            # Remove existing entry first
            db.ticket_metadata.delete_many({'ticket_id': ticket_id, 'key': key})
            # Add new entry
            db.add_ticket_metadata(ticket_id, key, str(value))
        
        # Create a reply with the Tech Director's assessment
        reply_data = {
            'ticket_id': ticket_id,
            'thread_id': ticket.get('thread_id', ''),
            'message': """Technical Director Assessment Complete

Assessment Category: {assessment_category}

Technical Notes:
{tech_director_notes}

{f'Recommended Action: {recommended_action}' if recommended_action else ''}

This assessment has been completed by the Technical Director and the ticket has been returned to Support for follow-up action.""",
            'sender': 'tech_director'
        }
        db.create_reply(reply_data)
        
        # Send email notification to Support team about Tech Director feedback
        success = send_support_team_notification(ticket_id, ticket, {
            'assessment_category': assessment_category,
            'tech_director_notes': tech_director_notes,
            'recommended_action': recommended_action,
            'reviewer': session.get('member_name', 'Technical Director')
        })
        
        app.logger.info(f"Tech Director feedback submitted for ticket {ticket_id} by {session.get('member_name')}")
        
        # [NEW] NEW: Cancel any pending reminders since TD has responded
        try:
            cancellation_payload = {
                'ticket_id': ticket_id,
                'action': 'cancel_reminder',
                'reason': 'technical_director_responded',
                'cancelled_at': datetime.now().isoformat(),
                'responded_by': session.get('member_name', 'Technical Director')
            }
            
            REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
            
            response = requests.post(REMINDER_WEBHOOK_URL, json=cancellation_payload, timeout=5)
            response.raise_for_status()
            
            app.logger.info(f"Automatic reminder cancellation sent for ticket {ticket_id}")
            
            # Update metadata to mark reminder as cancelled
            db.add_ticket_metadata(ticket_id, 'auto_reminder_cancelled', datetime.now().isoformat())
            
        except Exception as e:
            app.logger.warning(f"Failed to cancel automatic reminder for ticket {ticket_id}: {e}")
            # Don't fail feedback submission if reminder cancellation fails
        
        return jsonify({
            'status': 'success',
            'message': 'Technical assessment submitted successfully. Support team has been notified.',
            'email_sent': success,
            'reminder_cancelled': True
        })
        
    except Exception as e:
        app.logger.error(f"Error submitting tech director feedback: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

 

 
 

  







@app.route('/api/tickets/<ticket_id>/assign', methods=['POST'])
def assign_ticket(ticket_id):
    """Assign ticket to member - Technical Director can FORWARD but not take over"""
    
    # Enhanced error handling and debugging
    try:
        app.logger.info(f"[TARGET] ASSIGN REQUEST - Ticket: {ticket_id}")
        
        # Check authentication first
        if 'member_id' not in session:
            app.logger.warning(f"[ERROR] UNAUTHORIZED - No session for ticket {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in'}), 401
        
        # Log request data
        request_data = request.get_json() if request.is_json else {}
        target_member_id = request_data.get('member_id', 'MISSING')
        is_forwarded_flag = request_data.get('is_forwarded', False)
        
        app.logger.info(f"[INFO] ASSIGN DATA - Target: {target_member_id}, Forwarded: {is_forwarded_flag}, Session User: {session.get('member_id')}")
        
    except Exception as debug_error:
        app.logger.error(f"[ALERT] ASSIGN INIT ERROR: {debug_error}")
        return jsonify({'status': 'error', 'message': 'Request processing error'}), 500
    
    # Technical Director can only forward tickets, not take them over
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    is_tech_director = current_member and current_member['role'] == 'Technical Director'
    
    if is_tech_director:
        # Technical Director can only forward, check if this is a forward operation
        data = request.json
        is_forwarded = data.get('is_forwarded', False)
        if not is_forwarded:
            return jsonify({'status': 'error', 'message': 'Technical Director can only forward tickets, not take them over.'}), 403
        
        # Ensure the ticket is referred to Technical Director
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket or ticket.get('status') != 'Referred to Tech Director':
            return jsonify({'status': 'error', 'message': 'You can only forward tickets that have been referred to you.'}), 403
    
    # Step 1: Authentication Check
    if 'member_id' not in session:
        app.logger.warning(f"Unauthorized assignment attempt for ticket {ticket_id}")
        return jsonify({
            'status': 'error', 
            'message': 'Unauthorized - Please log in first',
            'error_code': 'AUTH_REQUIRED'
        }), 401
    
    # Step 2: Basic Request Validation
    try:
        # Get request data
        data = request.get_json()
        app.logger.info(f"ASSIGN REQUEST - Ticket: {ticket_id}, Data: {data}, Session: {session.get('member_id')}")
        
        if not data:
            app.logger.error(f"Empty request body for ticket {ticket_id}")
            return jsonify({
                'status': 'error',
                'message': 'Request body is required',
                'error_code': 'EMPTY_BODY'
            }), 400
            
        if not data.get('member_id'):
            app.logger.error(f"Missing member_id in request for ticket {ticket_id}")
            app.logger.error(f"Request data received: {data}")
            return jsonify({
                'status': 'error',
                'message': 'Member ID is required. Please select a team member to assign the ticket to.',
                'error_code': 'MISSING_MEMBER_ID',
                'debug_info': {
                    'received_data': data,
                    'required_field': 'member_id'
                }
            }), 400
            
    except Exception as e:
        app.logger.error(f"Request parsing error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': 'Invalid JSON in request body',
            'error_code': 'INVALID_JSON'
        }), 400
    
    # Step 3: Database Connection
    try:
        db = get_db()
        app.logger.info(f"Database connection established for ticket {ticket_id}")
        
        # Check if ticket exists first
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        if not ticket:
            app.logger.error(f"Ticket not found: {ticket_id}")
            app.logger.info(f"Available tickets sample: {[t['ticket_id'] for t in db.tickets.find().limit(5)]}")
            return jsonify({
                'status': 'error',
                'message': f'Ticket {ticket_id} not found. Please verify the ticket ID.',
                'error_code': 'TICKET_NOT_FOUND'
            }), 404
    except Exception as e:
        app.logger.error(f"Database connection failed for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': 'Database connection failed',
            'error_code': 'DB_CONNECTION_FAILED'
        }), 500
    
    # Step 4: Validate and Process Member ID
    try:
        member_id_raw = data.get('member_id')
        app.logger.info(f"Processing member_id: '{member_id_raw}' (type: {type(member_id_raw)})")
        
        # Clean and validate member_id
        if not member_id_raw:
            return jsonify({
                'status': 'error',
                'message': 'member_id cannot be empty',
                'error_code': 'EMPTY_MEMBER_ID'
            }), 400
            
        member_id_str = str(member_id_raw).strip()
        if not member_id_str:
            return jsonify({
                'status': 'error',
                'message': 'member_id cannot be empty after trimming',
                'error_code': 'EMPTY_MEMBER_ID_TRIMMED'
            }), 400
            
        # Validate ObjectId format
        if not ObjectId.is_valid(member_id_str):
            app.logger.error(f"Invalid ObjectId format: '{member_id_str}'")
            return jsonify({
                'status': 'error',
                'message': f'Invalid member ID format: {member_id_str}',
                'error_code': 'INVALID_OBJECTID_FORMAT'
            }), 400
            
        member_id_obj = ObjectId(member_id_str)
        app.logger.info(f"Valid ObjectId created: {member_id_obj}")
        
    except Exception as e:
        app.logger.error(f"Member ID processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error processing member ID: {str(e)}',
            'error_code': 'MEMBER_ID_PROCESSING_ERROR'
        }), 400
    
    # Step 5: Validate Member Exists
    try:
        member = db.get_member_by_id(member_id_str)
        if not member:
            app.logger.error(f"Member not found: {member_id_str}")
            return jsonify({
                'status': 'error',
                'message': f'Member not found: {member_id_str}',
                'error_code': 'MEMBER_NOT_FOUND'
            }), 404
        # [ALERT] CRITICAL DEBUG: Member analysis
        member_role = member.get('role', 'NO_ROLE')
        member_name = member.get('name', 'NO_NAME')
        
        print("-" * 60)
        print(f"[ALERT] MEMBER FOUND: {member_name}")
        print(f"[ALERT] MEMBER ROLE: '{member_role}'")
        print(f"[ALERT] CURRENT USER is_tech_director: {is_tech_director}")
        print(f"[ALERT] ROLE CHECK: '{member_role}' == 'Technical Director' ? {member_role == 'Technical Director'}")
        print(f"[ALERT] USER CHECK: not is_tech_director ? {not is_tech_director}")
        print(f"[ALERT] WEBHOOK TRIGGER CONDITION: {member_role == 'Technical Director' and not is_tech_director}")
        print("-" * 60)
        
        app.logger.info(f"Member found: {member_name} (Role: {member_role}) - Webhook condition: {member_role == 'Technical Director' and not is_tech_director}")
        
        # Also check if Tech Director exists in database
        try:
            db_tech_directors = list(db.members.find({"role": "Technical Director"}))
            print(f"[ALERT] TECH DIRECTORS IN DB: {len(db_tech_directors)}")
            for td in db_tech_directors:
                print(f"[ALERT]   - {td.get('name', 'NO_NAME')} (ID: {str(td.get('_id', 'NO_ID'))}, Role: '{td.get('role', 'NO_ROLE')}')")
        except Exception as db_check_error:
            print(f"[ALERT] DB CHECK ERROR: {db_check_error}")
        
    except Exception as e:
        app.logger.error(f"Member lookup error for {member_id_str}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error finding member: {str(e)}',
            'error_code': 'MEMBER_LOOKUP_ERROR'
        }), 500
    
    # Step 7: Handle Existing Assignments - FIXED TRANSACTION LOGIC
    try:
        existing_assignment = db.get_assignment_by_ticket(ticket_id)
        app.logger.info(f"[DEBUG] EXISTING ASSIGNMENT CHECK - Ticket: {ticket_id}, Assignment: {existing_assignment}")
        
        if existing_assignment:
            existing_member_id = str(existing_assignment.get('member_id'))
            target_member_id_str = str(member_id_obj)
            
            app.logger.info(f"[INFO] ASSIGNMENT COMPARISON - Existing: {existing_member_id}, Target: {target_member_id_str}")
            
            # [FIX] Allow forwarding back to same user - only block if it's NOT a forward operation
            is_forwarding_to_same_user = (str(existing_assignment['member_id']) == member_id_str)
            is_forward_operation = data.get('is_forwarded', False)
            
            if is_forwarding_to_same_user and not is_forward_operation:
                # Only block if trying to assign to same user AND it's not a forward operation
                return jsonify({
                    'status': 'error',
                    'message': f'Ticket already assigned to {member["name"]}',
                    'error_code': 'ALREADY_ASSIGNED'
                }), 400
            elif is_forwarding_to_same_user and is_forward_operation:
                # Allow forwarding back to same user - this is valid
                app.logger.info(f"[FORWARD] Allowing forward back to same user: {member['name']}")
            
            # Remove existing assignment for reassignment (including forward to same user)
            result = db.ticket_assignments.delete_one({'ticket_id': ticket_id})
            app.logger.info(f"Removed existing assignment: {result.deleted_count} records")
        else:
            app.logger.info(f"No existing assignment for ticket {ticket_id}")
            
    except Exception as e:
        app.logger.error(f"Assignment check error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error checking existing assignments: {str(e)}',
            'error_code': 'ASSIGNMENT_CHECK_ERROR'
        }), 500
    
    # Step 8: Handle Forwarding Logic
    is_forwarded = data.get('is_forwarded', False)
    forwarded_from = None
    
    if is_forwarded:
        try:
            # Try to get forwarded_from from request
            forwarded_from_raw = data.get('forwarded_from')
            if forwarded_from_raw and ObjectId.is_valid(str(forwarded_from_raw)):
                forwarded_from = ObjectId(str(forwarded_from_raw))
                # Verify the forwarded_from member exists and log their role
                forwarded_member = db.get_member_by_id(forwarded_from)
                if forwarded_member:
                    app.logger.info(f"Using provided forwarded_from: {forwarded_from} ({forwarded_member.get('name')} - {forwarded_member.get('role')})")
                else:
                    app.logger.warning(f"Provided forwarded_from ID {forwarded_from} does not exist, using session user")
                    forwarded_from = ObjectId(session['member_id']) if session.get('member_id') else None
            
            # Fallback to current session user
            elif session.get('member_id') and ObjectId.is_valid(session['member_id']):
                forwarded_from = ObjectId(session['member_id'])
                # Log the session user's role for clarity
                session_member = db.get_member_by_id(forwarded_from)
                if session_member:
                    app.logger.info(f"Using session user as forwarded_from: {forwarded_from} ({session_member.get('name')} - {session_member.get('role')})")
                else:
                    app.logger.warning(f"Session member {forwarded_from} not found!")
            
            app.logger.info(f"Final forwarded_from value: {forwarded_from}")
            
        except Exception as e:
            app.logger.warning(f"Forwarding logic error (non-critical): {str(e)}")
            forwarded_from = None

    # Step 9: Create New Assignment
    try:
        assignment_data = {
            'ticket_id': ticket_id,
            'member_id': member_id_obj,  # Ensure this is ObjectId type
            'notes': data.get('notes', ''),
            'is_forwarded': is_forwarded,
            'forwarded_from': forwarded_from,
            'assigned_at': datetime.now(),
            'assigned_by': ObjectId(session['member_id']) if ObjectId.is_valid(session.get('member_id', '')) else None
        }
        
        app.logger.info(f"[ASSIGNMENT] Creating assignment with data: ticket_id={ticket_id}, member_id={member_id_obj} (type: {type(member_id_obj).__name__}), is_forwarded={is_forwarded}")
        app.logger.info(f"[ASSIGNMENT] Full assignment_data: {assignment_data}")
        
        # CRITICAL DEBUG: Check if the member actually exists
        test_member = db.get_member_by_id(str(member_id_obj))
        app.logger.info(f"[ASSIGNMENT] Member verification: member_id={member_id_obj}, exists={test_member is not None}, name={test_member.get('name') if test_member else 'NOT_FOUND'}")
        
        assignment_id = db.assign_ticket(assignment_data)
        app.logger.info(f"[SUCCESS] Assignment created with ID: {assignment_id}")
        
        # IMMEDIATE VERIFICATION: Check if assignment can be retrieved AND if member lookup works
        try:
            verification_check = db.get_assignment_by_ticket(ticket_id)
            if verification_check:
                app.logger.info(f"[VERIFY] Assignment immediately retrievable: {verification_check.get('_id')}")
                # Test the exact same lookup that dashboard uses
                stored_member_id = verification_check.get('member_id')
                app.logger.info(f"[VERIFY] Stored member_id: {stored_member_id} (type: {type(stored_member_id).__name__})")
                lookup_member = db.get_member_by_id(str(stored_member_id))
                app.logger.info(f"[VERIFY] Member lookup result: {lookup_member.get('name') if lookup_member else 'LOOKUP_FAILED'}")
            else:
                app.logger.error(f"[VERIFY] WARNING: Assignment not immediately retrievable after creation!")
        except Exception as verify_error:
            app.logger.error(f"[VERIFY] Error checking assignment: {verify_error}")
        
        # [NEW] COMPREHENSIVE DEBUG LOGGING BEFORE WEBHOOK LOGIC
        app.logger.info(f"[DEBUG] WEBHOOK TRIGGER ANALYSIS - Ticket: {ticket_id}")
        app.logger.info(f"  ?? Target Member: {member.get('name', 'Unknown')} (ID: {member_id_str})")
        app.logger.info(f"  ?? Target Member Role: '{member.get('role', 'No role')}'")
        app.logger.info(f"  ?? Current User: {session.get('member_name', 'Unknown')} (ID: {session.get('member_id')})")
        app.logger.info(f"  ?? Current User is_tech_director: {is_tech_director}")
        app.logger.info(f"  ?? Is Forwarded: {is_forwarded}")
        app.logger.info(f"  ?? Role Check: member.get('role') == 'Technical Director' ? {member.get('role') == 'Technical Director'}")
        app.logger.info(f"  ?? User Check: not is_tech_director ? {not is_tech_director}")
        app.logger.info(f"  ?? WEBHOOK CONDITION: {member.get('role') == 'Technical Director' and not is_tech_director}")
        
        if member.get('role') == 'Technical Director' and not is_tech_director:
            app.logger.info(f"[SUCCESS] WEBHOOK CONDITIONS MET - Proceeding with webhook")
        else:
            app.logger.info(f"[ERROR] WEBHOOK CONDITIONS NOT MET - Will skip webhook")
        
        # [ALERT] WEBHOOK TRIGGER: Check if ticket is being forwarded TO the tech director
        webhook_condition = member.get('role') == 'Technical Director' and not is_tech_director
        
        # Log webhook decision using app.logger.error to ensure visibility
        app.logger.error(f"[ALERT] WEBHOOK CHECK - Ticket: {ticket_id}, Member: {member.get('name')}, Role: '{member.get('role')}', Condition: {webhook_condition}")
        
        if webhook_condition:
            app.logger.error(f"[LAUNCH] WEBHOOK ACTIVATED - Triggering for ticket {ticket_id}")
            app.logger.info(f"[TARGET] FORWARDING TO TECH DIRECTOR - Triggering webhook for ticket {ticket_id}")
            
            # Update ticket status to "Referred to Tech Director" 
            db.update_ticket(ticket_id, {
                'status': 'Referred to Tech Director',
                'updated_at': datetime.now()
            })
            app.logger.info(f"[SUCCESS] Updated ticket {ticket_id} status to 'Referred to Tech Director'")
            
            # [LAUNCH] TRIGGER ASYNC WEBHOOK - Real-time behavior for assignments
            # Get ticket data for reminder
            ticket = db.get_ticket_by_id(ticket_id)
            
            # ðŸš¨ TEMPORARILY DISABLED: Tech Director webhook causing automatic replies
            # webhook_queued = trigger_tech_director_webhook_async(ticket_id, ticket, 'assignment', session.get('member_name', 'Support Team'))
            webhook_queued = False
            app.logger.warning(f"ðŸš¨ TECH DIRECTOR WEBHOOK DISABLED - Ticket {ticket_id} to prevent automatic replies")
            app.logger.info(f"[SUCCESS] ASSIGNMENT ASYNC WEBHOOK: Queued for ticket {ticket_id}")
        
        # [NEW] Handle when Technical Director forwards tickets to others
        elif is_tech_director and is_forwarded:
            # [FIX] FIX: Clear "Referred to Tech Director" status - ticket now belongs to new assignee
            app.logger.info(f"[RETRY] Tech Director forwarding ticket {ticket_id} to {member.get('name')} - Clearing TD status")
            
            # Determine appropriate status based on who is receiving the ticket
            target_role = member.get('role', 'Support')
            if target_role == 'Administrator':
                new_status = 'Open'  # Back to admin for review
            elif target_role in ['Support', 'Engineer', 'IT']:
                new_status = 'Under Review'  # With support team
            else:
                new_status = 'Open'  # Default fallback
            
            db.update_ticket(ticket_id, {
                'status': new_status,
                'updated_at': datetime.now(),
                'forwarded_from_tech_director': True,
                'forwarded_from_tech_director_at': datetime.now(),
                'forwarded_from_tech_director_to': member.get('name', 'Unknown')
            })
            
            app.logger.info(f"[SUCCESS] CLEARED TD STATUS - Ticket {ticket_id} status changed from 'Referred to Tech Director' to '{new_status}' (forwarded to {member.get('name')})")
            
            # Cancel reminder since Technical Director has completed their review by forwarding
            try:
                cancellation_payload = {
                    'ticket_id': ticket_id,
                    'action': 'cancel_reminder',
                    'reason': 'technical_director_forwarded',
                    'cancelled_at': datetime.now().isoformat(),
                    'forwarded_to': member["name"],
                    'new_status': new_status
                }
                
                REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
                
                response = requests.post(REMINDER_WEBHOOK_URL, json=cancellation_payload, timeout=5)
                response.raise_for_status()
                
                app.logger.info(f"[SUCCESS] CANCELLED TD REMINDER - Ticket {ticket_id} forwarded to {member['name']} with status '{new_status}'")
                db.add_ticket_metadata(ticket_id, 'auto_reminder_cancelled_forwarded', datetime.now().isoformat())
                db.add_ticket_metadata(ticket_id, 'status_cleared_by_td_forward', f'Changed to {new_status}')
                
            except Exception as e:
                app.logger.warning(f"Failed to cancel reminder for forwarded ticket {ticket_id}: {e}")

        else:
            # Add debugging for when webhook doesn't trigger
            app.logger.error(f"[ERROR] NO WEBHOOK - Ticket: {ticket_id}, Role: '{member.get('role')}', is_tech_director: {is_tech_director}, forwarded: {data.get('is_forwarded', False)}")
            
            app.logger.info(f"[DEBUG] NO WEBHOOK TRIGGER - Ticket: {ticket_id}")
            app.logger.info(f"  ?? Member role: {member.get('role', 'No role')}")
            app.logger.info(f"  ?? Is tech director: {is_tech_director}")
            app.logger.info(f"  ?? Is forwarded: {data.get('is_forwarded', False)}")
            app.logger.info(f"[ERROR] SKIPPING STATUS UPDATE - Conditions not met for ticket {ticket_id}")
        
    except Exception as e:
        app.logger.error(f"Assignment creation error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error creating assignment: {str(e)}',
            'error_code': 'ASSIGNMENT_CREATION_ERROR'
        }), 500
    
    # Step 9: Success Response
    try:
        action_type = "forwarded" if is_forwarded else "assigned"
        success_message = f'Ticket successfully {action_type} to {member["name"]}'
        
        app.logger.info(f"SUCCESS - {success_message} (Ticket: {ticket_id})")
        
        return jsonify({
            'status': 'success',
            'member_name': member['name'],
            'member_gender': member.get('gender', ''),
            'user_id': member.get('user_id', ''),

            'message': success_message,
            'assignment_id': str(assignment_id),
            'action': action_type
        }), 200
        
    except Exception as e:
        app.logger.error(f"Success response error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Assignment created but response error: {str(e)}',
            'error_code': 'RESPONSE_ERROR'
        }), 500
    


    

@app.route('/api/tickets/<ticket_id>/assign/debug', methods=['POST', 'GET'])
def debug_assign_ticket(ticket_id):
    """Debug endpoint to test assignment functionality step by step"""
    debug_info = {
        'ticket_id': ticket_id,
        'timestamp': datetime.now().isoformat(),
        'session': {},
        'request_data': {},
        'validation_steps': {},
        'database_checks': {}
    }
    
    # Check session
    debug_info['session'] = {
        'has_member_id': 'member_id' in session,
        'member_id': session.get('member_id'),
        'member_name': session.get('member_name'),
        'member_role': session.get('member_role')
    }
    
    if request.method == 'POST':
        # Check request data
        try:
            data = request.get_json()
            debug_info['request_data'] = {
                'raw_data': data,
                'has_member_id': 'member_id' in data if data else False,
                'member_id_value': data.get('member_id') if data else None,
                'member_id_type': type(data.get('member_id')).__name__ if data and data.get('member_id') else None
            }
        except Exception as e:
            debug_info['request_data']['error'] = str(e)
        
        # Database checks
        try:
            db = get_db()
            
            # Check ticket exists
            ticket = db.tickets.find_one({'ticket_id': ticket_id})
            debug_info['database_checks']['ticket_exists'] = ticket is not None
            debug_info['database_checks']['ticket_data'] = str(ticket) if ticket else None
            
            # Check member exists (if member_id provided)
            if data and data.get('member_id'):
                member_id_str = str(data.get('member_id')).strip()
                debug_info['validation_steps']['member_id_cleaned'] = member_id_str
                debug_info['validation_steps']['is_valid_objectid'] = ObjectId.is_valid(member_id_str)
                
                if ObjectId.is_valid(member_id_str):
                    member = db.get_member_by_id(member_id_str)
                    debug_info['database_checks']['member_exists'] = member is not None
                    debug_info['database_checks']['member_data'] = {
                        'name': member.get('name') if member else None,
                        'user_id': member.get('user_id') if member else None
                    }
                
            # Check existing assignment
            existing = db.get_assignment_by_ticket(ticket_id)
            debug_info['database_checks']['existing_assignment'] = existing is not None
            debug_info['database_checks']['existing_assignment_data'] = str(existing) if existing else None
            
        except Exception as e:
            debug_info['database_checks']['error'] = str(e)
    
    return jsonify({
        'status': 'debug',
        'debug_info': debug_info
    })

@app.route('/api/tickets/<ticket_id>/assignment', methods=['DELETE'])
def unassign_ticket(ticket_id):
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    try:
        db.remove_assignment(ticket_id, session['member_id'])
        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/ticket/<ticket_id>')
def ticket_detail(ticket_id):
    """Show details for a specific ticket"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get current member role for access control
        current_member = db.get_member_by_id(session['member_id'])
        is_tech_director = current_member and current_member['role'] == 'Technical Director'
        
        # Technical Director can only view tickets referred to them
        if is_tech_director:
            ticket = db.get_ticket_by_id(ticket_id)
            if not ticket:
                return render_template('error.html', error="Ticket not found"), 404
            
            # Check if ticket is referred to Technical Director
            if ticket.get('status') != 'Referred to Tech Director':
                flash('You can only view tickets that have been referred to you for technical review.', 'warning')
                return redirect(url_for('tech_director_dashboard'))
            # If status IS "Referred to Tech Director", continue to show the ticket details
        
                # Only mark unread replies as read if there are actually new replies to be seen
        # This ensures the red dot stays visible until support actually sees the new replies
        if not is_tech_director:
            # Get latest reply to check if it's from customer
            replies = db.get_replies_by_ticket(ticket_id)
            if replies:
                # Sort by created_at descending to get latest first
                replies.sort(key=lambda x: x.get('created_at', datetime.min), reverse=True)
                latest_reply = replies[0]
                if latest_reply.get('sender') == 'customer':
                    # Mark as read only if viewing the ticket page (not just passing through)
                    db.update_ticket(ticket_id, {'has_unread_reply': False})
        
        # Get ticket with assignment info
        ticket = db.get_ticket_by_id(ticket_id)

        # Debug: Check for ticket ID consistency
        if ticket:
            actual_ticket_id = ticket.get('ticket_id', 'NO_TICKET_ID_FIELD')
            if str(ticket_id) != str(actual_ticket_id):
                app.logger.warning(f"âš ï¸ TICKET ID MISMATCH IN PORTAL - URL: {ticket_id}, Database: {actual_ticket_id}")
                app.logger.warning(f"âš ï¸ This could cause email template vs portal ticket ID mismatch!")

        # Mark forwarded assignment as seen when assignee opens the ticket
        try:
            if ticket and ticket.get('assignment'):
                assignment = ticket['assignment'][0]
                if assignment.get('is_forwarded'):
                    assignee_members = ticket.get('assigned_member') or []
                    if assignee_members:
                        assignee_id = assignee_members[0].get('_id')
                        if assignee_id and str(assignee_id) == str(session.get('member_id')):
                            db.mark_assignment_seen(ticket_id, assignee_id)
        except Exception as _:
            # Never block page render on seen-mark failure
            pass
        
        if not ticket:
            return render_template('error.html', error="Ticket not found"), 404
        
        # Get all replies for this ticket
        replies = db.get_replies_by_ticket(ticket_id)
        
        # Get all members for assignment dropdown
        members = db.get_all_members()
        
        # Get all technicians for technician assignment dropdown
        technicians = db.get_all_technicians()
        app.logger.info(f"ðŸ”§ Retrieved {len(technicians)} technicians for ticket {ticket_id}")
        for tech in technicians:
            app.logger.info(f"  - Technician: {tech.get('name')} (ID: {tech.get('_id')}, Role: {tech.get('role')})")
        
        # Debug: Check if technicians list is empty
        if not technicians:
            app.logger.warning(f" No technicians found for ticket {ticket_id} - this will cause dropdown to be empty!")
        else:
            app.logger.info(f" Successfully loaded {len(technicians)} technicians for dropdown")
        
        # Convert ObjectIds to strings for template and ensure consistency
        for member in members:
            member['_id'] = str(member['_id'])
            member['id'] = member['_id']  # Add 'id' field for admin.html compatibility
        
        # Convert technicians ObjectIds to strings for template
        for technician in technicians:
            technician['_id'] = str(technician['_id'])
            technician['id'] = technician['_id']
        
        # Debug: Log technician data after conversion
        app.logger.info(f"ðŸ”§ After ObjectId conversion - {len(technicians)} technicians:")
        for tech in technicians:
            app.logger.info(f"  - Converted: {tech.get('name')} (ID: {tech.get('id')}, _id: {tech.get('_id')})")
        
        # Convert ticket to dict and clean all ObjectIds and undefined values
        ticket = dict(ticket)
        
        def clean_data_for_template(obj):
            """Recursively clean data to make it JSON serializable"""
            if isinstance(obj, dict):
                cleaned = {}
                for k, v in obj.items():
                    if v is None:
                        cleaned[k] = None
                    elif hasattr(v, '__class__') and v.__class__.__name__ == 'ObjectId':
                        cleaned[k] = str(v)
                    elif isinstance(v, (dict, list)):
                        cleaned[k] = clean_data_for_template(v)
                    elif hasattr(v, '__class__') and v.__class__.__name__ == 'Undefined':
                        cleaned[k] = None  # Convert Undefined to None
                    else:
                        cleaned[k] = v
                return cleaned
            elif isinstance(obj, list):
                return [clean_data_for_template(item) for item in obj]
            elif hasattr(obj, '__class__') and obj.__class__.__name__ == 'ObjectId':
                return str(obj)
            elif hasattr(obj, '__class__') and obj.__class__.__name__ == 'Undefined':
                return None
            else:
                return obj
        
        # Initialize variables first (will clean them later)
        

        
        # Handle both datetime objects (from MongoDB) and string dates
        if ticket.get('created_at') and isinstance(ticket['created_at'], datetime):
            formatted_date = ticket['created_at'].strftime("%b %d, %Y %I:%M %p")
        else:
            try:
                created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                formatted_date = created_at.strftime("%b %d, %Y %I:%M %p")
            except:
                formatted_date = str(ticket['created_at'])
        
        formatted_replies = []
        for reply in replies:
            reply_dict = dict(reply)
            # Handle both datetime objects (from MongoDB) and string dates
            if isinstance(reply_dict['created_at'], datetime):
                reply_dict['formatted_date'] = reply_dict['created_at'].strftime("%b %d, %I:%M %p")
            else:
                try:
                    created_at = datetime.strptime(str(reply_dict['created_at']), "%Y-%m-%d %H:%M:%S")
                    reply_dict['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                except:
                    reply_dict['formatted_date'] = str(reply_dict['created_at'])
            reply_dict['is_customer'] = reply_dict.get('sender', 'support') == 'customer'
            
            # Get any attachments for this reply (stored in the reply document itself)
            reply_dict['attachments'] = reply_dict.get('attachments', [])
            
            # Format attachments for template compatibility
            formatted_attachments = []
            for attachment in reply_dict['attachments']:
                attachment_type = attachment.get('type', 'file')  # Default to 'file' if type missing
                
                if attachment_type == 'file':
                    # Get file path and calculate file size if missing
                    file_path = attachment.get('path', '')
                    file_size = attachment.get('size', 0)
                    
                    # Try to get file size from disk if not in database
                    if file_size == 0 and file_path:
                        try:
                            if os.path.exists(file_path):
                                file_size = os.path.getsize(file_path)
                            else:
                                # Try in uploads directory
                                uploads_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path))
                                if os.path.exists(uploads_path):
                                    file_size = os.path.getsize(uploads_path)
                        except Exception:
                            file_size = 0
                    
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', attachment.get('path', ''))),
                        'type': 'file',
                        'path': file_path,
                        'filename': attachment.get('filename', attachment.get('name', os.path.basename(file_path) if file_path else 'Unknown')),
                        'name': attachment.get('filename', attachment.get('name', os.path.basename(file_path) if file_path else 'Unknown')),
                        'url': attachment.get('url', f"/uploads/{os.path.basename(file_path)}" if file_path else ''),
                        'size': file_size,
                        'is_warranty': attachment.get('is_warranty', False)
                    })
                elif attachment_type == 'common-document':
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', attachment.get('ref', ''))),
                        'type': 'common-document',
                        'ref': attachment.get('ref', ''),
                        'name': attachment.get('name', 'Common Document')
                    })
                elif attachment_type == 'text_reference':
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', str(attachment))),
                        'type': 'text_reference',
                        'name': attachment.get('name', 'Document Reference'),
                        'description': attachment.get('description', '')
                    })
                else:
                    # Handle unknown attachment types gracefully
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', str(attachment))),
                        'type': attachment_type,
                        'name': attachment.get('name', 'Unknown attachment'),
                        'path': attachment.get('path', ''),
                        'ref': attachment.get('ref', ''),
                        'size': attachment.get('size', 0)
                    })
            reply_dict['attachments'] = formatted_attachments
            
            formatted_replies.append(reply_dict)
        
        # Get ticket metadata with new fields
        vehicle_registration = None
        service_date = None
        claim_date = None
        engineer_id = None
        engineer_name = None
        attachments = []
        
        # New customer name fields
        customer_title = None
        customer_first_name = None
        customer_surname = None
        type_of_claim = None
        
        # New fields
        technician = None
        technician_id = None
        technician_info = None
        vhc_link = None
        days_between_service_claim = None
        
        # Checklist metadata fields
        advisories_followed = None
        within_warranty = None
        new_fault_codes = None
        dpf_light_on = None
        eml_light_on = None
        
        # Outcome fields
        outcome_category = None
        revisit_carried_out = None
        clean_under_warranty = None
        outcome_notes = None
        
        # Get metadata for this ticket
        metadata = db.get_ticket_metadata(ticket_id)
        
        # Process metadata attachments for manually created tickets
        metadata_attachments = []
        app.logger.info(f"DEBUG: Processing metadata for ticket {ticket_id} - Found {len(metadata)} metadata entries")
        
        for meta in metadata:
            app.logger.info(f"DEBUG: Processing metadata key: {meta.get('key')}")
            if meta.get('key', '').startswith('attachment_'):
                app.logger.info(f"DEBUG: Found attachment metadata: {meta.get('key')} = {meta.get('value')}")
                try:
                    attachment_data = json.loads(meta.get('value', '{}'))
                    app.logger.info(f"DEBUG: Parsed attachment data: {attachment_data}")
                    if attachment_data and isinstance(attachment_data, dict):
                        # FIXED: Convert metadata attachment to standard attachment format with base64 data
                        metadata_attachments.append({
                            'filename': attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File')),
                            'name': attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File')),
                            'size': attachment_data.get('size', 0),
                            'path': attachment_data.get('path', ''),
                            'data': attachment_data.get('data', ''),  # FIXED: Include base64 data
                            'is_warranty': attachment_data.get('is_warranty', False),
                            'source': 'metadata',
                            'type': 'file'
                        })
                        app.logger.info(f"SUCCESS: Added metadata attachment: {attachment_data.get('original_name', 'Unknown')} (base64: {len(attachment_data.get('data', ''))} chars)")
                    else:
                        app.logger.warning(f"WARNING: Attachment data is empty or not a dict: {attachment_data}")
                except (json.JSONDecodeError, TypeError) as e:
                    app.logger.warning(f"ERROR: Failed to parse attachment metadata for {meta.get('key')}: {e}")
                    continue
            else:
                app.logger.info(f"DEBUG: Non-attachment metadata: {meta.get('key')} = {meta.get('value')}")
        
        # Process main ticket document attachments (for manual tickets)
        ticket_attachments = []
        app.logger.info(f"DEBUG: Ticket {ticket_id} - has_attachments: {ticket.get('has_attachments', False)}")
        app.logger.info(f"DEBUG: Ticket {ticket_id} - attachments field: {ticket.get('attachments', 'NOT_FOUND')}")
        
        if ticket.get('has_attachments', False) and ticket.get('attachments'):
            app.logger.info(f"DEBUG: Processing {len(ticket['attachments'])} ticket document attachments")
            for i, att in enumerate(ticket['attachments']):
                app.logger.info(f"DEBUG: Processing attachment {i}: {att}")
                if isinstance(att, dict):
                    # FIXED: Include base64 data from ticket document attachments
                    ticket_attachments.append({
                        'filename': att.get('filename', att.get('original_name', 'Unknown File')),
                        'name': att.get('original_name', att.get('filename', 'Unknown File')),
                        'size': att.get('size', 0),
                        'path': att.get('path', ''),
                        'data': att.get('data', ''),  # FIXED: Include base64 data
                        'is_warranty': att.get('is_warranty', False),
                        'source': 'ticket_document',
                        'type': 'file',
                        'index': i  # For download URLs
                    })
                    app.logger.info(f"SUCCESS: Added ticket document attachment {i+1}: {att.get('filename', 'Unknown')} (base64: {len(att.get('data', ''))} chars)")
                else:
                    app.logger.warning(f"WARNING: Attachment {i} is not a dict: {type(att)} - {att}")
        else:
            app.logger.warning(f"WARNING: Ticket {ticket_id} has no attachments or has_attachments is False")
        
        # Combine all attachment sources - PRIORITIZE metadata attachments (manual tickets)
        app.logger.info(f"DEBUG: Before combining - metadata_attachments: {len(metadata_attachments)}, ticket_attachments: {len(ticket_attachments)}")
        
        # PRIORITY: Use metadata attachments for manually created tickets (source: 'metadata')
        if metadata_attachments:
            attachments.extend(metadata_attachments)
            app.logger.info(f"SUCCESS: Added {len(metadata_attachments)} metadata attachments to ticket {ticket_id}")
            # Skip ticket document attachments if we have metadata attachments (prevents duplicates)
            app.logger.info(f"INFO: Skipping ticket document attachments to prevent duplicates")
        elif ticket_attachments:
            # Only use ticket document attachments if no metadata attachments exist
            attachments.extend(ticket_attachments)
            app.logger.info(f"SUCCESS: Added {len(ticket_attachments)} ticket document attachments to ticket {ticket_id}")
        else:
            app.logger.info(f"INFO: No attachments found for ticket {ticket_id}")
        
        app.logger.info(f"FINAL RESULT: Total attachments for ticket {ticket_id}: {len(attachments)}")
        app.logger.info(f"DEBUG: Final attachments array: {attachments}")
        
        # ENHANCED DEBUGGING: Check what's in the ticket object itself
        app.logger.info(f"DEBUG: Ticket {ticket_id} has_attachments field: {ticket.get('has_attachments', 'NOT_FOUND')}")
        app.logger.info(f"DEBUG: Ticket {ticket_id} attachments field: {ticket.get('attachments', 'NOT_FOUND')}")
        if ticket.get('attachments'):
            app.logger.info(f"DEBUG: Ticket {ticket_id} attachments count: {len(ticket['attachments'])}")
            for i, att in enumerate(ticket['attachments']):
                app.logger.info(f"DEBUG: Ticket attachment {i}: {att}")
        
        # ENHANCED DEBUGGING: Check metadata attachments
        app.logger.info(f"DEBUG: Metadata attachments count: {len(metadata_attachments)}")
        for i, att in enumerate(metadata_attachments):
            app.logger.info(f"DEBUG: Metadata attachment {i}: {att}")
        
        # ENHANCED DEBUGGING: Check ticket document attachments
        app.logger.info(f"DEBUG: Ticket document attachments count: {len(ticket_attachments)}")
        for i, att in enumerate(ticket_attachments):
            app.logger.info(f"DEBUG: Ticket document attachment {i}: {att}")
            
        metadata_dict = {}
        for item in metadata:
            key = item['key']
            value = item['value']
            
            if key == 'vehicle_registration':
                vehicle_registration = value
            elif key == 'service_date':
                service_date = value
            elif key == 'claim_date':
                claim_date = value
            elif key == 'engineer':
                engineer_id = value
            elif key == 'customer_title':
                customer_title = value
            elif key == 'customer_first_name':
                customer_first_name = value
            elif key == 'customer_surname':
                customer_surname = value
            elif key == 'type_of_claim':
                type_of_claim = value
            elif key == 'technician_name':
                technician = value
            elif key == 'technician_id':
                technician_id = value
            elif key == 'vhc_link':
                vhc_link = value
            elif key == 'days_between_service_claim':
                days_between_service_claim = value
            elif key == 'advisories_followed':
                advisories_followed = value
            elif key == 'within_warranty':
                within_warranty = value
            elif key == 'new_fault_codes':
                new_fault_codes = value
            elif key == 'dpf_light_on':
                dpf_light_on = value
            elif key == 'eml_light_on':
                eml_light_on = value
            elif key == 'outcome_category':
                outcome_category = value
            elif key == 'revisit_carried_out':
                revisit_carried_out = value
            elif key == 'clean_under_warranty':
                clean_under_warranty = value
            elif key == 'outcome_notes':
                outcome_notes = value
            # ============================================================================
            # COMPLETELY REMOVED: Old metadata attachment processing
            # NO MORE warranty_form, dpf_report, or other_file_ metadata processing
            # All attachments must be real files in ticket.attachments or structured metadata
            # ============================================================================
            elif key in ['dpf_report', 'warranty_form'] or key.startswith('other_file_'):
                app.logger.info(f"ðŸš« IGNORED LEGACY METADATA: {key} = '{value}' (no longer processed for attachments)")
            else:
                metadata_dict[key] = value
        
        # If engineer ID is set, get engineer name (legacy support)
        if engineer_id:
            engineer = db.get_member_by_id(engineer_id)
            if engineer:
                engineer_name = engineer['name']
        
        # Get technician information if technician_id is set
        if technician_id and ObjectId.is_valid(technician_id):
            # Look in technicians collection first, then fallback to members collection
            technician_data = db.get_technician_by_id(technician_id)
            if technician_data:
                technician_info = {
                    'id': str(technician_data['_id']),
                    'name': technician_data['name'],
                    'user_id': technician_data.get('user_id', ''),
                    'gender': technician_data.get('gender', ''),
                    'role': technician_data.get('role', 'Technician')  # Default to 'Technician' if no role
                }
                # Set technician name for display (overrides legacy name if both exist)
                technician = technician_data['name']
                app.logger.info(f" Found technician in technicians collection: {technician} (ID: {technician_id})")
            else:
                # Fallback to members collection for backward compatibility
                technician_member = db.get_member_by_id(technician_id)
                if technician_member:
                    technician_info = {
                        'id': str(technician_member['_id']),
                        'name': technician_member['name'],
                        'user_id': technician_member.get('user_id', ''),
                        'gender': technician_member.get('gender', ''),
                        'role': technician_member.get('role', 'Technician')
                    }
                    technician = technician_member['name']
                    app.logger.info(f" Found technician in members collection (fallback): {technician} (ID: {technician_id})")
                else:
                    app.logger.warning(f" Technician with ID {technician_id} not found in either technicians or members collection")
        elif technician_id:
            app.logger.warning(f" Invalid technician_id format: {technician_id}")
        
        # Debug logging for technician data
        app.logger.info(f"Ticket {ticket_id} - Technician: {technician}, Technician ID: {technician_id}, Technician Info: {technician_info is not None}")
        
        # Handle assignment info for forwarded tickets
        if ticket.get('assignment') and len(ticket['assignment']) > 0:
            assignment = ticket['assignment'][0]
            ticket['is_forwarded'] = assignment.get('is_forwarded', False)
            
            # Handle forwarded from member info
            if ticket['is_forwarded'] and ticket.get('forwarded_from_member') and len(ticket['forwarded_from_member']) > 0:
                forwarded_member = ticket['forwarded_from_member'][0]
                ticket['forwarded_from_name'] = forwarded_member.get('name')
        
        # [FIX] NEW: Format attachments exactly like simple app with JSON cleaning
        simple_app_attachments = []
        
        # Process both ticket document attachments and metadata attachments (email attachments)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            for i, att in enumerate(ticket['attachments']):
                try:
                    # Clean any potential malformed JSON in attachment data
                    cleaned_att = {}
                    for k, v in att.items():
                        if isinstance(v, str):
                            # Clean potential JSON strings
                            try:
                                if v.strip() and v.strip() not in ['{}', '[]', 'null', 'undefined']:
                                    # Try to parse and re-serialize to ensure valid JSON
                                    if v.strip().startswith('{') or v.strip().startswith('['):
                                        clean_json = v.strip()
                                        if clean_json.endswith(',}'):
                                            clean_json = clean_json[:-2] + '}'
                                        elif clean_json.endswith(',]'):
                                            clean_json = clean_json[:-2] + ']'
                                        # Test parse to validate
                                        json.loads(clean_json)
                                        cleaned_att[k] = clean_json
                                    else:
                                        cleaned_att[k] = v
                                else:
                                    cleaned_att[k] = v
                            except (json.JSONDecodeError, TypeError):
                                # If JSON parsing fails, just use the string as-is
                                cleaned_att[k] = str(v) if v is not None else ''
                        else:
                            cleaned_att[k] = v
                    
                    simple_attachment = {
                        'id': f"{ticket_id}_{i}",  # Create unique ID for download URL
                        'fileName': cleaned_att.get('filename', 'unknown_file'),
                        'fileData': cleaned_att.get('data', ''),  # Keep for download
                        'size': cleaned_att.get('size', 0),
                        'is_warranty': cleaned_att.get('is_warranty', False)
                    }
                    simple_app_attachments.append(simple_attachment)
                except Exception as att_error:
                    app.logger.warning(f"Skipping malformed attachment {i} in ticket {ticket_id}: {att_error}")
                    continue
        
        # [FIX] NEW: Also process email attachments stored in metadata
        if metadata_attachments:
            for i, att in enumerate(metadata_attachments):
                try:
                    simple_attachment = {
                        'id': f"{ticket_id}_metadata_{i}",  # Create unique ID for download URL
                        'fileName': att.get('filename', 'unknown_file'),
                        'fileData': att.get('data', ''),  # Keep for download
                        'size': att.get('size', 0),
                        'is_warranty': att.get('is_warranty', False)
                    }
                    simple_app_attachments.append(simple_attachment)
                    app.logger.info(f"Added metadata attachment to simple_app_attachments: {att.get('filename', 'Unknown')}")
                except Exception as att_error:
                    app.logger.warning(f"Skipping malformed metadata attachment {i} in ticket {ticket_id}: {att_error}")
                    continue
        
        # Add simple app attachments to ticket for template (after cleaning)
        ticket['simple_attachments'] = simple_app_attachments
        ticket['attachments_count'] = len(simple_app_attachments)
        
        # DEBUGGING: Log attachments before template rendering
        app.logger.info(f" FINAL ATTACHMENTS FOR TEMPLATE: {len(attachments)} attachments")
        for i, att in enumerate(attachments):
            app.logger.info(f"  {i+1}. name: '{att.get('name', 'NO_NAME')}', file_path: '{att.get('file_path', 'NO_PATH')}', key: '{att.get('key', 'NO_KEY')}'")
        
        # Clean ALL data before template rendering (after all variables are initialized)
        try:
            app.logger.info(f"ðŸ§¹ Starting data cleaning for ticket {ticket_id}")
            
            # Special cleaning for attachments that might contain malformed JSON
            def clean_attachments_data(attachments_list):
                cleaned_list = []
                for item in attachments_list:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for k, v in item.items():
                            if isinstance(v, str):
                                # Clean any JSON strings that might be malformed
                                try:
                                    if v.strip() and v.strip() not in ['{}', '[]', 'null', 'undefined']:
                                        if v.strip().startswith('{') or v.strip().startswith('['):
                                            clean_json = v.strip()
                                            if clean_json.endswith(',}'):
                                                clean_json = clean_json[:-2] + '}'
                                            elif clean_json.endswith(',]'):
                                                clean_json = clean_json[:-2] + ']'
                                            # Test parse to validate
                                            json.loads(clean_json)
                                            cleaned_item[k] = clean_json
                                        else:
                                            cleaned_item[k] = v
                                    else:
                                        cleaned_item[k] = v
                                except (json.JSONDecodeError, TypeError):
                                    cleaned_item[k] = str(v) if v is not None else ''
                            else:
                                cleaned_item[k] = v
                        cleaned_list.append(cleaned_item)
                    else:
                        cleaned_list.append(item)
                return cleaned_list
            
            # Clean all variables
            ticket = clean_data_for_template(ticket)
            formatted_replies = clean_data_for_template(formatted_replies)
            attachments = clean_attachments_data(attachments)
            simple_app_attachments = clean_attachments_data(simple_app_attachments)
            members = clean_data_for_template(members)
            app.logger.info(f" Data cleaning completed for ticket {ticket_id}")
        except Exception as clean_error:
            app.logger.error(f" Error during data cleaning for ticket {ticket_id}: {clean_error}")
            # Ensure attachments is at least an empty list to prevent template errors
            attachments = []
            simple_app_attachments = []
            app.logger.info(f"ðŸ”„ Using empty attachments as fallback for ticket {ticket_id}")
        
        try:
            app.logger.info(f"ðŸŽ¨ Starting template render for ticket {ticket_id}")
            
            # Final safety check - test JSON serialization of attachments before template rendering
            try:
                json.dumps(attachments)
                app.logger.info(f" Attachments JSON serialization test passed for ticket {ticket_id}")
            except (TypeError, ValueError) as json_error:
                app.logger.warning(f" Attachments failed JSON serialization test: {json_error}, using empty list")
                attachments = []
            
            return render_template('ticket_detail.html', 
                                ticket=ticket,
                                formatted_date=formatted_date,
                                replies=formatted_replies,
                                members=members,
                                technicians=technicians,
                                vehicle_registration=vehicle_registration,
                                service_date=service_date,
                                claim_date=claim_date,
                                engineer_name=engineer_name,
                                customer_title=customer_title,
                                customer_first_name=customer_first_name,
                                customer_surname=customer_surname,
                                type_of_claim=type_of_claim,
                                technician=technician,
                                technician_name=technician,
                                technician_id=technician_id,
                                technician_info=technician_info,
                                vhc_link=vhc_link,
                                days_between_service_claim=days_between_service_claim,
                                advisories_followed=advisories_followed,
                                within_warranty=within_warranty,
                                new_fault_codes=new_fault_codes,
                                dpf_light_on=dpf_light_on,
                                eml_light_on=eml_light_on,
                                outcome_category=outcome_category,
                                revisit_carried_out=revisit_carried_out,
                                clean_under_warranty=clean_under_warranty,
                                outcome_notes=outcome_notes,
                                attachments=attachments,
                                current_user_id=session.get('member_id'),
                                current_user=session.get('member_name'),
                                current_user_role=current_member['role'] if current_member else 'Unknown',
                                is_tech_director=is_tech_director)
        except Exception as render_error:
            app.logger.error(f" Template render error for ticket {ticket_id}: {render_error}")
            return render_template('error.html', error=f"Error loading ticket details: {render_error}"), 500
    except Exception as e:
        app.logger.error(f" Error in ticket_detail for {ticket_id}: {e}")
        import traceback
        app.logger.error(f" Traceback: {traceback.format_exc()}")
        return render_template('error.html', error=f"Database error: {e}"), 500

# OLD ENDPOINT DISABLED - Using unified endpoint below
# @app.route('/api/tickets', methods=['POST'])
def create_ticket_api_DISABLED():
    """Create new ticket via API - Technical Director BLOCKED"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Block Technical Director from this route
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if current_member and current_member['role'] == 'Technical Director':
        return jsonify({'status': 'error', 'message': 'Access denied. Use Technical Director dashboard.'}), 403
    
    db = None
    try:
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400

        thread_id = data.get('threadId')
        if not thread_id:
            return jsonify({'status': 'error', 'message': 'threadId is required'}), 400

        email = extract_email(data.get('form', ''))
        ticket_id = data.get('ticketId')
        
        db = get_db()
        
        # Check if ticket with this thread_id already exists
        existing_ticket = db.tickets.find_one({'thread_id': thread_id})

        if existing_ticket:
            # Update existing ticket - reopen if customer replied
            is_customer_reply = data.get('body') and data.get('body') != data.get('draft', '')
            
            update_data = {
                'draft_body': data.get('draft', ''),
                'classification': data.get('classification'),
                'priority': data.get('priority'),
                'updated_at': datetime.now()
            }
            
            if is_customer_reply:
                update_data['status'] = 'Open'
                update_data['has_unread_reply'] = True
            
            db.update_ticket(existing_ticket['ticket_id'], update_data)
            
            # Add reply if this is a response from customer
            if is_customer_reply:
                reply_data = {
                    'ticket_id': existing_ticket['ticket_id'],
                    'thread_id': thread_id,
                    'message': data.get('body'),
                    'sender': 'customer'
                }
                db.create_reply(reply_data)
            
            ticket_id = existing_ticket['ticket_id']
            action = 'updated'
        else:
            # Create new ticket with race condition protection
            if not ticket_id:
                # Use proper classification and priority codes to avoid conflicts
                class_code = get_classification_code(data.get('classification', 'General'))
                priority_code = get_priority_code(data.get('priority', 'Medium'))
                
                # Generate unique email ticket ID with race condition protection (same logic as n8n email system)
                max_attempts = 50
                for attempt in range(max_attempts):
                    # Use thread_id + email to generate 4-digit code (same as n8n email system)
                    thread_seed = str(thread_id) if thread_id else email
                    seed_string = f"{thread_seed}{email}{datetime.now().isoformat()}"
                    
                    # Calculate sum of character codes (matching n8n email system)
                    sum_chars = 0
                    for char in seed_string:
                        sum_chars += ord(char)
                    
                    # Generate 4-digit number (same as n8n: sum % 10000)
                    four_digit_code = sum_chars % 10000
                    four_digit_str = f"{four_digit_code:04d}"  # Ensure 4 digits with leading zeros
                    
                    potential_id = f"{class_code}{priority_code}{four_digit_str}"
                    app.logger.debug(f"? Email ticket calculation: thread_seed={thread_seed}, sum_chars={sum_chars}, 4-digit={four_digit_code}")
                    
                    try:
                        # Try to create ticket with this ID - will fail if duplicate
                        ticket_data = {
                            'ticket_id': potential_id,
                            'email': email,
                            'name': data.get('name'),
                            'phone': data.get('phone', ''),
                            'subject': data.get('subject'),
                            'body': data.get('body'),
                            'draft_body': data.get('draft', ''),
                            'classification': data.get('classification'),
                            'priority': data.get('priority'),
                            'status': 'Open',
                            'thread_id': thread_id,
                            'message_id': data.get('messageid'),
                            'creation_method': 'email'
                        }
                        
                        # ðŸš€ GENERATE DRAFT RESPONSE if none provided or empty
                        existing_draft = ticket_data.get('draft_body', '').strip()
                        if not existing_draft:
                            app.logger.info(f"ðŸ¤– GENERATING SMART DRAFT for email ticket {potential_id} (no existing draft)")
                            draft_response = generate_email_draft_response(ticket_data)
                            ticket_data['draft_body'] = draft_response
                            app.logger.info(f" SMART DRAFT GENERATED for ticket {potential_id} - Length: {len(draft_response)} chars")
                        else:
                            app.logger.info(f"ðŸ“ USING EXISTING DRAFT for ticket {potential_id} - Length: {len(existing_draft)} chars")
                        
                        # This will throw ValueError if ticket ID already exists (race condition safe)
                        db.create_ticket(ticket_data)
                        ticket_id = potential_id
                        app.logger.info(f"Successfully created email ticket with ID: {ticket_id} on attempt {attempt + 1}")
                        break
                        
                    except ValueError as e:
                        if "Ticket ID already exists" in str(e):
                            app.logger.debug(f"Email ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                            continue  # Try next ID
                        else:
                            # Different error, re-raise
                            raise e
                
                if not ticket_id:
                    return jsonify({'status': 'error', 'message': 'Failed to generate unique ticket ID. Please try again.'}), 500
            action = 'created'
        return jsonify({
            'status': 'success', 
            'ticket_id': ticket_id,
            'customer_number': ticket_id,
            'action': action,
            'message': f'Ticket {action} successfully! Customer Number: {ticket_id}',
            'reference_message': f'Your Customer Number is {ticket_id}. Please reference this number for all inquiries.'
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

# [Rest of the code remains exactly the same until the send_reply function]

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.route('/api/tickets/<ticket_id>/reply', methods=['POST'])
def send_reply(ticket_id):
    """Send a reply to a ticket - All team members can participate in conversations"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # All team members (including Technical Director) can reply to tickets
    
    try:
        # Input validation
        if not ticket_id or len(ticket_id) > 20:
            return jsonify({'status': 'error', 'message': 'Invalid ticket ID'}), 400
            
        # Get the response text from form data
        response_text = request.form.get('response', '').strip()
        if not response_text:
            return jsonify({'status': 'error', 'message': 'Response text is required'}), 400
        
        if len(response_text) > 10000:  # Reasonable limit
            return jsonify({'status': 'error', 'message': 'Response text too long'}), 400

        # ANTI-SPAM: Check for duplicate submissions within last 5 seconds
        member_id = session['member_id']
        current_time = datetime.now()
        cache_key = f"reply_spam_{ticket_id}_{member_id}_{response_text[:50]}"
        
        # Simple in-memory cache for spam prevention
        if not hasattr(app, '_reply_cache'):
            app._reply_cache = {}
        
        # Clean old entries (older than 5 seconds)
        app._reply_cache = {k: v for k, v in app._reply_cache.items() 
                           if (current_time - v).total_seconds() < 5}
        
        if cache_key in app._reply_cache:
            app.logger.warning(f"ðŸš« SPAM BLOCKED - Duplicate reply attempt for ticket {ticket_id} by member {member_id}")
            return jsonify({'status': 'error', 'message': 'Duplicate submission detected. Please wait before sending again.'}), 429
        
        # Record this submission to prevent duplicates
        app._reply_cache[cache_key] = current_time
        
        app.logger.info(f" PROCESSING REPLY - Ticket: {ticket_id}, Member: {member_id}, Text: {response_text[:30]}...")

        db = get_db()
        
        # Get ticket details
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        
        if not ticket:
            app.logger.warning(f"Reply attempt for non-existent ticket: {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404

        # Save reply to database
        reply_data = {
            'ticket_id': ticket_id,
            'thread_id': ticket['thread_id'],
            'message': response_text,
            'sender': 'support'
        }
        
        reply_id = db.create_reply(reply_data)
        
        # Process file attachments - handle both attachment_ and response_attachments
        attachment_files = []
        
        # Handle multiple files from response_attachments field (from ticket detail page)
        app.logger.info(f"ðŸ“Ž PROCESSING REPLY ATTACHMENTS for ticket {ticket_id}")
        app.logger.info(f"ðŸ“Ž Files in request: {list(request.files.keys())}")
        
        if 'response_attachments' in request.files:
            files = request.files.getlist('response_attachments')
            app.logger.info(f"ðŸ“Ž Found {len(files)} files in response_attachments")
            
            for i, file in enumerate(files):
                app.logger.info(f"ðŸ“Ž Processing file {i+1}: {file.filename if file else 'No file'}")
                
                if file and file.filename and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_uuid = str(uuid.uuid4())
                    safe_filename = f"{file_uuid}_{filename}"
                    file_path = os.path.join(UPLOAD_FOLDER, safe_filename)
                    
                    try:
                        file.save(file_path)
                        file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                        
                        attachment_files.append({
                            'path': file_path,
                            'original_name': filename,
                            'size': file_size
                        })
                        app.logger.info(f" SAVED ATTACHMENT: {filename} as {safe_filename} ({file_size} bytes)")
                    except Exception as e:
                        app.logger.error(f" ERROR saving attachment {filename}: {e}")
                else:
                    app.logger.warning(f" SKIPPED invalid file: {file.filename if file else 'None'}")
        else:
            app.logger.info("ðŸ“Ž No response_attachments field found in request")
        
        # Handle individual attachment_ fields (backward compatibility)
        for key in request.files:
            if key.startswith('attachment_'):
                file = request.files[key]
                if file and file.filename and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_uuid = str(uuid.uuid4())
                    safe_filename = f"{file_uuid}_{filename}"
                    file_path = os.path.join(UPLOAD_FOLDER, safe_filename)
                    file.save(file_path)
                    attachment_files.append({
                        'path': file_path,
                        'original_name': filename,
                        'size': os.path.getsize(file_path) if os.path.exists(file_path) else 0
                    })
                    app.logger.info(f"Saved attachment: {filename} as {safe_filename}")
        
        # Process common document references
        common_document_refs = []
        common_document_names = []
        
        # Debug: Log all form fields to understand what's being sent
        app.logger.info(f"ðŸ” DEBUG: All form fields received: {list(request.form.keys())}")
        
        for key in request.form:
            # Only process fields that are exactly in the format common_document_<number> (the document ID fields)
            # This regex matches: common_document_0, common_document_1, common_document_2, etc.
            if re.match(r'^common_document_\d+$', key):
                doc_id = request.form[key]
                doc_name_key = f"{key}_name"
                doc_name = request.form.get(doc_name_key, 'Unknown Document')
                
                app.logger.info(f"ðŸ” DEBUG: Processing document field: {key} = {doc_id}, name_key = {doc_name_key}, name = {doc_name}")
                
                # Additional validation: ensure doc_id is not empty and looks like a valid ID
                if doc_id and doc_id.strip() and doc_id != 'undefined' and doc_id != 'null':
                    common_document_refs.append(doc_id)
                    common_document_names.append(doc_name)
                    app.logger.info(f"ðŸ“„ Found common document reference: {doc_name} (ID: {doc_id})")
                    
                    # Debug: Check if the name field actually exists and has a value
                    if doc_name_key in request.form:
                        app.logger.info(f"âœ… Name field {doc_name_key} exists with value: {request.form[doc_name_key]}")
                    else:
                        app.logger.warning(f"âš ï¸ Name field {doc_name_key} NOT FOUND in form data!")
                        app.logger.warning(f"âš ï¸ Available form fields: {[k for k in request.form.keys() if k.startswith('common_document_')]}")
                else:
                    app.logger.warning(f"âš ï¸ Skipping invalid document ID: {doc_id} for key: {key}")
            elif key.startswith('common_document_'):
                # Log metadata fields for debugging
                app.logger.info(f"ðŸ” DEBUG: Skipping metadata field: {key} = {request.form[key]}")
        
        app.logger.info(f"ðŸ“„ Total common documents processed: {len(common_document_refs)}")
        
        # Additional safety check: ensure we don't have duplicate document IDs
        unique_doc_refs = list(dict.fromkeys(common_document_refs))
        if len(unique_doc_refs) != len(common_document_refs):
            app.logger.warning(f"âš ï¸ Duplicate document IDs detected! Original: {len(common_document_refs)}, Unique: {len(unique_doc_refs)}")
            app.logger.warning(f"âš ï¸ Original IDs: {common_document_refs}")
            app.logger.warning(f"âš ï¸ Unique IDs: {unique_doc_refs}")
            app.logger.warning(f"âš ï¸ Original Names: {common_document_names}")
            # Use unique IDs to prevent duplicates
            common_document_refs = unique_doc_refs
            # Also deduplicate names to match
            common_document_names = [common_document_names[common_document_refs.index(doc_id)] for doc_id in unique_doc_refs]
            app.logger.info(f"ðŸ“„ After deduplication: {len(common_document_refs)} documents")
            app.logger.info(f"ðŸ“„ After deduplication names: {common_document_names}")
        else:
            app.logger.info(f"ðŸ“„ No duplicates found - keeping original names: {common_document_names}")
        
        # Save file attachments - handle both old and new attachment format
        attachments = []
        for attachment_info in attachment_files:
            if isinstance(attachment_info, dict):
                # New format with detailed info
                file_path = attachment_info['path']
                filename = attachment_info['original_name']
                file_size = attachment_info['size']
            else:
                # Old format (backward compatibility)
                file_path = attachment_info
            filename = os.path.basename(file_path)
            file_size = 0
            try:
                file_size = os.path.getsize(file_path)
            except OSError:
                file_size = 0
            
            # Create URL for n8n to download the file
            file_url = f"{request.host_url.rstrip('/')}/uploads/{os.path.basename(file_path)}"
            # Automatic warranty detection for reply attachments
            is_warranty = detect_warranty_form(filename)
            file_type_info = get_enhanced_file_type_info(filename, file_size)
            
            attachments.append({
                'type': 'file',
                'path': file_path,
                'filename': filename,
                'url': file_url,
                'size': file_size,
                'name': filename,  # Add name field for template compatibility
                'is_warranty': is_warranty,
                'file_type_info': file_type_info,
                'original_name': filename  # Ensure original filename is preserved
            })
        
        # Save common document references with detailed info
        for i, doc_ref in enumerate(common_document_refs):
            doc_name = common_document_names[i] if i < len(common_document_names) else 'Unknown Document'
            app.logger.info(f"ðŸ” DEBUG: Creating attachment {i+1}: ref={doc_ref}, name={doc_name}, available_names={common_document_names}")
            
            attachments.append({
                'type': 'common-document',
                'ref': doc_ref,
                'name': doc_name,
                'filename': doc_name,
                'original_name': doc_name,
                'is_warranty': False,  # Common documents are not warranty forms
                'file_type_info': {'type': 'common_document', 'icon': 'ðŸ“„'}
            })
            app.logger.info(f"ðŸ“„ Added common document attachment: {doc_name} (ID: {doc_ref})")
        
        # If there are attachments, update the reply with them
        if attachments:
            app.logger.info(f"ðŸ“Ž SAVING {len(attachments)} attachments to reply {reply_id}")
            for i, att in enumerate(attachments):
                app.logger.info(f"ðŸ“Ž Attachment {i+1}: {att.get('name', 'Unknown')} - Type: {att.get('type', 'file')}")
            
            result = db.replies.update_one(
                {'_id': reply_id},
                {'$set': {'attachments': attachments}}
            )
            app.logger.info(f"ðŸ“Ž Database update result: {result.modified_count} modified")
        else:
            app.logger.info("ðŸ“Ž No attachments to save to reply")
        
        # Update ticket status - preserve TD status when Tech Director replies
        current_member = db.get_member_by_id(session['member_id'])
        is_tech_director = current_member and current_member['role'] == 'Technical Director'
        
        # If Tech Director replies to a ticket referred to them, keep the status so it stays in their dashboard
        if is_tech_director and ticket.get('status') == 'Referred to Tech Director':
            # Keep the "Referred to Tech Director" status so TD can continue working on it
            new_status = 'Referred to Tech Director'
            app.logger.info(f"[TARGET] TD REPLY - Preserving 'Referred to Tech Director' status for ticket {ticket_id}")
        else:
            # Normal behavior for other users
            new_status = 'Waiting for Response'
        
        update_data = {
            'status': new_status,
            'draft_body': '',
            'updated_at': datetime.now(),
            'has_unread_reply': False
        }
        db.update_ticket(ticket_id, update_data)
        
        # Prepare webhook payload in the required format (as array with specific structure)
        current_timestamp = datetime.now().isoformat()
        
        # Format attachments to match required structure with proper base64 encoding
        formatted_attachments = []
        app.logger.info(f"ðŸ” Processing {len(attachments)} attachments for webhook payload")
        
        for i, attachment in enumerate(attachments):
            app.logger.info(f"ðŸ” Processing attachment {i}: type={attachment.get('type')}, name={attachment.get('filename', attachment.get('name', 'unknown'))}")
            
            if attachment.get('type') == 'file':
                # Read file data and convert to base64 if it's a file attachment
                try:
                    file_path = attachment.get('path', '')
                    filename = attachment.get('filename', attachment.get('name', 'unknown_file'))
                    
                    if file_path and os.path.exists(file_path):
                        with open(file_path, 'rb') as f:
                            file_data = base64.b64encode(f.read()).decode('utf-8')
                        app.logger.info(f"âœ… Successfully encoded file attachment {filename} ({len(file_data)} base64 chars)")
                    else:
                        file_data = ""
                        app.logger.warning(f"âš ï¸ Attachment file not found: {file_path}")
                    
                    formatted_attachments.append({
                        "fileName": filename,
                        "fileData": file_data,
                        "id": str(attachment.get('id', uuid.uuid4().hex[:8])),
                        "size": attachment.get('size', 0),
                        "isWarranty": attachment.get('is_warranty', False)
                    })
                except Exception as e:
                    app.logger.error(f"âŒ Could not process file attachment {filename}: {e}")
                    
            elif attachment.get('type') in ['common-document', 'common_document']:
                # ðŸš€ FIXED: Handle both hyphen and underscore versions
                app.logger.info(f"ðŸ“„ Processing common document attachment: {attachment.get('filename', attachment.get('name', 'unknown'))}")
                
                # Use helper function to ensure common documents include file data
                enhanced_attachment = ensure_common_document_file_data(attachment)
                formatted_attachments.append(enhanced_attachment)
                
                app.logger.info(f"âœ… Enhanced common document attachment: {enhanced_attachment.get('fileName')} (fileData length: {len(enhanced_attachment.get('fileData', ''))})")
                
            else:
                app.logger.warning(f"âš ï¸ Unknown attachment type: {attachment.get('type')} for {attachment.get('filename', attachment.get('name', 'unknown'))}")
                # Include as basic attachment
                formatted_attachments.append({
                    "fileName": attachment.get('filename', attachment.get('name', 'unknown_file')),
                    "fileData": "",
                    "id": str(attachment.get('id', uuid.uuid4().hex[:8])),
                    "size": attachment.get('size', 0),
                    "isWarranty": False
                })
                
        app.logger.info(f"ðŸ“Š Formatted {len(formatted_attachments)} attachments for webhook payload")
        
        # Use original email message ID if this ticket came from an email, otherwise generate a custom one
        original_message_id = ticket.get('message_id', '')
        is_email_originated = bool(original_message_id and original_message_id.strip() and not original_message_id.startswith('msg-'))
        
        if is_email_originated:
            # Use the original email's message ID for Microsoft Outlook to reply properly
            message_id = original_message_id.strip()
            app.logger.info(f"Using original email message ID for Outlook reply: {message_id[:50]}...")
        else:
            # Generate custom ID for manually created tickets
            message_id = f"msg-{ticket_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}-{uuid.uuid4().hex[:8]}"
            app.logger.info(f"Generated custom message ID for manual ticket: {message_id}")
            
        # Determine if this ticket supports reply operation
        can_reply_to_email = is_email_originated
        
        # ðŸš€ SINGLE WEBHOOK PAYLOAD: Create one unified payload for n8n compatibility
        webhook_payload = {
            'ticket_id': ticket_id,
            'response_text': response_text,
            'replyMessage': response_text,
            'timestamp': current_timestamp,
            'user_id': session.get('member_id', 'unknown'),
            'ticket_subject': ticket.get('subject', ''),
            'subject': ticket.get('subject', ''),
            'ticket_status': new_status,
            'customer_email': ticket.get('email', ''),
            'customer_name': ticket.get('name', ''),
            'priority': ticket.get('priority', 'Medium'),
            'has_attachments': len(formatted_attachments) > 0,
            'attachments': formatted_attachments,
            'attachment_count': len(formatted_attachments),
            'message_id': message_id,
            'is_email_ticket': is_email_originated,
            'ticketSource': 'email' if is_email_originated else 'manual',
            # Additional n8n compatibility fields
            'id': ticket_id,
            'threadId': ticket.get('thread_id', ''),
            'email': ticket.get('email', ''),
            'body': ticket.get('body', ''),
            'draft': response_text,
            'message': response_text,
            'content': response_text,
            'classification': ticket.get('classification', 'General'),
            'date': current_timestamp,
            'created_at': current_timestamp,
            'canReplyToEmail': can_reply_to_email,
            'isEmailOriginated': is_email_originated,
            'recommendedOperation': 'reply' if can_reply_to_email else 'send'
        }
            
                    # ðŸš€ RE-ENABLED: Send webhook request to n8n for conversation module
        # This ensures webhooks trigger for all ticket replies
        try:
            app.logger.info(f"ðŸš€ SENDING BACKEND WEBHOOK for ticket: {ticket_id}")
            
            # Send to n8n webhook
            webhook_url = os.environ.get('WEBHOOK_URL', 'https://ffxtrading.app.n8n.cloud/webhook/fb4af014-26e6-4477-821f-917fc9b3ee96')
            response = requests.post(webhook_url, json=webhook_payload, timeout=10)
            
            if response.ok:
                app.logger.info(f"âœ… BACKEND WEBHOOK SUCCESS: {response.status_code}")
            else:
                app.logger.warning(f"âš ï¸ BACKEND WEBHOOK WARNING: {response.status_code} - {response.text}")
                
        except Exception as webhook_error:
            app.logger.error(f"âŒ BACKEND WEBHOOK ERROR: {webhook_error}")
            # Don't fail the main process if webhook fails
        
        app.logger.info(f"ðŸ“ Reply saved to database, backend webhook sent")
        
        app.logger.info(f"ðŸŽ‰ REPLY COMPLETED - Ticket: {ticket_id}, Member: {member_id}")
        
        # Return JSON response that the frontend expects
        return jsonify({
            'status': 'success',
            'message': 'Reply sent successfully',
            'redirect': url_for('ticket_detail', ticket_id=ticket_id)
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/important', methods=['POST'])
def mark_as_important(ticket_id):
    """Toggle important status for a ticket"""
    try:
        db = get_db()
        # Get current status
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        if ticket:
            new_status = not ticket.get('is_important', False)
            db.update_ticket(ticket_id, {
                'is_important': new_status,
                'updated_at': datetime.now()
            })
        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/priority', methods=['POST'])
def update_ticket_priority(ticket_id):
    """Update ticket priority"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        new_priority = data.get('priority')
        
        if not new_priority:
            return jsonify({'status': 'error', 'message': 'Priority is required'}), 400
        
        # Validate priority value
        valid_priorities = ['Urgent', 'High', 'Medium', 'Low']
        if new_priority not in valid_priorities:
            return jsonify({'status': 'error', 'message': 'Invalid priority value'}), 400
        
        db = get_db()
        
        # Update the ticket priority
        update_result = db.update_ticket(ticket_id, {
            'priority': new_priority,
            'updated_at': datetime.now()
        })
        
        # Log priority change
        app.logger.info(f"Ticket {ticket_id} priority updated to: {new_priority} by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket priority updated to: {new_priority}'
        })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket priority: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/technician', methods=['POST'])
def update_ticket_technician(ticket_id):
    """Update ticket technician assignment"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        technician_id = data.get('technician_id')
        
        try:
            db = get_db()
        except Exception as db_error:
            app.logger.error(f"Database connection failed: {db_error}")
            return jsonify({'status': 'error', 'message': 'Database connection failed. Please check your MongoDB configuration.'}), 500
        
        if technician_id:
            # Get technician details
            try:
                app.logger.info(f" Looking for technician with ID: {technician_id}")
                technician = db.get_technician_by_id(technician_id)
                app.logger.info(f" Retrieved technician: {technician}")
            except Exception as e:
                app.logger.error(f" Error getting technician by ID {technician_id}: {e}")
                return jsonify({'status': 'error', 'message': f'Error retrieving technician: {str(e)}'}), 500
                
            if not technician:
                app.logger.warning(f"Technician not found for ID: {technician_id}")
                return jsonify({'status': 'error', 'message': 'Technician not found'}), 404
            
            # Update ticket metadata with technician information
            try:
                app.logger.info(f"ðŸ’¾ Setting metadata for ticket {ticket_id}: technician_id={technician_id}, technician_name={technician['name']}")
                result1 = db.set_ticket_metadata(ticket_id, 'technician_id', technician_id)
                result2 = db.set_ticket_metadata(ticket_id, 'technician_name', technician['name'])
                app.logger.info(f" Metadata set results: technician_id={result1}, technician={result2}")
                
                # Verify the metadata was saved by retrieving it
                verification_metadata = db.get_ticket_metadata(ticket_id)
                app.logger.info(f" Verification: Retrieved metadata after save: {verification_metadata}")
                
                # Check if technician data is properly saved
                technician_saved = False
                for meta in verification_metadata:
                    if meta.get('key') == 'technician_name' and meta.get('value') == technician['name']:
                        technician_saved = True
                        break
                
                if not technician_saved:
                    app.logger.warning(f" Technician assignment may not have been saved properly for ticket {ticket_id}")
                    return jsonify({'status': 'error', 'message': 'Technician assignment was not saved properly. Please try again.'}), 500
                    
            except Exception as e:
                app.logger.error(f" Error setting metadata for ticket {ticket_id}: {e}")
                return jsonify({'status': 'error', 'message': f'Error saving technician assignment: {str(e)}'}), 500
            
            app.logger.info(f"Ticket {ticket_id} assigned to technician: {technician['name']} (ID: {technician_id}) by user {session.get('member_name')}")
            
            return jsonify({
                'status': 'success',
                'message': f'Ticket assigned to technician: {technician["name"]}',
                'technician_name': technician['name']
            })
        else:
            # Remove technician assignment
            try:
                app.logger.info(f"ðŸ—‘ Removing technician assignment for ticket {ticket_id}")
                result1 = db.delete_ticket_metadata(ticket_id, 'technician_id')
                result2 = db.delete_ticket_metadata(ticket_id, 'technician_name')
                app.logger.info(f" Metadata deletion results: technician_id={result1}, technician={result2}")
                
                # Verify deletion by checking metadata
                remaining_metadata = db.get_ticket_metadata(ticket_id)
                app.logger.info(f" Remaining metadata after deletion: {remaining_metadata}")
                
            except Exception as e:
                app.logger.error(f" Error removing technician assignment for ticket {ticket_id}: {e}")
                return jsonify({'status': 'error', 'message': f'Error removing technician assignment: {str(e)}'}), 500
            
            app.logger.info(f"Ticket {ticket_id} technician assignment removed by user {session.get('member_name')}")
            
            return jsonify({
                'status': 'success',
                'message': 'Technician assignment removed',
                'technician_name': None
            })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket technician assignment: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/technician-assignments', methods=['GET'])
def get_all_technician_assignments():
    """Get all technician assignments for debugging"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get all technician metadata from database
        all_metadata = list(db.ticket_metadata.find({"key": {"$in": ["technician_id", "technician_name"]}}))
        
        # Group by ticket_id
        assignments = {}
        for meta in all_metadata:
            ticket_id = meta.get('ticket_id')
            if ticket_id not in assignments:
                assignments[ticket_id] = {}
            assignments[ticket_id][meta.get('key')] = meta.get('value')
        
        # Get ticket details for each assignment
        result = []
        for ticket_id, tech_data in assignments.items():
            try:
                ticket = db.get_ticket(ticket_id)
                if ticket:
                    result.append({
                        'ticket_id': ticket_id,
                        'subject': ticket.get('subject', 'No Subject'),
                        'technician_id': tech_data.get('technician_id'),
                        'technician_name': tech_data.get('technician_name'),
                        'status': ticket.get('status', 'Unknown'),
                        'created_at': ticket.get('created_at')
                    })
            except Exception as e:
                app.logger.error(f"Error getting ticket {ticket_id}: {e}")
                result.append({
                    'ticket_id': ticket_id,
                    'subject': 'Error retrieving ticket',
                    'technician_id': tech_data.get('technician_id'),
                    'technician_name': tech_data.get('technician_name'),
                    'status': 'Error',
                    'created_at': None
                })
        
        return jsonify({
            'status': 'success',
            'assignments': result,
            'total_assignments': len(result)
        })
        
    except Exception as e:
        app.logger.error(f"Error getting technician assignments: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# ============ COMMON DOCUMENTS API ENDPOINTS ============

def ensure_common_document_file_data(attachment):
    """
    Helper function to ensure common document attachments include their actual file data
    This function can be used across all webhook payload constructions
    """
    # ðŸš€ FIXED: Handle both hyphen and underscore versions
    if attachment.get('type') in ['common-document', 'common_document']:
        try:
            doc_ref = attachment.get('ref', '')
            if doc_ref:
                # Fetch the actual document file content from database
                db = get_db()
                file_data = db.get_document_file_content(doc_ref)
                
                if file_data and file_data.get('content'):
                    # â­ file_data['content'] IS NOW ALREADY BASE64 STRING
                    file_content_base64 = file_data['content']  # No need to encode again
                    file_size = file_data.get('file_size', len(file_content_base64))
                    filename = file_data.get('file_name', f"common_doc_{doc_ref}")
                    
                    app.logger.info(f"Successfully retrieved common document {filename} ({len(file_content_base64)} base64 chars)")
                    
                    # Return enhanced attachment with file data
                    return {
                        "fileName": filename,
                        "fileData": file_content_base64,  # â­ BASE64 DATA READY TO USE
                        "id": str(doc_ref),
                        "size": file_size,
                        "isWarranty": False,
                        "type": "common_document",
                        "original_attachment": attachment
                    }
                else:
                    app.logger.warning(f"Common document {doc_ref} file content not found")
                    return {
                        "fileName": f"common_doc_{doc_ref}",
                        "fileData": "",  # Fallback to empty if no content
                        "id": str(doc_ref),
                        "size": 0,
                        "isWarranty": False,
                        "type": "common_document",
                        "original_attachment": attachment
                    }
            else:
                app.logger.warning(f"Common document attachment missing ref: {attachment}")
                return {
                    "fileName": "unknown_common_doc",
                    "fileData": "",
                    "id": str(uuid.uuid4().hex[:8]),
                    "size": 0,
                    "isWarranty": False,
                    "type": "common_document",
                    "original_attachment": attachment
                }
        except Exception as e:
            app.logger.error(f"Error processing common document attachment: {e}")
            # Fallback to basic structure if processing fails
            return {
                "fileName": f"common_doc_{attachment.get('ref', 'unknown')}",
                "fileData": "",
                "id": str(attachment.get('ref', uuid.uuid4().hex[:8])),
                "size": 0,
                "isWarranty": False,
                "type": "common_document",
                "original_attachment": attachment
            }
    
    # Return original attachment if not a common document
    return attachment

@app.route('/api/common-documents', methods=['GET'])
def get_common_documents():
    """Get all common documents"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common documents access without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        db = get_db()
        documents = db.get_all_common_documents()
        
        return jsonify({
            'status': 'success',
            'documents': documents,
            'total': len(documents)
        })
    except Exception as e:
        app.logger.error(f"Error getting common documents: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500
    
    try:
        db = get_db()
        documents = db.get_all_common_documents()
        
        return jsonify({
            'status': 'success',
            'documents': documents,
            'total': len(documents)
        })
    except Exception as e:
        app.logger.error(f"Error getting common documents: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents', methods=['POST'])
def create_common_document():
    """Create a new common document with file upload and webhook trigger"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document creation without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        # Check if this is a multipart form data request (file upload)
        if request.content_type and 'multipart/form-data' in request.content_type:
            # Handle file upload
            name = request.form.get('name', '').strip()
            doc_type = request.form.get('type', 'form')
            description = request.form.get('description', '').strip()
            
            if not name:
                return jsonify({'status': 'error', 'message': 'Document name is required'}), 400
            
            # Get the uploaded file
            if 'file' not in request.files:
                return jsonify({'status': 'error', 'message': 'No file uploaded'}), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({'status': 'error', 'message': 'No file selected'}), 400
            
            # ENHANCED: Process file upload with same logic as manual tickets
            app.logger.info(f"ðŸ“„ Processing common document upload: {file.filename}")
            
            # Generate safe filename and save to disk
            filename = secure_filename(file.filename)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_filename = f"{timestamp}_{filename}"
            
            # Create uploads directory for common documents
            upload_dir = os.path.join(UPLOAD_FOLDER, 'common_documents')
            os.makedirs(upload_dir, exist_ok=True)
            
            file_path = os.path.join(upload_dir, safe_filename)
            
            # Save file to disk (for backup and compatibility)
            file.save(file_path)
            app.logger.info(f"ðŸ“„ File saved to disk: {file_path}")
            
            # Get file size
            file_size = os.path.getsize(file_path)
            
            # ðŸš€ ENHANCED: Read file content with comprehensive validation
            try:
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                    
                # ðŸš¨ CRITICAL VALIDATION: Ensure file content is not empty
                if not file_content:
                    raise ValueError(f"File {filename} is empty (0 bytes)")
                
                # ðŸš¨ CRITICAL VALIDATION: Check file size limits (100MB max)
                if len(file_content) > 100 * 1024 * 1024:
                    raise ValueError(f"File {filename} too large: {len(file_content)} bytes (max 100MB)")
                
                # ðŸš€ ENHANCED: Convert to base64 with validation
                file_data_base64 = base64.b64encode(file_content).decode('utf-8')
                
                # ðŸš¨ CRITICAL VALIDATION: Verify base64 conversion integrity
                if not file_data_base64:
                    raise ValueError(f"Base64 conversion failed for {filename}")
                
                # ðŸš€ ENHANCED: Test base64 decode to ensure integrity
                test_decode = base64.b64decode(file_data_base64)
                if test_decode != file_content:
                    raise ValueError(f"Base64 integrity check failed for {filename}")
                
                app.logger.info(f"ðŸ“„ SUCCESS: File validated and converted to base64: {filename} ({len(file_content)} bytes -> {len(file_data_base64)} chars)")
                
            except Exception as e:
                app.logger.error(f"ðŸ“„ CRITICAL ERROR: File processing failed for {filename}: {e}")
                # Clean up the corrupted file
                try:
                    os.remove(file_path)
                    app.logger.info(f"ðŸ“„ Cleaned up corrupted file: {file_path}")
                except:
                    pass
                return jsonify({'status': 'error', 'message': f'File processing failed: {str(e)}'}), 500
            
            # ðŸš€ ENHANCED: Determine file type with comprehensive validation
            import mimetypes
            file_type, encoding = mimetypes.guess_type(filename)
            
            # ðŸš¨ CRITICAL VALIDATION: Ensure proper MIME type detection
            if not file_type:
                # Fallback MIME type detection based on file extension
                file_extension = filename.lower().split('.')[-1] if '.' in filename else ''
                mime_type_map = {
                    'pdf': 'application/pdf',
                    'doc': 'application/msword',
                    'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    'xls': 'application/vnd.ms-excel',
                    'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    'txt': 'text/plain',
                    'jpg': 'image/jpeg',
                    'jpeg': 'image/jpeg',
                    'png': 'image/png',
                    'gif': 'image/gif',
                    'bmp': 'image/bmp',
                    'tiff': 'image/tiff',
                    'zip': 'application/zip',
                    'rar': 'application/x-rar-compressed',
                    '7z': 'application/x-7z-compressed'
                }
                file_type = mime_type_map.get(file_extension, 'application/octet-stream')
                app.logger.info(f"ðŸ“„ MIME type fallback for {filename}: {file_type}")
            
            # ðŸš¨ CRITICAL VALIDATION: Log file type for debugging
            app.logger.info(f"ðŸ“„ Final MIME type for {filename}: {file_type}")
            
            db = get_db()
            
            # ðŸš€ ENHANCED: Create document data using proven ticket attachment logic
            document_data = {
                'name': name,
                'type': doc_type,
                'description': description,
                'file_name': filename,
                'original_filename': file.filename,
                'safe_filename': safe_filename,
                'file_path': file_path,  # Full path for file operations (backup storage)
                'file_size': file_size,
                'file_type': file_type,
                'created_by': session.get('member_name', 'Unknown'),
                'upload_method': 'web_upload',
                
                # ðŸš€ CRITICAL: Dual storage system (like tickets)
                'has_file_data': True,
                'file_data': file_data_base64,      # Primary storage (base64)
                'file_content': file_data_base64,   # Legacy compatibility
                
                # ðŸš€ ENHANCED: Additional fields for consistency
                'source': 'common_document_upload',
                'is_common_document': True,
                'status': 'active',
                'uploaded_at': datetime.now().isoformat(),
                'file_extension': os.path.splitext(filename)[1] if '.' in filename else '',
                
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            }
            
            # Create common document in database
            document_id = db.create_common_document(document_data)
            app.logger.info(f"ðŸ“„ SUCCESS: Created enhanced common document with ID: {document_id}")
            
            # ðŸš€ ENHANCED: Store additional metadata (like ticket system)
            try:
                metadata_entries = [
                    {'document_id': document_id, 'key': 'upload_method', 'value': 'web_upload'},
                    {'document_id': document_id, 'key': 'file_category', 'value': 'common_document'},
                    {'document_id': document_id, 'key': 'access_count', 'value': '0'},
                    {'document_id': document_id, 'key': 'last_accessed', 'value': datetime.now().isoformat()},
                    {'document_id': document_id, 'key': 'file_extension', 'value': os.path.splitext(filename)[1] if '.' in filename else ''},
                    {'document_id': document_id, 'key': 'storage_type', 'value': 'dual_storage'},
                    {'document_id': document_id, 'key': 'base64_length', 'value': str(len(file_data_base64))},
                    {'document_id': document_id, 'key': 'disk_backup', 'value': 'true'},
                    {'document_id': document_id, 'key': 'mime_type', 'value': file_type}
                ]
                
                for metadata in metadata_entries:
                    db.add_common_document_metadata(document_id, metadata['key'], metadata['value'])
                
                app.logger.info(f"ðŸ“„ SUCCESS: Enhanced metadata stored for document: {document_id}")
            except Exception as metadata_error:
                app.logger.warning(f"ðŸ“„ WARNING: Metadata storage failed: {metadata_error}")
            
            # ðŸš€ FIXED: Removed webhook trigger for common documents
            # Common documents should NOT trigger the main ticket webhook
            # They are just document storage, not ticket-related actions
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: Common documents don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Enhanced common document uploaded successfully',
                'document_id': document_id,
                'filename': filename,
                'file_size': file_size,
                'storage_method': 'dual_storage',
                'base64_available': True,
                'disk_backup': True,
                'file_type': file_type
            })
            
        else:
            # Handle JSON request (for backward compatibility)
            data = request.json
            required_fields = ['name', 'type', 'description']
            
            for field in required_fields:
                if not data.get(field):
                    return jsonify({'status': 'error', 'message': f'Missing required field: {field}'}), 400
            
            db = get_db()
            
            document_data = {
                'name': data['name'],
                'type': data['type'],
                'description': data['description'],
                'file_name': data.get('file_name', ''),
                'created_by': session.get('member_name', 'Unknown'),
                'upload_method': 'json_api',
                'has_file_data': False,
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            }
            
            document_id = db.create_common_document(document_data)
            
            # ðŸš€ FIXED: Removed webhook trigger for JSON common documents
            # Common documents should NOT trigger the main ticket webhook
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: JSON common documents don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Document created successfully',
                'document_id': document_id
            })
            
    except Exception as e:
        app.logger.error(f"ðŸ“„ ERROR: Error creating common document: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ Full traceback: {traceback.format_exc()}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>', methods=['PUT'])
def update_common_document(document_id):
    """Update a common document"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document update without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        data = request.json
        db = get_db()
        
        update_data = {}
        if 'name' in data:
            update_data['name'] = data['name']
        if 'type' in data:
            update_data['type'] = data['type']
        if 'description' in data:
            update_data['description'] = data['description']
        if 'file_name' in data:
            update_data['file_name'] = data['file_name']
        if 'file_url' in data:
            update_data['file_url'] = data['file_url']
        
        if not update_data:
            return jsonify({'status': 'error', 'message': 'No fields to update'}), 400
        
        success = db.update_common_document(document_id, update_data)
        
        if success:
            # ðŸš€ FIXED: Removed webhook trigger for common document updates
            # Common documents should NOT trigger the main ticket webhook
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: Common document updates don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Document updated successfully'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'Document not found or no changes made'
            }), 404
    except Exception as e:
        app.logger.error(f"Error updating common document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>', methods=['DELETE'])
def delete_common_document(document_id):
    """Delete a common document"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document deletion without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        db = get_db()
        success = db.delete_common_document(document_id)
        
        if success:
            # ðŸš€ FIXED: Removed webhook trigger for common document deletions
            # Common documents should NOT trigger the main ticket webhook
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: Common document deletions don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Document deleted successfully'
            })
        else:
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
    except Exception as e:
        app.logger.error(f"Error deleting common document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/download', methods=['GET'])
def download_common_document(document_id):
    """Download a document file"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document download without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"Download request for document ID: {document_id}")
        db = get_db()
        
        # First, let's check if the document exists at all
        document_exists = db.get_common_document_by_id(document_id)
        if not document_exists:
            app.logger.error(f"Document {document_id} not found in database")
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
        
        app.logger.info(f"Document found: {document_exists.get('name', 'Unknown')}")
        
        # ðŸš€ ENHANCED: Get file content using priority-based retrieval (like tickets)
        file_data = db.get_document_file_content(document_id)
        
        if not file_data:
            app.logger.warning(f"âš ï¸ File content not found for document {document_id} - attempting enhanced retrieval...")
            
            # ðŸš€ ENHANCED: Try multiple retrieval methods (like ticket system)
            try:
                # METHOD 1: Try repair first
                repair_success, repair_message = db.repair_document_file_content(document_id)
                if repair_success:
                    app.logger.info(f"âœ… Document repaired successfully: {repair_message}")
                    file_data = db.get_document_file_content(document_id)
                    if file_data:
                        app.logger.info(f"âœ… File content retrieved after repair")
                    else:
                        app.logger.error(f"âŒ File content still not found after repair")
                
                # METHOD 2: If repair failed, try direct file access
                if not file_data:
                    app.logger.info(f"ðŸ”„ Attempting direct file access for document {document_id}")
                    document = db.get_common_document_by_id(document_id)
                    if document and document.get('file_path'):
                        file_path = document['file_path']
                        if os.path.exists(file_path):
                            app.logger.info(f"ðŸ”„ Found file on disk: {file_path}")
                            try:
                                with open(file_path, 'rb') as f:
                                    file_content = f.read()
                                    file_data_base64 = base64.b64encode(file_content).decode('utf-8')
                                
                                # Auto-repair: Update database with base64 data
                                db.update_common_document(document_id, {
                                    'file_data': file_data_base64,
                                    'file_content': file_data_base64,
                                    'has_file_data': True
                                })
                                
                                file_data = {'content': file_data_base64}
                                app.logger.info(f"âœ… Auto-repaired document with disk data: {len(file_content)} bytes")
                            except Exception as file_error:
                                app.logger.error(f"âŒ Error reading file from disk: {file_error}")
                
                # METHOD 3: Final check
                if not file_data:
                    app.logger.error(f"âŒ All retrieval methods failed for document {document_id}")
                    return jsonify({'status': 'error', 'message': 'File content not found and all recovery methods failed'}), 404
                    
            except Exception as retrieval_error:
                app.logger.error(f"âŒ Error during enhanced retrieval: {retrieval_error}")
                return jsonify({'status': 'error', 'message': f'File content not found. Retrieval error: {str(retrieval_error)}'}), 404
        
        app.logger.info(f"File data retrieved: {file_data.get('file_name', 'Unknown')} ({len(file_data.get('content', ''))} base64 chars)")
        
        # Increment download count
        db.increment_document_download_count(document_id)
        
        # Return the file as a download
        from flask import send_file
        import io
        import base64
        
        # ðŸš€ ENHANCED: CONVERT BASE64 BACK TO BINARY FOR DOWNLOAD WITH VALIDATION
        try:
            # ðŸš¨ CRITICAL VALIDATION: Ensure we have base64 content
            if not file_data.get('content'):
                raise ValueError("No file content found in database")
            
            # ðŸš€ ENHANCED: Decode base64 with comprehensive error handling
            try:
                file_binary = base64.b64decode(file_data['content'])
            except Exception as base64_error:
                app.logger.error(f"ðŸš¨ CRITICAL: Base64 decode failed for {file_data.get('file_name', 'Unknown')}: {base64_error}")
                raise ValueError(f"File content is corrupted or invalid base64 format")
            
            # ðŸš¨ CRITICAL VALIDATION: Verify decoded content integrity
            if not file_binary:
                raise ValueError("Decoded file content is empty")
            
            # ðŸš€ ENHANCED: Create file stream with proper positioning
            file_stream = io.BytesIO(file_binary)
            file_stream.seek(0)
            
            # ðŸš¨ CRITICAL VALIDATION: Verify file stream integrity
            if file_stream.getvalue() != file_binary:
                raise ValueError("File stream creation failed")
            
            # ðŸš€ ENHANCED: Get proper filename and MIME type
            download_filename = file_data.get('file_name', 'document')
            mime_type = file_data.get('file_type', 'application/octet-stream')
            
            # ðŸš¨ CRITICAL VALIDATION: Ensure MIME type is valid
            if not mime_type or mime_type == 'application/octet-stream':
                # Try to detect MIME type from filename
                import mimetypes
                detected_type, _ = mimetypes.guess_type(download_filename)
                if detected_type:
                    mime_type = detected_type
                    app.logger.info(f"ðŸ“„ MIME type corrected for {download_filename}: {mime_type}")
            
            app.logger.info(f"ðŸ“„ DOWNLOAD: Sending file {download_filename} ({len(file_binary)} bytes, MIME: {mime_type})")
            
            return send_file(
                file_stream,
                as_attachment=True,
                download_name=download_filename,
                mimetype=mime_type
            )
            
        except Exception as decode_error:
            app.logger.error(f"ðŸš¨ CRITICAL ERROR: File download failed for {file_data.get('file_name', 'Unknown')}: {decode_error}")
            return jsonify({'status': 'error', 'message': f'File download failed: {str(decode_error)}'}), 500
        
    except Exception as e:
        app.logger.error(f"Error downloading document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/increment-download', methods=['POST'])
def increment_document_download_count(document_id):
    """Increment download count for a document"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        success = db.increment_document_download_count(document_id)
        
        if success:
            return jsonify({
                'status': 'success',
                'message': 'Download count updated'
            })
        else:
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
    except Exception as e:
        app.logger.error(f"Error updating download count: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/validate', methods=['GET'])
def validate_common_document(document_id):
    """ðŸš€ ENHANCED: Validate common document integrity and fix issues if possible"""
    # Allow access if user has any valid session
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        app.logger.warning(f"Common document validation without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"ðŸ” Validating document integrity for ID: {document_id}")
        db = get_db()
        
        # Validate document integrity
        is_valid, message = db.validate_document_integrity(document_id)
        
        if is_valid:
            app.logger.info(f"âœ… Document {document_id} validation successful: {message}")
            return jsonify({
                'status': 'success',
                'message': 'Document integrity validated successfully',
                'details': message,
                'document_id': document_id
            })
        else:
            app.logger.warning(f"âš ï¸ Document {document_id} validation failed: {message}")
            return jsonify({
                'status': 'warning',
                'message': 'Document validation issues detected',
                'details': message,
                'document_id': document_id
            }), 200  # Return 200 with warning status
            
    except Exception as e:
        app.logger.error(f"âŒ Error validating document {document_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Validation error: {str(e)}'}), 500

@app.route('/api/common-documents/<document_id>/repair', methods=['POST'])
def repair_common_document(document_id):
    """ðŸš€ NEW: Repair common document file content by restoring from disk"""
    # Allow access if user has any valid session
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        app.logger.warning(f"Common document repair without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"ðŸ”§ Repairing document file content for ID: {document_id}")
        db = get_db()
        
        # Attempt to repair document
        repair_success, repair_message = db.repair_document_file_content(document_id)
        
        if repair_success:
            app.logger.info(f"âœ… Document {document_id} repair successful: {repair_message}")
            return jsonify({
                'status': 'success',
                'message': 'Document repaired successfully',
                'details': repair_message,
                'document_id': document_id
            })
        else:
            app.logger.error(f"âŒ Document {document_id} repair failed: {repair_message}")
            return jsonify({
                'status': 'error',
                'message': 'Document repair failed',
                'details': repair_message,
                'document_id': document_id
            }), 400
            
    except Exception as e:
        app.logger.error(f"âŒ Error repairing document {document_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Repair error: {str(e)}'}), 500

@app.route('/api/common-documents/repair-all', methods=['POST'])
def repair_all_common_documents():
    """ðŸš€ NEW: Repair all common documents that have missing file content"""
    # Allow access if user has any valid session
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        app.logger.warning(f"Bulk common document repair without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"ðŸ”§ Starting bulk repair of all common documents")
        db = get_db()
        
        # Get all documents
        all_documents = db.get_all_common_documents()
        repair_results = []
        
        for doc in all_documents:
            doc_id = doc.get('_id')
            doc_name = doc.get('name', 'Unknown')
            
            app.logger.info(f"ðŸ”§ Checking document: {doc_name} (ID: {doc_id})")
            
            # Check if document needs repair
            is_valid, message = db.validate_document_integrity(doc_id)
            
            if not is_valid:
                app.logger.info(f"ðŸ”§ Document {doc_name} needs repair: {message}")
                
                # Attempt repair
                repair_success, repair_message = db.repair_document_file_content(doc_id)
                
                repair_results.append({
                    'document_id': doc_id,
                    'name': doc_name,
                    'needed_repair': True,
                    'repair_success': repair_success,
                    'repair_message': repair_message
                })
                
                if repair_success:
                    app.logger.info(f"âœ… Document {doc_name} repaired successfully")
                else:
                    app.logger.error(f"âŒ Document {doc_name} repair failed: {repair_message}")
            else:
                repair_results.append({
                    'document_id': doc_id,
                    'name': doc_name,
                    'needed_repair': False,
                    'repair_success': True,
                    'repair_message': 'Document was already valid'
                })
        
        # Count results
        total_docs = len(repair_results)
        docs_needing_repair = len([r for r in repair_results if r['needed_repair']])
        successful_repairs = len([r for r in repair_results if r['needed_repair'] and r['repair_success']])
        failed_repairs = len([r for r in repair_results if r['needed_repair'] and not r['repair_success']])
        
        app.logger.info(f"ðŸ”§ Bulk repair completed: {total_docs} total, {docs_needing_repair} needed repair, {successful_repairs} successful, {failed_repairs} failed")
        
        return jsonify({
            'status': 'success',
            'message': f'Bulk repair completed: {successful_repairs}/{docs_needing_repair} documents repaired successfully',
            'summary': {
                'total_documents': total_docs,
                'documents_needing_repair': docs_needing_repair,
                'successful_repairs': successful_repairs,
                'failed_repairs': failed_repairs
            },
            'results': repair_results
        })
        
    except Exception as e:
        app.logger.error(f"âŒ Error during bulk repair: {e}")
        return jsonify({'status': 'error', 'message': f'Bulk repair error: {str(e)}'}), 500

@app.route('/api/common-documents/<document_id>', methods=['GET'])
def get_common_document(document_id):
    """Get a specific common document"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        document = db.get_common_document_by_id(document_id)
        
        if document:
            return jsonify({
                'status': 'success',
                'document': document
            })
        else:
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
    except Exception as e:
        app.logger.error(f"Error getting common document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/send-data', methods=['GET'])
def get_common_document_send_data(document_id):
    """Get common document data formatted for external transmission with fileData key"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document send data access without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"Send data request for document ID: {document_id}")
        db = get_db()
        
        # Get the document metadata
        document = db.get_common_document_by_id(document_id)
        if not document:
            app.logger.error(f"Document {document_id} not found in database")
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
        
        # Get the file content
        file_data = db.get_document_file_content(document_id)
        if not file_data:
            app.logger.error(f"File content not found for document {document_id}")
            return jsonify({'status': 'error', 'message': 'File content not found'}), 404
        
        # Convert binary file content to base64 for transmission
        import base64
        file_content_base64 = base64.b64encode(file_data['content']).decode('utf-8')
        
        # Format document data with fileData key for external transmission
        send_data = {
            'document_id': document_id,
            'name': document.get('name', ''),
            'fileName': file_data.get('file_name', document.get('file_name', '')),
            'fileData': file_content_base64,  # Key requested by user
            'file_type': file_data.get('file_type', 'application/octet-stream'),
            'file_size': file_data.get('file_size', len(file_data['content']) if file_data.get('content') else 0),
            'description': document.get('description', ''),
            'type': document.get('type', 'form'),
            'created_at': document.get('created_at', ''),
            'created_by': document.get('created_by', ''),
            'download_count': document.get('download_count', 0),
            'timestamp': datetime.now().isoformat(),
            'status': 'ready_for_transmission'
        }
        
        # Increment download count since this is a data access
        db.increment_document_download_count(document_id)
        
        app.logger.info(f"Document send data prepared: {document.get('name', 'Unknown')} ({len(file_content_base64)} chars base64)")
        
        return jsonify({
            'status': 'success',
            'message': 'Document data ready for transmission',
            'data': send_data
        })
        
    except Exception as e:
        app.logger.error(f"Error preparing document send data: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/send-data', methods=['POST'])
def get_multiple_common_documents_send_data():
    """Get multiple common documents data formatted for external transmission with fileData key"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Multiple common documents send data access without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        data = request.json
        document_ids = data.get('document_ids', [])
        
        if not document_ids:
            return jsonify({'status': 'error', 'message': 'Document IDs are required'}), 400
        
        app.logger.info(f"Send data request for {len(document_ids)} documents: {document_ids}")
        db = get_db()
        
        documents_data = []
        
        for document_id in document_ids:
            try:
                # Get the document metadata
                document = db.get_common_document_by_id(document_id)
                if not document:
                    app.logger.warning(f"Document {document_id} not found, skipping")
                    continue
                
                # Get the file content
                file_data = db.get_document_file_content(document_id)
                if not file_data:
                    app.logger.warning(f"File content not found for document {document_id}, skipping")
                    continue
                
                # Convert binary file content to base64 for transmission
                import base64
                file_content_base64 = base64.b64encode(file_data['content']).decode('utf-8')
                
                # Format document data with fileData key for external transmission
                send_data = {
                    'document_id': document_id,
                    'name': document.get('name', ''),
                    'fileName': file_data.get('file_name', document.get('file_name', '')),
                    'fileData': file_content_base64,  # Key requested by user
                    'file_type': file_data.get('file_type', 'application/octet-stream'),
                    'file_size': file_data.get('file_size', len(file_data['content']) if file_data.get('content') else 0),
                    'description': document.get('description', ''),
                    'type': document.get('type', 'form'),
                    'created_at': document.get('created_at', ''),
                    'created_by': document.get('created_by', ''),
                    'download_count': document.get('download_count', 0),
                    'timestamp': datetime.now().isoformat(),
                    'status': 'ready_for_transmission'
                }
                
                documents_data.append(send_data)
                
                # Increment download count since this is a data access
                db.increment_document_download_count(document_id)
                
                app.logger.info(f"Document prepared: {document.get('name', 'Unknown')} ({len(file_content_base64)} chars base64)")
                
            except Exception as doc_error:
                app.logger.error(f"Error processing document {document_id}: {doc_error}")
                continue
        
        if not documents_data:
            return jsonify({'status': 'error', 'message': 'No valid documents found'}), 404
        
        app.logger.info(f"Prepared {len(documents_data)} documents for transmission")
        
        return jsonify({
            'status': 'success',
            'message': f'{len(documents_data)} documents ready for transmission',
            'count': len(documents_data),
            'data': documents_data
        })
        
    except Exception as e:
        app.logger.error(f"Error preparing multiple documents send data: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


# ============ COMMON DOCUMENT WEBHOOK TRIGGER ============
def trigger_common_document_webhook(document_id, document_data):
    """
    Trigger webhook for common document creation/update
    Uses the same webhook infrastructure as tickets
    """
    try:
        app.logger.info(f"ðŸ“„ TRIGGERING COMMON DOCUMENT WEBHOOK - Document: {document_id}")
        
        # Prepare webhook payload with enhanced document data
        webhook_payload = {
            "json": [{
                "document_id": document_id,
                "name": document_data.get('name', 'Unknown'),
                "type": document_data.get('type', 'form'),
                "description": document_data.get('description', ''),
                "file_name": document_data.get('file_name', ''),
                "original_filename": document_data.get('original_filename', ''),
                "safe_filename": document_data.get('safe_filename', ''),
                "file_path": document_data.get('file_path', ''),
                "file_size": document_data.get('file_size', 0),
                "file_type": document_data.get('file_type', 'application/octet-stream'),
                "created_by": document_data.get('created_by', 'Unknown'),
                "upload_method": document_data.get('upload_method', 'unknown'),
                "has_file_data": document_data.get('has_file_data', False),
                "file_data": document_data.get('file_data', ''),  # Base64 encoded file content
                "created_at": document_data.get('created_at', datetime.now()).isoformat() if hasattr(document_data.get('created_at'), 'isoformat') else str(document_data.get('created_at', datetime.now())),
                "updated_at": document_data.get('updated_at', datetime.now()).isoformat() if hasattr(document_data.get('updated_at'), 'isoformat') else str(document_data.get('updated_at', datetime.now())),
                "webhook_type": "common_document_created",
                "webhook_timestamp": datetime.now().isoformat(),
                "system": "AutoAssistGroup",
                "version": "2.0"
            }],
            "binary": {
                "has_attachments": document_data.get('has_file_data', False),
                "total_attachments": 1 if document_data.get('has_file_data') else 0,
                "attachments": [{
                    "filename": document_data.get('file_name', ''),
                    "original_name": document_data.get('original_filename', ''),
                    "name": document_data.get('file_name', ''),
                    "size": document_data.get('file_size', 0),
                    "is_warranty": False,  # Common documents are not warranty forms
                    "file_type": document_data.get('file_type', 'application/octet-stream'),
                    "uploaded_at": document_data.get('created_at', datetime.now()).isoformat() if hasattr(document_data.get('created_at'), 'isoformat') else str(document_data.get('created_at', datetime.now())),
                    "source": "common_document_upload",
                    "path": document_data.get('file_path', ''),
                    "type": "file",
                    "data": document_data.get('file_data', ''),  # Base64 data for webhook
                    "is_common_document": True,
                    "document_id": document_id
                }] if document_data.get('has_file_data') else []
            }
        }
        
        # Use the main webhook URL for common documents
        webhook_url = os.environ.get('WEBHOOK_URL', 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a')
        
        app.logger.info(f"ðŸ“„ SENDING COMMON DOCUMENT WEBHOOK - URL: {webhook_url}")
        app.logger.info(f"ðŸ“„ PAYLOAD: Document {document_id} - {document_data.get('name', 'Unknown')} ({document_data.get('file_size', 0)} bytes)")
        
        # Send webhook request with retry logic
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    webhook_url,
                    json=webhook_payload,
                    timeout=15,
                    headers={'Content-Type': 'application/json'}
                )
                response.raise_for_status()
                
                app.logger.info(f"ðŸ“„ SUCCESS: Common document webhook sent successfully - Document: {document_id}, Status: {response.status_code}")
                
                # Store webhook metadata
                try:
                    db = get_db()
                    db.add_ticket_metadata(document_id, 'webhook_triggered', datetime.now().isoformat())
                    db.add_ticket_metadata(document_id, 'webhook_url', webhook_url)
                    db.add_ticket_metadata(document_id, 'webhook_status', 'success')
                    db.add_ticket_metadata(document_id, 'webhook_response_code', str(response.status_code))
                except Exception as metadata_error:
                    app.logger.warning(f"ðŸ“„ WARNING: Failed to store webhook metadata: {metadata_error}")
                
                return True
                
            except requests.exceptions.RequestException as e:
                app.logger.warning(f"ðŸ“„ WARNING: Common document webhook attempt {attempt + 1} failed - Document: {document_id}: {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(1)  # Brief pause before retry
                    continue
                else:
                    app.logger.error(f"ðŸ“„ ERROR: Common document webhook final failure - Document: {document_id} after {max_retries} attempts")
                    
                    # Store failure metadata
                    try:
                        db = get_db()
                        db.add_ticket_metadata(document_id, 'webhook_failed', datetime.now().isoformat())
                        db.add_ticket_metadata(document_id, 'webhook_error', str(e))
                    except Exception as metadata_error:
                        app.logger.warning(f"ðŸ“„ WARNING: Failed to store webhook failure metadata: {metadata_error}")
                    
                    return False
                    
            except Exception as e:
                app.logger.error(f"ðŸ“„ ERROR: Common document webhook unexpected error - Document: {document_id}: {e}")
                return False
        
        return False
        
    except Exception as e:
        app.logger.error(f"ðŸ“„ ERROR: Failed to trigger common document webhook - Document: {document_id}: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ Full traceback: {traceback.format_exc()}")
        return False


# ============ COMMON DOCUMENT WEBHOOK TEST ENDPOINT ============
@app.route('/debug/common-document-webhook-test')
def debug_common_document_webhook_test():
    """Debug endpoint to test common document webhook functionality"""
    try:
        app.logger.info(f"ðŸ“„ TESTING COMMON DOCUMENT WEBHOOK FUNCTIONALITY")
        
        # Create test document data
        test_document_data = {
            'name': 'Test Common Document',
            'type': 'test',
            'description': 'This is a test document for webhook testing',
            'file_name': 'test_document.txt',
            'original_filename': 'test_document.txt',
            'safe_filename': '20250126_120000_test_document.txt',
            'file_path': '/tmp/test_path.txt',
            'file_size': 1024,
            'file_type': 'text/plain',
            'created_by': 'Test User',
            'upload_method': 'test',
            'has_file_data': True,
            'file_data': 'VGhpcyBpcyBhIHRlc3QgZmlsZSBjb250ZW50IGZvciB3ZWJob29rIHRlc3Rpbmc=',  # Base64 encoded test content
            'created_at': datetime.now(),
            'updated_at': datetime.now()
        }
        
        # Test webhook trigger
        webhook_result = trigger_common_document_webhook('test_document_id', test_document_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Common document webhook test completed',
            'webhook_triggered': webhook_result,
            'test_data': {
                'document_name': test_document_data['name'],
                'file_size': test_document_data['file_size'],
                'has_file_data': test_document_data['has_file_data'],
                'base64_length': len(test_document_data['file_data'])
            }
        })
        
    except Exception as e:
        app.logger.error(f"ðŸ“„ ERROR: Common document webhook test failed: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ Full traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Common document webhook test failed: {str(e)}',
            'error_type': type(e).__name__
        }), 500


# ============ ENHANCED COMMON DOCUMENT FILE DATA HELPER ============
def ensure_common_document_file_data_enhanced(attachment):
    """
    Enhanced helper function to ensure common document attachments include their actual file data
    Works with both new and legacy data structures
    """
    try:
        if attachment.get('type') == 'common-document':
            doc_ref = attachment.get('ref')
            if doc_ref:
                app.logger.info(f"ðŸ“„ ENHANCED: Processing common document attachment: {doc_ref}")
                
                db = get_db()
                document = db.get_common_document_by_id(doc_ref)
                
                if document:
                    filename = document.get('file_name', 'Unknown')
                    
                    # ENHANCED: Check for file_data first (new structure), then file_content (legacy)
                    file_content_base64 = None
                    if document.get('file_data'):
                        file_content_base64 = document.get('file_data')
                        app.logger.info(f"ðŸ“„ ENHANCED: Using new file_data structure: {filename} ({len(file_content_base64)} base64 chars)")
                    elif document.get('file_content'):
                        file_content_base64 = document.get('file_content')
                        app.logger.info(f"ðŸ“„ ENHANCED: Using legacy file_content structure: {filename} ({len(file_content_base64)} base64 chars)")
                    
                    if file_content_base64:
                        app.logger.info(f"ðŸ“„ ENHANCED: SUCCESS: Retrieved common document {filename} ({len(file_content_base64)} base64 chars)")
                        
                        return {
                            "type": "common_document",
                            "name": filename,
                            "data": file_content_base64,
                            "size": document.get('file_size', 0),
                            "is_warranty": False,
                            "file_type_info": {'type': 'common_document', 'icon': 'ðŸ“„'},
                            "document_id": doc_ref,
                            "original_filename": document.get('original_filename', filename),
                            "safe_filename": document.get('safe_filename', filename),
                            "file_path": document.get('file_path', ''),
                            "file_type": document.get('file_type', 'application/octet-stream'),
                            "upload_method": document.get('upload_method', 'unknown'),
                            "has_file_data": True,
                            "is_common_document": True
                        }
                    else:
                        app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Common document {doc_ref} has no file content (neither file_data nor file_content)")
                        return attachment
                else:
                    app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Common document {doc_ref} not found in database")
                    return attachment
            else:
                app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Common document attachment missing ref: {attachment}")
                return attachment
        else:
            app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Not a common document attachment: {attachment}")
            return attachment
            
    except Exception as e:
        app.logger.error(f"ðŸ“„ ENHANCED: ERROR: Error processing common document attachment: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ ENHANCED: Full traceback: {traceback.format_exc()}")
        return {
            "type": "common_document",
            "name": "Error",
            "data": "",
            "size": 0,
            "is_warranty": False,
            "file_type_info": {'type': 'common_document', 'icon': 'ðŸ“„'},
            "is_common_document": True,
            "has_file_data": False
        }
    
    # Return original attachment if not a common document
    return attachment


@app.route('/api/tickets/<ticket_id>/classification', methods=['POST'])
def update_ticket_classification(ticket_id):
    """Update ticket classification"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        new_classification = data.get('classification')
        
        if not new_classification:
            return jsonify({'status': 'error', 'message': 'Classification is required'}), 400
        
        # Validate classification value
        valid_classifications = ['General', 'Technical', 'Payment', 'Account', 'Warranty Claim', 'Support', 'Others']
        if new_classification not in valid_classifications:
            return jsonify({'status': 'error', 'message': 'Invalid classification value'}), 400
        
        db = get_db()
        
        # Update the ticket classification
        update_result = db.update_ticket(ticket_id, {
            'classification': new_classification,
            'updated_at': datetime.now()
        })
        
        # Log classification change
        app.logger.info(f"Ticket {ticket_id} classification updated to: {new_classification} by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket classification updated to: {new_classification}'
        })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket classification: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/outcome', methods=['POST'])
def update_ticket_outcome(ticket_id):
    """Update ticket outcome information"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        outcome_category = data.get('outcome_category', '')
        revisit_carried_out = '1' if data.get('revisit_carried_out') else '0'
        clean_under_warranty = '1' if data.get('clean_under_warranty') else '0'
        outcome_notes = data.get('outcome_notes', '')
        
        db = get_db()
        
        # Update or create outcome metadata entries
        outcome_metadata = [
            {'key': 'outcome_category', 'value': outcome_category},
            {'key': 'revisit_carried_out', 'value': revisit_carried_out},
            {'key': 'clean_under_warranty', 'value': clean_under_warranty},
            {'key': 'outcome_notes', 'value': outcome_notes}
        ]
        
        for metadata in outcome_metadata:
            # Remove existing entry
            db.ticket_metadata.delete_many({
                'ticket_id': ticket_id,
                'key': metadata['key']
            })
            # Add updated entry if value is not empty
            if metadata['value']:
                db.add_ticket_metadata(ticket_id, metadata['key'], metadata['value'])
        
        # Update ticket timestamp
        db.update_ticket(ticket_id, {'updated_at': datetime.now()})
        
        # Log outcome update
        app.logger.info(f"Ticket {ticket_id} outcome updated by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': 'Outcome information updated successfully'
        })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket outcome: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/warranty-check')
def check_ticket_warranty_status(ticket_id):
    """ Check if a specific ticket has warranty claim classification"""
    try:
        db = get_db()
        
        # Get ticket details
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({
                'status': 'error',
                'message': f'Ticket #{ticket_id} not found',
                'ticket_id': ticket_id
            }), 404
        
        # Extract warranty-related information
        classification = ticket.get('classification', 'Unknown')
        has_warranty = ticket.get('has_warranty', False)
        priority = ticket.get('priority', 'Unknown')
        name = ticket.get('name', 'Unknown')
        email = ticket.get('email', 'Unknown')
        subject = ticket.get('subject', 'Unknown')
        creation_method = ticket.get('creation_method', 'Unknown')
        
        # Get attachments metadata
        metadata = db.get_ticket_metadata(ticket_id)
        warranty_attachments = []
        
        if metadata:
            for meta in metadata:
                key = meta.get('key', 'unknown')
                filename = meta.get('filename', 'unknown')
                
                # Check if this is a warranty-related attachment
                is_warranty_related = (
                    'warranty' in key.lower() or 
                    'warranty' in filename.lower() or
                    'claim' in key.lower() or
                    'dpf' in key.lower()
                )
                
                if is_warranty_related:
                    warranty_attachments.append({
                        'key': key,
                        'filename': filename,
                        'is_warranty_related': is_warranty_related
                    })
        
        # Check content for warranty keywords
        body = ticket.get('body', '').lower()
        warranty_keywords = ['warranty', 'claim', 'dpf', 'filter', 'defect', 'fault', 'repair']
        found_keywords = [kw for kw in warranty_keywords if kw in body or kw in subject.lower()]
        
        # Determine if should be warranty claim
        should_be_warranty = (
            classification == 'Warranty Claim' or
            has_warranty or
            len(warranty_attachments) > 0 or
            len(found_keywords) > 0
        )
        
        is_warranty_claim = classification == 'Warranty Claim'
        
        app.logger.info(f" WARRANTY CHECK: Ticket {ticket_id} - Classification: {classification}, Has Warranty: {has_warranty}, Warranty Attachments: {len(warranty_attachments)}, Keywords: {found_keywords}")
        
        return jsonify({
            'status': 'success',
            'ticket_id': ticket_id,
            'warranty_analysis': {
                'is_warranty_claim': is_warranty_claim,
                'should_be_warranty_claim': should_be_warranty,
                'classification_correct': is_warranty_claim == should_be_warranty
            },
            'ticket_details': {
                'classification': classification,
                'has_warranty_flag': has_warranty,
                'priority': priority,
                'customer': f"{name} ({email})",
                'subject': subject,
                'creation_method': creation_method
            },
            'warranty_evidence': {
                'warranty_attachments': warranty_attachments,
                'warranty_keywords_found': found_keywords,
                'total_warranty_attachments': len(warranty_attachments),
                'total_warranty_keywords': len(found_keywords)
            },
            'verdict': {
                'status': ' WARRANTY CLAIM' if is_warranty_claim else ' NOT WARRANTY CLAIM',
                'recommendation': ' CORRECT' if is_warranty_claim == should_be_warranty else (' SHOULD BE WARRANTY CLAIM' if should_be_warranty else ' SHOULD NOT BE WARRANTY CLAIM'),
                'confidence': 'HIGH' if (len(warranty_attachments) > 0 or len(found_keywords) >= 2) else 'MEDIUM'
            }
        })
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ Error checking warranty status for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Failed to check warranty status: {str(e)}',
            'ticket_id': ticket_id
        }), 500

@app.route('/api/tickets/search', methods=['GET'])
def search_tickets():
    """Search tickets with filters"""
    try:
        query = request.args.get('q', '')
        priority = request.args.get('priority', '')
        classification = request.args.get('type', '')
        status = request.args.get('status', '')
        advisor = request.args.get('advisor', '')
        age = request.args.get('age', '')
        
        db = get_db()
        
        # Use MongoDB search functionality
        tickets = db.search_tickets(
            query=query if query else None,
            priority=priority if priority and priority != 'All' else None,
            classification=classification if classification and classification != 'All' else None,
            status=status if status and status != 'All' else None
        )
        
        # Additional client-side filtering for dashboard-specific filters
        if advisor or age:
            filtered_tickets = []
            for ticket in tickets:
                include_ticket = True
                
                # Filter by advisor (assigned member)
                if advisor:
                    # Check if ticket has assignment
                    assignment = db.get_assignment_by_ticket(ticket.get('ticket_id'))
                    if assignment:
                        assigned_member = db.get_member_by_id(assignment.get('member_id'))
                        if not assigned_member or assigned_member.get('name') != advisor:
                            include_ticket = False
                    else:
                        include_ticket = False
                
                # Filter by age
                if age and include_ticket:
                    from datetime import datetime, timedelta
                    now = datetime.now()
                    created_at = ticket.get('created_at')
                    
                    if isinstance(created_at, datetime):
                        ticket_age = now - created_at
                        
                        if age == 'today' and ticket_age.days > 0:
                            include_ticket = False
                        elif age == '1-3days' and (ticket_age.days < 1 or ticket_age.days > 3):
                            include_ticket = False
                        elif age == 'overdue' and ticket_age.days <= 3:
                            include_ticket = False
                
                if include_ticket:
                    filtered_tickets.append(ticket)
            
            tickets = filtered_tickets
        
        formatted_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Format date
            if 'created_at' in ticket_dict and ticket_dict['created_at']:
                if isinstance(ticket_dict['created_at'], datetime):
                    ticket_dict['formatted_date'] = ticket_dict['created_at'].strftime("%b %d, %I:%M %p")
                else:
                    try:
                        created_at = datetime.strptime(str(ticket_dict['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket_dict['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                    except:
                        ticket_dict['formatted_date'] = str(ticket_dict['created_at'])
            
            formatted_tickets.append(ticket_dict)
            
        return jsonify({
            'status': 'success',
            'tickets': formatted_tickets
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/close', methods=['POST'])
def close_ticket(ticket_id):
    """Close ticket - Available for ALL users including Technical Director (with takeover check)"""
    
    # Enhanced error handling and debugging
    app.logger.info(f"[TARGET] CLOSE TICKET REQUEST - Ticket: {ticket_id}")
    
    if 'member_id' not in session:
        app.logger.warning(f"[ERROR] UNAUTHORIZED - No session for close ticket {ticket_id}")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in'}), 401
    
    try:
        db = get_db()

        app.logger.info(f"[INFO] CLOSE TICKET - User: {session.get('member_name')} closing ticket {ticket_id}")
        
        # Validate ticket exists
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            app.logger.warning(f"[ERROR] TICKET NOT FOUND - {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # CHECK TAKEOVER STATUS: Ticket must be taken over before closing
        assignment = db.ticket_assignments.find_one({'ticket_id': ticket_id})
        
        if not assignment:
            app.logger.warning(f"[ERROR] TICKET NOT TAKEN OVER - {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Please take over the ticket first before closing it'}), 400
        
        # Verify the assignment is not just a forward (must be taken over)
        if assignment.get('is_forwarded', False):
            app.logger.warning(f"[ERROR] TICKET ONLY FORWARDED - {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket is only forwarded. Please take over the ticket first before closing it'}), 400
        
        app.logger.info(f"[SUCCESS] TAKEOVER VALIDATED - Ticket {ticket_id} taken over by member {assignment.get('member_id')}")
        
        # Update ticket status to closed
        db.update_ticket(ticket_id, {
            'status': 'Resolved',
            'updated_at': datetime.now(),
            'closed_by': session.get('member_name'),
            'closed_at': datetime.now()
        })
        
        app.logger.info(f"[SUCCESS] TICKET CLOSED - {ticket_id} by {session.get('member_name')}")
        return jsonify({'status': 'success', 'message': 'Ticket closed successfully'})
        
    except Exception as e:
        app.logger.error(f"[ERROR] ERROR CLOSING TICKET {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Failed to close ticket: {str(e)}'}), 500

@app.route('/api/admin/update-creation-methods', methods=['POST', 'GET'])
def update_creation_methods():
    """Admin endpoint to retroactively add creation_method to existing tickets"""
    # Allow GET for easy testing - in production you might want to remove this
    # if 'member_id' not in session:
    #     return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get all tickets without creation_method
        tickets_to_update = list(db.tickets.find({
            "$or": [
                {"creation_method": {"$exists": False}},
                {"creation_method": None}
            ]
        }))
        
        updated_count = 0
        manual_count = 0
        email_count = 0
        
        for ticket in tickets_to_update:
            ticket_id = ticket.get('ticket_id', '')
            creation_method = None
            
            # Determine creation method based on ticket ID patterns
            if ticket_id.startswith('M') or ticket_id.startswith('WM'):
                # Manual tickets: M{type_code}{4_digits} or legacy WM prefixes
                creation_method = 'manual'
                manual_count += 1
            elif ticket_id.startswith('W') and not ticket_id.startswith('WM'):
                # Warranty tickets: W{5_digits} - treat as email since they come from forms
                creation_method = 'email'
                email_count += 1
            elif ticket_id.startswith(('E', 'G', 'S', 'T', 'O')):
                # Email tickets with classification codes: {class_code}{priority_code}{4_digits}
                creation_method = 'email'
                email_count += 1
            else:
                # Better fallback: analyze ticket content for better detection
                thread_id = ticket.get('thread_id', '')
                body = ticket.get('body', '').lower()
                
                # Check for email indicators
                if thread_id or '@' in ticket.get('email', '') or 'email' in body:
                    creation_method = 'email'
                    email_count += 1
                elif ticket.get('name') == 'System' or 'manual' in body:
                    creation_method = 'manual'
                    manual_count += 1
                else:
                    # Default to email as most tickets come from email/forms
                    creation_method = 'email'
                    email_count += 1
            
            # Update the ticket
            if creation_method:
                result = db.tickets.update_one(
                    {"ticket_id": ticket_id},
                    {"$set": {
                        "creation_method": creation_method,
                        "updated_at": datetime.now()
                    }}
                )
                
                if result.modified_count > 0:
                    updated_count += 1
        
        return jsonify({
            'status': 'success',
            'message': f'Updated {updated_count} tickets',
            'details': {
                'total_updated': updated_count,
                'manual_tickets': manual_count,
                'email_tickets': email_count
            }
        })
        
    except Exception as e:
        app.logger.error(f"Error updating creation methods: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/reset-creation-methods', methods=['POST'])
def reset_creation_methods():
    """Reset all tickets back to unknown creation method"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Remove creation_method field from all tickets
        result = db.tickets.update_many(
            {},
            {"$unset": {"creation_method": ""}}
        )
        
        return jsonify({
            'status': 'success',
            'message': f'Reset {result.modified_count} tickets to unknown',
            'modified_count': result.modified_count
        })
        
    except Exception as e:
        app.logger.error(f"Error resetting creation methods: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/status')
def status_dashboard():
    """Dedicated status dashboard page"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get pagination parameters
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status_filter = request.args.get('status', 'All')
        priority_filter = request.args.get('priority', 'All')
        search_query = request.args.get('search', '')
        
        # Get paginated tickets with assignment info
        tickets = db.get_tickets_with_assignments(
            page=page, 
            per_page=per_page, 
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # Get total count for pagination
        total_tickets = db.get_tickets_count(
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # Convert to dict format and format dates
        formatted_tickets = []
        for ticket in tickets:
            ticket['_id'] = str(ticket['_id'])
            
            # Handle assignment info
            if ticket.get('assignment') and len(ticket['assignment']) > 0:
                if ticket.get('assigned_member') and len(ticket['assigned_member']) > 0:
                    member = ticket['assigned_member'][0]
                    ticket['assigned_to'] = member.get('name')
                else:
                    ticket['assigned_to'] = None
            else:
                ticket['assigned_to'] = None
            
            # Format created_at date
            if 'created_at' in ticket and ticket['created_at']:
                if isinstance(ticket['created_at'], datetime):
                    ticket['formatted_date'] = ticket['created_at'].strftime("%b %d, %I:%M %p")
                else:
                    try:
                        created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                    except:
                        ticket['formatted_date'] = str(ticket['created_at'])
            else:
                ticket['formatted_date'] = 'Unknown'
            
            formatted_tickets.append(ticket)
        
        # Calculate stats - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(formatted_tickets)
        
        # Status counts
        status_counts = {}
        for ticket in formatted_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # Priority counts
        priority_counts = {}
        for ticket in formatted_tickets:
            priority = ticket.get('priority', 'Unknown')
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
        
        # Creation method counts
        creation_methods = {}
        for ticket in formatted_tickets:
            method = ticket.get('creation_method', 'unknown')
            creation_methods[method] = creation_methods.get(method, 0) + 1
        
        # Calculate specific metrics
        open_tickets = len([t for t in formatted_tickets if t.get('status') == 'Open'])
        waiting_tickets = len([t for t in formatted_tickets if t.get('status') == 'Waiting for Response'])
        active_tickets = open_tickets + waiting_tickets
        
        # Resolved today
        today = datetime.now().date()
        resolved_today = 0
        for ticket in formatted_tickets:
            if ticket.get('status') in ['Resolved', 'Closed']:
                if 'created_at' in ticket and ticket['created_at']:
                    try:
                        if isinstance(ticket['created_at'], datetime):
                            ticket_date = ticket['created_at'].date()
                        else:
                            ticket_date = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S").date()
                        
                        if ticket_date == today:
                            resolved_today += 1
                    except:
                        pass
        
        # Get recent tickets (last 50)
        recent_tickets = sorted(formatted_tickets, 
                              key=lambda x: x.get('created_at', datetime.min), 
                              reverse=True)[:50]
        
        # Get current user info for navbar
        current_member = db.get_member_by_id(session['member_id'])
        current_user_role = current_member['role'] if current_member else 'Unknown'
        
        # Calculate pagination info
        total_pages = (total_tickets + per_page - 1) // per_page
        has_prev = page > 1
        has_next = page < total_pages
        prev_page = page - 1 if has_prev else None
        next_page = page + 1 if has_next else None
        
        pagination_info = {
            'current_page': page,
            'per_page': per_page,
            'total_tickets': total_tickets,
            'total_pages': total_pages,
            'has_prev': has_prev,
            'has_next': has_next,
            'prev_page': prev_page,
            'next_page': next_page,
            'status_filter': status_filter,
            'priority_filter': priority_filter,
            'search_query': search_query
        }
        
        return render_template('status.html',
                             total_tickets=total_tickets,
                             active_tickets=active_tickets,
                             waiting_tickets=waiting_tickets,
                             resolved_today=resolved_today,
                             status_counts=status_counts,
                             priority_counts=priority_counts,
                             creation_methods=creation_methods,
                             recent_tickets=recent_tickets,
                             current_user=session.get('member_name'),
                             current_user_role=current_user_role,
                             pagination=pagination_info)
                             
    except Exception as e:
        app.logger.error(f"Error loading status dashboard: {e}")
        return render_template('error.html', error="Failed to load status dashboard"), 500

# Add custom Jinja2 filters
@app.template_filter('basename')
def get_basename(path):
    """Jinja2 filter to get basename of a path"""
    return os.path.basename(path)

@app.template_filter('format_datetime')
def format_datetime(value):
    """Jinja2 filter to format datetime"""
    return safe_date_format(value)


@app.route('/create-first-user')
def create_first_user():
    db = get_db()
    try:
        # Check if admin user already exists
        existing_admin = db.get_member_by_user_id('admin')
        if existing_admin:
            return 'User already exists'
        
        member_data = {
            'name': 'Admin User',
            'role': 'Administrator',
            'gender': 'male',
            'user_id': 'admin',
            'password_hash': generate_password_hash('admin123')
        }
        
        db.create_member(member_data)
        return 'Created first user: admin/admin123'
    except Exception as e:
        return f'Error creating user: {str(e)}'

@app.route('/debug-members')
def debug_members():
    """Debug endpoint to check all members and find tech director"""
    try:
        db = get_db()
        
        # Get all members
        all_members = list(db.members.find({}))
        
        # Find tech directors
        tech_directors = [m for m in all_members if m.get('role') == 'Technical Director']
        
        debug_info = {
            'total_members': len(all_members),
            'tech_directors_count': len(tech_directors),
            'all_members': [
                {
                    'name': m.get('name'),
                    'role': m.get('role'),
                    'user_id': m.get('user_id'),
                    'id': str(m.get('_id')),
                    'email': m.get('email')
                } for m in all_members
            ],
            'tech_directors': [
                {
                    'name': m.get('name'),
                    'role': m.get('role'),
                    'user_id': m.get('user_id'),
                    'id': str(m.get('_id')),
                    'email': m.get('email')
                } for m in tech_directors
            ]
        }
        
        return f'''
        <h2>[DEBUG] Member Debug Info</h2>
        <h3>Total Members: {len(all_members)}</h3>
        <h3>Tech Directors Found: {len(tech_directors)}</h3>
        
        <h4>All Members:</h4>
        <table border="1">
            <tr><th>Name</th><th>Role</th><th>User ID</th><th>Object ID</th><th>Email</th></tr>
            {"".join([f"<tr><td>{m.get('name', 'N/A')}</td><td>{m.get('role', 'N/A')}</td><td>{m.get('user_id', 'N/A')}</td><td>{str(m.get('_id', 'N/A'))}</td><td>{m.get('email', 'N/A')}</td></tr>" for m in all_members])}
        </table>
        
        <h4>Tech Directors:</h4>
        <table border="1">
            <tr><th>Name</th><th>Role</th><th>User ID</th><th>Object ID</th><th>Email</th></tr>
            {"".join([f"<tr><td>{m.get('name', 'N/A')}</td><td>{m.get('role', 'N/A')}</td><td>{m.get('user_id', 'N/A')}</td><td>{str(m.get('_id', 'N/A'))}</td><td>{m.get('email', 'N/A')}</td></tr>" for m in tech_directors])}
        </table>
        
        <p><a href="/test-webhook">Test Webhook</a> | <a href="/create-tech-director">Create Tech Director</a></p>
        '''
        
    except Exception as e:
        return f'<h2>[ERROR] Debug Error:</h2><p>{str(e)}</p>'


@app.route('/debug-tech-director')
def debug_tech_director():
    """Debug endpoint to check Technical Director details"""
    db = get_db()
    try:
        # Check all members with Technical Director role
        all_members = list(db.members.find({"role": "Technical Director"}))
        
        # Also check by user_id
        marc_user = db.get_member_by_user_id('marc001')
        
        debug_info = {
            'total_tech_directors': len(all_members),
            'tech_directors_found': [
                {
                    'name': member.get('name'),
                    'role': member.get('role'), 
                    'user_id': member.get('user_id'),
                    'id': str(member.get('_id')),
                    'email': member.get('email')
                } for member in all_members
            ],
            'marc_user_lookup': {
                'found': marc_user is not None,
                'details': {
                    'name': marc_user.get('name') if marc_user else None,
                    'role': marc_user.get('role') if marc_user else None,
                    'id': str(marc_user.get('_id')) if marc_user else None
                } if marc_user else None
            }
        }
        
        return f'''
        <h2>[DEBUG] Technical Director Debug Info</h2>
        <pre>{str(debug_info)}</pre>
        <hr>
        <p><a href="/create-tech-director">Create/Check Tech Director</a></p>
        '''
        
    except Exception as e:
        return f'<h2>[ERROR] Debug Error:</h2><p>{str(e)}</p>'

@app.route('/create-tech-director')
def create_tech_director():
    """Create or verify Technical Director account exists"""
    db = get_db()
    try:
        # Check if tech director user already exists
        existing_tech_director = db.get_member_by_user_id('marc001')
        if existing_tech_director:
            return f'''
            <h2>[SUCCESS] Technical Director Account Status</h2>
            <p><strong>Account exists:</strong> marc001</p>
            <p><strong>Name:</strong> {existing_tech_director.get('name', 'Unknown')}</p>
            <p><strong>Role:</strong> {existing_tech_director.get('role', 'Unknown')}</p>
            <p><strong>Email:</strong> {existing_tech_director.get('email', 'Not set')}</p>
            <p><strong>Status:</strong> Active and ready to use</p>
            <hr>
            <p><a href="/login">Login to System</a> | <a href="/tech-director">Tech Director Portal</a></p>
            '''
        
        # Create Technical Director account
        member_data = {
            'name': 'Marc (Technical Director)',
            'role': 'Technical Director',
            'gender': 'male',
            'user_id': 'marc001',
            'password_hash': generate_password_hash('tech@123'),
            'email': 'marc@autoassistgroup.com',
            'department': 'Technical',
            'is_active': True,
            'created_at': datetime.now()
        }
        
        db.create_member(member_data)
        return '''
        <h2>[SUCCESS] Technical Director Account Created Successfully!</h2>
        <p><strong>Username:</strong> marc001</p>
        <p><strong>Password:</strong> tech@123</p>
        <p><strong>Role:</strong> Technical Director</p>
        <p><strong>Email:</strong> marc@autoassistgroup.com</p>
        <hr>
        <p><strong>[WARNING] Important:</strong> Change the password after first login!</p>
        <p><a href="/login">Login Now</a> | <a href="/tech-director">Tech Director Portal</a></p>
        '''
    except Exception as e:
        return f'<h2>[ERROR] Error creating Technical Director account:</h2><p>{str(e)}</p>'

@app.route('/debug/ticket-creation', methods=['GET'])
def debug_ticket_creation():
    """Debug endpoint to test ticket creation without full form"""
    try:
        db = get_db()
        
        # Test database connection
        db.client.admin.command('ping')
        
        # Generate a simple test ticket
        test_ticket_id = f"TEST{str(uuid.uuid4())[:2].upper()}"
        
        ticket_data = {
            'ticket_id': test_ticket_id,
            'email': 'test@example.com',
            'name': 'Test User',
            'subject': 'Debug Test Ticket',
            'body': 'This is a debug test ticket',
            'status': 'Open',
            'priority': 'Medium',
            'creation_method': 'debug'
        }
        
        # Try to create the ticket
        result = db.create_ticket(ticket_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Debug ticket created successfully',
            'ticket_id': test_ticket_id,
            'mongodb_result': str(result),
            'db_connection': 'OK'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'status': 'error',
            'message': str(e),
            'error_type': type(e).__name__,
            'traceback': traceback.format_exc()
        }), 500

# Add route to serve uploaded files with enhanced error handling for Vercel
@app.route('/uploads/<filename>')
def uploaded_file(filename):
    """Serve uploaded files with Vercel compatibility"""
    try:
        # Check authentication
        if 'member_id' not in session:
            app.logger.warning(f"Unauthorized access attempt to file: {filename}")
            return redirect(url_for('portal'))
        
        # Log the request
        app.logger.info(f"FOLDER FILE REQUEST: {filename}")
        app.logger.info(f"FOLDER UPLOAD_FOLDER: {UPLOAD_FOLDER}")
        
        # Check if upload folder exists
        if not os.path.exists(UPLOAD_FOLDER):
            app.logger.error(f" UPLOAD_FOLDER does not exist: {UPLOAD_FOLDER}")
            return jsonify({'error': 'Upload directory not found'}), 404
        
        # Get full file path
        file_path = os.path.join(UPLOAD_FOLDER, filename)
        app.logger.info(f"FOLDER FULL PATH: {file_path}")
        
        # Check if file exists
        if not os.path.exists(file_path):
            app.logger.error(f" FILE NOT FOUND: {file_path}")
            # List available files for debugging
            try:
                available_files = os.listdir(UPLOAD_FOLDER)
                app.logger.info(f"FOLDER AVAILABLE FILES: {available_files}")
            except Exception as e:
                app.logger.error(f" Cannot list directory: {e}")
            return jsonify({'error': 'File not found'}), 404
        
        # Serve the file
        app.logger.info(f" SERVING FILE: {filename}")
        return send_from_directory(UPLOAD_FOLDER, filename)

    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR SERVING FILE {filename}: {e}")
        return jsonify({'error': f'Server error: {str(e)}'}), 500

# Debug endpoint for uploads directory
@app.route('/debug/uploads')
def debug_uploads():
    """Debug endpoint to check uploads directory status on Vercel"""
    try:
        debug_info = {
            'upload_folder': UPLOAD_FOLDER,
            'upload_folder_exists': os.path.exists(UPLOAD_FOLDER) if UPLOAD_FOLDER else False,
            'is_production': is_production,
            'environment': os.environ.get('FLASK_ENV', 'development'),
            'current_directory': os.getcwd(),
            'temp_directory': '/tmp',
            'temp_exists': os.path.exists('/tmp'),
            'files_in_upload_folder': [],
            'files_in_tmp': [],
            'error': None
        }
        
        # List files in upload folder if it exists
        if debug_info['upload_folder_exists']:
            try:
                debug_info['files_in_upload_folder'] = os.listdir(UPLOAD_FOLDER)
            except Exception as e:
                debug_info['error'] = f"Cannot list upload folder: {e}"
        
        # List files in /tmp
        try:
            debug_info['files_in_tmp'] = os.listdir('/tmp')[:20]  # Limit to first 20 files
        except Exception as e:
            debug_info['files_in_tmp'] = f"Cannot list /tmp: {e}"
        
        return jsonify(debug_info)
        
    except Exception as e:
        return jsonify({
            'error': f'Debug endpoint error: {str(e)}',
            'upload_folder': UPLOAD_FOLDER,
            'is_production': is_production
        }), 500

@app.route('/dashboard')
def live_dashboard():
    """Display the live ticket dashboard with detailed statistics"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get current user's role
        current_member = db.get_member_by_id(session['member_id'])
        if not current_member:
            return redirect(url_for('portal'))
        current_user_role = current_member['role']
        
        # Redirect Technical Director to their specific dashboard
        if current_user_role == 'Technical Director':
            return redirect(url_for('tech_director_dashboard'))
        
        # Get pagination parameters
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status_filter = request.args.get('status', 'All')
        priority_filter = request.args.get('priority', 'All')
        search_query = request.args.get('search', '')
        
        # Get paginated tickets with assignment info
        try:
            tickets = db.get_tickets_with_assignments(
                page=page, 
                per_page=per_page, 
                status_filter=status_filter,
                priority_filter=priority_filter,
                search_query=search_query
            )
            if not tickets:
                app.logger.warning("No tickets found in database")
                tickets = []
        except Exception as e:
            app.logger.error(f"Error getting tickets: {e}")
            tickets = []
        
        # Get total count for pagination
        try:
            total_tickets = db.get_tickets_count(
                status_filter=status_filter,
                priority_filter=priority_filter,
                search_query=search_query
            )
        except Exception as e:
            app.logger.error(f"Error getting tickets count: {e}")
            total_tickets = 0
        
        # Convert to dict format for easier manipulation
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
                ticket_dict['is_forwarded'] = assignment.get('is_forwarded', False)
                
                # Handle forwarded from member info
                if ticket_dict['is_forwarded'] and ticket_dict.get('forwarded_from_member') and len(ticket_dict['forwarded_from_member']) > 0:
                    forwarded_member = ticket_dict['forwarded_from_member'][0]
                    ticket_dict['forwarded_from_name'] = forwarded_member.get('name')
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
                ticket_dict['is_forwarded'] = False
            
            # Get vehicle registration from metadata
            try:
                metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
                for meta in metadata:
                    if meta['key'] == 'vehicle_registration':
                        ticket_dict['vehicle_registration'] = meta['value']
                        break
            except Exception as e:
                app.logger.warning(f"Error getting metadata for ticket {ticket_dict.get('ticket_id')}: {e}")
                ticket_dict['vehicle_registration'] = ''
            
            # Set default values for missing fields that template expects
            ticket_dict.setdefault('has_warranty', False)
            ticket_dict.setdefault('has_attachments', False)
            ticket_dict.setdefault('attachments', [])
            ticket_dict.setdefault('priority', 'Medium')
            ticket_dict.setdefault('classification', 'General')
            ticket_dict.setdefault('subject', ticket_dict.get('body', '')[:100] if ticket_dict.get('body') else 'No Subject')
            ticket_dict.setdefault('body', 'No description available')
            ticket_dict.setdefault('warranty_forms_count', 0)
            ticket_dict.setdefault('creation_method', 'auto-detect')
            ticket_dict.setdefault('thread_id', None)
            ticket_dict.setdefault('email', None)
            
            # Check if ticket has attachments
            if ticket_dict.get('attachments') and len(ticket_dict['attachments']) > 0:
                ticket_dict['has_attachments'] = True
            
            # Check if ticket has warranty (basic check)
            if ticket_dict.get('classification') == 'Warranty Claim':
                ticket_dict['has_warranty'] = True
            
            all_tickets.append(ticket_dict)
        
        # 1. Ticket Status Breakdown (Live Count)
        status_counts = {}
        for ticket in all_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # 2. Outstanding Claims (Aged Tickets)
        now = datetime.now()
        overdue_tickets = []
        open_1_3_days = []
        open_today = []
        
        for ticket in all_tickets:
            # Handle both datetime objects (from MongoDB) and string dates
            if isinstance(ticket['created_at'], datetime):
                created_at = ticket['created_at']
            else:
                try:
                    created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                except:
                    continue  # Skip tickets with invalid dates
            
            days_open = (now - created_at).days
            
            if days_open > 3:
                overdue_tickets.append(ticket)
            elif 1 <= days_open <= 3:
                open_1_3_days.append(ticket)
            elif days_open == 0:
                open_today.append(ticket)
        
        # 3. Average Resolution Time
        resolved_tickets = [t for t in all_tickets if t['status'] == 'Resolved' or t['status'] == 'Closed']
        total_resolution_time = 0
        for ticket in resolved_tickets:
            try:
                # Handle both datetime objects (from MongoDB) and string dates
                if isinstance(ticket['created_at'], datetime):
                    created_at = ticket['created_at']
                else:
                    created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                
                if isinstance(ticket['updated_at'], datetime):
                    updated_at = ticket['updated_at']
                else:
                    updated_at = datetime.strptime(str(ticket['updated_at']), "%Y-%m-%d %H:%M:%S")
                
                resolution_time = (updated_at - created_at).total_seconds() / 3600  # in hours
                total_resolution_time += resolution_time
            except:
                continue  # Skip tickets with invalid dates
        
        avg_resolution_time = 0
        if resolved_tickets:
            avg_resolution_time = total_resolution_time / len(resolved_tickets)
        
        # 4. Claim Outcomes Summary
        total_claims = len(all_tickets)
        approved_claims = len([t for t in all_tickets if t['status'] == 'Approved - Revisit Booked'])
        declined_claims = len([t for t in all_tickets if t['status'] == 'Declined - Not Covered'])
        referred_claims = len([t for t in all_tickets if t['status'] == 'Referred to Tech Director'])
        
        approved_percent = (approved_claims / total_claims * 100) if total_claims > 0 else 0
        declined_percent = (declined_claims / total_claims * 100) if total_claims > 0 else 0
        referred_percent = (referred_claims / total_claims * 100) if total_claims > 0 else 0
        
        # 5. Advisory-Related Rejections
        # Get rejection reasons from metadata
        rejection_reasons = {
            'uncompleted_advisories': 0,
            'no_fault_code': 0,
            'warranty_expired': 0
        }
        
        for ticket in all_tickets:
            if ticket.get('status') == 'Declined - Not Covered':
                # Check metadata for rejection reasons
                metadata = db.get_ticket_metadata(ticket['ticket_id'])
                
                for meta in metadata:
                    if meta['key'] == 'advisories_followed' and meta['value'] == '0':
                        rejection_reasons['uncompleted_advisories'] += 1
                    elif meta['key'] == 'new_fault_codes' and meta['value'] == '0':
                        rejection_reasons['no_fault_code'] += 1
                    elif meta['key'] == 'within_warranty' and meta['value'] == '0':
                        rejection_reasons['warranty_expired'] += 1
        
        # 6. Team Performance
        team_performance = {}
        
        # Get all team members first
        all_members = db.get_all_members()
        
        # Initialize all members with 0 tickets
        for member in all_members:
            if member.get('role', '').lower() != 'administrator':  # Exclude admin users
                team_performance[member['name']] = 0
        
        # Use MongoDB aggregation to get team performance
        pipeline = [
            {
                "$lookup": {
                    "from": "members",
                    "localField": "member_id",
                    "foreignField": "_id",
                    "as": "member"
                }
            },
            {
                "$unwind": "$member"
            },
            {
                "$group": {
                    "_id": "$member.name",
                    "tickets_count": {"$sum": 1}
                }
            }
        ]
        
        try:
            assignments = list(db.ticket_assignments.aggregate(pipeline))
            # Update counts for members who have assignments
            for assignment in assignments:
                team_performance[assignment['_id']] = assignment['tickets_count']
        except Exception as e:
            # Fallback: count assignments manually
            try:
                assignments = list(db.ticket_assignments.find())
                for assignment in assignments:
                    member = db.get_member_by_id(str(assignment['member_id']))
                    if member and member.get('role', '').lower() != 'administrator':
                        name = member['name']
                        team_performance[name] = team_performance.get(name, 0) + 1
            except Exception as fallback_error:
                # Log error in production: Team performance calculation failed
                # If everything fails, at least show team members with 0 tickets
                pass
        
        # Calculate pagination info
        total_pages = (total_tickets + per_page - 1) // per_page
        has_prev = page > 1
        has_next = page < total_pages
        prev_page = page - 1 if has_prev else None
        next_page = page + 1 if has_next else None
        
        pagination_info = {
            'current_page': page,
            'per_page': per_page,
            'total_tickets': total_tickets,
            'total_pages': total_pages,
            'has_prev': has_prev,
            'has_next': has_next,
            'prev_page': prev_page,
            'next_page': next_page,
            'status_filter': status_filter,
            'priority_filter': priority_filter,
            'search_query': search_query
        }
        
        return render_template('dashboard.html',
                            status_counts=status_counts,
                            overdue_tickets=overdue_tickets,
                            open_1_3_days=open_1_3_days,
                            open_today=open_today,
                            avg_resolution_time=avg_resolution_time,
                            total_claims=total_claims,
                            approved_claims=approved_claims,
                            declined_claims=declined_claims,
                            referred_claims=referred_claims,
                            approved_percent=approved_percent,
                            declined_percent=declined_percent,
                            referred_percent=referred_percent,
                            rejection_reasons=rejection_reasons,
                            team_performance=team_performance,
                            all_tickets=all_tickets,
                            current_user=session.get('member_name'),
                            current_user_role=current_user_role,
                            pagination=pagination_info)
    except Exception as e:
        return render_template('error.html', error=f"Database error: {e}"), 500

@app.route('/export/csv')
def export_csv():
    """Export dashboard data as CSV file"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get all tickets with assignment info (reuse the same logic as dashboard)
        tickets = db.get_tickets_with_assignments()
        
        # Convert to dict format for easier manipulation
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
                ticket_dict['is_forwarded'] = assignment.get('is_forwarded', False)
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
                ticket_dict['is_forwarded'] = False
            
            # Get vehicle registration from metadata
            ticket_dict['vehicle_registration'] = ''
            metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
            for meta in metadata:
                if meta['key'] == 'vehicle_registration':
                    ticket_dict['vehicle_registration'] = meta['value']
                    break
            
            all_tickets.append(ticket_dict)
        
        # Create CSV content
        output = io.StringIO()
        fieldnames = [
            'ticket_id', 'status', 'priority', 'created_at', 'updated_at',
            'customer_name', 'customer_email', 'customer_phone',
                            'vehicle_registration', 'assigned_to', 'assigned_at', 'is_forwarded',
            'description', 'notes'
        ]
        
        writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction='ignore')
        writer.writeheader()
        
        for ticket in all_tickets:
            # Format datetime objects for CSV
            row = ticket.copy()
            if isinstance(row.get('created_at'), datetime):
                row['created_at'] = row['created_at'].strftime('%Y-%m-%d %H:%M:%S')
            if isinstance(row.get('updated_at'), datetime):
                row['updated_at'] = row['updated_at'].strftime('%Y-%m-%d %H:%M:%S')
            if isinstance(row.get('assigned_at'), datetime):
                row['assigned_at'] = row['assigned_at'].strftime('%Y-%m-%d %H:%M:%S')
                
            writer.writerow(row)
        
        # Create response
        csv_content = output.getvalue()
        output.close()
        
        # Generate filename with current timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'warranty_dashboard_export_{timestamp}.csv'
        
        response = Response(
            csv_content,
            mimetype='text/csv',
            headers={
                'Content-Disposition': f'attachment; filename={filename}'
            }
        )
        
        return response
        
    except Exception as e:
        return render_template('error.html', error=f"Export error: {e}"), 500

@app.route('/export/pdf')
def export_pdf():
    """Export dashboard data as PDF file"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get all tickets with assignment info (reuse the same logic as dashboard)
        tickets = db.get_tickets_with_assignments()
        
        # Convert to dict format for easier manipulation
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
            
            # Get vehicle registration from metadata
            ticket_dict['vehicle_registration'] = ''
            metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
            for meta in metadata:
                if meta['key'] == 'vehicle_registration':
                    ticket_dict['vehicle_registration'] = meta['value']
                    break
            
            all_tickets.append(ticket_dict)
        
        # Calculate dashboard statistics
        status_counts = {}
        for ticket in all_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        total_claims = len(all_tickets)
        approved_claims = len([t for t in all_tickets if t['status'] == 'Approved - Revisit Booked'])
        declined_claims = len([t for t in all_tickets if t['status'] == 'Declined - Not Covered'])
        referred_claims = len([t for t in all_tickets if t['status'] == 'Referred to Tech Director'])
        
        # Create PDF content
        output = io.BytesIO()
        doc = SimpleDocTemplate(output, pagesize=A4, rightMargin=72, leftMargin=72,
                               topMargin=72, bottomMargin=18)
        
        # Container for the 'Flowable' objects
        elements = []
        
        # Get styles
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=18,
            spaceAfter=30,
            alignment=1  # Center alignment
        )
        
        # Add title
        elements.append(Paragraph("Warranty Dashboard Report", title_style))
        elements.append(Spacer(1, 12))
        
        # Add generation timestamp
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        elements.append(Paragraph(f"Generated on: {timestamp}", styles['Normal']))
        elements.append(Spacer(1, 20))
        
        # Add summary statistics
        elements.append(Paragraph("Summary Statistics", styles['Heading2']))
        
        summary_data = [
            ['Total Claims', str(total_claims)],
            ['Approved Claims', f"{approved_claims} ({(approved_claims / total_claims * 100) if total_claims > 0 else 0:.1f}%)"],
            ['Declined Claims', f"{declined_claims} ({(declined_claims / total_claims * 100) if total_claims > 0 else 0:.1f}%)"],
            ['Referred Claims', f"{referred_claims} ({(referred_claims / total_claims * 100) if total_claims > 0 else 0:.1f}%)"]
        ]
        
        summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        elements.append(summary_table)
        elements.append(Spacer(1, 20))
        
        # Add status breakdown
        elements.append(Paragraph("Status Breakdown", styles['Heading2']))
        
        status_data = [['Status', 'Count']]
        for status, count in status_counts.items():
            status_data.append([status, str(count)])
        
        status_table = Table(status_data, colWidths=[4*inch, 1*inch])
        status_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        elements.append(status_table)
        elements.append(Spacer(1, 20))
        
        # Add detailed ticket list (first 20 tickets to avoid huge PDFs)
        elements.append(Paragraph("Recent Tickets (Latest 20)", styles['Heading2']))
        
        ticket_data = [['Ticket ID', 'Status', 'Customer', 'Created', 'Assigned To']]
        
        # Sort tickets by creation date (newest first) and take first 20
        sorted_tickets = sorted(all_tickets, 
                               key=lambda x: x.get('created_at', datetime.min) if isinstance(x.get('created_at'), datetime) else datetime.min, 
                               reverse=True)[:20]
        
        for ticket in sorted_tickets:
            created_date = ""
            if isinstance(ticket.get('created_at'), datetime):
                created_date = ticket['created_at'].strftime('%Y-%m-%d')
            elif ticket.get('created_at'):
                try:
                    created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                    created_date = created_at.strftime('%Y-%m-%d')
                except:
                    created_date = str(ticket.get('created_at', ''))[:10]
            
            ticket_data.append([
                ticket.get('ticket_id', '')[:10],  # Truncate long IDs
                ticket.get('status', '')[:20],     # Truncate long status
                ticket.get('customer_name', '')[:15],  # Truncate long names
                created_date,
                ticket.get('assigned_to', 'Unassigned')[:15]  # Truncate long names
            ])
        
        ticket_table = Table(ticket_data, colWidths=[1.2*inch, 1.5*inch, 1.2*inch, 1*inch, 1.1*inch])
        ticket_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('FONTSIZE', (0, 1), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('VALIGN', (0, 0), (-1, -1), 'TOP'),
        ]))
        elements.append(ticket_table)
        
        # Build PDF
        doc.build(elements)
        
        # Get PDF content
        pdf_content = output.getvalue()
        output.close()
        
        # Generate filename with current timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'warranty_dashboard_report_{timestamp}.pdf'
        
        response = Response(
            pdf_content,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'attachment; filename={filename}'
            }
        )
        
        return response
        
    except Exception as e:
        return render_template('error.html', error=f"PDF Export error: {e}"), 500

# Enhanced API endpoint for getting dashboard data with date filtering
@app.route('/api/ticket/analysis/<ticket_id>')
def ticket_analysis(ticket_id):
    """Get detailed analysis of ticket origin and structure"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Get ticket origin analysis
        origin_info = identify_ticket_origin(ticket)
        
        return jsonify({
            'status': 'success',
            'ticket_id': ticket_id,
            'origin_analysis': origin_info,
            'creation_method': ticket.get('creation_method', 'unknown'),
            'created_at': str(ticket.get('created_at', '')),
            'thread_id': ticket.get('thread_id', ''),
        })
    except Exception as e:
        app.logger.error(f"Error analyzing ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/dashboard/data', methods=['GET'])
def dashboard_data():
    """API endpoint to get dashboard data for AJAX updates with date filtering"""
    app.logger.info(" API: Dashboard data request received")
    
    # Enhanced session validation
    if 'member_id' not in session:
        app.logger.warning("API: Unauthorized access attempt - no member_id in session")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in again'}), 401
    
    if not session.get('member_id'):
        app.logger.warning("API: Unauthorized access attempt - empty member_id in session")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Invalid session'}), 401
    
    try:
        app.logger.info("API: Getting database connection")
        db = get_db()
        app.logger.info("API: Database connection successful")
        
        # Get date range parameters
        start_date_str = request.args.get('start_date')
        end_date_str = request.args.get('end_date')
        
        # Parse dates if provided
        start_date = None
        end_date = None
        try:
            if start_date_str:
                start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
            if end_date_str:
                end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
                end_date = end_date.replace(hour=23, minute=59, second=59)  # End of day
        except ValueError as e:
            app.logger.warning(f"Invalid date format provided: {e}")
            # Continue without date filtering
            start_date = None
            end_date = None
        
        # Get all tickets with assignment info with error handling
        try:
            app.logger.info("API: Attempting to get tickets with assignments")
            tickets = db.get_tickets_with_assignments()
            if not tickets:
                app.logger.warning("API: No tickets found in database")
                tickets = []
            else:
                app.logger.info(f"API: Successfully retrieved {len(tickets)} tickets with assignments")
        except Exception as e:
            app.logger.error(f"API: Failed to get tickets with assignments: {e}")
            # Fallback to simple ticket fetch
            try:
                app.logger.info("API: Attempting fallback ticket fetch")
                tickets = list(db.tickets.find().sort([("created_at", -1)]))
                app.logger.info(f"API: Fallback ticket fetch returned {len(tickets)} tickets")
            except Exception as fallback_error:
                app.logger.error(f"API: Fallback ticket fetch also failed: {fallback_error}")
                # Return empty response instead of crashing
                return jsonify({
                    'status': 'error',
                    'message': 'Database temporarily unavailable. Please try again later.',
                    'data': {
                        'total_tickets': 0,
                        'status_counts': {},
                        'priority_counts': {},
                        'classification_counts': {},
                        'outstanding_claims': {'overdue': 0, 'open_1_3_days': 0, 'open_today': 0, 'overdue_tickets': []},
                        'resolution_metrics': {'avg_resolution_time': 0, 'resolved_count': 0},
                        'claim_outcomes': {'approved': 0, 'declined': 0, 'referred': 0, 'warranty_received': 0, 'approved_percent': 0, 'declined_percent': 0, 'referred_percent': 0},
                        'date_range': {'start_date': start_date_str, 'end_date': end_date_str, 'filtered': False}
                    }
                }), 503
        
        # Convert to dict format and apply date filtering
        app.logger.info(f"API: Processing {len(tickets)} tickets")
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Convert any other ObjectId fields that might cause JSON serialization issues
            if 'member_id' in ticket_dict and hasattr(ticket_dict['member_id'], '__class__') and ticket_dict['member_id'].__class__.__name__ == 'ObjectId':
                ticket_dict['member_id'] = str(ticket_dict['member_id'])
            
            # Handle assignment ObjectIds
            if 'assignment' in ticket_dict and isinstance(ticket_dict['assignment'], list):
                for assignment in ticket_dict['assignment']:
                    if isinstance(assignment, dict):
                        if 'member_id' in assignment and hasattr(assignment['member_id'], '__class__') and assignment['member_id'].__class__.__name__ == 'ObjectId':
                            assignment['member_id'] = str(assignment['member_id'])
                        if 'forwarded_from' in assignment and hasattr(assignment['forwarded_from'], '__class__') and assignment['forwarded_from'].__class__.__name__ == 'ObjectId':
                            assignment['forwarded_from'] = str(assignment['forwarded_from'])
            
            # Handle assigned_member ObjectIds
            if 'assigned_member' in ticket_dict and isinstance(ticket_dict['assigned_member'], list):
                for member in ticket_dict['assigned_member']:
                    if isinstance(member, dict) and '_id' in member and hasattr(member['_id'], '__class__') and member['_id'].__class__.__name__ == 'ObjectId':
                        member['_id'] = str(member['_id'])
            
            # Handle forwarded_from_member ObjectIds
            if 'forwarded_from_member' in ticket_dict and isinstance(ticket_dict['forwarded_from_member'], list):
                for member in ticket_dict['forwarded_from_member']:
                    if isinstance(member, dict) and '_id' in member and hasattr(member['_id'], '__class__') and member['_id'].__class__.__name__ == 'ObjectId':
                        member['_id'] = str(member['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
                ticket_dict['is_forwarded'] = assignment.get('is_forwarded', False)
                
                # Handle forwarded from member info
                if ticket_dict['is_forwarded'] and ticket_dict.get('forwarded_from_member') and len(ticket_dict['forwarded_from_member']) > 0:
                    forwarded_member = ticket_dict['forwarded_from_member'][0]
                    ticket_dict['forwarded_from_name'] = forwarded_member.get('name')
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
                ticket_dict['is_forwarded'] = False
            
            # Get vehicle registration from metadata
            try:
                metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
                for meta in metadata:
                    if meta['key'] == 'vehicle_registration':
                        ticket_dict['vehicle_registration'] = meta['value']
                        break
            except Exception as e:
                app.logger.warning(f"Error getting metadata for API ticket {ticket_dict.get('ticket_id')}: {e}")
                ticket_dict['vehicle_registration'] = ''
            
            # Set default values for missing fields that template expects
            ticket_dict.setdefault('has_warranty', False)
            ticket_dict.setdefault('has_attachments', False)
            ticket_dict.setdefault('attachments', [])
            ticket_dict.setdefault('priority', 'Medium')
            ticket_dict.setdefault('classification', 'General')
            ticket_dict.setdefault('subject', ticket_dict.get('body', '')[:100] if ticket_dict.get('body') else 'No Subject')
            ticket_dict.setdefault('body', 'No description available')
            ticket_dict.setdefault('warranty_forms_count', 0)
            ticket_dict.setdefault('creation_method', 'auto-detect')
            ticket_dict.setdefault('thread_id', None)
            ticket_dict.setdefault('email', None)
            
            # Check if ticket has attachments
            if ticket_dict.get('attachments') and len(ticket_dict['attachments']) > 0:
                ticket_dict['has_attachments'] = True
            
            # Check if ticket has warranty (basic check)
            if ticket_dict.get('classification') == 'Warranty Claim':
                ticket_dict['has_warranty'] = True
            
            # Parse created_at for filtering
            if 'created_at' in ticket_dict and ticket_dict['created_at']:
                if isinstance(ticket_dict['created_at'], datetime):
                    created_at = ticket_dict['created_at']
                else:
                    try:
                        created_at = datetime.strptime(str(ticket_dict['created_at']), "%Y-%m-%d %H:%M:%S")
                    except:
                        continue  # Skip tickets with invalid dates
                
                # Apply date filtering
                if start_date and created_at < start_date:
                    continue
                if end_date and created_at > end_date:
                    continue
                
                ticket_dict['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                ticket_dict['created_at_dt'] = created_at
            
            all_tickets.append(ticket_dict)
        
        #  DYNAMIC WARRANTY CLASSIFICATION: Update classification for tickets with warranty attachments
        for ticket_dict in all_tickets:
            ticket_id = ticket_dict.get('ticket_id')
            if ticket_id:
                try:
                    # Check if ticket has warranty attachments
                    metadata = db.get_ticket_metadata(ticket_id)
                    has_warranty_attachment = False
                    
                    if metadata:
                        for meta in metadata:
                            try:
                                # Ensure meta is a dictionary
                                if not isinstance(meta, dict):
                                    continue
                                
                                meta_value = meta.get('value')
                                if isinstance(meta_value, str):
                                    # Handle potential malformed JSON
                                    if meta_value.strip() and meta_value.strip() not in ['{}', '']:
                                        try:
                                            # Clean JSON before parsing
                                            clean_json = meta_value.strip()
                                            # Remove trailing commas and fix common JSON issues
                                            if clean_json.endswith(',}'):
                                                clean_json = clean_json[:-2] + '}'
                                            elif clean_json.endswith(',]'):
                                                clean_json = clean_json[:-2] + ']'
                                            # Remove any leading/trailing whitespace and quotes
                                            clean_json = clean_json.strip().strip('"\'')
                                            # Skip if still empty after cleaning
                                            if not clean_json or clean_json in ['{}', '[]', 'null', 'undefined']:
                                                meta_data = {}
                                            else:
                                                meta_data = json.loads(clean_json)
                                        except json.JSONDecodeError as json_err:
                                            # Only log if it's actually malformed, not just empty
                                            if meta_value.strip() and meta_value.strip() not in ['{}', '[]', 'null', 'undefined', '']:
                                                app.logger.debug(f"Skipping malformed JSON in API metadata: {json_err} - Value: {meta_value[:50]}")
                                            meta_data = {}
                                    else:
                                        meta_data = {}
                                elif isinstance(meta_value, dict):
                                    meta_data = meta_value
                                else:
                                    meta_data = {}
                                
                                # Check if this attachment is warranty-related
                                if isinstance(meta_data, dict):
                                    is_warranty = meta_data.get('is_warranty', False)
                                    if is_warranty:
                                        has_warranty_attachment = True
                                        break
                            except (json.JSONDecodeError, TypeError, AttributeError) as e:
                                app.logger.warning(f"Error processing API metadata for ticket {ticket_id}: {e}")
                                continue
                    
                    # Also check direct has_warranty flag on ticket
                    has_warranty_flag = ticket_dict.get('has_warranty', False)
                    
                    # If ticket has warranty attachments or warranty flag, ensure classification is "Warranty Claim"
                    if has_warranty_attachment or has_warranty_flag:
                        original_classification = ticket_dict.get('classification')
                        ticket_dict['classification'] = 'Warranty Claim'
                        
                        if original_classification != 'Warranty Claim':
                            app.logger.info(f" API DASHBOARD WARRANTY CLASSIFICATION: Ticket {ticket_id} updated from '{original_classification}' to 'Warranty Claim'")
                
                except Exception as e:
                    app.logger.error(f"Error checking warranty status for API ticket {ticket_id}: {e}")
        
        # Calculate comprehensive statistics - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(all_tickets)
        
        # 1. Ticket Status Breakdown
        status_counts = {}
        for ticket in all_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # 2. Priority Breakdown
        priority_counts = {}
        for ticket in all_tickets:
            priority = ticket.get('priority', 'Medium')
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
        
        # 3. Classification Breakdown
        classification_counts = {}
        for ticket in all_tickets:
            classification = ticket.get('classification', 'General')
            classification_counts[classification] = classification_counts.get(classification, 0) + 1
        
        # 4. Outstanding Claims Analysis
        now = datetime.now()
        overdue_tickets = []
        open_1_3_days = []
        open_today = []
        
        for ticket in all_tickets:
            if 'created_at_dt' in ticket:
                days_open = (now - ticket['created_at_dt']).days
                
                if days_open > 3:
                    overdue_tickets.append(ticket)
                elif 1 <= days_open <= 3:
                    open_1_3_days.append(ticket)
                elif days_open == 0:
                    open_today.append(ticket)
        
        # 5. Average Resolution Time
        resolved_tickets = [t for t in all_tickets if t.get('status') in ['Resolved', 'Closed']]
        avg_resolution_time = 0
        total_resolution_time = 0
        
        for ticket in resolved_tickets:
            try:
                if 'created_at_dt' in ticket and 'updated_at' in ticket:
                    created_at = ticket['created_at_dt']
                    
                    if isinstance(ticket['updated_at'], datetime):
                        updated_at = ticket['updated_at']
                    else:
                        updated_at = datetime.strptime(str(ticket['updated_at']), "%Y-%m-%d %H:%M:%S")
                    
                    resolution_time = (updated_at - created_at).total_seconds() / 3600  # in hours
                    total_resolution_time += resolution_time
            except:
                continue
        
        if resolved_tickets:
            avg_resolution_time = total_resolution_time / len(resolved_tickets)
        
        # 6. Claim Outcomes
        approved_claims = len([t for t in all_tickets if t.get('status') == 'Approved - Revisit Booked'])
        declined_claims = len([t for t in all_tickets if t.get('status') == 'Declined - Not Covered'])
        referred_claims = len([t for t in all_tickets if t.get('status') == 'Referred to Tech Director'])
        warranty_received = len([t for t in all_tickets if t.get('status') == 'Warranty Form Received'])
        
        # Calculate percentages
        approved_percent = (approved_claims / total_tickets * 100) if total_tickets > 0 else 0
        declined_percent = (declined_claims / total_tickets * 100) if total_tickets > 0 else 0
        referred_percent = (referred_claims / total_tickets * 100) if total_tickets > 0 else 0
        
        app.logger.info(f"API: Successfully processed dashboard data - {total_tickets} tickets")
        
        # Final safety check: ensure no ObjectIds remain in the response data
        try:
            response_data = {
                'status': 'success',
                'data': {
                    'total_tickets': total_tickets,
                    'status_counts': status_counts,
                    'priority_counts': priority_counts,
                    'classification_counts': classification_counts,
                    'outstanding_claims': {
                        'overdue': len(overdue_tickets),
                        'open_1_3_days': len(open_1_3_days),
                        'open_today': len(open_today),
                        'overdue_tickets': overdue_tickets[:5]  # Top 5 most urgent
                    },
                    'resolution_metrics': {
                        'avg_resolution_time': avg_resolution_time,
                        'resolved_count': len(resolved_tickets)
                    },
                    'claim_outcomes': {
                        'approved': approved_claims,
                        'declined': declined_claims,
                        'referred': referred_claims,
                        'warranty_received': warranty_received,
                        'approved_percent': approved_percent,
                        'declined_percent': declined_percent,
                        'referred_percent': referred_percent
                    },
                    'date_range': {
                        'start_date': start_date_str,
                        'end_date': end_date_str,
                        'filtered': bool(start_date_str or end_date_str)
                    }
                }
            }
            
            # Test JSON serialization to catch any remaining ObjectIds
            json.dumps(response_data)
            app.logger.info("API: JSON serialization test passed")
            
            return jsonify(response_data)
            
        except TypeError as e:
            app.logger.error(f"API: JSON serialization failed due to ObjectId: {e}")
            # Return a simplified response without problematic data
            return jsonify({
                'status': 'success',
                'data': {
                    'total_tickets': total_tickets,
                    'status_counts': status_counts,
                    'priority_counts': priority_counts,
                    'classification_counts': classification_counts,
                    'outstanding_claims': {
                        'overdue': len(overdue_tickets),
                        'open_1_3_days': len(open_1_3_days),
                        'open_today': len(open_today),
                        'overdue_tickets': []  # Skip detailed ticket data to avoid ObjectId issues
                    },
                    'resolution_metrics': {
                        'avg_resolution_time': avg_resolution_time,
                        'resolved_count': len(resolved_tickets)
                    },
                    'claim_outcomes': {
                        'approved': approved_claims,
                        'declined': declined_claims,
                        'referred': referred_claims,
                        'warranty_received': warranty_received,
                        'approved_percent': approved_percent,
                        'declined_percent': declined_percent,
                        'referred_percent': referred_percent
                    },
                    'date_range': {
                        'start_date': start_date_str,
                        'end_date': end_date_str,
                        'filtered': bool(start_date_str or end_date_str)
                    }
                }
            })
    except Exception as e:
        app.logger.error(f"Error getting dashboard data: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# AI-based warranty form detection (placeholder for future AI integration)
def analyze_warranty_form(file_path, filename):
    """
    Analyze uploaded file to determine if it's a warranty form
    This is a placeholder for future AI integration
    """
    try:
        # For now, simple heuristic based on filename and extension
        filename_lower = filename.lower()
        
        # Check for warranty-related keywords in filename
        warranty_keywords = ['warranty', 'claim', 'form', 'dpf', 'service', 'guarantee']
        has_warranty_keyword = any(keyword in filename_lower for keyword in warranty_keywords)
        
        # Check file extension
        valid_extensions = ['.pdf', '.doc', '.docx', '.jpg', '.jpeg', '.png']
        has_valid_extension = any(filename_lower.endswith(ext) for ext in valid_extensions)
        
        # Simple confidence calculation
        confidence = 0
        if has_warranty_keyword:
            confidence += 70
        if has_valid_extension:
            confidence += 30
        
        # Return analysis result
        return {
            'is_warranty_form': confidence >= 70,
            'confidence': confidence,
            'analysis': {
                'has_warranty_keywords': has_warranty_keyword,
                'valid_file_type': has_valid_extension,
                'detected_keywords': [kw for kw in warranty_keywords if kw in filename_lower]
            }
        }
    except Exception as e:
        app.logger.error(f"Error analyzing warranty form: {e}")
        return {
            'is_warranty_form': False,
            'confidence': 0,
            'analysis': {'error': str(e)}
        }

# API endpoint for warranty form analysis
@app.route('/api/tickets/<ticket_id>/analyze-warranty-form', methods=['POST'])
def analyze_ticket_warranty_form(ticket_id):
    """Analyze warranty form and suggest status update"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get ticket metadata to check for warranty form
        metadata = db.get_ticket_metadata(ticket_id)
        
        warranty_form_path = None
        for item in metadata:
            if item['key'] == 'warranty_form':
                warranty_form_path = item['value']
                break
        
        if not warranty_form_path:
            return jsonify({
                'status': 'error', 
                'message': 'No warranty form found for this ticket'
            }), 404
        
        # Extract filename from path
        filename = os.path.basename(warranty_form_path)
        
        # Analyze the warranty form
        analysis_result = analyze_warranty_form(warranty_form_path, filename)
        
        # Add suggested actions
        suggestions = []
        if analysis_result['is_warranty_form']:
            suggestions.append({
                'action': 'update_status',
                'status': 'Warranty Form Received',
                'reason': f"AI detected warranty form with {analysis_result['confidence']}% confidence"
            })
            suggestions.append({
                'action': 'notify_team',
                'message': 'Warranty form detected and ready for manual verification'
            })
        else:
            suggestions.append({
                'action': 'manual_review',
                'reason': f"Low confidence ({analysis_result['confidence']}%) - manual review recommended"
            })
        
        return jsonify({
            'status': 'success',
            'analysis': analysis_result,
            'suggestions': suggestions,
            'requires_manual_confirmation': True
        })
        
    except Exception as e:
        app.logger.error(f"Error analyzing warranty form for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Analysis failed'}), 500

# API endpoint to confirm AI warranty form detection
@app.route('/api/tickets/<ticket_id>/confirm-warranty-form', methods=['POST'])
def confirm_warranty_form(ticket_id):
    """Confirm AI warranty form detection and update status"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        is_correct = data.get('is_correct', False)
        user_feedback = data.get('feedback', '')
        
        db = get_db()
        
        if is_correct:
            # Update ticket status to "Warranty Form Received"
            db.update_ticket(ticket_id, {'status': 'Warranty Form Received'})
            
            # Log successful AI detection
            app.logger.info(f"AI warranty form detection confirmed for ticket {ticket_id} by {session.get('member_name')}")
            
            return jsonify({
                'status': 'success',
                'message': 'Warranty form confirmed and ticket status updated',
                'new_status': 'Warranty Form Received'
            })
        else:
            # Log incorrect AI detection for improvement
            app.logger.warning(f"AI warranty form detection incorrect for ticket {ticket_id}. Feedback: {user_feedback}")
            
            return jsonify({
                'status': 'success',
                'message': 'Feedback recorded. Please upload the correct warranty form.',
                'action_required': 'request_correct_form'
            })
        
    except Exception as e:
        app.logger.error(f"Error confirming warranty form for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Confirmation failed'}), 500

# Add route for the create ticket page
@app.route('/technicians')
def technicians_management():
    """Technicians management page"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if current user is admin
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return render_template('error.html', error="Access denied. Administrator access required."), 403
    
    try:
        db = get_db()
        technicians = db.get_all_technicians()
        for tech in technicians:
            tech['_id'] = str(tech['_id'])
        
        return render_template('technicians.html', 
                         technicians=technicians,
                         current_user=session.get('member_name'),
                         current_user_role=session.get('member_role'))
    except Exception as e:
        app.logger.error(f"Error loading technicians page: {e}")
        return render_template('error.html', error="Failed to load technicians page"), 500

@app.route('/create-ticket')
def create_ticket_form():
    """Display form for creating a new ticket"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        # Get all technicians for the dropdown
        technicians = db.get_all_technicians()
        for tech in technicians:
            tech['_id'] = str(tech['_id'])
        
        # Get current user info for navbar
        current_member = db.get_member_by_id(session['member_id'])
        current_user_role = current_member['role'] if current_member else 'Unknown'
        
        return render_template('create_ticket.html', 
                         technicians=technicians,
                         current_user=session.get('member_name'),
                         current_user_role=current_user_role)
    except Exception as e:
        app.logger.error(f"Error loading create ticket form: {e}")
        return render_template('create_ticket.html', 
                         technicians=[],
                         current_user=session.get('member_name'),
                         current_user_role=session.get('member_role', 'Unknown'))

# Add API endpoint for ticket creation with new structured fields
@app.route('/api/dashboard/updates', methods=['POST'])
def dashboard_updates():
    """
    API endpoint to provide real-time dashboard updates
    Returns only changed data to minimize bandwidth and improve performance
    """
    try:
        # Enhanced session validation with automatic restoration
        if 'member_id' not in session:
            app.logger.warning(f"Dashboard updates API called without valid session from {request.remote_addr}")
            
            # Try to restore the session before giving up
            if check_and_restore_session():
                app.logger.info(f"Session restored successfully for dashboard updates API")
            else:
                app.logger.warning(f"Failed to restore session for dashboard updates API")
                return jsonify({'status': 'error', 'message': 'Session expired - Please select your portal again'}), 401
        
        # Sessions are permanent - no timeout checks needed
        # Users stay logged in forever
        
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'Invalid request data'}), 400
            
        last_update = data.get('last_update', 0)
        current_tickets = data.get('current_tickets', [])
        
        # Convert timestamp to datetime
        last_update_dt = datetime.fromtimestamp(last_update / 1000) if last_update > 0 else datetime.min
        
        db = get_db()
        
        # Get all tickets with assignments
        all_tickets = db.get_tickets_with_assignments()
        
        # Check for new tickets
        new_tickets = []
        updated_tickets = []
        removed_tickets = []
        
        # Process tickets to find changes
        for ticket in all_tickets:
            ticket_id = ticket.get('ticket_id')
            created_at = ticket.get('created_at')
            
            if created_at and created_at > last_update_dt:
                # New ticket
                new_tickets.append({
                    'ticket_id': ticket_id,
                    'name': ticket.get('name', 'Unknown'),
                    'subject': ticket.get('subject', 'No Subject'),
                    'body': ticket.get('body', ''),
                    'priority': ticket.get('priority', 'Medium'),
                    'classification': ticket.get('classification', 'General'),
                    'status': ticket.get('status', 'New'),
                    'has_attachments': ticket.get('has_attachments', False),
                    'has_warranty': ticket.get('has_warranty', False),
                    'has_unread_reply': ticket.get('has_unread_reply', False),
                    'created_at': created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at),
                    'date': created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at)
                })
            elif ticket_id in current_tickets:
                # Check if existing ticket has updates
                # For now, we'll consider all existing tickets as potentially updated
                # In a more sophisticated implementation, you could track modification times
                pass
        
        # Calculate current stats - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(all_tickets)
        open_tickets = len([t for t in all_tickets if t.get('status') == 'Open'])
        resolved_tickets = len([t for t in all_tickets if t.get('status') == 'Resolved'])
        waiting_tickets = len([t for t in all_tickets if t.get('status') == 'Waiting for Response'])
        
        # Calculate breakdowns
        priorities = {}
        classifications = {}
        for ticket in all_tickets:
            priority = ticket.get('priority', 'Medium')
            classification = ticket.get('classification', 'General')
            
            priorities[priority] = priorities.get(priority, 0) + 1
            classifications[classification] = classifications.get(classification, 0) + 1
        
        has_updates = len(new_tickets) > 0 or len(updated_tickets) > 0 or len(removed_tickets) > 0
        
        app.logger.debug(f"Dashboard updates API: {len(new_tickets)} new, {len(updated_tickets)} updated tickets for user {session.get('member_name', 'Unknown')}")
        
        return jsonify({
            'status': 'success',
            'has_updates': has_updates,
            'stats': {
                'total_tickets': total_tickets,
                'open_tickets': open_tickets,
                'resolved_tickets': resolved_tickets,
                'waiting_tickets': waiting_tickets
            },
            'tickets': {
                'new_tickets': new_tickets,
                'updated_tickets': updated_tickets,
                'removed_tickets': removed_tickets
            },
            'breakdowns': {
                'priorities': priorities,
                'classifications': classifications
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error in dashboard updates: {e}")
        return jsonify({'status': 'error', 'message': 'Internal server error'}), 500

@app.route('/api/tickets', methods=['POST'])
def n8n_tickets_api():
    """
    [FIXED] N8N TICKETS CREATION ENDPOINT - Creates actual tickets in database
    
    Designed specifically for n8n workflows:
    - No authentication required (perfect for n8n)
    - ACCEPTS any ticket ID format from N8N (GS5160, EO5267, TO3356, etc.)
    - CREATES tickets in database for frontend display
    - Handles attachments and saves them to disk
    - Full ticket processing with database storage
    - Always returns proper success/error responses
    - Perfect for N8N workflows that need to create real tickets
    """
    try:
        # Get request data (same as working simple app)
        raw_data = request.get_data()
        app.logger.info(f"[FIX] N8N /api/tickets received request: Content-Type={request.content_type}, Size={len(raw_data)}")
        
        # Parse JSON data (same as working simple app)
        try:
            if request.is_json:
                data = request.get_json()
            else:
                # Try to parse as JSON anyway
                data = json.loads(raw_data.decode('utf-8'))
        except Exception as json_error:
                app.logger.error(f"[ERROR] JSON parsing error: {json_error}")
                return jsonify({
                'success': False,
                'message': f'Invalid JSON format: {str(json_error)}'
                }), 400
            
        app.logger.info(f"? Parsed data type: {type(data)}")
        
        # [CRITICAL DEBUG] Log the exact data received to identify ticket ID issue
        app.logger.info(f"[DEBUG] RECEIVED DATA ANALYSIS:")
        app.logger.info(f"  - Raw data length: {len(raw_data)} bytes")
        app.logger.info(f"  - Content-Type: {request.content_type}")
        app.logger.info(f"  - Parsed data type: {type(data)}")
        if isinstance(data, dict):
            app.logger.info(f"  - Top-level keys: {list(data.keys())}")
            if 'ticket_id' in data:
                app.logger.info(f"  - ticket_id field: '{data['ticket_id']}' (type: {type(data['ticket_id'])})")
            else:
                app.logger.info(f"  - âŒ NO ticket_id field found in top-level data!")
        elif isinstance(data, list):
            app.logger.info(f"  - Array length: {len(data)}")
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    app.logger.info(f"  - Item {i} keys: {list(item.keys())}")
                    if 'ticket_id' in item:
                        app.logger.info(f"  - Item {i} ticket_id: '{item['ticket_id']}'")
                    elif 'complete' in item:
                        app.logger.info(f"  - Item {i} has 'complete' field (length: {len(str(item['complete']))})")
                else:
                    app.logger.info(f"  - Item {i} type: {type(item)}")
        else:
            app.logger.info(f"  - Unexpected data structure: {data}")
        
        # [CRITICAL FIX] Extract and preserve N8N ticket ID from ANY location in the data
        preserved_n8n_ticket_id = None
        
        # Search for ticket_id in the data structure
        if isinstance(data, dict) and 'ticket_id' in data:
            preserved_n8n_ticket_id = data['ticket_id']
            app.logger.info(f"[CRITICAL] Found N8N ticket ID at top level: {preserved_n8n_ticket_id}")
        elif isinstance(data, list):
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    # Check direct ticket_id
                    if 'ticket_id' in item:
                        preserved_n8n_ticket_id = item['ticket_id']
                        app.logger.info(f"[CRITICAL] Found N8N ticket ID in array item {i}: {preserved_n8n_ticket_id}")
                        break
                    
                    # Check in 'complete' field
                    elif 'complete' in item:
                        try:
                            clean_json = item['complete'].strip()
                            if clean_json.endswith(',}'):
                                clean_json = clean_json[:-2] + '}'
                            elif clean_json.endswith(',]'):
                                clean_json = clean_json[:-2] + ']'
                            
                            parsed_complete = json.loads(clean_json)
                            if isinstance(parsed_complete, dict) and 'ticket_id' in parsed_complete:
                                preserved_n8n_ticket_id = parsed_complete['ticket_id']
                                app.logger.info(f"[CRITICAL] Found N8N ticket ID in complete field of item {i}: {preserved_n8n_ticket_id}")
                                break
                        except Exception as parse_error:
                            app.logger.warning(f"[CRITICAL] Failed to parse complete field for item {i}: {parse_error}")
        
        if preserved_n8n_ticket_id:
            app.logger.info(f"[CRITICAL] ðŸŽ¯ N8N TICKET ID PRESERVED: {preserved_n8n_ticket_id}")
        else:
            app.logger.warning(f"[CRITICAL] âš ï¸ NO N8N TICKET ID FOUND in the data structure!")
        
        # Process data and create tickets in database (FIXED - now creates real tickets)
        processed_tickets = []
        
        # Case 1: Direct ticket data structure
        if isinstance(data, dict) and any(key in data for key in ['threadId', 'ticket_id', 'name', 'body', 'from']):
            app.logger.info("[DEBUG] Processing direct ticket data structure")
            # Pass preserved ticket ID if available
            if preserved_n8n_ticket_id:
                data['_preserved_n8n_ticket_id'] = preserved_n8n_ticket_id
            ticket = process_n8n_ticket_data(data)
            if ticket:
                processed_tickets.append(ticket)
                
        # Case 2: Array of data items
        elif isinstance(data, list):
            app.logger.info(f"[DEBUG] Processing array with {len(data)} items")
            
            # Special handling for your n8n format with "complete" fields
            complete_items = []
            attachments_data = []
            ticket_data_item = None
            
            # [ENHANCED DEBUG] Log the complete field parsing process
            app.logger.info(f"[DEBUG] Processing N8N 'complete' field format:")
            
            # First pass: collect and parse all "complete" items
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    # Check if item has ticket fields directly
                    if any(key in item for key in ['threadId', 'ticket_id', 'name', 'body', 'from']):
                        app.logger.info(f"[DEBUG] Item {i} has direct ticket fields: {list(item.keys())}")
                        ticket = process_n8n_ticket_data(item)
                        if ticket:
                            processed_tickets.append(ticket)
                    # Check if item has 'complete' field with JSON data (your real n8n format)
                    elif 'complete' in item:
                        app.logger.info(f"[DEBUG] Item {i} has 'complete' field, length: {len(str(item['complete']))}")
                        try:
                            # Clean JSON before parsing
                            clean_json = item['complete'].strip()
                            if clean_json.endswith(',}'):
                                clean_json = clean_json[:-2] + '}'
                            elif clean_json.endswith(',]'):
                                clean_json = clean_json[:-2] + ']'
                            
                            app.logger.info(f"[DEBUG] Cleaned JSON for item {i}: {clean_json[:100]}...")
                            parsed_data = json.loads(clean_json)
                            
                            if isinstance(parsed_data, dict):
                                complete_items.append(parsed_data)
                                app.logger.info(f"[DEBUG] Parsed complete item {i}: {list(parsed_data.keys())}")
                                
                                # [CRITICAL] Check if this contains the ticket_id we're looking for
                                if 'ticket_id' in parsed_data:
                                    app.logger.info(f"[DEBUG] âœ… FOUND ticket_id in complete item {i}: '{parsed_data['ticket_id']}'")
                                else:
                                    app.logger.info(f"[DEBUG] âŒ NO ticket_id in complete item {i}")
                            else:
                                app.logger.warning(f"[DEBUG] Complete item {i} is not a dict: {type(parsed_data)}")
                                
                        except Exception as parse_error:
                            app.logger.warning(f"[DEBUG] Failed to parse 'complete' field for item {i}: {parse_error}")
                            app.logger.warning(f"[DEBUG] Raw complete content: {item['complete'][:200]}...")
            
            # Second pass: separate attachments from ticket data
            if complete_items:
                app.logger.info(f"[DEBUG] Processing {len(complete_items)} parsed complete items")
                for parsed_item in complete_items:
                    # Check if it's attachment data (has fileName and fileData)
                    if 'fileName' in parsed_item and 'fileData' in parsed_item:
                        attachments_data.append({
                            'fileName': parsed_item['fileName'],
                            'fileData': parsed_item['fileData']
                        })
                        app.logger.info(f"[DEBUG] Found attachment: {parsed_item['fileName']}")
                    # Check if it's ticket data (has ticket_id)
                    elif 'ticket_id' in parsed_item:
                        ticket_data_item = parsed_item
                        app.logger.info(f"[DEBUG] âœ… Found ticket data with ID: {parsed_item['ticket_id']}")
                        app.logger.info(f"[DEBUG] Ticket data keys: {list(parsed_item.keys())}")
                    else:
                        app.logger.info(f"[DEBUG] Complete item has neither attachment nor ticket data: {list(parsed_item.keys())}")
                
                # Third pass: combine ticket data with attachments
                if ticket_data_item:
                    app.logger.info(f"[DEBUG] Processing ticket data item with ID: {ticket_data_item['ticket_id']}")
                    # Add attachments to ticket data
                    if attachments_data:
                        ticket_data_item['attachments'] = attachments_data
                        app.logger.info(f"[DEBUG] Combined ticket {ticket_data_item['ticket_id']} with {len(attachments_data)} attachments")
                    
                    # Pass preserved ticket ID if available
                    if preserved_n8n_ticket_id:
                        ticket_data_item['_preserved_n8n_ticket_id'] = preserved_n8n_ticket_id
                    
                    ticket = process_n8n_ticket_data(ticket_data_item)
                    if ticket:
                        processed_tickets.append(ticket)
                elif attachments_data:
                    app.logger.info(f"[DEBUG] Only attachments found, no ticket data")
                    # If we only have attachments without ticket data, create file upload tickets
                    for attachment in attachments_data:
                        ticket = create_file_upload_ticket(attachment)
                        if ticket:
                            processed_tickets.append(ticket)
                            
        # Case 3: File upload only
        elif isinstance(data, dict) and 'fileName' in data and 'fileData' in data:
            app.logger.info("[DEBUG] Processing file upload only")
            ticket = create_file_upload_ticket(data)
            if ticket:
                processed_tickets.append(ticket)
        else:
            app.logger.warning(f"[ERROR] No valid ticket structure found in data: {list(data.keys()) if isinstance(data, dict) else type(data)}")
        
        # [DUPLICATE PREVENTION] Add deduplication logic to prevent duplicate tickets
        if processed_tickets:
            app.logger.info(f"[DEDUP] Processing {len(processed_tickets)} tickets before deduplication")
            
            # Deduplication based on ticket_id
            seen_ticket_ids = set()
            unique_processed_tickets = []
            duplicate_count = 0
            
            for ticket_data in processed_tickets:
                ticket_id = ticket_data.get('ticket_id')
                if ticket_id and ticket_id not in seen_ticket_ids:
                    seen_ticket_ids.add(ticket_id)
                    unique_processed_tickets.append(ticket_data)
                    app.logger.info(f"[DEDUP] âœ… Keeping unique ticket: {ticket_id}")
                else:
                    duplicate_count += 1
                    app.logger.warning(f"[DEDUP] ðŸš« Duplicate ticket ID {ticket_id} detected, skipping")
            
            # Update processed_tickets with deduplicated list
            processed_tickets = unique_processed_tickets
            app.logger.info(f"[DEDUP] Deduplication complete: {len(processed_tickets)} unique tickets, {duplicate_count} duplicates removed")
        
        # [FIXED] Create actual tickets in database instead of just accepting them
        if processed_tickets:
            db = get_db()
            created_tickets = []
            received_ticket_ids = []
            
            for ticket_data in processed_tickets:
                try:
                    ticket_id = ticket_data.get('ticket_id', 'unknown')
                    app.logger.info(f"[DATABASE] Creating ticket {ticket_id} in database...")
                    
                    # Prepare ticket data for database creation
                    db_ticket_data = {
                        'ticket_id': ticket_id,
                        'name': ticket_data.get('name', 'Unknown'),
                        'email': ticket_data.get('email', ''),
                        'subject': ticket_data.get('subject', 'No Subject'),
                        'body': ticket_data.get('body', ''),
                        'status': 'New',
                        'priority': ticket_data.get('priority', 'Medium'),
                        'classification': ticket_data.get('classification', 'General'),
                        'is_important': False,
                        'has_unread_reply': False,
                        'has_warranty': ticket_data.get('has_warranty', False),
                        'has_attachments': ticket_data.get('has_attachments', False),
                        'warranty_forms_count': ticket_data.get('warranty_forms_count', 0),
                        'total_attachments': ticket_data.get('total_attachments', 0),
                        'attachment_total_size': ticket_data.get('attachment_total_size', 0),
                        'processing_method': 'n8n_tickets_api',
                        'created_at': datetime.now(),
                        'thread_id': f"THREAD_{ticket_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(100, 999)}"
                    }
                    
                    # Create ticket in database
                    created_id = db.create_ticket(db_ticket_data)
                    app.logger.info(f"[SUCCESS] âœ… Created ticket {ticket_id} in database with ID: {created_id}")
                    
                    # Process attachments if present
                    if ticket_data.get('attachments'):
                        for i, attachment in enumerate(ticket_data['attachments']):
                            try:
                                filename = attachment.get('filename', f'attachment_{i}')
                                file_data = attachment.get('data', '')
                                is_warranty = attachment.get('is_warranty', False)
                                
                                # Save file to disk
                                file_path = None
                                if file_data:
                                    try:
                                        decoded_data = base64.b64decode(file_data)
                                        safe_filename = secure_filename(filename)
                                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                        unique_filename = f"{timestamp}_{ticket_id}_{safe_filename}"
                                        
                                        file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                                        with open(file_path, 'wb') as f:
                                            f.write(decoded_data)
                                        
                                        app.logger.info(f"[SUCCESS] Saved attachment: {file_path}")
                                        
                                    except Exception as save_error:
                                        app.logger.error(f"Failed to save attachment {filename}: {save_error}")
                                        file_path = None
                                
                                # Store attachment metadata
                                attachment_metadata = {
                                    'key': f'attachment_{i}',
                                    'filename': filename,
                                    'file_path': file_path,
                                    'data': file_data,
                                    'is_warranty': is_warranty,
                                    'size': attachment.get('size', 0),
                                    'saved_to_disk': bool(file_path)
                                }
                                db.add_ticket_metadata(ticket_id, f'attachment_{i}', json.dumps(attachment_metadata))
                                
                            except Exception as att_error:
                                app.logger.error(f"Error processing attachment {i}: {att_error}")
                    
                    created_tickets.append({
                        'ticket_id': ticket_id,
                        'database_id': str(created_id),
                        'status': 'created',
                        'message': f'Ticket {ticket_id} created successfully in database'
                    })
                    
                    received_ticket_ids.append({
                        'ticket_id': ticket_id,
                        'status': 'created',
                        'message': f'Ticket ID {ticket_id} created successfully in database'
                    })
                    
                except Exception as ticket_error:
                    app.logger.error(f"Error creating ticket {ticket_data.get('ticket_id', 'unknown')}: {ticket_error}")
                    received_ticket_ids.append({
                        'ticket_id': ticket_data.get('ticket_id', 'unknown'),
                        'status': 'error',
                        'message': f'Failed to create ticket: {str(ticket_error)}'
                    })
            
            return jsonify({
                'success': True,
                'message': f'Successfully created {len(created_tickets)} ticket(s) in database',
                'tickets_created': len(created_tickets),
                'ticket_ids': received_ticket_ids,
                'note': 'Tickets are now created in database and will appear on frontend'
            }), 200
        else:
            return jsonify({
                'success': False,
                'message': 'No valid ticket data found in the provided data'
            }), 400

    except Exception as e:
        app.logger.error(f"[ERROR] Error in n8n_tickets_api: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Error processing request: {str(e)}'
        }), 500

def process_n8n_ticket_data(data):
    """
    Process n8n ticket data into database-ready format (based on working simple app)
    """
    try:
        app.logger.info(f"Processing ticket data: {data.get('ticket_id', 'no_id')} from {data.get('from', 'no_sender')}")
        
        # Extract name from email or use provided name
        name = data.get('name', '')
        if not name and data.get('from'):
            name = extract_name_from_email(data.get('from', ''))
        if not name:
            name = 'Unknown'
        
        # [CRITICAL FIX] Enhanced N8N ticket ID handling with better debugging
        # Check if we have a preserved N8N ticket ID from the main endpoint
        preserved_id = data.get('_preserved_n8n_ticket_id', None)
        if preserved_id:
            app.logger.info(f"[CRITICAL] Using preserved N8N ticket ID: {preserved_id}")
            n8n_ticket_id = preserved_id
        else:
            n8n_ticket_id = data.get('ticket_id', '').strip()
        
        app.logger.info(f"[DEBUG] N8N ticket ID extraction:")
        app.logger.info(f"  - Raw ticket_id field: '{data.get('ticket_id', 'NOT_FOUND')}'")
        app.logger.info(f"  - Stripped ticket_id: '{n8n_ticket_id}'")
        app.logger.info(f"  - Preserved ID: '{preserved_id}'")
        app.logger.info(f"  - Data keys available: {list(data.keys())}")
        app.logger.info(f"  - Data type: {type(data)}")
        
        if n8n_ticket_id:
            # Use n8n ticket ID EXACTLY as provided (no formatting, no prefixes)
            db = get_db()
            if not db.ticket_id_exists(n8n_ticket_id):
                ticket_id = n8n_ticket_id
                app.logger.info(f"[N8N_PROCESS] âœ… SUCCESS: Using n8n ticket ID exactly as provided: {ticket_id}")
            else:
                # If n8n ticket ID already exists, append a suffix to make it unique
                # This preserves the n8n ID while ensuring uniqueness
                suffix = 1
                while True:
                    unique_ticket_id = f"{n8n_ticket_id}_{suffix}"
                    if not db.ticket_id_exists(unique_ticket_id):
                        ticket_id = unique_ticket_id
                        app.logger.info(f"[N8N_PROCESS] âš ï¸ N8N ticket ID {n8n_ticket_id} already exists, using unique variant: {ticket_id}")
                        break
                    suffix += 1
                    if suffix > 999:  # Prevent infinite loops
                        app.logger.error(f"[N8N_PROCESS] âŒ Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
                        raise Exception(f"Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
        else:
            # [FALLBACK] Only generate new ID if no n8n ticket ID was provided
            app.logger.warning(f"[N8N_PROCESS] âš ï¸ No n8n ticket ID provided in data, falling back to generation")
            app.logger.warning(f"[N8N_PROCESS] âš ï¸ This should NOT happen if N8N is sending ticket_id: GS5160")
            
            # Generate new email ticket ID as fallback
            email = data.get('from', 'unknown@example.com')
            classification = data.get('Classification', 'General')
            
            # Use new email ticket ID generation (same format as manual tickets)
            db = get_db()
            ticket_id = generate_email_ticket_id(email, name, classification, db)
            app.logger.info(f"[N8N_PROCESS] ðŸ”„ Generated fallback email ticket ID: {ticket_id}")
        
        # [VERIFICATION] Log final ticket ID decision
        app.logger.info(f"[N8N_PROCESS] ðŸŽ¯ FINAL DECISION:")
        app.logger.info(f"  - Original N8N ID: '{n8n_ticket_id}'")
        app.logger.info(f"  - Final ticket ID: '{ticket_id}'")
        app.logger.info(f"  - ID preserved: {'âœ… YES' if ticket_id == n8n_ticket_id else 'âŒ NO - ID was modified!'}")
        
        # Process attachments
        attachments = []
        if 'attachments' in data and isinstance(data['attachments'], list):
            for att_data in data['attachments']:
                if isinstance(att_data, dict) and 'fileName' in att_data and 'fileData' in att_data:
                    attachments.append({
                        'filename': att_data['fileName'],
                        'data': att_data['fileData'],
                        'is_warranty': enhanced_detect_warranty_form(att_data['fileName']),
                        'size': len(base64.b64decode(att_data['fileData'])) if att_data['fileData'] else 0
                    })
        
        # Create simplified ticket data for acceptance (no database fields)
        ticket_data = {
            'ticket_id': ticket_id,
            'name': name,
            'email': data.get('from', 'unknown@example.com'),
            'subject': data.get('subject', f"Email from {name}"),
            'body': data.get('body', ''),
            'classification': data.get('Classification', 'Support'),
            'priority': data.get('Priority', 'Medium'),
            'has_attachments': len(attachments) > 0,
            'total_attachments': len(attachments),
            'has_warranty': any(att.get('is_warranty', False) for att in attachments),
            'attachments': attachments,
            'processing_method': 'n8n_acceptance',  # Track that this is just acceptance
            'n8n_original_id': n8n_ticket_id if n8n_ticket_id else None,  # Track original N8N ID for debugging
            'accepted_at': datetime.now().isoformat()
        }
        
        app.logger.info(f"[SUCCESS] âœ… ACCEPTED ticket ID {ticket_id} from N8N: {len(attachments)} attachments, warranty: {ticket_data['has_warranty']}")
        app.logger.info(f"[SUCCESS] âœ… Ticket ID {ticket_id} will be accepted in any format (GS5160, EO5267, TO3356, etc.)")
        return ticket_data
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error processing ticket data: {e}")
        import traceback
        app.logger.error(f"[ERROR] Full traceback: {traceback.format_exc()}")
        return None

def create_file_upload_ticket(data):
    """
    Create a ticket for file upload only (based on working simple app)
    """
    try:
        ticket_id = f"FILE{random.randint(100000, 999999)}"
        filename = data.get('fileName', 'unknown_file')
        
        # Create attachment
        attachment = {
            'filename': filename,
            'data': data.get('fileData', ''),
            'is_warranty': enhanced_detect_warranty_form(filename),
            'size': len(base64.b64decode(data['fileData'])) if data.get('fileData') else 0
        }
        
        ticket_data = {
            'ticket_id': ticket_id,
            'thread_id': f"THREAD_{ticket_id}",
            'name': 'File Upload User',
            'email': 'fileupload@system.com',
            'subject': f'File Upload: {filename}',
            'body': f'A file has been uploaded: {filename}',
            'draft_body': f'Thank you for uploading {filename}. We have received your file and will process it accordingly.\n\nBest regards,\nSupport Team',  # [FIX] Add draft response
            'status': 'Open',
            'priority': 'Medium',
            'classification': 'File Upload',
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'is_important': False,
            'has_unread_reply': False,
            'has_attachments': True,
            'total_attachments': 1,
            'has_warranty': attachment.get('is_warranty', False),
            'attachments': [attachment]
        }
        
        app.logger.info(f"[SUCCESS] Created file upload ticket {ticket_id}: {filename}")
        return ticket_data
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error creating file upload ticket: {e}")
        return None

def save_ticket_attachments(ticket_id, attachments, db):
    """
    Save ticket attachments to filesystem and add metadata to database
    """
    try:
        for i, attachment in enumerate(attachments):
            if attachment.get('data'):
                # Decode base64 data
                file_data = base64.b64decode(attachment.get('data', ''))
                filename = attachment.get('filename', 'unknown_file')
                safe_filename = secure_filename(filename)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                unique_filename = f"{timestamp}_{ticket_id}_{safe_filename}"
                
                # Save to uploads directory
                file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                with open(file_path, 'wb') as f:
                    f.write(file_data)
                
                # Add attachment metadata to database
                attachment_key = 'warranty_form' if attachment.get('is_warranty') else f'attachment_{i+1}'
                attachment_metadata = {
                    'key': attachment_key,
                    'file_path': unique_filename,
                    'original_name': filename,
                    'size': attachment.get('size', len(file_data)),
                    'is_warranty': attachment.get('is_warranty', False),
                    'uploaded_at': datetime.now().isoformat()
                }
                
                db.add_ticket_metadata(ticket_id, attachment_key, json.dumps(attachment_metadata))
                app.logger.info(f"[SUCCESS] Saved attachment: {filename} for ticket {ticket_id}")
                
    except Exception as e:
        app.logger.error(f"[ERROR] Error saving attachments for ticket {ticket_id}: {e}")

@app.route('/api/tickets/<ticket_id>/attachments/<attachment_id>/download')
def download_email_attachment(ticket_id, attachment_id):
    """Download email attachment by ticket ID and attachment ID"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        target_attachment = None
        
        # METHOD 1: Check for direct attachments in ticket (n8n email tickets)
        attachments = ticket.get('attachments', [])
        for i, att in enumerate(attachments):
            if f"{ticket_id}_{i}" == attachment_id:
                target_attachment = att
                break
        
        # METHOD 2: Check for metadata attachments (email attachments stored in metadata)
        if not target_attachment:
            metadata = db.get_ticket_metadata(ticket_id)
            for meta in metadata:
                if meta.get('key', '').startswith('attachment_'):
                    try:
                        attachment_data = json.loads(meta.get('value', '{}'))
                        if attachment_data and isinstance(attachment_data, dict):
                            # Check if this is the attachment we're looking for
                            metadata_index = meta.get('key', '').replace('attachment_', '')
                            if f"{ticket_id}_metadata_{metadata_index}" == attachment_id:
                                target_attachment = attachment_data
                                break
                    except (json.JSONDecodeError, TypeError):
                        continue
        
        if not target_attachment:
            return jsonify({'error': 'Attachment not found'}), 404
        
        # Decode base64 file data
        file_data = target_attachment.get('data', '')
        if not file_data:
            return jsonify({'error': 'No file data available'}), 404
        
        try:
            decoded_data = base64.b64decode(file_data)
        except Exception as e:
            app.logger.error(f"Failed to decode attachment data: {e}")
            return jsonify({'error': 'Failed to decode file data'}), 500
        
        filename = target_attachment.get('filename', target_attachment.get('original_name', 'attachment'))
        
        # Determine MIME type based on file extension
        mime_type = 'application/octet-stream'  # default
        if filename.lower().endswith('.pdf'):
            mime_type = 'application/pdf'
        elif filename.lower().endswith(('.jpg', '.jpeg')):
            mime_type = 'image/jpeg'
        elif filename.lower().endswith('.png'):
            mime_type = 'image/png'
        elif filename.lower().endswith('.gif'):
            mime_type = 'image/gif'
        elif filename.lower().endswith(('.doc', '.docx')):
            mime_type = 'application/msword'
        elif filename.lower().endswith(('.xls', '.xlsx')):
            mime_type = 'application/vnd.ms-excel'
        
        # Create response with proper headers for download
        response = make_response(decoded_data)
        response.headers['Content-Type'] = mime_type
        response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
        response.headers['Content-Length'] = len(decoded_data)
        
        # Add additional headers for better PDF handling
        if filename.lower().endswith('.pdf'):
            response.headers['Accept-Ranges'] = 'bytes'
            response.headers['Cache-Control'] = 'no-cache'
            response.headers['X-Content-Type-Options'] = 'nosniff'
            # Enhanced PDF validation for downloads
            pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
            is_valid_pdf = any(decoded_data.startswith(sig) for sig in pdf_signatures)
            
            # Also check for PDF content in the first 1024 bytes
            if not is_valid_pdf and len(decoded_data) > 100:
                first_kb = decoded_data[:1024]
                is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
            
            # Log warning but don't reject the file
            if not is_valid_pdf:
                app.logger.warning(f"PDF validation failed for download: {filename}, but serving anyway")
                app.logger.debug(f"First 100 bytes: {decoded_data[:100]}")
        
        app.logger.info(f"Download response for {filename}: {mime_type}, size: {len(decoded_data)} bytes")
        
        return response
        
    except Exception as e:
        app.logger.error(f"Error downloading attachment: {e}")
        return jsonify({'error': 'Internal server error'}), 500

@app.route('/api/tickets/<ticket_id>/attachments/<int:attachment_index>/preview')
def preview_attachment(ticket_id, attachment_index):
    """Preview attachment by ticket ID and attachment index from multiple sources"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        app.logger.info(f" Preview request for ticket {ticket_id}, attachment {attachment_index}")
        
        # METHOD 1: Check for direct attachments in ticket (n8n email tickets)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            attachments = ticket['attachments']
            app.logger.info(f"Found {len(attachments)} direct attachments in ticket")
            
            if attachment_index < len(attachments):
                attachment = attachments[attachment_index]
                filename = attachment.get('filename', 'unknown_file')
                file_data = attachment.get('data', '')
                
                if file_data:
                    app.logger.info(f" Previewing base64 attachment: {filename}")
                    try:
                        decoded_data = base64.b64decode(file_data)
                        return create_preview_response(decoded_data, filename)
                    except Exception as e:
                        app.logger.error(f"Failed to decode base64 data: {e}")
                        return jsonify({'error': 'Invalid attachment data'}), 500
        
        # METHOD 1.5: Check for simple_attachments (conversation section attachments)
        if ticket.get('simple_attachments'):
            simple_attachments = ticket['simple_attachments']
            app.logger.info(f"Found {len(simple_attachments)} simple attachments in ticket")
            
            if attachment_index < len(simple_attachments):
                attachment = simple_attachments[attachment_index]
                filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
                file_path = attachment.get('file_path', '')
                
                app.logger.info(f" Simple attachment for preview: {attachment}")
                
                # Try to read the file from the file_path
                if file_path and os.path.exists(file_path):
                    app.logger.info(f" FOUND SIMPLE ATTACHMENT FILE FOR PREVIEW: {file_path}")
                    try:
                        with open(file_path, 'rb') as f:
                            file_data = f.read()
                        return create_preview_response(file_data, filename)
                    except Exception as e:
                        app.logger.error(f"Failed to read simple attachment file: {e}")
                        return jsonify({'error': 'Failed to read file'}), 500
                else:
                    app.logger.warning(f" Simple attachment file not found for preview: {file_path}")
                    # Try to find the file in uploads directory
                    if filename:
                        upload_path = os.path.join('uploads', filename)
                        if os.path.exists(upload_path):
                            app.logger.info(f" FOUND SIMPLE ATTACHMENT IN UPLOADS FOR PREVIEW: {upload_path}")
                            try:
                                with open(upload_path, 'rb') as f:
                                    file_data = f.read()
                                return create_preview_response(file_data, filename)
                            except Exception as e:
                                app.logger.error(f"Failed to read simple attachment from uploads: {e}")
                                return jsonify({'error': 'Failed to read file'}), 500
                        else:
                            app.logger.warning(f" Simple attachment not found in uploads for preview: {upload_path}")
                            # List files in uploads directory for debugging
                            if os.path.exists('uploads'):
                                upload_files = os.listdir('uploads')
                                app.logger.info(f"FOLDER Files in uploads directory: {upload_files}")
                            else:
                                app.logger.warning(" Uploads directory does not exist")
        
        # METHOD 2: Check reply attachments (webhook files)
        replies = db.replies.find({'ticket_id': ticket_id}).sort('created_at', -1)
        all_reply_attachments = []
        
        for reply in replies:
            if reply.get('attachments'):
                for att in reply['attachments']:
                    if att.get('type') == 'file':
                        all_reply_attachments.append(att)
        
        app.logger.info(f"Found {len(all_reply_attachments)} reply attachments")
        
        if attachment_index < len(all_reply_attachments):
            attachment = all_reply_attachments[attachment_index]
            filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
            file_path = attachment.get('path', '')
            
            if file_path and os.path.exists(file_path):
                app.logger.info(f" FOUND REPLY FILE FOR PREVIEW: {file_path}")
                try:
                    with open(file_path, 'rb') as f:
                        file_data = f.read()
                    return create_preview_response(file_data, filename)
                except Exception as e:
                    app.logger.error(f"Failed to read reply file: {e}")
                    return jsonify({'error': 'Failed to read file'}), 500
            else:
                app.logger.warning(f" Reply file not found for preview: {file_path}")
        
        # METHOD 3: Check metadata collection for file attachments
        ticket_metadata = db.get_ticket_metadata(ticket_id)
        attachment_files = []
        
        for metadata_entry in ticket_metadata:
            if metadata_entry['key'].startswith('attachment_'):
                try:
                    attachment_data = json.loads(metadata_entry['value'])
                    attachment_files.append(attachment_data)
                except:
                    continue
        
        app.logger.info(f"Found {len(attachment_files)} metadata attachments")
        
        if attachment_index < len(attachment_files):
            attachment = attachment_files[attachment_index]
            filename = attachment.get('original_name', attachment.get('filename', 'unknown_file'))
            
            # Try saved file path first
            saved_file_path = attachment.get('file_path')
            if saved_file_path and os.path.exists(saved_file_path):
                app.logger.info(f" FOUND SAVED FILE FOR PREVIEW: {saved_file_path}")
                try:
                    with open(saved_file_path, 'rb') as f:
                        file_data = f.read()
                    return create_preview_response(file_data, filename)
                except Exception as e:
                    app.logger.error(f"Failed to read saved file: {e}")
                    return jsonify({'error': 'Failed to read file'}), 500
            
            # Try base64 data as fallback
            elif 'data' in attachment and attachment['data']:
                app.logger.info(f" FALLBACK TO BASE64 FOR PREVIEW: {filename}")
                try:
                    decoded_data = base64.b64decode(attachment.get('data', ''))
                    return create_preview_response(decoded_data, filename)
                except Exception as e:
                    app.logger.error(f"Failed to decode metadata base64: {e}")
                    return jsonify({'error': 'Invalid attachment data'}), 500
        
        # If we get here, attachment not found
        app.logger.warning(f" Attachment {attachment_index} not found for preview in ticket {ticket_id}")
        return jsonify({'error': 'Attachment not found'}), 404
        
    except Exception as e:
        app.logger.error(f"Error previewing attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Internal server error'}), 500

def create_preview_response(file_data, filename):
    """Helper function to create preview response with proper MIME type handling"""
    # Validate file data
    if not file_data or len(file_data) == 0:
        app.logger.error(f"Empty file data for {filename}")
        return jsonify({'error': 'Empty file data'}), 400
    
    # Determine MIME type based on file extension
    mime_type = 'application/octet-stream'  # default
    if filename.lower().endswith('.pdf'):
        mime_type = 'application/pdf'
        # Enhanced PDF validation - check multiple possible signatures
        pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
        is_valid_pdf = any(file_data.startswith(sig) for sig in pdf_signatures)
        
        # Also check for PDF content in the first 1024 bytes (some PDFs have headers)
        if not is_valid_pdf and len(file_data) > 100:
            # Look for PDF signature in first 1KB
            first_kb = file_data[:1024]
            is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
        
        # If still not valid, check if it might be a corrupted but recoverable PDF
        if not is_valid_pdf:
            app.logger.warning(f"PDF validation failed for {filename}, but attempting to serve anyway")
            app.logger.debug(f"First 100 bytes: {file_data[:100]}")
            # Don't reject the file - let the browser try to handle it
            # This prevents false positives from blocking valid PDFs with unusual headers
    elif filename.lower().endswith(('.jpg', '.jpeg')):
        mime_type = 'image/jpeg'
    elif filename.lower().endswith('.png'):
        mime_type = 'image/png'
    elif filename.lower().endswith('.gif'):
        mime_type = 'image/gif'
    elif filename.lower().endswith('.txt'):
        mime_type = 'text/plain'
    elif filename.lower().endswith('.md'):
        mime_type = 'text/markdown'
    elif filename.lower().endswith(('.doc', '.docx')):
        # For Word docs, show a message instead of trying to display
        return render_template_string('''
            <html><body style="font-family: Arial, sans-serif; padding: 20px;">
                <h3>Document Preview</h3>
                <p><strong>Filename:</strong> {{ filename }}</p>
                <p><strong>Type:</strong> Microsoft Word Document</p>
                <p>This document cannot be previewed in the browser. Please download it to view the contents.</p>
                <br>
                <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px;">Close</button>
            </body></html>
        ''', filename=filename)
    elif filename.lower().endswith(('.xls', '.xlsx')):
        # For Excel files, show a message instead of trying to display
        return render_template_string('''
            <html><body style="font-family: Arial, sans-serif; padding: 20px;">
                <h3>Spreadsheet Preview</h3>
                <p><strong>Filename:</strong> {{ filename }}</p>
                <p><strong>Type:</strong> Microsoft Excel Spreadsheet</p>
                <p>This spreadsheet cannot be previewed in the browser. Please download it to view the contents.</p>
                <br>
                <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px;">Close</button>
            </body></html>
        ''', filename=filename)
    
    # Create response with proper headers for inline display
    response = make_response(file_data)
    response.headers['Content-Type'] = mime_type
    response.headers['Content-Disposition'] = f'inline; filename="{filename}"'
    response.headers['Content-Length'] = len(file_data)
    
    # Add additional headers for better PDF handling
    if filename.lower().endswith('.pdf'):
        response.headers['Accept-Ranges'] = 'bytes'
        response.headers['Cache-Control'] = 'public, max-age=3600'
        response.headers['X-Content-Type-Options'] = 'nosniff'
    
    app.logger.info(f"Created preview response for {filename}: {mime_type}, size: {len(file_data)} bytes")
    
    return response

# ðŸš€ NEW: File System Attachment Routes (for metadata-stored files)
@app.route('/api/tickets/<ticket_id>/file-attachments/<attachment_key>/download')
def download_file_system_attachment(ticket_id, attachment_key):
    """Download file system attachment by ticket ID and attachment key (from metadata)"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Get ticket metadata to find file path
        metadata = db.get_ticket_metadata(ticket_id)
        file_path = None
        
        for meta in metadata:
            if meta['key'] == attachment_key:
                file_path = meta['value']
                break
        
        if not file_path:
            app.logger.error(f" No file path found for attachment key: {attachment_key}")
            return jsonify({'error': 'Attachment not found in metadata'}), 404
        
        # Check if file exists in uploads directory
        upload_path = os.path.join('uploads', os.path.basename(file_path))
        full_path = os.path.join(os.getcwd(), upload_path)
        
        app.logger.info(f" Looking for file at: {full_path}")
        
        if not os.path.exists(full_path):
            app.logger.error(f" File not found at path: {full_path}")
            return jsonify({'error': 'File not found on server'}), 404
        
        try:
            filename = os.path.basename(file_path)
            app.logger.info(f" Serving file: {filename}")
            
            # For PDFs, read and validate the file
            if filename.lower().endswith('.pdf'):
                try:
                    with open(full_path, 'rb') as f:
                        file_data = f.read()
                    
                    # Enhanced PDF validation - check multiple possible signatures
                    pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
                    is_valid_pdf = any(file_data.startswith(sig) for sig in pdf_signatures)
                    
                    # Also check for PDF content in the first 1024 bytes (some PDFs have headers)
                    if not is_valid_pdf and len(file_data) > 100:
                        first_kb = file_data[:1024]
                        is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
                    
                    # Log warning but don't reject the file - let browser try to handle it
                    if not is_valid_pdf:
                        app.logger.warning(f"PDF validation failed for download: {filename}, but serving anyway")
                        app.logger.debug(f"First 100 bytes: {file_data[:100]}")
                        # Don't reject the file - let the browser try to handle it
                        # This prevents false positives from blocking valid PDFs with unusual headers
                    
                    # Create custom response with proper headers
                    response = make_response(file_data)
                    response.headers['Content-Type'] = 'application/pdf'
                    response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
                    response.headers['Content-Length'] = len(file_data)
                    response.headers['Accept-Ranges'] = 'bytes'
                    response.headers['Cache-Control'] = 'no-cache'
                    response.headers['X-Content-Type-Options'] = 'nosniff'
                    
                    app.logger.info(f"PDF download response for {filename}: size: {len(file_data)} bytes")
                    return response
                    
                except Exception as e:
                    app.logger.error(f"Error reading PDF file for download: {e}")
                    return jsonify({'error': 'Failed to read PDF file'}), 500
            
            # For other files, use send_file
            return send_file(
                full_path,
                as_attachment=True,
                download_name=filename,
                mimetype='application/octet-stream'
            )
        except Exception as e:
            app.logger.error(f"ðŸ’¥ Error serving file: {e}")
            return jsonify({'error': 'Failed to serve file'}), 500
            
    except Exception as e:
        app.logger.error(f"ðŸ’¥ Error downloading file system attachment: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/file-attachments/<attachment_key>/preview')
def preview_file_system_attachment(ticket_id, attachment_key):
    """Preview file system attachment by ticket ID and attachment key (from metadata)"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Get ticket metadata to find file path
        metadata = db.get_ticket_metadata(ticket_id)
        file_path = None
        
        for meta in metadata:
            if meta['key'] == attachment_key:
                file_path = meta['value']
                break
        
        if not file_path:
            app.logger.error(f" No file path found for attachment key: {attachment_key}")
            return jsonify({'error': 'Attachment not found in metadata'}), 404
        
        # Check if file exists in uploads directory
        upload_path = os.path.join('uploads', os.path.basename(file_path))
        full_path = os.path.join(os.getcwd(), upload_path)
        
        app.logger.info(f"ðŸ‘€ Looking for preview file at: {full_path}")
        
        if not os.path.exists(full_path):
            app.logger.error(f" File not found at path: {full_path}")
            return jsonify({'error': 'File not found on server'}), 404
        
        try:
            filename = os.path.basename(file_path)
            
            # Determine content type for preview
            content_type = 'application/octet-stream'
            if filename.lower().endswith('.pdf'):
                content_type = 'application/pdf'
            elif filename.lower().endswith(('.jpg', '.jpeg')):
                content_type = 'image/jpeg'
            elif filename.lower().endswith('.png'):
                content_type = 'image/png'
            elif filename.lower().endswith('.gif'):
                content_type = 'image/gif'
            elif filename.lower().endswith(('.doc', '.docx')):
                # For Word docs, show message instead of trying to display
                return render_template_string('''
                    <html><body style="font-family: Arial, sans-serif; padding: 20px; text-align: center;">
                        <h3>ðŸ“„ Document Preview - File System</h3>
                        <p><strong>Filename:</strong> {{ filename }}</p>
                        <p><strong>Type:</strong> Microsoft Word Document</p>
                        <p>This document cannot be previewed in the browser. Please download it to view the contents.</p>
                        <br>
                        <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer;">Close</button>
                    </body></html>
                ''', filename=filename)
            elif filename.lower().endswith(('.xls', '.xlsx')):
                # For Excel files, show message instead of trying to display
                return render_template_string('''
                    <html><body style="font-family: Arial, sans-serif; padding: 20px; text-align: center;">
                        <h3>ðŸ“Š Spreadsheet Preview - File System</h3>
                        <p><strong>Filename:</strong> {{ filename }}</p>
                        <p><strong>Type:</strong> Microsoft Excel Spreadsheet</p>
                        <p>This spreadsheet cannot be previewed in the browser. Please download it to view the contents.</p>
                        <br>
                        <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer;">Close</button>
                    </body></html>
                ''', filename=filename)
            else:
                # For non-previewable files, force download instead
                app.logger.info(f"ðŸ”„ Non-previewable file, redirecting to download: {filename}")
                return download_file_system_attachment(ticket_id, attachment_key)
            
            app.logger.info(f"ðŸ‘€ Previewing file: {filename} as {content_type}")
            
            # For PDFs, read the file and validate it
            if filename.lower().endswith('.pdf'):
                try:
                    with open(full_path, 'rb') as f:
                        file_data = f.read()
                    
                    # Enhanced PDF validation - check multiple possible signatures
                    pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
                    is_valid_pdf = any(file_data.startswith(sig) for sig in pdf_signatures)
                    
                    # Also check for PDF content in the first 1024 bytes (some PDFs have headers)
                    if not is_valid_pdf and len(file_data) > 100:
                        first_kb = file_data[:1024]
                        is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
                    
                    # Log warning but don't reject the file - let browser try to handle it
                    if not is_valid_pdf:
                        app.logger.warning(f"PDF validation failed for preview: {filename}, but serving anyway")
                        app.logger.debug(f"First 100 bytes: {file_data[:100]}")
                        # Don't reject the file - let the browser try to handle it
                        # This prevents false positives from blocking valid PDFs with unusual headers
                    
                    # Create custom response with proper headers
                    response = make_response(file_data)
                    response.headers['Content-Type'] = 'application/pdf'
                    response.headers['Content-Disposition'] = f'inline; filename="{filename}"'
                    response.headers['Content-Length'] = len(file_data)
                    response.headers['Accept-Ranges'] = 'bytes'
                    response.headers['Cache-Control'] = 'public, max-age=3600'
                    response.headers['X-Content-Type-Options'] = 'nosniff'
                    
                    app.logger.info(f"PDF preview response for {filename}: size: {len(file_data)} bytes")
                    return response
                    
                except Exception as e:
                    app.logger.error(f"Error reading PDF file: {e}")
                    return jsonify({'error': 'Failed to read PDF file'}), 500
            
            # For other files, use send_file
            return send_file(
                full_path,
                as_attachment=False,
                download_name=filename,
                mimetype=content_type
            )
        except Exception as e:
            app.logger.error(f"ðŸ’¥ Error serving preview file: {e}")
            return jsonify({'error': 'Failed to serve preview'}), 500
            
    except Exception as e:
        app.logger.error(f"ðŸ’¥ Error previewing file system attachment: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickets/test-n8n', methods=['POST'])
def test_n8n_integration():
    """
    Test endpoint for n8n integration - simulates your real data format
    """
    try:
        # Your real n8n data format for testing
        test_data = [
            {
                "complete": "{\"result\":false,\"fileName\":\"warranty_dashboard_report_20250726_112229.pdf\",\"fileData\":\"JVBERi0xLjQKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUgo+PgplbmRvYmoKMiAwIG9iago8PAovQmFzZUZ4Kc3RhcnR4cmVmCjIyNDcKJSVFT0YK\"}"
            },
            {
                "complete": "{\"threadId\":\"AQQkADAwATM3ZmYBLTljMmQtMmQ5ZS0wMAItMDAKABAA62jpB7tOGUO0IrhdiiKqQg==\",\"name\":\"muhammad zeeshan liaqat\",\"body\":\"The mails\",\"Classification\":\"Others\",\"Priority\":\"Low\",\"ticket_id\":\"706393\",\"from\":\"fa22-bse-061@outlook.com\",\"date\":\"2025-08-07T20:52:53Z\",\"draft\":\"Dear muhammad zeeshan liaqat,\\\\n\\\\nThank you for your message regarding the test emails. We have noted your communication and will keep it on record.\\\\n\\\\nIf you have any specific inquiries or need further assistance, please feel free to reach out.\\\\n\\\\n(Ticket ID: 706393)\\\\n\\\\nSincerely,\\\\nCustomer Services\",\"messageid\":\"AQMkADAwATM3AAAADdI5CgAAAA==\",\"\":\"\"}"
            }
        ]
        
        # Create a test request context and call the main endpoint
        with app.test_request_context('/api/tickets', method='POST', json=test_data):
            response = n8n_tickets_api()
            return response
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Test failed: {str(e)}'
        }), 500

@app.route('/api/tickets/n8n-health', methods=['GET'])
def n8n_health_check():
    """
    Health check endpoint specifically for n8n integration
    """
    try:
        db = get_db()
        db.client.admin.command('ping')
        
        return jsonify({
            'status': 'healthy',
            'n8n_endpoint': '/api/tickets',
            'test_endpoint': '/api/tickets/test-n8n',
            'database': 'connected',
            'upload_folder_exists': os.path.exists(UPLOAD_FOLDER),
            'message': 'N8N integration ready for use',
            'supported_formats': [
                'Direct ticket data with attachments',
                'Array with complete JSON fields (your format)',
                'File upload only'
            ]
        }), 200
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'N8N integration health check failed: {str(e)}'
        }), 500

@app.route('/api/tickets/debug-n8n', methods=['POST'])
def debug_n8n_data():
    """
    Debug endpoint to analyze N8N data structure without creating tickets
    This will help identify why GS5160 is becoming EO5267
    """
    try:
        # Get request data
        raw_data = request.get_data()
        app.logger.info(f"[DEBUG-N8N] Debug endpoint received request: Content-Type={request.content_type}, Size={len(raw_data)}")
        
        # Parse JSON data
        try:
            if request.is_json:
                data = request.get_json()
            else:
                data = json.loads(raw_data.decode('utf-8'))
        except Exception as json_error:
            return jsonify({
                'status': 'error',
                'message': f'Invalid JSON format: {str(json_error)}',
                'raw_data': raw_data.decode('utf-8')[:500] + '...' if len(raw_data) > 500 else raw_data.decode('utf-8')
            }), 400
        
        # Analyze the data structure
        analysis = {
            'data_type': str(type(data)),
            'data_length': len(str(data)),
            'analysis': {}
        }
        
        if isinstance(data, dict):
            analysis['analysis']['top_level'] = {
                'keys': list(data.keys()),
                'has_ticket_id': 'ticket_id' in data,
                'ticket_id_value': data.get('ticket_id', 'NOT_FOUND'),
                'ticket_id_type': str(type(data.get('ticket_id')))
            }
        elif isinstance(data, list):
            analysis['analysis']['array'] = {
                'length': len(data),
                'items': []
            }
            
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    item_analysis = {
                        'index': i,
                        'keys': list(item.keys()),
                        'has_ticket_id': 'ticket_id' in item,
                        'ticket_id_value': item.get('ticket_id', 'NOT_FOUND'),
                        'has_complete': 'complete' in item
                    }
                    
                    if 'complete' in item:
                        try:
                            # Try to parse the complete field
                            clean_json = item['complete'].strip()
                            if clean_json.endswith(',}'):
                                clean_json = clean_json[:-2] + '}'
                            elif clean_json.endswith(',]'):
                                clean_json = clean_json[:-2] + ']'
                            
                            parsed_complete = json.loads(clean_json)
                            item_analysis['complete_parsed'] = {
                                'type': str(type(parsed_complete)),
                                'keys': list(parsed_complete.keys()) if isinstance(parsed_complete, dict) else 'Not a dict',
                                'has_ticket_id': 'ticket_id' in parsed_complete if isinstance(parsed_complete, dict) else 'N/A',
                                'ticket_id_value': parsed_complete.get('ticket_id', 'NOT_FOUND') if isinstance(parsed_complete, dict) else 'N/A'
                            }
                        except Exception as parse_error:
                            item_analysis['complete_parsed'] = {
                                'error': str(parse_error),
                                'raw_content': item['complete'][:200] + '...' if len(item['complete']) > 200 else item['complete']
                            }
                    
                    analysis['analysis']['array']['items'].append(item_analysis)
                else:
                    analysis['analysis']['array']['items'].append({
                        'index': i,
                        'type': str(type(item)),
                        'value': str(item)[:100] + '...' if len(str(item)) > 100 else str(item)
                    })
        
        # Return detailed analysis
        return jsonify({
            'status': 'success',
            'message': 'N8N data structure analyzed',
            'analysis': analysis,
            'recommendation': 'Check the analysis above to see where ticket_id is located in your data structure'
        })
        
    except Exception as e:
        app.logger.error(f"[DEBUG-N8N] Error in debug endpoint: {e}")
        import traceback
        return jsonify({
            'status': 'error',
            'message': f'Debug analysis failed: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/tickets/<ticket_id>/debug', methods=['GET'])
def debug_ticket_data(ticket_id):
    """
    Debug endpoint to check exactly what's stored for a ticket
    """
    try:
        db = get_db()
        
        # Get the ticket
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Get metadata
        metadata = db.get_ticket_metadata(ticket_id)
        
        # Parse the ticket data for debugging
        debug_info = {
            'ticket_id': ticket_id,
            'ticket_found': True,
            'has_attachments_flag': ticket.get('has_attachments', False),
            'total_attachments_count': ticket.get('total_attachments', 0),
            'attachments_in_ticket': ticket.get('attachments', []),
            'attachments_count_in_ticket': len(ticket.get('attachments', [])),
            'metadata_count': len(metadata),
            'metadata_items': []
        }
        
        # Check metadata for attachments
        for item in metadata:
            metadata_item = {
                'key': item['key'],
                'created_at': item.get('created_at', 'unknown')
            }
            
            # Try to parse the value if it's JSON
            try:
                if isinstance(item['value'], str) and item['value'].strip():
                    # Clean the JSON string before parsing
                    clean_value = item['value'].strip()
                    # Remove trailing commas and fix common JSON issues
                    if clean_value.endswith(',}'):
                        clean_value = clean_value[:-2] + '}'
                    elif clean_value.endswith(',]'):
                        clean_value = clean_value[:-2] + ']'
                    # Remove any leading/trailing whitespace and quotes
                    clean_value = clean_value.strip().strip('"\'')
                    # Skip if still empty after cleaning
                    if not clean_value or clean_value in ['{}', '[]', 'null', 'undefined']:
                        metadata_item['raw_value'] = 'empty'
                        metadata_item['is_attachment'] = False
                    else:
                        parsed_value = json.loads(clean_value)
                        metadata_item['parsed_value'] = parsed_value
                        metadata_item['is_attachment'] = 'file_path' in parsed_value or 'filename' in parsed_value
                else:
                    metadata_item['raw_value'] = str(item['value'])
                    metadata_item['is_attachment'] = False
            except json.JSONDecodeError as e:
                # Only log if it's actually malformed, not just empty
                if isinstance(item['value'], str) and item['value'].strip() and item['value'].strip() not in ['{}', '[]', 'null', 'undefined', '']:
                    app.logger.debug(f"JSON parse error in debug endpoint: {e} - Value: {item['value'][:50]}")
                metadata_item['raw_value'] = item['value'][:100] + '...' if len(str(item['value'])) > 100 else str(item['value'])
                metadata_item['is_attachment'] = False
                metadata_item['json_error'] = str(e)
            
            debug_info['metadata_items'].append(metadata_item)
        
        # Check for attachment files in metadata
        attachment_metadata = [item for item in metadata if item['key'].startswith('attachment_') or item['key'] == 'warranty_form']
        debug_info['attachment_metadata_count'] = len(attachment_metadata)
        
        # Check for direct attachments in ticket document
        if 'attachments' in ticket:
            debug_info['direct_attachments_details'] = []
            for i, att in enumerate(ticket['attachments']):
                att_info = {
                    'index': i,
                    'filename': att.get('filename', 'unknown'),
                    'has_data': bool(att.get('data', '')),
                    'data_length': len(att.get('data', '')),
                    'is_warranty': att.get('is_warranty', False),
                    'size': att.get('size', 0)
                }
                debug_info['direct_attachments_details'].append(att_info)
        
        return jsonify(debug_info), 200
        
    except Exception as e:
        return jsonify({
            'error': f'Debug failed: {str(e)}',
            'ticket_id': ticket_id
        }), 500

def process_n8n_item_for_tickets_api(item, item_index):
    """
    Process n8n data item and return the expected format for /api/tickets
    Returns list of items in the format: [attachments..., ticket_data]
    """
    result_items = []
    app.logger.info(f"[DEBUG] Processing n8n item {item_index}: type={type(item)}")
    
    try:
        # Initialize ticket data
        ticket_data = {
            'threadId': '',
            'name': 'Unknown',
            'body': '',
            'Classification': 'Others',
            'Priority': 'Low',
            'ticket_id': f"API{random.randint(100000, 999999)}",
            'from': '',
            'date': datetime.now().isoformat(),
            'draft': '',
            'messageid': ''
        }
        
        # Handle different data structures
        if isinstance(item, dict):
            # Check for direct email data
            if 'from' in item or 'subject' in item or 'body' in item:
                app.logger.info("? Found direct email data")
                ticket_data.update({
                    'threadId': item.get('threadI', item.get('threadId', f"THREAD_{ticket_data['ticket_id']}")),
                    'name': item.get('name', extract_name_from_email(item.get('from', ''))),
                    'subject': item.get('subject', 'No Subject'),  # Fix: Properly extract subject
                    'body': item.get('body', 'No content'),  # Fix: Don't use subject as fallback for body
                    'Classification': item.get('Classification', 'Others'),
                    'Priority': item.get('Priority', 'Low'),
                    'from': item.get('from', ''),
                    'date': item.get('date', datetime.now().isoformat()),
                    'draft': item.get('draft', ''),
                    'messageid': item.get('messageid', '')
                })
                
                # Extract and process attachments
                attachments = item.get('attachments', [])
                if attachments:
                    app.logger.info(f"? Found {len(attachments)} attachments")
                    for att in attachments:
                        if isinstance(att, dict):
                            # Handle different attachment data structures
                            file_name = att.get('fileName', att.get('filename', 'unknown_file'))
                            file_data = att.get('data', att.get('fileData', ''))
                            
                            if file_name and file_data:
                                attachment_item = {
                                    'result': True,
                                    'fileName': file_name,
                                    'fileData': file_data
                                }
                                result_items.append(attachment_item)
                                app.logger.info(f"[SUCCESS] Added attachment: {file_name}")
                            else:
                                app.logger.warning(f"[WARNING] Incomplete attachment data: fileName={file_name}, has_data={bool(file_data)}")
            
            # Check for nested data structures (common in n8n)
            elif 'data' in item:
                app.logger.info("[DEBUG] Found nested data structure")
                nested_data = item['data']
                
                if isinstance(nested_data, list):
                    # Process each item in the nested list
                    for nested_item in nested_data:
                        sub_results = process_n8n_item_for_tickets_api(nested_item, item_index)
                        result_items.extend(sub_results)
                elif isinstance(nested_data, dict):
                    # Process the nested object
                    sub_results = process_n8n_item_for_tickets_api(nested_data, item_index)
                    result_items.extend(sub_results)
                elif isinstance(nested_data, str):
                    # Try to parse as JSON
                    try:
                        # Clean JSON before parsing
                        clean_json = nested_data.strip()
                        if clean_json.endswith(',}'):
                            clean_json = clean_json[:-2] + '}'
                        elif clean_json.endswith(',]'):
                            clean_json = clean_json[:-2] + ']'
                        parsed_data = json.loads(clean_json)
                        sub_results = process_n8n_item_for_tickets_api(parsed_data, item_index)
                        result_items.extend(sub_results)
                    except:
                        app.logger.warning("Failed to parse nested string data as JSON")
            
            # Check for direct attachment data
            elif 'fileName' in item and 'fileData' in item:
                app.logger.info(f"? Found direct attachment: {item['fileName']}")
                attachment_item = {
                    'result': True,
                    'fileName': item['fileName'],
                    'fileData': item['fileData']
                }
                result_items.append(attachment_item)
        
        # If we found attachments, add the ticket data at the end
        if result_items or any(key in str(item) for key in ['from', 'subject', 'body', 'email']):
            result_items.append(ticket_data)
            app.logger.info(f"[SUCCESS] Added ticket data: {ticket_data['ticket_id']}")
        
        return result_items
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error processing n8n item {item_index}: {e}")
        # Return basic structure to prevent failure
        return [{
            'error': str(e),
            'item_index': item_index,
            'ticket_id': f"ERROR{random.randint(100000, 999999)}"
        }]

def extract_name_from_email(email_address):
    """Extract name from email address"""
    if not email_address:
        return 'Unknown'
    
    # Split by @ and take the part before
    local_part = email_address.split('@')[0]
    
    # Replace dots/underscores with spaces and title case
    name = local_part.replace('.', ' ').replace('_', ' ').title()
    
    return name if name else 'Unknown'

@app.route('/api/tickets/simple-test', methods=['POST'])
def simple_test_endpoint():
    """
    ? TEMPORARY TEST ENDPOINT - Works exactly like your simple app (no database)
    This will help us determine if the issue is Vercel caching or database-related
    """
    try:
        # Get raw data first (exactly like simple app)
        raw_data = request.get_data()
        app.logger.info(f"? Simple test endpoint - Raw request data: {raw_data}")
        
        # Try to get JSON data (exactly like simple app)
        try:
            data = request.get_json(force=True)  # Force JSON parsing
            app.logger.info(f"? Simple test - Parsed JSON data: {data}")
        except Exception as json_error:
            app.logger.error(f"? Simple test - JSON parsing error: {json_error}")
            # Try to parse raw data as JSON
            try:
                data = json.loads(raw_data.decode('utf-8'))
                app.logger.info(f"? Simple test - Parsed raw JSON data: {data}")
            except:
                return jsonify({'error': f'Invalid JSON format: {str(json_error)}'}), 400
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # Process the email data using simple app logic (NO DATABASE)
        processed_tickets = process_robust_email_data(data)
        app.logger.info(f"? Simple test - Processed tickets: {len(processed_tickets) if processed_tickets else 0}")
        
        if not processed_tickets:
            # Even if no tickets processed, return success to prevent hanging (like simple app)
            return jsonify({
                'success': True,
                'message': 'Request processed but no valid ticket data found (SIMPLE TEST)',
                'count': 0,
                'tickets': []
            }), 200
        
        # Format response exactly like simple app (NO DATABASE SAVING)
        response_tickets = []
        for ticket in processed_tickets:
            # Don't override ticket_id if it exists from n8n data (like simple app)
            if not ticket.get('ticket_id'):
                ticket['ticket_id'] = f"TEST{datetime.now().strftime('%H%M%S%f')[:-3]}"
            ticket.setdefault('date', datetime.now().isoformat())
            ticket.setdefault('Priority', 'Medium')
            ticket.setdefault('Classification', 'General')
            ticket.setdefault('name', 'Unknown')
            ticket.setdefault('from', '')
            ticket.setdefault('subject', 'No Subject')
            ticket.setdefault('body', '')
            ticket.setdefault('draft', '')
            
            response_tickets.append(ticket)
        
        # Return success response exactly like simple app
        response = jsonify({
            'success': True,
            'message': 'SIMPLE TEST: Tickets processed successfully (NO DATABASE)',
            'count': len(response_tickets),
            'tickets': response_tickets,
            'test_mode': True
        })
        response.status_code = 200
        response.headers['Content-Type'] = 'application/json'
        
        app.logger.info(f"? Simple test - Sending successful response: {len(response_tickets)} tickets")
        return response
        
    except Exception as e:
        app.logger.error(f"? Simple test - Error processing request: {str(e)}")
        import traceback
        app.logger.error(f"? Simple test - Stack trace: {traceback.format_exc()}")
        
        # Ensure we always return a response to prevent hanging (like simple app)
        error_response = jsonify({
            'success': True,  # Return success even on error to prevent n8n hanging
            'error': f'Simple test server error: {str(e)}',
            'message': 'SIMPLE TEST: Request failed but acknowledged (NO DATABASE)',
            'test_mode': True
        })
        error_response.status_code = 200  # Return 200 even on error
        error_response.headers['Content-Type'] = 'application/json'
        return error_response

def detect_warranty_form(filename, file_data=None):
    """
    Detect if attachment is a warranty form based on filename or content
    """
    warranty_keywords = ['warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante']
    filename_lower = filename.lower()
    
    for keyword in warranty_keywords:
        if keyword in filename_lower:
            return True
    
    # Additional logic can be added here to analyze file content
    return False

def process_robust_email_data(data):
    """
    Robust email data processing logic adapted from the working simple app
    """
    processed_tickets = []
    attachments_list = []
    main_ticket = None
    warranty_detected = False
    
    app.logger.info(f"[DEBUG] Processing robust email data: {type(data)}")
    app.logger.info(f"[DEBUG] DEBUG: Data content preview: {str(data)[:200]}...")
    
    # Handle case where data is a list
    if isinstance(data, list):
        app.logger.info(f"[DEBUG] DEBUG: Processing {len(data)} items in list")
        for i, item in enumerate(data):
            if isinstance(item, dict):
                # Check if this item has attachment data
                if 'data' in item and isinstance(item['data'], list):
                    # This is the attachments route data
                    for att_data in item['data']:
                        if isinstance(att_data, dict):
                            if 'data' in att_data and isinstance(att_data['data'], str):
                                # Parse JSON string data
                                try:
                                    parsed_att = json.loads(att_data['data'])
                                    if 'fileName' in parsed_att:
                                        attachments_list.append(parsed_att)
                                        # Check for warranty form
                                        if detect_warranty_form(parsed_att['fileName']):
                                            warranty_detected = True
                                except json.JSONDecodeError as e:
                                    app.logger.warning(f"JSON decode error in attachment: {e}")
                            elif 'fileName' in att_data:
                                # Direct attachment data
                                attachments_list.append(att_data)
                                if detect_warranty_form(att_data['fileName']):
                                    warranty_detected = True
                
                # Check if this is main ticket data (text route)
                elif 'ticket_id' in item or 'threadI' in item or 'body' in item:
                    main_ticket = item
                    
                # Check if item has direct data field with JSON
                elif 'data' in item and isinstance(item['data'], str):
                    try:
                        parsed_data = json.loads(item['data'])
                        if 'fileName' in parsed_data:
                            attachments_list.append(parsed_data)
                            if detect_warranty_form(parsed_data['fileName']):
                                warranty_detected = True
                        else:
                            main_ticket = parsed_data
                    except json.JSONDecodeError:
                        pass
                
                # [FIX] CRITICAL FIX: Check for flat attachment structure BEFORE treating as main ticket
                elif 'fileName' in item and 'fileData' in item:
                    # This is a flat attachment structure
                    app.logger.info(f"[TARGET] DEBUG: FLAT ATTACHMENT DETECTED! fileName: {item['fileName']}")
                    attachments_list.append(item)
                    if detect_warranty_form(item['fileName']):
                        warranty_detected = True
                        app.logger.info(f"Warranty detected in flat attachment: {item['fileName']}")
                    app.logger.info(f"Detected flat attachment: {item['fileName']}")
                        
                # Direct ticket data without nesting (fallback)
                else:
                    if not main_ticket:  # Only set if we don't have one yet
                        main_ticket = item
    else:
        # Single item case
        if isinstance(data, dict):
            if 'ticket_id' in data or 'threadI' in data or 'body' in data:
                main_ticket = data
    
    # Combine main ticket with attachments
    app.logger.info(f"[TARGET] DEBUG: Final processing results - Attachments found: {len(attachments_list)}, Main ticket: {main_ticket is not None}")
    if main_ticket:
        combined_ticket = main_ticket.copy()
        combined_ticket['attachments'] = []
        combined_ticket['has_attachments'] = len(attachments_list) > 0
        combined_ticket['has_warranty'] = warranty_detected
        app.logger.info(f"[TARGET] DEBUG: Setting has_attachments to: {combined_ticket['has_attachments']}")
        
        for att in attachments_list:
            attachment = {
                'filename': att.get('fileName', 'unknown_file'),
                'data': att.get('fileData', ''),
                'is_warranty': detect_warranty_form(att.get('fileName', '')),
                'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0
            }
            combined_ticket['attachments'].append(attachment)
        
        processed_tickets.append(combined_ticket)
    
    # If we have attachments but no main ticket, create a basic ticket
    elif attachments_list:
        for att in attachments_list:
            ticket = {
                'ticket_id': att.get('ticketNo', att.get('ticket_id', 'UNKNOWN')),
                'name': 'Unknown',
                'from': att.get('from', ''),
                'subject': att.get('subject', 'Attachment Only'),
                'body': f"Ticket created from attachment: {att.get('fileName', 'unknown')}",
                'date': datetime.now().isoformat(),
                'priority': 'Medium',
                'classification': 'General',
                'attachments': [{
                    'filename': att.get('fileName', 'unknown_file'),
                    'data': att.get('fileData', ''),
                    'is_warranty': detect_warranty_form(att.get('fileName', '')),
                    'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0
                }],
                'has_attachments': True,
                'has_warranty': detect_warranty_form(att.get('fileName', ''))
            }
            processed_tickets.append(ticket)
    
    return processed_tickets

def process_enhanced_email_ticket(raw_data):
    """Process enhanced email data from n8n with warranty detection"""
    try:
        # Test database connection first
        try:
            db = get_db()
        except ValueError as db_error:
            if "MONGODB_URI environment variable is required" in str(db_error):
                app.logger.error("[ERROR] Database configuration error: MONGODB_URI environment variable not set")
                return jsonify({
                    'status': 'error',
                    'error_type': 'DatabaseConfigurationError',
                    'message': 'Database connection failed. Please check server configuration.',
                    'details': 'MONGODB_URI environment variable is required'
                }), 500
            else:
                raise db_error
        except Exception as db_error:
            app.logger.error(f"[ERROR] Database connection failed: {str(db_error)}")
            return jsonify({
                'status': 'error',
                'error_type': 'DatabaseConnectionError',
                'message': 'Database connection failed. Please try again later.'
            }), 500
        
        # Use robust email processing adapted from working simple app
        processed_tickets = process_robust_email_data(raw_data)
        
        if not processed_tickets:
            return jsonify({
                'status': 'warning',
                'message': 'No valid ticket data found in email',
                'count': 0,
                'tickets': []
            }), 200
        
        created_tickets = []
        
        for ticket_data in processed_tickets:
            # [FIX] Use n8n provided ticket_id if available, otherwise generate one
            n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
            
            if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                # Use n8n provided ticket ID if it doesn't exist in database
                ticket_id = n8n_ticket_id
                app.logger.info(f"[ENHANCED_EMAIL] Using n8n provided ticket ID: {ticket_id}")
                
                # Prepare enhanced ticket data
                enhanced_ticket = {
                    'ticket_id': ticket_id,
                    'name': ticket_data.get('name', 'Unknown'),
                    'email': ticket_data.get('from', ''),
                    'subject': ticket_data.get('subject', 'Email Ticket'),
                    'body': ticket_data.get('body', ''),
                    'priority': ticket_data.get('Priority', 'High' if ticket_data.get('has_warranty') else 'Medium'),
                    'classification': 'Warranty Claim' if ticket_data.get('has_warranty') else ticket_data.get('Classification', 'General'),
                    'status': 'New',
                    'creation_method': 'email',
                    
                    # Enhanced warranty & attachment data
                    'has_warranty': ticket_data.get('has_warranty', False),
                    'has_attachments': ticket_data.get('has_attachments', False),
                    'warranty_forms_count': ticket_data.get('warranty_forms_count', 0),
                    'total_attachments': ticket_data.get('total_attachments', 0),
                    'attachment_total_size': ticket_data.get('attachment_total_size', 0),
                    'processing_method': ticket_data.get('processing_method', 'enhanced_email_processor'),
                    'attachments': ticket_data.get('attachments', []),
                    
                    # Threading data - Generate completely unique thread_id to prevent attachment collisions
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                    'message_id': ticket_data.get('messageid', ''),
                    'processed_at': datetime.now().isoformat()
                }
                
                try:
                    # Create in database
                    db.create_ticket(enhanced_ticket)
                    app.logger.info(f"[SUCCESS] Enhanced email ticket created using n8n ID: {ticket_id} | Warranty: {enhanced_ticket['has_warranty']} | Attachments: {enhanced_ticket['total_attachments']}")
                    
                    created_tickets.append({
                        'ticket_id': ticket_id,
                        'has_warranty': enhanced_ticket['has_warranty'],
                        'warranty_forms_count': enhanced_ticket['warranty_forms_count'],
                        'has_attachments': enhanced_ticket['has_attachments'],
                        'total_attachments': enhanced_ticket['total_attachments'],
                        'priority': enhanced_ticket['priority']
                    })
                except ValueError as e:
                    app.logger.error(f"Failed to create enhanced email ticket with n8n ID {ticket_id}: {e}")
            else:
                # Generate unique ticket ID with enhanced collision protection as fallback
                timestamp = datetime.now()
                base_prefix = "EMAIL"  # Changed from "OL" to be more specific
                
                base_ticket_id = f"{base_prefix}{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                
                max_attempts = 20  # Increased attempts for busy periods
                ticket_id = None
                
                if n8n_ticket_id:
                    app.logger.warning(f"[ENHANCED_EMAIL] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                else:
                    app.logger.info(f"[ENHANCED_EMAIL] No n8n ticket ID provided, generating new ID")
                
                for attempt in range(max_attempts):
                    potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                    
                    try:
                        # Prepare enhanced ticket data
                        enhanced_ticket = {
                            'ticket_id': potential_id,
                            'name': ticket_data.get('name', 'Unknown'),
                            'email': ticket_data.get('from', ''),
                            'subject': ticket_data.get('subject', 'Email Ticket'),
                            'body': ticket_data.get('body', ''),
                            'priority': ticket_data.get('Priority', 'High' if ticket_data.get('has_warranty') else 'Medium'),
                            'classification': 'Warranty Claim' if ticket_data.get('has_warranty') else ticket_data.get('Classification', 'General'),
                            'status': 'New',
                            'creation_method': 'email',
                            
                            # Enhanced warranty & attachment data
                            'has_warranty': ticket_data.get('has_warranty', False),
                            'has_attachments': ticket_data.get('has_attachments', False),
                            'warranty_forms_count': ticket_data.get('warranty_forms_count', 0),
                            'total_attachments': ticket_data.get('total_attachments', 0),
                            'attachment_total_size': ticket_data.get('attachment_total_size', 0),
                            'processing_method': ticket_data.get('processing_method', 'enhanced_email_processor'),
                            'attachments': ticket_data.get('attachments', []),
                            
                            # Threading data - Generate completely unique thread_id to prevent attachment collisions
                            'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                            'message_id': ticket_data.get('messageid', ''),
                            'processed_at': datetime.now().isoformat()
                        }
                        
                        # Log warranty classification for debugging
                        if enhanced_ticket.get('has_warranty'):
                            app.logger.info(f" ENHANCED EMAIL WARRANTY: Ticket {potential_id} created with classification '{enhanced_ticket['classification']}' (has_warranty: {enhanced_ticket.get('has_warranty')})")
                        
                        # Create in database
                        db.create_ticket(enhanced_ticket)
                        ticket_id = potential_id
                        
                        # Log successful creation
                        app.logger.info(f"[SUCCESS] Email ticket created: {ticket_id} | Warranty: {enhanced_ticket['has_warranty']} | Attachments: {enhanced_ticket['total_attachments']}")
                        
                        created_tickets.append({
                            'ticket_id': ticket_id,
                            'has_warranty': enhanced_ticket['has_warranty'],
                            'warranty_forms_count': enhanced_ticket['warranty_forms_count'],
                            'has_attachments': enhanced_ticket['has_attachments'],
                            'total_attachments': enhanced_ticket['total_attachments'],
                            'priority': enhanced_ticket['priority']
                        })
                        break
                        
                    except ValueError as e:
                        if "Ticket ID already exists" in str(e):
                            app.logger.debug(f"[RETRY] Email ticket ID collision: {potential_id}, retrying (attempt {attempt + 1})")
                            continue
                        else:
                            raise e
            
            if not ticket_id:
                app.logger.error(f"[ERROR] Failed to generate unique ticket ID after {max_attempts} attempts")
                return jsonify({
                    'status': 'error',
                    'message': 'Failed to generate unique ticket ID. Please try again.'
                }), 500
        
        return jsonify({
            'status': 'success',
            'message': f'Successfully created {len(created_tickets)} email ticket(s) with enhanced processing',
            'count': len(created_tickets),
            'tickets': created_tickets,
            'warranty_forms_detected': sum(1 for t in created_tickets if t['has_warranty']),
            'total_attachments': sum(t['total_attachments'] for t in created_tickets)
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] Enhanced email processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Email processing failed: {str(e)}'
        }), 500

def process_simple_json_ticket(data):
    """Process simple JSON ticket data"""
    try:
        # Test database connection first
        try:
            db = get_db()
        except ValueError as db_error:
            if "MONGODB_URI environment variable is required" in str(db_error):
                app.logger.error("[ERROR] Database configuration error: MONGODB_URI environment variable not set")
                return jsonify({
                    'status': 'error',
                    'error_type': 'DatabaseConfigurationError',
                    'message': 'Database connection failed. Please check server configuration.',
                    'details': 'MONGODB_URI environment variable is required'
                }), 500
            else:
                raise db_error
        except Exception as db_error:
            app.logger.error(f"[ERROR] Database connection failed: {str(db_error)}")
            return jsonify({
                'status': 'error',
                'error_type': 'DatabaseConnectionError',
                'message': 'Database connection failed. Please try again later.'
            }), 500
        
        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
        n8n_ticket_id = data.get('ticket_id', '').strip() if isinstance(data, dict) else ''
        
        if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
            # Use n8n provided ticket ID if it doesn't exist in database
            ticket_id = n8n_ticket_id
            app.logger.info(f"[JSAPI_PROCESS] Using n8n provided ticket ID: {ticket_id}")
            
            try:
                # Create basic ticket with unique thread_id (CRITICAL FIX for attachment collisions)
                ticket = {
                    'ticket_id': ticket_id,
                    'name': data.get('name', 'Unknown'),
                    'email': data.get('email', ''),
                    'subject': data.get('subject', 'API Ticket'),
                    'body': data.get('body', ''),
                    'priority': data.get('priority', 'Medium'),
                    'classification': data.get('classification', 'General'),
                    'status': 'New',
                    'creation_method': 'simple_json_api',
                    'has_warranty': False,
                    'has_attachments': False,
                    'warranty_forms_count': 0,
                    'total_attachments': 0,
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"  # CRITICAL: Added missing thread_id
                }
                
                db.create_ticket(ticket)
                app.logger.info(f"[SUCCESS] Simple JSON ticket created using n8n ID: {ticket_id}")
                
            except ValueError as e:
                app.logger.error(f"Failed to create simple JSON ticket with n8n ID {ticket_id}: {e}")
                # Fall through to generate new ID
                ticket_id = None
        
        if not ticket_id:
            # Generate collision-resistant ticket ID as fallback
            timestamp = datetime.now()
            base_id = f"JSAPI{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
            
            # Collision protection loop
            max_attempts = 20
            
            if n8n_ticket_id:
                app.logger.warning(f"[JSAPI_PROCESS] N8N ticket ID {n8n_ticket_id} already exists or failed, generating new ID")
            else:
                app.logger.info(f"[JSAPI_PROCESS] No n8n ticket ID provided, generating new ID")
            
            for attempt in range(max_attempts):
                potential_id = f"{base_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                
                try:
                    # Create basic ticket with unique thread_id
                    ticket = {
                        'ticket_id': potential_id,
                        'name': data.get('name', 'Unknown'),
                        'email': data.get('email', ''),
                        'subject': data.get('subject', 'API Ticket'),
                        'body': data.get('body', ''),
                        'priority': data.get('priority', 'Medium'),
                        'classification': data.get('classification', 'General'),
                        'status': 'New',
                        'creation_method': 'simple_json_api',
                        'has_warranty': False,
                        'has_attachments': False,
                        'warranty_forms_count': 0,
                        'total_attachments': 0,
                        'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                    }
                    
                    db.create_ticket(ticket)
                    ticket_id = potential_id
                    break
                    
                except ValueError as e:
                    if "Ticket ID already exists" in str(e):
                        app.logger.debug(f"[RETRY] Simple JSON ticket ID collision: {potential_id}, retrying (attempt {attempt + 1})")
                        continue
                    else:
                        raise e
        
        if not ticket_id:
            app.logger.error(f"[ERROR] Failed to generate unique simple JSON ticket ID after {max_attempts} attempts")
            return jsonify({
                'status': 'error',
                'message': 'Failed to generate unique ticket ID. Please try again.'
            }), 500
        
        app.logger.info(f"[SUCCESS] Simple JSON ticket created: {ticket_id}")
        
        return jsonify({
            'status': 'success',
            'message': 'Simple JSON ticket created successfully',
            'ticket_id': ticket_id,
            'creation_method': 'simple_json_api'
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] Simple JSON processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Ticket creation failed: {str(e)}'
        }), 500

def process_manual_form_ticket():
    """Process manual form data from UI (redirect to existing create endpoint)"""
    app.logger.info("[RETRY] Redirecting manual form to existing /api/tickets/create endpoint")
    return api_create_ticket()

@app.route('/api/tickets/n8n-create', methods=['POST'])
def n8n_create_ticket():
    """Dedicated endpoint for n8n ticket creation without authentication - WITH DATABASE"""
    app.logger.info("? N8N dedicated endpoint called - processing WITH database (fixed thread_id)")
    return process_n8n_form_ticket()

def process_n8n_form_ticket():
    """Process form data from n8n without authentication requirements"""
    try:
        # Test database connection first
        try:
            db = get_db()
            # Test database connectivity with a simple operation
            test_count = db.tickets.count_documents({})
            app.logger.info(f"?? Database connection successful for n8n form. Current ticket count: {test_count}")
        except Exception as db_error:
            app.logger.error(f"[ERROR] CRITICAL: Database connection failed for n8n form: {db_error}")
            return jsonify({
                'status': 'error',
                'message': 'Database connection failed. Please try again later.',
                'error_type': 'DatabaseConnectionError'
            }), 500
        
        app.logger.info("? Processing n8n form data without authentication")
        
        # Extract form data (similar to manual processing but without auth)
        name = request.form.get('name', request.form.get('customer_name', 'Unknown')).strip()
        email = request.form.get('email', request.form.get('from', '')).strip()
        subject = request.form.get('subject', 'N8N Form Ticket').strip()
        body = request.form.get('body', request.form.get('message', '')).strip()
        priority = request.form.get('priority', 'Medium').strip()
        classification = request.form.get('classification', 'General').strip()
        
        app.logger.info(f"[NOTE] N8N Form Data: name='{name}', email='{email}', subject='{subject[:50]}...'")
        
        # Check for warranty indicators in form data
        has_warranty = False
        warranty_keywords = ['warranty', 'guarantee', 'claim', 'dpf', 'emission', 'defect']
        search_text = f"{subject} {body}".lower()
        
        for keyword in warranty_keywords:
            if keyword in search_text:
                has_warranty = True
                break
        
        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
        # Upgrade classification for warranty claims
        final_classification = 'Warranty Claim' if has_warranty else classification
        
        if has_warranty:
            app.logger.info(f" WARRANTY EMAIL DETECTED: Setting classification from '{classification}' to 'Warranty Claim' for {name} ({email})")
        
        # Check for n8n provided ticket_id first
        n8n_ticket_id = request.form.get('ticket_id', '').strip()
        
        if n8n_ticket_id:
            # Use n8n ticket ID EXACTLY as provided (no formatting, no prefixes)
            if not db.ticket_id_exists(n8n_ticket_id):
                # Use n8n ticket ID exactly as-is
                ticket_id = n8n_ticket_id
                app.logger.info(f"[N8N_FORM] Using n8n ticket ID exactly as provided: {ticket_id}")
            else:
                # If n8n ticket ID already exists, append a suffix to make it unique
                # This preserves the n8n ID while ensuring uniqueness
                suffix = 1
                while True:
                    unique_ticket_id = f"{n8n_ticket_id}_{suffix}"
                    if not db.ticket_id_exists(unique_ticket_id):
                        ticket_id = unique_ticket_id
                        app.logger.info(f"[N8N_FORM] N8N ticket ID {n8n_ticket_id} already exists, using unique variant: {ticket_id}")
                        break
                    suffix += 1
                    if suffix > 999:  # Prevent infinite loops
                        app.logger.error(f"[N8N_FORM] Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
                        raise Exception(f"Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
        else:
            # No n8n ticket ID provided, generate new one
            app.logger.info(f"[N8N_FORM] No n8n ticket ID provided, generating new ID")
            ticket_id = generate_email_ticket_id(email, name, final_classification, db)
        
        # Generate unique thread_id to prevent attachment collisions
        thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
        
        app.logger.info(f"[SUCCESS] Using ticket ID: {ticket_id}")
        
        # Create ticket data
        ticket_data = {
            'ticket_id': ticket_id,
            'name': name,
            'email': email,
            'subject': subject,
            'body': body,
            'draft_body': '',  # Will be generated below
            'priority': 'High' if has_warranty else priority,
            'classification': final_classification,
            'status': 'New',
            'creation_method': 'n8n_form',
            'has_warranty': has_warranty,
            'has_attachments': False,  # Form data typically doesn't have attachments
            'warranty_forms_count': 1 if has_warranty else 0,
            'total_attachments': 0,
            'processing_method': 'n8n_form_processor',
            'thread_id': thread_id
        }
        
        # ðŸš€ GENERATE SMART DRAFT RESPONSE for N8N form tickets
        app.logger.info(f"ðŸ¤– GENERATING SMART DRAFT for N8N form ticket {ticket_id}")
        app.logger.info(f"ðŸ” DEBUG: ticket_data['ticket_id'] = {ticket_data.get('ticket_id')} (should be formatted like EO980494)")
        draft_response = generate_email_draft_response(ticket_data)
        ticket_data['draft_body'] = draft_response
        app.logger.info(f"ðŸ“ DRAFT GENERATED: {draft_response[:200]}..." if len(draft_response) > 200 else f"ðŸ“ DRAFT GENERATED: {draft_response}")
        app.logger.info(f" SMART DRAFT GENERATED for N8N form ticket {ticket_id} - Length: {len(draft_response)} chars")
        
        # Create ticket (collision protection is handled by generate_email_ticket_id)
        db.create_ticket(ticket_data)
        app.logger.info(f"[SUCCESS] N8N form ticket created: {ticket_id} | Warranty: {has_warranty} | Priority: {ticket_data['priority']}")
        
        # Success - return result
        return jsonify({
            'status': 'success',
            'message': 'N8N form ticket created successfully',
            'ticket_id': ticket_id,
            'has_warranty': has_warranty
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] N8N form processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'N8N form ticket creation failed: {str(e)}'
        }), 500

@app.route('/api/tickets/create', methods=['POST'])
def api_create_ticket():
    """
    Create a ticket with new structured fields and attachments
    """
    app.logger.info("=== STARTING TICKET CREATION ===")
    app.logger.info(f"Request method: {request.method}")
    app.logger.info(f"Request form data: {dict(request.form)}")
    app.logger.info(f"Request files: {dict(request.files)}")
    app.logger.info(f"Request files keys: {list(request.files.keys())}")
    app.logger.info(f"Session data: {dict(session)}")
    
    """
    
    TICKET NUMBERING SYSTEM (All tickets are 6 characters):
    - Manual tickets: M{type}{4 random} (e.g., MP1A2B for Premium DPF, MK3F8E for Workshop)
    - Email tickets: {class}{priority}{4 random} (e.g., TM3F8E for Technical Medium, XU9A2B for Spam Urgent)
    - Warranty tickets: W{5 random} (e.g., W7K9L2)
    
    Type codes for manual tickets:
    - P = DPF Clean - Premium
    - S = DPF Clean - Standard  
    - J = Part Job
    - O = Other
    - K = Workshop Job (worKshop)
    
    Duplicate checking ensures unique ticket IDs across all types.
    """
    # Check if this is an unauthenticated request
    if 'member_id' not in session:
        # Process dynamic email JSON instead of redirecting to form handler
        app.logger.info("? Unauthenticated request to /api/tickets/create - processing dynamic email JSON")
        try:
            incoming_data = request.get_json(silent=True)
            if incoming_data is None and 'data' in request.form:
                try:
                    incoming_data = json.loads(request.form.get('data', '{}'))
                except Exception:
                    incoming_data = None

            # If incoming_data is a list, try to find a dict with typical email keys
            if isinstance(incoming_data, list):
                candidate = None
                for item in incoming_data:
                    if isinstance(item, dict) and (('body' in item) or ('from' in item) or ('subject' in item) or ('ticket_id' in item)):
                        candidate = item
                        break
                incoming_data = candidate if candidate else (incoming_data[0] if incoming_data else None)

            if isinstance(incoming_data, dict):
                ticket_data = process_n8n_ticket_data(incoming_data)
                if ticket_data:
                    # Ensure required fields for DB insert
                    if 'thread_id' not in ticket_data or not ticket_data.get('thread_id'):
                        ticket_data['thread_id'] = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                    ticket_data['status'] = ticket_data.get('status', 'New')
                    ticket_data['creation_method'] = ticket_data.get('creation_method', 'email_ingest')

                    # Generate draft response if not present
                    try:
                        if not ticket_data.get('draft_body'):
                            draft_response = generate_email_draft_response(ticket_data)
                            ticket_data['draft_body'] = draft_response
                    except Exception as draft_err:
                        app.logger.error(f"[ERROR] Failed generating draft response: {draft_err}")

                    # Persist ticket
                    try:
                        db = get_db()
                        db.create_ticket(ticket_data)
                        app.logger.info(f"[SUCCESS] Email JSON ticket created: {ticket_data.get('ticket_id')}")
                        return jsonify({
                            'status': 'success',
                            'message': 'Email JSON ticket created successfully',
                            'ticket_id': ticket_data.get('ticket_id'),
                            'creation_method': ticket_data.get('creation_method')
                        }), 200
                    except Exception as db_err:
                        app.logger.error(f"[ERROR] Failed to create email JSON ticket: {db_err}")
                        return jsonify({'status': 'error', 'message': 'Failed to create ticket from email JSON'}), 500

            # If we reach here, we couldn't parse dynamic data; fail rather than creating default form ticket
            return jsonify({'status': 'error', 'message': 'No valid email JSON provided for unauthenticated request'}), 400
        except Exception as e:
            app.logger.error(f"[ERROR] Unauthenticated email JSON processing failed: {e}")
            return jsonify({'status': 'error', 'message': 'Unauthenticated email JSON processing failed'}), 500
    
    try:
        # Extract required form data
        customer_title = request.form.get('customer_title', '').strip()
        customer_first_name = request.form.get('customer_first_name', '').strip()
        customer_surname = request.form.get('customer_surname', '').strip()
        email = request.form.get('email', '').strip()
        vehicle_registration = request.form.get('vehicle_registration', '').strip().upper()
        type_of_claim = request.form.get('type_of_claim', '').strip()
        priority = request.form.get('priority', '').strip()
        technician = request.form.get('technician', '').strip()
        subject = request.form.get('subject', '').strip()
        description = request.form.get('description', '').strip()
        service_date = request.form.get('service_date', '').strip()
        claim_date = request.form.get('claim_date', '').strip()
        vhc_link = request.form.get('vhc_link', '').strip()
        
        # Validate required fields
        required_fields = {
            'customer_title': customer_title,
            'customer_first_name': customer_first_name,
            'customer_surname': customer_surname,
            'email': email,
            'vehicle_registration': vehicle_registration,
            'type_of_claim': type_of_claim,
            'priority': priority,
            'technician': technician,
            'subject': subject,
            'description': description,
            'service_date': service_date,
            'claim_date': claim_date
        }
        
        for field_name, field_value in required_fields.items():
            if not field_value:
                return jsonify({'status': 'error', 'message': f'Missing required field: {field_name.replace("_", " ").title()}'}), 400
        
        # Validate email format
        if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
            return jsonify({'status': 'error', 'message': 'Invalid email format'}), 400
        
        # Validate dates
        try:
            service_date_obj = datetime.strptime(service_date, '%Y-%m-%d')
            claim_date_obj = datetime.strptime(claim_date, '%Y-%m-%d')
            if claim_date_obj < service_date_obj:
                return jsonify({'status': 'error', 'message': 'Claim date cannot be before service date'}), 400
        except ValueError:
            return jsonify({'status': 'error', 'message': 'Invalid date format'}), 400
        
        # Create combined customer name for compatibility
        customer_full_name = f"{customer_title} {customer_first_name} {customer_surname}"
        
        # Connect to database early (needed for duplicate checking)
        try:
            db = get_db()
            # Test database connectivity
            test_count = db.tickets.count_documents({})
            app.logger.info(f"?? Database connection successful. Current ticket count: {test_count}")
        except Exception as db_error:
            app.logger.error(f"[ERROR] CRITICAL: Database connection failed: {db_error}")
            return jsonify({
                'status': 'error',
                'message': 'Database connection failed. Please try again later.',
                'error_type': 'DatabaseConnectionError'
            }), 500
        
        # Generate automatic ticket ID for manual tickets (6 chars total: M + type + 4 random)
        type_code_mapping = {
            'DPF Clean - Premium': 'P',  # Premium
            'DPF Clean-Standard': 'S',   # Standard
            'Part Job': 'J',             # Job
            'Other': 'O',                # Other
            'Workshop Job': 'K'          # worKshop (changed from 'W' to avoid conflict with Warranty tickets)
        }
        
        type_code = type_code_mapping.get(type_of_claim, 'O')
        
        # Generate unique ticket ID with improved collision detection
        import random
        import string
        import time
        import uuid
        
        ticket_id = None
        max_attempts = 100
        
        # Log current ticket statistics for debugging
        try:
            manual_ticket_count = db.tickets.count_documents({'ticket_id': {'$regex': f'^M{type_code}'}})
            total_ticket_count = db.tickets.count_documents({})
            app.logger.info(f"Current database state: {total_ticket_count} total tickets, {manual_ticket_count} with prefix M{type_code}")
        except Exception as e:
            app.logger.warning(f"Could not get ticket statistics: {e}")
        
        for attempt in range(max_attempts):
            try:
                # Generate 4-digit code using same logic as email tickets (deterministic based on customer data)
                # Use customer email + timestamp to create unique seed for calculation
                seed_string = f"{email}{customer_full_name}{datetime.now().isoformat()}"
                
                # Calculate sum of character codes (same logic as email system)
                sum_chars = 0
                for char in seed_string:
                    sum_chars += ord(char)
                
                # Generate 4-digit number (same as email system: sum % 10000)
                four_digit_code = sum_chars % 10000
                four_digit_str = f"{four_digit_code:04d}"  # Ensure 4 digits with leading zeros
                
                potential_id = f"M{type_code}{four_digit_str}"  # Exactly 6 chars: M + 1 + 4 digits
                
                app.logger.info(f"Attempting ticket ID: {potential_id} (attempt {attempt + 1}/{max_attempts})")
                app.logger.debug(f"? Calculation details: seed='{seed_string[:50]}...', sum_chars={sum_chars}, 4-digit={four_digit_code}")
                
                # Use dedicated ticket_id_exists method for faster checking
                app.logger.debug(f"[DEBUG] Checking if ticket ID {potential_id} exists...")
                
                try:
                    exists = db.ticket_id_exists(potential_id)
                    app.logger.debug(f"[SUCCESS] Database check complete: {potential_id} exists = {exists}")
                except Exception as db_check_error:
                    app.logger.error(f"[ERROR] Database check failed for {potential_id}: {db_check_error}")
                    # On database connectivity issues, wait briefly and retry the same ID
                    import time
                    time.sleep(0.1)  # Brief pause to allow for database recovery
                    try:
                        # Retry the database check once more
                        exists = db.ticket_id_exists(potential_id)
                        app.logger.info(f"[SUCCESS] Database check retry successful: {potential_id} exists = {exists}")
                    except Exception as retry_error:
                        app.logger.error(f"[ERROR] Database check retry also failed: {retry_error}")
                        # Skip this attempt and try the next ID
                        continue
                
                if not exists:
                    # ID is unique, create the ticket
                    # Generate unique thread_id for manual tickets (required due to unique index)
                    # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
                    thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                    
                    ticket_data = {
                        'ticket_id': potential_id,
                        'email': email,
                        'name': customer_full_name,
                        'subject': subject,
                        'body': description,
                        'status': 'Open',
                        'priority': priority,
                        'classification': type_of_claim,
                        'technician': technician,
                        'vehicle_registration': vehicle_registration,
                        'service_date': service_date,
                        'claim_date': claim_date,
                        'creation_method': 'manual',
                        'thread_id': thread_id,  # CRITICAL: Must be unique due to database constraint
                        'created_at': datetime.now(),
                        'updated_at': datetime.now()
                    }
                    
                    # Add created_by only if we have a session
                    if session.get('member_id'):
                        ticket_data['created_by'] = session.get('member_id')
                    
                    try:
                        app.logger.debug(f"? Attempting to create ticket with ID {potential_id}, thread_id {thread_id}")
                        result = db.create_ticket(ticket_data)
                        ticket_id = potential_id
                        app.logger.info(f"[SUCCESS] Successfully created manual ticket with ID: {ticket_id} on attempt {attempt + 1}")
                        app.logger.info(f"? Ticket data: email={email}, name={customer_full_name[:20]}..., thread_id={thread_id}")
                        break
                        
                    except ValueError as e:
                        error_str = str(e)
                        if "Ticket ID already exists" in error_str:
                            app.logger.warning(f"[WARNING] Race condition detected for ticket ID {potential_id}, retrying (attempt {attempt + 1})")
                            continue  # Race condition, try again
                        elif "Thread ID already exists" in error_str:
                            app.logger.warning(f"[WARNING] Thread ID collision detected, generating new thread_id and retrying (attempt {attempt + 1})")
                            # Generate a new thread_id and try again with the same ticket_id
                            # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
                            thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                            continue
                        else:
                            # Different ValueError, log and re-raise
                            app.logger.error(f"[ERROR] ValueError creating ticket {potential_id}: {e}")
                            raise e
                    except Exception as e:
                        app.logger.error(f"[ERROR] Unexpected error creating ticket with ID {potential_id}: {e}")
                        app.logger.error(f"[DEBUG] Full error details: {type(e).__name__}: {str(e)}")
                        import traceback
                        app.logger.error(f"? Stack trace: {traceback.format_exc()}")
                        raise e
                else:
                    # ID already exists
                    app.logger.debug(f"[RETRY] Ticket ID {potential_id} already exists, retrying (attempt {attempt + 1})")
                    continue
                        
            except Exception as e:
                app.logger.error(f"[ERROR] Error during ticket ID generation attempt {attempt + 1}: {str(e)}")
                continue
        
        if not ticket_id:
            # Last resort: Try fallback ID generation with UUID
            app.logger.warning(f"[WARNING] Primary ID generation failed, attempting fallback method...")
            
            fallback_attempts = 5
            for fallback_attempt in range(fallback_attempts):
                try:
                    # Generate a completely different style ID using UUID
                    import uuid
                    short_uuid = str(uuid.uuid4()).replace('-', '')[:8].upper()
                    fallback_id = f"M{type_code}{short_uuid}"[:12]  # Limit to 12 chars max
                    
                    app.logger.info(f"? Fallback attempt {fallback_attempt + 1}: trying ID {fallback_id}")
                    
                    # Check if this fallback ID exists
                    try:
                        exists = db.ticket_id_exists(fallback_id)
                        if not exists:
                            # Create ticket with fallback ID
                            # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
                            thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                            ticket_data = {
                                'ticket_id': fallback_id,
                                'email': email,
                                'name': customer_full_name,
                                'subject': subject,
                                'body': description,
                                'status': 'Open',
                                'priority': priority,
                                'classification': type_of_claim,
                                'technician': technician,
                                'vehicle_registration': vehicle_registration,
                                'service_date': service_date,
                                'claim_date': claim_date,
                                'creation_method': 'manual_fallback',
                                'thread_id': thread_id,
                                'created_at': datetime.now(),
                                'updated_at': datetime.now()
                            }
                            
                            if session.get('member_id'):
                                ticket_data['created_by'] = session.get('member_id')
                            
                            result = db.create_ticket(ticket_data)
                            ticket_id = fallback_id
                            app.logger.info(f"[TARGET] SUCCESS: Fallback ticket created with ID {ticket_id}")
                            break
                            
                    except Exception as fallback_db_error:
                        app.logger.error(f"[ERROR] Fallback database error: {fallback_db_error}")
                        continue
                        
                except Exception as fallback_error:
                    app.logger.error(f"[ERROR] Fallback generation error: {fallback_error}")
                    continue
            
            if not ticket_id:
                error_msg = f'Failed to generate unique ticket ID after {max_attempts} attempts and {fallback_attempts} fallback attempts. Type code: M{type_code}. This may indicate severe database connectivity issues or extremely high collision rate. Please contact system administrator.'
                app.logger.error(f"[ERROR] CRITICAL: {error_msg}")
                return jsonify({
                    'status': 'error', 
                    'message': error_msg,
                    'debug_info': {
                        'type_code': type_code,
                        'max_attempts': max_attempts,
                        'fallback_attempts': fallback_attempts,
                        'suggested_action': 'Contact system administrator - severe database issues detected'
                    }
                }), 500
        
        app.logger.info(f"Ticket created successfully with ID: {ticket_id}")
        
        # Handle file uploads - FIXED: Store files in database as base64p
        uploaded_files = []
        app.logger.info(f"Starting file upload processing for ticket {ticket_id}")
        
        # ENHANCED DEBUGGING: Check what's in request.files
        app.logger.info(f"DEBUG: request.files keys: {list(request.files.keys())}")
        app.logger.info(f"DEBUG: request.files content: {dict(request.files)}")
        app.logger.info(f"DEBUG: request.content_type: {request.content_type}")
        app.logger.info(f"DEBUG: request.content_length: {request.content_length}")
        
        try:
            # Create uploads directory for this ticket
            upload_dir = os.path.join(UPLOAD_FOLDER, ticket_id)
            os.makedirs(upload_dir, exist_ok=True)
            app.logger.info(f"Created upload directory: {upload_dir}")
            
            # Process each attachment type
            attachment_fields = {
                'dpf_report': 'DPF Report',
                'warranty_form': 'Warranty Form',
                'other_attachments': 'Other Documents'
            }
            
            for field_name, display_name in attachment_fields.items():
                app.logger.info(f"DEBUG: Checking field '{field_name}'")
                
                # Get files using getlist (handles both single and multiple files)
                files = request.files.getlist(field_name)
                app.logger.info(f"DEBUG: getlist('{field_name}') returned {len(files)} files")
                
                # Filter out empty files and duplicates
                valid_files = []
                seen_filenames = set()
                
                for file in files:
                    if file and hasattr(file, 'filename') and file.filename and file.filename.strip():
                        # Check for duplicate filenames
                        if file.filename not in seen_filenames:
                            valid_files.append(file)
                            seen_filenames.add(file.filename)
                            app.logger.info(f"DEBUG: Added valid file: {file.filename}")
                        else:
                            app.logger.warning(f"DEBUG: Skipping duplicate file: {file.filename}")
                    else:
                        app.logger.warning(f"DEBUG: Skipping invalid file object for field '{field_name}'")
                
                app.logger.info(f"Processing field '{field_name}' - found {len(valid_files)} valid files after deduplication")
                
                # Use the deduplicated files list
                files = valid_files
                
                for file in files:
                    app.logger.info(f"DEBUG: Processing file object: {file}")
                    app.logger.info(f"DEBUG: File type: {type(file)}")
                    app.logger.info(f"DEBUG: File has filename attr: {hasattr(file, 'filename')}")
                    
                    # ENHANCED FILE VALIDATION
                    if file and hasattr(file, 'filename') and file.filename and file.filename.strip():
                        app.logger.info(f"Processing file: {file.filename} (field: {field_name})")
                        
                        # Generate safe filename
                        filename = secure_filename(file.filename)
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        safe_filename = f"{timestamp}_{filename}"
                        file_path = os.path.join(upload_dir, safe_filename)
                        
                        # Save file to disk (for backup and compatibility)
                        file.save(file_path)
                        app.logger.info(f"File saved to disk: {file_path}")
                        
                        # Get file size
                        file_size = os.path.getsize(file_path)
                        
                        # FIXED: Read file content and convert to base64 for database storage
                        try:
                            with open(file_path, 'rb') as f:
                                file_content = f.read()
                                file_data = base64.b64encode(file_content).decode('utf-8')
                            app.logger.info(f"SUCCESS: Converted file to base64: {filename} ({len(file_data)} chars)")
                        except Exception as e:
                            app.logger.error(f"ERROR: Failed to read file for base64 conversion: {e}")
                            file_data = ''
                        
                        file_info = {
                            'type': display_name,
                            'filename': safe_filename,
                            'original_name': filename,
                            'path': file_path,  # Keep path for fallback
                            'size': file_size,
                            'data': file_data,  # FIXED: Add base64 data for database storage
                            'is_warranty': field_name == 'warranty_form',
                            'file_type_info': 'document'
                        }
                        uploaded_files.append(file_info)
                        app.logger.info(f"SUCCESS: Added file to uploaded_files: {filename} (size: {file_size} bytes, base64: {len(file_data)} chars)")
                    else:
                        app.logger.warning(f"DEBUG: File object is empty or has no filename for field '{field_name}'")
                        app.logger.warning(f"DEBUG: File object: {file}")
                        app.logger.warning(f"DEBUG: File type: {type(file)}")
                        app.logger.warning(f"DEBUG: File has filename attr: {hasattr(file, 'filename')}")
                        if hasattr(file, 'filename'):
                            app.logger.warning(f"DEBUG: File filename: '{file.filename}'")
                            app.logger.warning(f"DEBUG: File filename stripped: '{file.filename.strip() if file.filename else 'None'}'")
                        
        except Exception as e:
            app.logger.error(f"Error processing file uploads: {e}")
            app.logger.error(f"Full traceback: {traceback.format_exc()}")
            uploaded_files = []
        
        # Store structured metadata
        metadata_entries = [
            {'ticket_id': ticket_id, 'key': 'customer_title', 'value': customer_title},
            {'ticket_id': ticket_id, 'key': 'customer_first_name', 'value': customer_first_name},
            {'ticket_id': ticket_id, 'key': 'customer_surname', 'value': customer_surname},
            {'ticket_id': ticket_id, 'key': 'vehicle_registration', 'value': vehicle_registration},
            {'ticket_id': ticket_id, 'key': 'type_of_claim', 'value': type_of_claim},
            {'ticket_id': ticket_id, 'key': 'technician', 'value': technician},
            {'ticket_id': ticket_id, 'key': 'service_date', 'value': service_date},
            {'ticket_id': ticket_id, 'key': 'claim_date', 'value': claim_date}
        ]
        
        # Add VHC link if provided
        if vhc_link:
            metadata_entries.append({'ticket_id': ticket_id, 'key': 'vhc_link', 'value': vhc_link})
        
        # Add attachment metadata
        for i, file_info in enumerate(uploaded_files):
            metadata_entries.append({
                'ticket_id': ticket_id, 
                'key': f'attachment_{i+1}', 
                'value': json.dumps(file_info)
            })
        
        # Store all metadata
        for metadata in metadata_entries:
            db.add_ticket_metadata(metadata['ticket_id'], metadata['key'], metadata['value'])
        
        # Update the ticket document with attachment information
        app.logger.info(f"DEBUG: Final uploaded_files count: {len(uploaded_files)}")
        app.logger.info(f"DEBUG: Final uploaded_files details:")
        for i, file_info in enumerate(uploaded_files):
            app.logger.info(f"  File {i+1}: {file_info['original_name']} -> {file_info['filename']} (size: {file_info['size']} bytes)")
        
        if uploaded_files:
            app.logger.info(f"DEBUG: Creating attachments array for {len(uploaded_files)} files")
            
            # Create attachments array for the ticket - FIXED: Include base64 data
            attachments_array = []
            for file_info in uploaded_files:
                attachment_data = {
                    'filename': file_info['filename'],
                    'original_name': file_info['original_name'],
                    'name': file_info['original_name'],  # Add 'name' field for template compatibility
                    'size': file_info['size'],
                    'is_warranty': file_info['is_warranty'],
                    'file_type': file_info['file_type_info'],
                    'uploaded_at': datetime.now().isoformat(),
                    'source': 'manual_upload',
                    'path': file_info['path'],  # Full path for file operations
                    'type': 'file',  # Ensure type is set for template compatibility
                    'data': file_info['data']  # FIXED: Include base64 data for database storage
                }
                attachments_array.append(attachment_data)
                app.logger.info(f"DEBUG: Added attachment to array: {file_info['original_name']} (base64: {len(file_info['data'])} chars)")
            
            # Update ticket with attachment information - ENHANCED UPDATE
            update_data = {
                'has_attachments': True,
                'total_attachments': len(uploaded_files),
                'attachments': attachments_array,
                'has_warranty': any(f.get('is_warranty') for f in uploaded_files)
            }
            
            app.logger.info(f"DEBUG: Updating ticket {ticket_id} with data: {update_data}")
            
            try:
                # First update the ticket document
                db.update_ticket(ticket_id, update_data)
                app.logger.info(f"SUCCESS: Updated ticket {ticket_id} with attachment information: {len(uploaded_files)} attachments")
                
                # Also ensure the attachments are properly indexed in the database
                # This helps with search and retrieval
                for i, attachment in enumerate(attachments_array):
                    # Store each attachment as individual metadata for better retrieval
                    # FIXED: Include base64 data in metadata for complete storage
                    attachment_metadata = {
                        'ticket_id': ticket_id,
                        'key': f'file_attachment_{i+1}',
                        'value': json.dumps(attachment)
                    }
                    db.add_ticket_metadata(ticket_id, f'file_attachment_{i+1}', json.dumps(attachment))
                    app.logger.info(f"SUCCESS: Stored attachment {i+1} metadata for ticket {ticket_id} (base64: {len(attachment.get('data', ''))} chars)")
                
            except Exception as update_error:
                app.logger.error(f"ERROR: Failed to update ticket {ticket_id} with attachment info: {update_error}")
                app.logger.error(f"ERROR: Update data was: {update_data}")
        else:
            app.logger.warning(f"WARNING: No uploaded files to process for ticket {ticket_id}")
        
        # Save additional metadata for the ticket
        try:
            # Save technician information to metadata
            if technician:
                db.add_ticket_metadata(ticket_id, 'technician_name', technician)
                app.logger.info(f"Saved technician name to metadata: {technician}")
                
                # Also get and save technician ID for proper assignment
                technician_data = db.get_technician_by_name(technician)
                if technician_data:
                    db.add_ticket_metadata(ticket_id, 'technician_id', str(technician_data['_id']))
                    app.logger.info(f"Saved technician ID to metadata: {technician_data['_id']}")
                else:
                    app.logger.warning(f"Technician '{technician}' not found in database")
            
            # Save other form fields to metadata
            db.add_ticket_metadata(ticket_id, 'customer_title', customer_title)
            db.add_ticket_metadata(ticket_id, 'customer_first_name', customer_first_name)
            db.add_ticket_metadata(ticket_id, 'customer_surname', customer_surname)
            db.add_ticket_metadata(ticket_id, 'type_of_claim', type_of_claim)
            db.add_ticket_metadata(ticket_id, 'vehicle_registration', vehicle_registration)
            db.add_ticket_metadata(ticket_id, 'service_date', service_date)
            db.add_ticket_metadata(ticket_id, 'claim_date', claim_date)
            db.add_ticket_metadata(ticket_id, 'vhc_link', vhc_link)
            
            app.logger.info(f"Successfully saved all metadata for ticket {ticket_id}")
        except Exception as metadata_error:
            app.logger.error(f"Warning: Failed to save metadata for ticket {ticket_id}: {metadata_error}")
            # Don't fail the ticket creation if metadata saving fails
        
        app.logger.info(f"Ticket {ticket_id} created successfully by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket created successfully! Customer Number: {ticket_id}',
            'ticket_id': ticket_id,
            'customer_number': ticket_id,
            'reference_message': f'Please reference Customer Number {ticket_id} for all inquiries about this ticket.',
            'attachments_uploaded': len(uploaded_files)
        })
        
    except Exception as e:
        app.logger.error(f"Error creating ticket: {str(e)}")
        import traceback
        app.logger.error(f"Full traceback: {traceback.format_exc()}")
        # Return more detailed error for debugging (without non-serializable objects)
        return jsonify({
            'status': 'error', 
            'message': f'Error creating ticket: {str(e)}',
            'error_type': type(e).__name__
        }), 500

# Email Template System with Placeholders
DEFAULT_WARRANTY_TEMPLATE = {
    'name': 'Warranty Claim Template',
    'subject': 'Warranty Claim - <Vehicle Registration>| <Ticket Number> | Auto Assist Group',
    'body': '''Dear <First Name> <Surname> (TicketID: <Ticket Number>),

Thank you for contacting us regarding your recent DPF service with Auto Assist Group.

To begin your warranty claim process, please follow the steps below:

Click the link below to access the warranty claim form:

https://autoassistgroup.com/report/claims

The form will ask you to provide:

- Your vehicle registration number
- Current mileage (with a photo of the dashboard as proof)
- New OBD-II fault codes
- Confirmation and proof of any advisory work completed
- Driving habits since the clean (e.g. short trips, motorway usage, etc.)

Your original DPF service report is attached for your reference.

Once we receive your completed form, our Aftercare Team will review the information and update your warranty ticket. If any further information is required, we will contact you directly.

If you have any questions in the meantime, please reply to this email.

Kind regards,

Auto Assist Group - Aftercare Team'''
}

def replace_email_placeholders(template_text, ticket_id):
    """Replace email template placeholders with actual ticket data"""
    try:
        app.logger.info(f"ðŸ” REPLACING EMAIL PLACEHOLDERS - Input Ticket ID: {ticket_id}")
        
        db = get_db()
        
        # Get ticket metadata
        metadata = db.get_ticket_metadata(ticket_id)
        metadata_dict = {meta['key']: meta['value'] for meta in metadata}
        
        # Get ticket data for additional placeholders
        ticket = db.get_ticket_by_id(ticket_id)
        customer_name = ticket.get('name', '') if ticket else ''
        first_name = customer_name.split()[0] if customer_name else 'Customer'
        
        # Define placeholder mappings (support both formats)
        placeholders = {
            # Original format
            '<First Name>': metadata_dict.get('customer_first_name', first_name),
            '<Surname>': metadata_dict.get('customer_surname', ''),
            '<Customer Title>': metadata_dict.get('customer_title', ''),
            '<Vehicle Registration>': metadata_dict.get('vehicle_registration', ''),
            '<Ticket Number>': ticket_id,
            '<Type of Claim>': metadata_dict.get('type_of_claim', ''),
            '<Technician>': metadata_dict.get('technician', ''),
            '<Service Date>': metadata_dict.get('service_date', ''),
            '<Claim Date>': metadata_dict.get('claim_date', ''),
            
            # New format for generate_email_draft_response
            '{first_name}': first_name,
            '{customer_name}': customer_name,
            '{ticket_id}': ticket_id,
            '{ticket_data.get(\'ticket_id\', \'N/A\')}': ticket_id
        }
        
        app.logger.info(f"ðŸ” PLACEHOLDER MAPPINGS - <Ticket Number> will be replaced with: {ticket_id}")
        
        # Replace all placeholders
        result = template_text
        for placeholder, value in placeholders.items():
            result = result.replace(placeholder, value)
        
        return result
        
    except Exception as e:
        app.logger.error(f"Error replacing email placeholders: {str(e)}")
        return template_text

@app.route('/api/email/send-template', methods=['POST'])
def send_template_email():
    """Send email using template with placeholders"""
    app.logger.info(f"ðŸš€ EMAIL TEMPLATE ENDPOINT CALLED")
    if 'member_id' not in session:
        app.logger.error(f"ðŸ’¥ UNAUTHORIZED - No member_id in session")
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        app.logger.info(f"ðŸš€ EMAIL TEMPLATE TRY BLOCK ENTERED")
        data = request.json
        ticket_id = data.get('ticket_id')
        template_type = data.get('template_type', 'warranty')
        custom_subject = data.get('custom_subject', '')
        custom_body = data.get('custom_body', '')
        attachments = data.get('attachments', [])
        
        if not ticket_id:
            return jsonify({'status': 'error', 'message': 'Ticket ID required'}), 400

        # ANTI-SPAM: Check for duplicate email template submissions
        member_id = session['member_id']
        current_time = datetime.now()
        cache_key = f"email_template_spam_{ticket_id}_{member_id}_{custom_subject[:30]}"
        
        # Use the same cache as reply anti-spam
        if not hasattr(app, '_reply_cache'):
            app._reply_cache = {}
        
        # Clean old entries (older than 10 seconds for email templates)
        app._reply_cache = {k: v for k, v in app._reply_cache.items() 
                           if (current_time - v).total_seconds() < 10}
        
        if cache_key in app._reply_cache:
            app.logger.warning(f"ðŸš« EMAIL TEMPLATE SPAM BLOCKED - Duplicate email attempt for ticket {ticket_id} by member {member_id}")
            return jsonify({'status': 'error', 'message': 'Duplicate email submission detected. Please wait before sending again.'}), 429
        
        # Record this submission to prevent duplicates
        app._reply_cache[cache_key] = current_time
        
        app.logger.info(f" PROCESSING EMAIL TEMPLATE - Ticket: {ticket_id}, Member: {member_id}, Subject: {custom_subject[:50]}...")
        
        # Get ticket information
        try:
            db = get_db()
            app.logger.info(f" DEBUG: Got database connection for ticket {ticket_id}")
            ticket = db.get_ticket_by_id(ticket_id)
            app.logger.info(f" DEBUG: Retrieved ticket data: {ticket is not None}")
            if not ticket:
                return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        except Exception as e:
            app.logger.error(f"ðŸ’¥ DATABASE ERROR - Failed to get ticket {ticket_id}: {str(e)}")
            return jsonify({'status': 'error', 'message': 'Database error'}), 500
        
        # Use template or custom content
        try:
            if custom_subject and custom_body:
                # Use custom content
                app.logger.info(f" DEBUG: Using custom template content for ticket {ticket_id}")
                subject = replace_email_placeholders(custom_subject, ticket_id)
                body = replace_email_placeholders(custom_body, ticket_id)
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF CUSTOM EMAIL BODY
                ticket_id_header = f""
                enhanced_body = ticket_id_header + body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO CUSTOM EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            else:
                # Use default warranty template
                app.logger.info(f" DEBUG: Using default warranty template for ticket {ticket_id}")
                subject = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['subject'], ticket_id)
                body = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['body'], ticket_id)
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
                ticket_id_header = f""
                enhanced_body = ticket_id_header + body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
                
                app.logger.info(f" DEBUG: Template processing complete - Subject: {subject[:50]}...")
        except Exception as e:
            app.logger.error(f"ðŸ’¥ TEMPLATE ERROR - Failed to process template for ticket {ticket_id}: {str(e)}")
            return jsonify({'status': 'error', 'message': 'Template processing error'}), 500
        
        # INTEGRATE EMAIL SERVICE - Send actual email with attachments
        recipient_email = ticket.get('email', '')
        if not recipient_email:
            app.logger.error(f" No email address found for ticket {ticket_id}")
            return jsonify({'status': 'error', 'message': 'No recipient email address found'}), 400
        
        app.logger.info(f"ðŸ“§ PREPARING TO SEND EMAIL to {recipient_email}")
        app.logger.info(f"ðŸ“§ Subject: {subject}")
        app.logger.info(f"ðŸ“§ Body length: {len(body)} chars")
        app.logger.info(f"ðŸ“Ž RECEIVED ATTACHMENTS FROM FRONTEND: {len(attachments)} attachments")
        
        # Prepare attachments in the format expected by EmailService
        email_attachments = []
        
        # Process each attachment to prepare for email sending
        if attachments:
            app.logger.info(f"ðŸ”„ PROCESSING {len(attachments)} ATTACHMENTS for email sending")
        
        # FIXED: Enhanced original ticket attachment processing for manual tickets
        original_ticket_attachments = []
        if ticket.get('attachments'):
            app.logger.info(f"ðŸ“Ž PROCESSING {len(ticket['attachments'])} ORIGINAL TICKET ATTACHMENTS")
            for i, att in enumerate(ticket['attachments']):
                filename = att.get('filename', att.get('original_name', f'original_attachment_{i}'))
                # Include all attachments without filtering by name prefix
                if filename:
                    # FIXED: Handle both email tickets (with data) and manual tickets (with data)
                    if att.get('data'):  # Base64 data available
                        app.logger.info(f"ðŸ“Ž USING BASE64 DATA FOR EMAIL: {filename} ({len(att.get('data'))} chars)")
                        original_ticket_attachments.append({
                            'name': filename,
                            'data': att.get('data'),
                            'size': att.get('size', 0),
                            'is_warranty': att.get('is_warranty', False),
                            'is_manual_ticket_attachment': att.get('is_manual_ticket_attachment', False)
                        })
                    else:
                        app.logger.warning(f"ðŸ“Ž NO BASE64 DATA FOR EMAIL: {filename}")
                else:
                    app.logger.info(f"ðŸ“Ž SKIPPING ATTACHMENT: {filename} (no filename)")
        else:
            app.logger.info(f"ðŸ“Ž NO ORIGINAL TICKET ATTACHMENTS FOUND")
        
        # Only add metadata attachments for manually created tickets (not email-created tickets)
        # Check if this is an email-created ticket by looking for email-specific fields
        is_email_ticket = ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id')
        
        if not is_email_ticket:
            # Only process metadata attachments for manually created tickets
            metadata = db.get_ticket_metadata(ticket_id)
            for meta in metadata:
                if meta.get('key', '').startswith('attachment_'):
                    try:
                        attachment_data = json.loads(meta.get('value', '{}'))
                        if attachment_data and isinstance(attachment_data, dict):
                            # Read file from disk and convert to base64
                            file_path = attachment_data.get('path', '')
                            if file_path:
                                full_path = os.path.join(UPLOAD_FOLDER, file_path)
                                if os.path.exists(full_path):
                                    with open(full_path, 'rb') as f:
                                        file_data = base64.b64encode(f.read()).decode('utf-8')
                                    attachment_name = attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File'))
                                    # Include all metadata attachments without filtering by name prefix
                                    if attachment_name:
                                        original_ticket_attachments.append({
                                            'name': attachment_name,
                                            'data': file_data,
                                            'size': attachment_data.get('size', 0),
                                            'is_warranty': attachment_data.get('is_warranty', False),
                                            'is_manual_ticket_attachment': True  # FIXED: Flag for manual ticket attachments
                                        })
                                        app.logger.info(f"ðŸ“Ž ADDED METADATA ATTACHMENT TO EMAIL: {attachment_data.get('original_name')} (data: {len(file_data)} chars)")
                    except (json.JSONDecodeError, TypeError, IOError) as e:
                        app.logger.warning(f"Failed to process metadata attachment for email: {e}")
                        continue
        
        # Combine reply attachments with original ticket attachments - PREVENT DUPLICATES
        # Only include original ticket attachments if they're not already in reply attachments
        all_attachments = attachments.copy()  # Start with reply attachments
        
        # Add original ticket attachments only if they're not duplicates
        if original_ticket_attachments:
            for orig_att in original_ticket_attachments:
                orig_name = orig_att.get('name', '')
                # Check if this original attachment is already in reply attachments
                is_duplicate = False
                for reply_att in attachments:
                    if reply_att.get('name', '') == orig_name:
                        is_duplicate = True
                        app.logger.info(f"ðŸ“Ž SKIPPING DUPLICATE: {orig_name} already exists in reply attachments")
                        break
                
                if not is_duplicate:
                    all_attachments.append(orig_att)
                    app.logger.info(f"ðŸ“Ž ADDED ORIGINAL: {orig_name} (not a duplicate)")
                else:
                    app.logger.info(f"ðŸ“Ž SKIPPED DUPLICATE: {orig_name}")
        
        app.logger.info(f"ðŸ“Ž TOTAL ATTACHMENTS FOR EMAIL: {len(all_attachments)} (reply: {len(attachments)}, original added: {len(all_attachments) - len(attachments)})")
        
        # FIXED: Prepare email attachments with proper file data for manual tickets
        email_attachments = []
        for attachment in all_attachments:
            attachment_name = attachment.get('name', 'Unknown File')
            attachment_data = attachment.get('data', '')
            
            if attachment_data and len(attachment_data) > 10:  # Valid base64 data
                try:
                    # Decode base64 to get binary data
                    file_content = base64.b64decode(attachment_data)
                    
                    # Create email attachment object
                    email_attachment = {
                        'filename': attachment_name,
                        'content': file_content,
                        'content_type': get_mime_type(attachment_name),
                        'is_warranty': attachment.get('is_warranty', False),
                        'is_manual_ticket_attachment': attachment.get('is_manual_ticket_attachment', False)
                    }
                    
                    email_attachments.append(email_attachment)
                    app.logger.info(f"ðŸ“Ž PREPARED EMAIL ATTACHMENT: {attachment_name} ({len(file_content)} bytes, type: {email_attachment['content_type']})")
                    
                except Exception as e:
                    app.logger.error(f"ðŸ“Ž ERROR PREPARING EMAIL ATTACHMENT {attachment_name}: {e}")
                    continue
            else:
                app.logger.warning(f"ðŸ“Ž SKIPPING ATTACHMENT WITHOUT DATA: {attachment_name}")
        
        app.logger.info(f"ðŸ“Ž FINAL EMAIL ATTACHMENTS: {len(email_attachments)} attachments ready for sending")
        
        # Process each attachment to prepare for email sending
        for i, attachment in enumerate(attachments):
            if isinstance(attachment, dict):
                attachment_name = attachment.get('name', 'unknown_file')
                file_path = attachment.get('file_path', '')
                attachment_key = attachment.get('key', '')
                ticket_index = attachment.get('ticket_index')
                
                app.logger.info(f"ðŸ“Ž Processing attachment {i+1}/{len(attachments)}: {attachment_name} (ticket_index: {ticket_index})")
                
                # Try to get file data - PRIORITIZE FRONTEND fileData FIRST!
                file_data = ""
                try:
                    # ðŸš€ PRIORITY 0: Use fileData from frontend if available (MOST RELIABLE)
                    if attachment.get('fileData'):
                        file_data = attachment.get('fileData')
                        app.logger.info(f"ðŸŽ¯ FRONTEND fileData: Found data for {attachment_name} from frontend ({len(file_data)} chars)")
                        
                        # ðŸš€ CRITICAL VALIDATION: Ensure the fileData is valid base64
                        if file_data and len(file_data) > 10:
                            try:
                                # Validate base64 data by attempting to decode it
                                decoded_data = base64.b64decode(file_data)
                                app.logger.info(f"âœ… VALIDATED BASE64 DATA: {attachment_name} ({len(file_data)} chars, decoded to {len(decoded_data)} bytes)")
                                
                                # Add frontend attachment with validated fileData to email attachments
                                email_attachments.append({
                                    'filename': attachment_name,
                                    'fileData': file_data,
                                    'data': file_data,  # Support both keys for compatibility
                                    'size': len(decoded_data),  # Use actual decoded size
                                    'type': attachment.get('type', 'file'),
                                    'content': decoded_data,  # Include decoded binary content for email service
                                    'content_type': get_mime_type(attachment_name)
                                })
                                app.logger.info(f"âœ… ADDED VALIDATED FRONTEND ATTACHMENT: {attachment_name} with {len(file_data)} chars base64 ({len(decoded_data)} bytes)")
                                continue  # Skip further processing since we already have the data
                                
                            except Exception as e:
                                app.logger.error(f"âŒ INVALID BASE64 DATA for {attachment_name}: {e}")
                                file_data = ""  # Reset to empty to try other methods
                        else:
                            app.logger.warning(f"âš ï¸ FRONTEND fileData too short or empty for {attachment_name}: {len(file_data) if file_data else 0} chars")
                            file_data = ""  # Reset to empty to try other methods
                        
                    # PRIORITY 1: Use ticket_index to get data directly (FASTEST METHOD)
                    elif ticket_index is not None and ticket.get('attachments') and ticket_index < len(ticket['attachments']):
                        ticket_att = ticket['attachments'][ticket_index]
                        if ticket_att.get('data'):
                            file_data = ticket_att.get('data')
                            app.logger.info(f"ðŸŽ¯ DIRECT ACCESS: Found data for {attachment_name} using ticket_index {ticket_index} ({len(file_data)} chars)")
                        else:
                            app.logger.warning(f" No data at ticket_index {ticket_index} for {attachment_name}")
                    
                    # PRIORITY 2: If no ticket_index, go straight to metadata (for metadata attachments)
                    elif ticket_index is None and attachment_key:
                        app.logger.info(f" METADATA ATTACHMENT: Searching metadata directly for key: {attachment_key}")
                        db = get_db()
                        metadata = db.get_ticket_metadata(ticket_id)
                        
                        # DEBUG: Log all available metadata for debugging
                        app.logger.info(f" DEBUG METADATA: Found {len(metadata)} metadata entries:")
                        for idx, meta in enumerate(metadata):
                            meta_key = meta.get('key', 'NO_KEY')
                            meta_value_type = type(meta.get('value', None)).__name__
                            meta_value_preview = str(meta.get('value', ''))[:100] + ('...' if len(str(meta.get('value', ''))) > 100 else '')
                            app.logger.info(f"  [{idx}] key='{meta_key}', value_type={meta_value_type}, preview='{meta_value_preview}'")
                        
                        for meta in metadata:
                            if meta.get('key') == attachment_key:
                                app.logger.info(f" FOUND MATCHING KEY: {attachment_key}")
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                        app.logger.info(f" PARSED JSON METADATA: keys={list(meta_data.keys())}")
                                    else:
                                        meta_data = meta.get('value', {})
                                        app.logger.info(f" DIRECT METADATA: type={type(meta_data)}, keys={list(meta_data.keys()) if isinstance(meta_data, dict) else 'NOT_DICT'}")
                                    
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        app.logger.info(f" Found metadata attachment data for {attachment_name} ({len(file_data)} chars)")
                                        break
                                    else:
                                        app.logger.warning(f" METADATA HAS NO DATA: {attachment_key} - available keys: {list(meta_data.keys()) if isinstance(meta_data, dict) else 'NOT_DICT'}")
                                except (json.JSONDecodeError, TypeError) as e:
                                    app.logger.error(f" METADATA PARSE ERROR for {attachment_key}: {e}")
                                    continue
                        
                        if not file_data:
                            app.logger.error(f" METADATA ATTACHMENT NOT FOUND: Could not find data for key '{attachment_key}' in {len(metadata)} metadata entries")
                    
                    # PRIORITY 3: Fallback - search ticket attachments by filename if direct access failed
                    elif ticket.get('attachments'):
                        app.logger.info(f" FALLBACK: Searching ticket attachments by name for {attachment_name}")
                        for ticket_att in ticket['attachments']:
                            if isinstance(ticket_att, dict):
                                # Check various filename fields
                                ticket_filename = ticket_att.get('filename', ticket_att.get('fileName', ''))
                                
                                if ticket_filename and (
                                    ticket_filename == attachment_name or 
                                    attachment_name in ticket_filename or 
                                    ticket_filename in attachment_name
                                ):
                                    # Found matching filename, now get the data
                                    if ticket_att.get('data'):
                                        file_data = ticket_att.get('data')
                                        app.logger.info(f" Found base64 data in ticket attachments: {attachment_name} ({len(file_data)} chars)")
                                        break
                    
                    # PRIORITY 4: Final metadata search if still not found
                    if not file_data:
                        app.logger.info(f" Checking metadata for {attachment_name}")
                        db = get_db()
                        metadata = db.get_ticket_metadata(ticket_id)
                        
                        # Try to match by key first
                        if attachment_key:
                            for meta in metadata:
                                if meta.get('key') == attachment_key:
                                    try:
                                        if isinstance(meta.get('value'), str):
                                            meta_data = json.loads(meta.get('value'))
                                        else:
                                            meta_data = meta.get('value', {})
                                        
                                        if meta_data.get('data'):
                                            file_data = meta_data.get('data')
                                            app.logger.info(f" Found base64 data in metadata via key {attachment_key}")
                                            break
                                    except (json.JSONDecodeError, TypeError):
                                        continue
                            
                            # If no data found by key, try name matching in metadata
                            if not file_data:
                                for meta in metadata:
                                    try:
                                        if isinstance(meta.get('value'), str):
                                            meta_data = json.loads(meta.get('value'))
                                        else:
                                            meta_data = meta.get('value', {})
                                        
                                        # Check filename matches
                                        meta_filename = meta_data.get('filename', meta_data.get('fileName', ''))
                                        if meta_filename and (meta_filename == attachment_name or attachment_name in meta_filename):
                                            if meta_data.get('data'):
                                                file_data = meta_data.get('data')
                                                app.logger.info(f" Found base64 data in metadata via filename match")
                                                break
                                    except (json.JSONDecodeError, TypeError):
                                        continue
                        
                        # Add to email attachments list if data found
                        if file_data:
                            email_attachments.append({
                                'filename': attachment_name,
                                'fileData': file_data,
                                'data': file_data  # Support both keys for compatibility
                            })
                            app.logger.info(f" Added {attachment_name} to email attachments ({len(file_data)} chars base64)")
                        else:
                            app.logger.warning(f" No data found for attachment: {attachment_name}")
                    
                except Exception as e:
                    app.logger.error(f" Error processing attachment {attachment_name}: {e}")
        
        # Send the actual email using EmailService
        try:
            app.logger.info(f"ðŸ“§ SENDING EMAIL via EmailService to {recipient_email} with {len(email_attachments)} attachments")
            
            # Convert all attachments to the format expected by EmailService
            final_email_attachments = []
            for attachment in all_attachments:
                if attachment.get('data'):  # Base64 data
                    final_email_attachments.append({
                        'filename': attachment.get('name', 'attachment'),
                        'data': attachment.get('data'),
                        'content_type': 'application/octet-stream'
                    })
                elif attachment.get('file_path'):  # File path
                    try:
                        with open(attachment['file_path'], 'rb') as f:
                            file_data = base64.b64encode(f.read()).decode('utf-8')
                        final_email_attachments.append({
                            'filename': attachment.get('name', 'attachment'),
                            'data': file_data,
                            'content_type': 'application/octet-stream'
                        })
                    except IOError as e:
                        app.logger.warning(f"Failed to read attachment file: {e}")
                        continue
            
            # Create HTML body for better formatting
            # Use enhanced_body if available, otherwise fall back to body
            email_body = enhanced_body if 'enhanced_body' in locals() else body
            
            html_body = """
            <html>
                <body>
                    <p>{email_body.replace(chr(10), '<br>')}</p>
                    <br>
                    <hr>
                    <p style="font-size: 12px; color: #666;">
                        Ticket ID: {ticket_id}<br>
                        Sent via Email Template System
                    </p>
                </body>
            </html>
            """
            
            # Send email with attachments
            # Use enhanced_body if available, otherwise fall back to body
            email_body = enhanced_body if 'enhanced_body' in locals() else body
            
            email_success = email_service.send_email(
                to_email=recipient_email,
                subject=subject,
                body=email_body,
                html_body=html_body,
                attachments=final_email_attachments if final_email_attachments else None
            )
            
            if email_success:
                app.logger.info(f" EMAIL SENT SUCCESSFULLY to {recipient_email}")
            else:
                app.logger.error(f" EMAIL SENDING FAILED to {recipient_email}")
                
        except Exception as email_error:
            app.logger.error(f"ðŸ’¥ EMAIL SERVICE ERROR: {email_error}")
            email_success = False
        
        # Add email record to ticket history/replies
        try:
            # Create detailed message about email status
            email_status_msg = " Successfully sent" if email_success else " Failed to send"
            attachment_info = f" with {len(email_attachments)} attachments" if email_attachments else " with no attachments"
            
            reply_data = {
                'ticket_id': ticket_id,
                'thread_id': ticket.get('thread_id', ''),
                'message': f"ðŸ“§ **Email {email_status_msg} via Template{attachment_info}**\n\n**To:** {recipient_email}\n**Subject:** {subject}\n\n**Message:**\n{email_body}",
                'sender': 'support',
                'is_email': True,
                'email_subject': subject,
                'email_body': email_body,
                'email_status': 'sent' if email_success else 'failed',
                'email_recipient': recipient_email,
                'attachments': attachments,
                'email_attachments_count': len(email_attachments)
            }
            
            app.logger.info(f" DEBUG: Adding reply record for ticket {ticket_id}")
            db.create_reply(reply_data)
            app.logger.info(f" DEBUG: Reply record added successfully for ticket {ticket_id}")
        except Exception as e:
            app.logger.error(f"ðŸ’¥ REPLY ERROR - Failed to add reply for ticket {ticket_id}: {str(e)}")
            return jsonify({'status': 'error', 'message': 'Database reply error'}), 500
        
        # WEBHOOK INTEGRATION: Trigger webhook for email template sends - Enhanced format
        current_timestamp = datetime.now().isoformat()
        
        # ðŸ”§ FIX: Format attachments with actual file data for email templates
        formatted_attachments = []
        
        if not attachments:
            app.logger.warning(f" NO ATTACHMENTS TO PROCESS for ticket {ticket_id}")
        
        for i, attachment in enumerate(attachments):
            app.logger.info(f"ðŸ“Ž PROCESSING ATTACHMENT {i}: {attachment}")
            
            if isinstance(attachment, dict):
                attachment_name = attachment.get('name', 'unknown_file')
                file_path = attachment.get('file_path', '')
                attachment_key = attachment.get('key', '')
                ticket_index = attachment.get('ticket_index')
                
                app.logger.info(f"ðŸ“Ž ATTACHMENT DETAILS: name='{attachment_name}', file_path='{file_path}', key='{attachment_key}', ticket_index='{ticket_index}'")
                
                # Try to read actual file content
                file_data = ""
                file_size = 0
                
                try:
                    # PRIORITY 1: Use ticket_index for direct access (SAME AS EMAIL PROCESSING)
                    app.logger.info(f" SEARCHING FOR WEBHOOK ATTACHMENT: {attachment_name} (ticket_index: {ticket_index})")
                    
                    if ticket_index is not None and ticket.get('attachments') and ticket_index < len(ticket['attachments']):
                        ticket_att = ticket['attachments'][ticket_index]
                        if ticket_att.get('data'):
                            file_data = ticket_att.get('data')
                            file_size = ticket_att.get('size', 0)
                            app.logger.info(f"ðŸŽ¯ WEBHOOK DIRECT ACCESS: Found data for {attachment_name} using ticket_index {ticket_index} ({len(file_data)} chars)")
                        else:
                            app.logger.warning(f" No data at webhook ticket_index {ticket_index} for {attachment_name}")
                    
                    # PRIORITY 1.5: Fallback to filename search in ticket attachments
                    elif ticket.get('attachments'):
                        app.logger.info(f" WEBHOOK FALLBACK: Searching ticket attachments by name for {attachment_name}")
                        for ticket_att in ticket['attachments']:
                            if isinstance(ticket_att, dict):
                                # Check various filename fields
                                ticket_filename = ticket_att.get('filename', ticket_att.get('fileName', ''))
                                
                                if ticket_filename and (
                                    ticket_filename == attachment_name or 
                                    attachment_name in ticket_filename or 
                                    ticket_filename in attachment_name
                                ):
                                    # Found matching filename, now get the data
                                    if ticket_att.get('data'):
                                        file_data = ticket_att.get('data')
                                        file_size = ticket_att.get('size', 0)
                                        app.logger.info(f" Found attachment data in ticket for webhook: {attachment_name} ({len(file_data)} chars)")
                                        break
                    
                    # PRIORITY 2: If no ticket_index, check metadata directly (for metadata attachments)
                    if not file_data and ticket_index is None and attachment_key:
                        app.logger.info(f" METADATA ATTACHMENT FOR WEBHOOK: Searching metadata directly for key: {attachment_key}")
                        metadata = db.get_ticket_metadata(ticket_id)
                        
                        for meta in metadata:
                            if meta.get('key') == attachment_key:
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                    else:
                                        meta_data = meta.get('value', {})
                                    
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        file_size = meta_data.get('size', 0)
                                        app.logger.info(f" Found metadata attachment data for webhook {attachment_name} ({len(file_data)} chars)")
                                        break
                                except (json.JSONDecodeError, TypeError):
                                    continue
                    
                    # PRIORITY 3: Full metadata search if still not found
                    if not file_data:
                        app.logger.info(f" Checking metadata for webhook: {attachment_name}")
                    metadata = db.get_ticket_metadata(ticket_id)
                    app.logger.info(f" FOUND {len(metadata)} metadata entries for ticket {ticket_id}")
                    
                    # Try to match by key first (most reliable)
                    if attachment_key:
                        for idx, meta in enumerate(metadata):
                            if meta.get('key') == attachment_key:
                                app.logger.info(f" FOUND ATTACHMENT BY KEY: {attachment_key}")
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                    else:
                                        meta_data = meta.get('value', {})
                                    
                                    # Get file data directly from metadata
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        file_size = meta_data.get('size', 0)
                                        app.logger.info(f"ðŸ“§ USING BASE64 DATA FROM KEY: {attachment_name} ({file_size} bytes)")
                                        break
                                    
                                    # Try file path if available
                                    elif meta_data.get('file_path'):
                                        file_path_from_meta = meta_data.get('file_path')
                                        # Try multiple path combinations
                                        possible_paths = [
                                            os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                            os.path.join(os.getcwd(), file_path_from_meta),
                                            file_path_from_meta
                                        ]
                                        
                                        for path_attempt in possible_paths:
                                            if os.path.exists(path_attempt):
                                                with open(path_attempt, 'rb') as f:
                                                    file_content = f.read()
                                                    file_data = base64.b64encode(file_content).decode('utf-8')
                                                    file_size = len(file_content)
                                                    app.logger.info(f"FOLDER READ FILE BY KEY: {path_attempt} ({file_size} bytes)")
                                                    break
                                        
                                        if file_data:
                                            break
                                            
                                except (json.JSONDecodeError, TypeError) as e:
                                    app.logger.error(f"ðŸ’¥ METADATA PARSE ERROR for key {attachment_key}: {e}")
                                    continue
                    
                    # If not found by key, try by name matching
                    if not file_data:
                        for idx, meta in enumerate(metadata):
                            try:
                                if isinstance(meta.get('value'), str):
                                    meta_data = json.loads(meta.get('value'))
                                else:
                                    meta_data = meta.get('value', {})
                                
                                # Get all possible names from metadata
                                meta_filename = meta_data.get('filename', '')
                                meta_name = meta_data.get('name', '')
                                meta_fileName = meta_data.get('fileName', '')
                                
                                # Check for exact matches first, then partial matches
                                exact_matches = [
                                    meta_filename == attachment_name,
                                    meta_name == attachment_name,
                                    meta_fileName == attachment_name
                                ]
                                
                                partial_matches = [
                                    attachment_name in meta_filename and meta_filename != '',
                                    attachment_name in meta_name and meta_name != '',
                                    attachment_name in meta_fileName and meta_fileName != '',
                                    meta_filename in attachment_name and meta_filename != '',
                                    meta_name in attachment_name and meta_name != '',
                                    meta_fileName in attachment_name and meta_fileName != ''
                                ]
                                
                                if any(exact_matches) or any(partial_matches):
                                    match_type = "EXACT" if any(exact_matches) else "PARTIAL"
                                    app.logger.info(f" FOUND {match_type} MATCH: {attachment_name} matches metadata {idx}")
                                    
                                    # Try base64 data first
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        file_size = meta_data.get('size', 0)
                                        app.logger.info(f"ðŸ“§ USING BASE64 DATA: {attachment_name} ({file_size} bytes)")
                                        break
                                    
                                    # Try file path
                                    elif meta_data.get('file_path'):
                                        file_path_from_meta = meta_data.get('file_path')
                                        possible_paths = [
                                            os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                            os.path.join(os.getcwd(), file_path_from_meta),
                                            file_path_from_meta
                                        ]
                                        
                                        for path_attempt in possible_paths:
                                            if os.path.exists(path_attempt):
                                                with open(path_attempt, 'rb') as f:
                                                    file_content = f.read()
                                                    file_data = base64.b64encode(file_content).decode('utf-8')
                                                    file_size = len(file_content)
                                                    app.logger.info(f"FOLDER READ FILE BY NAME: {path_attempt} ({file_size} bytes)")
                                                    break
                                        
                                        if file_data:
                                            break
                                        
                            except (json.JSONDecodeError, TypeError) as e:
                                app.logger.error(f"ðŸ’¥ METADATA PARSE ERROR {idx}: {e}")
                                continue
                    
                    # Final fallback: try direct file path from frontend
                    if not file_data and file_path:
                        possible_paths = [
                            os.path.join(os.getcwd(), 'uploads', file_path),
                            os.path.join(os.getcwd(), file_path),
                            file_path
                        ]
                        
                        for path_attempt in possible_paths:
                            if os.path.exists(path_attempt):
                                with open(path_attempt, 'rb') as f:
                                    file_content = f.read()
                                    file_data = base64.b64encode(file_content).decode('utf-8')
                                    file_size = len(file_content)
                                    app.logger.info(f"FOLDER READ FILE BY DIRECT PATH: {path_attempt} ({file_size} bytes)")
                                    break
                    
                    # FINAL DESPERATE ATTEMPT: Try to find ANY matching attachment data
                    if not file_data:
                        app.logger.warning(f"ðŸ”„ FINAL ATTEMPT: Searching ALL metadata for ANY file with similar name...")
                        
                        # Try partial name matches with more flexible matching
                        for idx, meta in enumerate(metadata):
                            try:
                                if isinstance(meta.get('value'), str):
                                    meta_data = json.loads(meta.get('value'))
                                else:
                                    meta_data = meta.get('value', {})
                                
                                # Get all name variations
                                name_variants = [
                                    meta_data.get('filename', ''),
                                    meta_data.get('name', ''),
                                    meta_data.get('fileName', ''),
                                    meta.get('key', '')
                                ]
                                
                                # Very flexible matching - any partial match
                                for variant in name_variants:
                                    if variant and (
                                        variant.lower() in attachment_name.lower() or 
                                        attachment_name.lower() in variant.lower() or
                                        variant.split('.')[0].lower() in attachment_name.lower() or
                                        attachment_name.split('.')[0].lower() in variant.lower()
                                    ):
                                        app.logger.warning(f"ðŸ”„ FOUND PARTIAL MATCH: '{attachment_name}' ~= '{variant}' in metadata {idx}")
                                        
                                        if meta_data.get('data'):
                                            file_data = meta_data.get('data')
                                            file_size = meta_data.get('size', len(file_data) if file_data else 0)
                                            app.logger.info(f" SUCCESS WITH PARTIAL MATCH: {attachment_name} ({file_size} bytes)")
                                            break
                                            
                                if file_data:  # Break outer loop if found
                                    break
                                    
                            except Exception as e:
                                continue
                        
                        # Log failure details if STILL no data found
                        if not file_data:
                            app.logger.error(f" ATTACHMENT NOT FOUND: {attachment_name}")
                            # Log available attachment names for debugging
                            available_names = []
                            available_keys = []
                            for meta in metadata:
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                    else:
                                        meta_data = meta.get('value', {})
                                    
                                    names = [meta_data.get('filename'), meta_data.get('name'), meta_data.get('fileName')]
                                    available_names.extend([n for n in names if n])
                                    if meta.get('key'):
                                        available_keys.append(meta.get('key'))
                                except:
                                    pass
                            app.logger.error(f" AVAILABLE NAMES: {available_names}")
                            app.logger.error(f" AVAILABLE KEYS: {available_keys}")
                            app.logger.error(f" REQUESTED: name='{attachment_name}', key='{attachment_key}', file_path='{file_path}'")
                
                except Exception as e:
                    app.logger.error(f"ðŸ’¥ EMAIL TEMPLATE ATTACHMENT ERROR for {attachment_name}: {str(e)}")
                    file_data = ""
                    file_size = 0
                
                # Create the formatted attachment entry
                formatted_attachment = {
                    "fileName": attachment_name,
                    "fileData": file_data,
                    "id": str(uuid.uuid4().hex[:8]),
                    "size": file_size,
                    "isWarranty": 'warranty' in attachment_name.lower()
                }
                
                formatted_attachments.append(formatted_attachment)
                
                # Enhanced result logging
                if file_data and len(file_data) > 0:
                    app.logger.info(f" ATTACHMENT SUCCESS: {attachment_name} -> {len(file_data)} chars base64, {file_size} bytes")
                else:
                    app.logger.error(f" ATTACHMENT FAILED: {attachment_name} -> NO FILE DATA")
                    app.logger.error(f"   ðŸ“ Debug Info:")
                    app.logger.error(f"   - Original attachment object: {attachment}")
                    app.logger.error(f"   - Attachment name: '{attachment_name}'")
                    app.logger.error(f"   - File path: '{file_path}'")
                    app.logger.error(f"   - Attachment key: '{attachment_key}'")
                    app.logger.error(f"   - Searched: uploads/{file_path}")
                    app.logger.error(f"   - Searched: metadata for names matching '{attachment_name}'")
                    
                    # ENHANCED DEBUG: Let's see what's actually available
                    try:
                        app.logger.error(f"    DEBUG: Available ticket data keys: {list(ticket.keys()) if ticket else 'No ticket data'}")
                        if ticket and 'attachments' in ticket:
                            app.logger.error(f"    DEBUG: Ticket has {len(ticket['attachments'])} attachments")
                            for idx, att in enumerate(ticket['attachments']):
                                att_keys = list(att.keys()) if isinstance(att, dict) else []
                                att_filename = att.get('filename') if isinstance(att, dict) else 'N/A'
                                att_data = bool(att.get('data')) if isinstance(att, dict) else False
                                att_file_path = att.get('file_path') if isinstance(att, dict) else 'N/A'
                                app.logger.error(f"     Attachment {idx}: {att_keys} -> filename: {att_filename}, data: {att_data}, file_path: {att_file_path}")
                        else:
                            app.logger.error(f"    DEBUG: No attachments in ticket data")
                        
                        # Check what metadata keys exist
                        metadata = db.get_ticket_metadata(ticket_id)
                        metadata_keys = [meta.get('key') for meta in metadata]
                        app.logger.error(f"    DEBUG: Available metadata keys: {metadata_keys}")
                        
                        # Show first few metadata entries
                        for idx, meta in enumerate(metadata[:3]):
                            app.logger.error(f"     Metadata {idx}: key='{meta.get('key')}', value_type={type(meta.get('value'))}")
                            
                    except Exception as debug_e:
                        app.logger.error(f"    DEBUG ERROR: Could not get debug info: {debug_e}")
                        
                    app.logger.warning(f"    SENDING EMPTY ATTACHMENT to n8n for debugging")
                    
            else:
                app.logger.error(f"ðŸ’¥ INVALID ATTACHMENT FORMAT: {attachment} (type: {type(attachment)})")
        
        # Final summary with critical alerts
        total_attachments = len(formatted_attachments)
        working_attachments = sum(1 for att in formatted_attachments if att['fileData'])
        failed_attachments = total_attachments - working_attachments
        
        app.logger.info(f"ðŸ“Ž EMAIL TEMPLATE FINAL SUMMARY:")
        app.logger.info(f"  - Total requested: {len(attachments)}")
        app.logger.info(f"  - Total processed: {total_attachments}")
        app.logger.info(f"  - With file data: {working_attachments}")
        app.logger.info(f"  - Failed/empty: {failed_attachments}")
        
        if failed_attachments > 0:
            app.logger.error(f"ðŸš¨ CRITICAL: {failed_attachments} attachments have NO FILE DATA - emails will be missing attachments!")
        
        if total_attachments == 0:
            app.logger.error(f"ðŸš¨ CRITICAL: NO ATTACHMENTS will be sent - webhook payload will have empty attachments array!")
        
        # Convert base64 attachments to n8n binary format
        binary_data = {}
        for i, attachment in enumerate(formatted_attachments):
            if attachment.get('fileData'):  # Only process attachments with data
                # Decode base64 to get actual file size
                try:
                    decoded_data = base64.b64decode(attachment['fileData'])
                    
                    # Determine MIME type
                    filename = attachment.get('fileName', 'attachment')
                    import mimetypes
                    mime_type, _ = mimetypes.guess_type(filename)
                    if not mime_type:
                        # Default MIME types based on extension
                        ext = filename.lower().split('.')[-1] if '.' in filename else ''
                        mime_types_map = {
                            'pdf': 'application/pdf',
                            'doc': 'application/msword',
                            'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                            'jpg': 'image/jpeg',
                            'jpeg': 'image/jpeg',
                            'png': 'image/png',
                            'txt': 'text/plain'
                        }
                        mime_type = mime_types_map.get(ext, 'application/octet-stream')
                    
                    # Create n8n binary data entry
                    binary_key = f"attachment_{i}" if len(formatted_attachments) > 1 else "data"
                    binary_data[binary_key] = {
                        "data": attachment['fileData'],  # Keep as base64 for n8n
                        "mimeType": mime_type,
                        "fileName": filename,
                        "fileSize": len(decoded_data)
                    }
                    
                    app.logger.info(f"ðŸ“¦ Created binary data for n8n: {binary_key} -> {filename} ({mime_type}, {len(decoded_data)} bytes)")
                    
                except Exception as e:
                    app.logger.error(f" Failed to process binary data for {attachment.get('fileName')}: {e}")
        
        # Create the webhook payload as an array with the exact same structure as reply webhook
        # Include multiple field names for n8n Microsoft Outlook node compatibility
        webhook_payload = [
            {
            "id": ticket_id,
            "threadId": ticket.get('thread_id', ''),
            "name": ticket.get('name', ''),
            "email": ticket.get('email', ''),
            "subject": subject,  # Use processed email subject  
            "body": email_body,        # Use enhanced email body with ticket ID
            "draft": f"Email sent via template - Subject: {subject}",
            "message": email_body,  # Email template body with ticket ID
            "replyMessage": email_body,
            "content": email_body,
            "classification": ticket.get('classification', 'General'),
            "priority": ticket.get('priority', 'Medium'),
            "date": current_timestamp,
            "messageId": ticket.get('message_id', f"email-template-{ticket_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}"),
            "attachments": formatted_attachments,  # Keep original format for compatibility
            "created_at": current_timestamp,
                # Email template specific fields - keeping same keys but different values
            "isEmailTemplate": True,
            "templateType": template_type,
            "emailSubject": subject,
            "emailBody": email_body,
            "canReplyToEmail": False,  # Email templates are outbound
            "isEmailOriginated": False,
            "ticketSource": "email_template",
            "recommendedOperation": "send"
        }
        ]
        # Send to BOTH webhooks for complete functionality:
        # 1. Original email template webhook for actual email sending
        # 2. Main webhook for data consistency with reply conversations
        
        # Original Email Template Webhook (for email sending functionality)
        EMAIL_TEMPLATE_WEBHOOK = "https://ffxtrading.app.n8n.cloud/webhook/fb4af014-26e6-4477-821f-917fc9b3ee96"
        
        # Create original format payload for email sending webhook
        email_sending_payload = {
            "json": webhook_payload[0],  # Use the same data structure
            "binary": binary_data
        }
        
        try:
            app.logger.info(f"ðŸš€ SENDING EMAIL TEMPLATE WEBHOOK (Email Sending) - Ticket: {ticket_id}, URL: {EMAIL_TEMPLATE_WEBHOOK}")
            
            # Send to original email template webhook for email sending
            response = requests.post(EMAIL_TEMPLATE_WEBHOOK, json=email_sending_payload, timeout=10)
            response.raise_for_status()
            
            app.logger.info(f" EMAIL TEMPLATE WEBHOOK (Email Sending) SUCCESS - Ticket: {ticket_id}, Status: {response.status_code}")
            
        except requests.exceptions.RequestException as e:
            app.logger.error(f" EMAIL TEMPLATE WEBHOOK (Email Sending) FAILED - Ticket: {ticket_id}, Error: {e}")
            if hasattr(e, 'response') and e.response is not None:
                app.logger.error(f" Email sending webhook response status: {e.response.status_code}")
                app.logger.error(f" Email sending webhook response content: {e.response.text}")
        except Exception as e:
            app.logger.error(f"ðŸ’¥ EMAIL TEMPLATE WEBHOOK (Email Sending) UNEXPECTED ERROR - Ticket: {ticket_id}, Error: {e}")
        
        # Main Webhook - REMOVED TO PREVENT DUPLICATE WEBHOOKS
        # Only EMAIL_TEMPLATE_WEBHOOK is needed for email template functionality
        app.logger.info(f"ðŸš€ DUPLICATE WEBHOOK REMOVED - Using only EMAIL_TEMPLATE_WEBHOOK for ticket: {ticket_id}")
        app.logger.info(f"ðŸ“§ Email template webhook sent successfully, no duplicate webhook needed")
        
        app.logger.info(f"ðŸŽ‰ EMAIL TEMPLATE COMPLETED - Ticket: {ticket_id}, Member: {member_id}")
        
        # Return status based on actual email sending result
        if email_success:
            return jsonify({
                'status': 'success',
                'message': f'Email sent successfully to {recipient_email}',
                'subject': subject,
                'preview_body': body[:200] + '...' if len(body) > 200 else body,
                'attachments_sent': len(email_attachments),
                'recipient': recipient_email
            })
        else:
            return jsonify({
                'status': 'warning',
                'message': f'Email processing completed but sending failed to {recipient_email}. Please check email configuration.',
                'subject': subject,
                'preview_body': body[:200] + '...' if len(body) > 200 else body,
                'attachments_prepared': len(email_attachments),
                'recipient': recipient_email
            }), 207  # 207 Multi-Status - partial success
        
    except Exception as e:
        import traceback
        app.logger.error(f"ðŸ’¥ CRITICAL EMAIL TEMPLATE ERROR - Ticket: {ticket_id}")
        app.logger.error(f"ðŸ’¥ Error: {str(e)}")
        app.logger.error(f"ðŸ’¥ Traceback: {traceback.format_exc()}")
        return jsonify({'status': 'error', 'message': f'Email template error: {str(e)}'}), 500

@app.route('/api/email-template/<template_type>/<ticket_id>')
def load_email_template(template_type, ticket_id):
    """Load email template - Check for n8n draft first, fallback to default template"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        # Import base64 for file encoding
        import base64
        app.logger.info(f"ðŸ” LOADING EMAIL TEMPLATE - Type: {template_type}, URL Ticket ID: {ticket_id}")
        
        # Get ticket data
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            app.logger.error(f"âŒ TICKET NOT FOUND - URL Ticket ID: {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Debug: Log the actual ticket data retrieved
        actual_ticket_id = ticket.get('ticket_id', 'NO_TICKET_ID_FIELD')
        app.logger.info(f"ðŸ” TICKET DATA RETRIEVED - URL Ticket ID: {ticket_id}, Actual Ticket ID: {actual_ticket_id}")
        
        # Check for mismatch
        if str(ticket_id) != str(actual_ticket_id):
            app.logger.warning(f"âš ï¸ TICKET ID MISMATCH DETECTED - URL: {ticket_id}, Database: {actual_ticket_id}")
            app.logger.warning(f"âš ï¸ This explains why email template shows different ticket ID than portal!")
            
            # FIX: Use the actual ticket ID from database for email templates
            app.logger.info(f"ðŸ”§ FIXING TICKET ID MISMATCH - Using database ticket ID: {actual_ticket_id} instead of URL: {ticket_id}")
            ticket_id = actual_ticket_id  # Update ticket_id to use the correct one from database
        
        # Check if n8n-generated draft exists
        # Try multiple possible draft fields: 'draft_body', 'draft', 'n8n_draft'
        n8n_draft = ticket.get('draft_body', '').strip()
        if not n8n_draft:
            n8n_draft = ticket.get('draft', '').strip()
        if not n8n_draft:
            n8n_draft = ticket.get('n8n_draft', '').strip()
        
        # Log draft detection for debugging
        app.logger.info(f"ðŸ” DRAFT DETECTION - Ticket: {ticket_id}")
        app.logger.info(f"   - draft_body: {ticket.get('draft_body', 'NOT_FOUND')}")
        app.logger.info(f"   - draft: {ticket.get('draft', 'NOT_FOUND')}")
        app.logger.info(f"   - n8n_draft: {ticket.get('n8n_draft', 'NOT_FOUND')}")
        app.logger.info(f"   - Final n8n_draft: {n8n_draft[:100] if n8n_draft else 'EMPTY'}")
        ticket_subject = ticket.get('subject', '')
        
        # Check if this is an email-created ticket by looking for email-specific fields
        is_email_ticket = ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id')
        
        # Get ticket attachments for template
        ticket_attachments = []
        
        # FIXED: Enhanced main ticket attachment processing for both email and manual tickets
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            app.logger.info(f"ðŸ“Ž FOUND {len(ticket['attachments'])} MAIN TICKET ATTACHMENTS")
            for i, att in enumerate(ticket['attachments']):
                filename = att.get('filename', att.get('original_name', 'unknown_file'))
                app.logger.info(f"ðŸ“Ž MAIN ATTACHMENT {i}: {filename}")
                
                # Include all attachments without filtering by name prefix
                if filename:
                    # Get the actual file data for the attachment
                    file_data = ""
                    file_size = 0
                    try:
                        # ðŸš€ ENHANCED: Better file data extraction with multiple fallback methods
                        app.logger.info(f"ðŸ“Ž ðŸ” ANALYZING ATTACHMENT STRUCTURE for {filename}:")
                        app.logger.info(f"ðŸ“Ž   - Has 'data' field: {bool(att.get('data'))}")
                        app.logger.info(f"ðŸ“Ž   - Has 'file_path' field: {bool(att.get('file_path'))}")
                        app.logger.info(f"ðŸ“Ž   - Has 'path' field: {bool(att.get('path'))}")
                        app.logger.info(f"ðŸ“Ž   - Has 'url' field: {bool(att.get('url'))}")
                        app.logger.info(f"ðŸ“Ž   - All attachment keys: {list(att.keys())}")
                        
                        if att.get('data'):  # If attachment already has base64 data
                            file_data = att.get('data')
                            file_size = len(base64.b64decode(file_data)) if file_data else 0
                            app.logger.info(f"ðŸ“Ž âœ… USING EXISTING BASE64 DATA: {filename} ({len(file_data)} chars, {file_size} bytes)")
                        else:
                            # ðŸš€ ENHANCED: Try multiple possible file path fields
                            possible_file_paths = [
                                att.get('file_path'),
                                att.get('path'),
                                att.get('url'),
                                att.get('filename'),  # Sometimes filename contains the path
                                os.path.join(UPLOAD_FOLDER, filename)  # Try with upload folder
                            ]
                            
                            file_data = ""
                            file_size = 0
                            
                            for file_path in possible_file_paths:
                                if not file_path:
                                    continue
                                    
                            app.logger.info(f"ðŸ“Ž ðŸ” ATTEMPTING TO READ FROM FILE PATH: {file_path}")
                            
                            # Try multiple possible path combinations
                            possible_paths = [
                                file_path,
                                os.path.join(os.getcwd(), file_path),
                                os.path.join(UPLOAD_FOLDER, file_path),
                                    os.path.join(os.getcwd(), 'uploads', file_path),
                                    os.path.join(UPLOAD_FOLDER, os.path.basename(file_path))  # Try just filename in upload folder
                            ]
                            
                            for path_attempt in possible_paths:
                                app.logger.info(f"ðŸ“Ž ðŸ” TRYING PATH: {path_attempt}")
                                if os.path.exists(path_attempt):
                                    try:
                                        with open(path_attempt, 'rb') as f:
                                            file_content = f.read()
                                            file_data = base64.b64encode(file_content).decode('utf-8')
                                            file_size = len(file_content)
                                        app.logger.info(f"ðŸ“Ž âœ… SUCCESSFULLY READ FILE FROM PATH: {filename} ({len(file_data)} chars, {file_size} bytes)")
                                        break
                                    except Exception as e:
                                        app.logger.warning(f"ðŸ“Ž âš ï¸ FAILED TO READ FILE FROM {path_attempt}: {e}")
                                        continue
                                else:
                                    app.logger.info(f"ðŸ“Ž ðŸ” PATH NOT FOUND: {path_attempt}")
                                
                                if file_data:  # If we successfully read the file, break out of the file path loop
                                    break
                            
                            if not file_data:
                                app.logger.warning(f"ðŸ“Ž âŒ ALL FILE PATH ATTEMPTS FAILED FOR: {filename}")
                                app.logger.warning(f"ðŸ“Ž   - Tried paths: {possible_file_paths}")
                                app.logger.warning(f"ðŸ“Ž   - UPLOAD_FOLDER: {UPLOAD_FOLDER}")
                                app.logger.warning(f"ðŸ“Ž   - Current working directory: {os.getcwd()}")
                    except Exception as e:
                        app.logger.error(f"ðŸ“Ž âŒ ERROR READING FILE DATA FOR {filename}: {e}")
                    
                    # Determine if this is a manual ticket attachment
                    is_manual = not is_email_ticket or att.get('is_manual_ticket_attachment', False)
                    
                    ticket_attachments.append({
                        'name': filename,
                        'file_path': f"/api/tickets/{ticket_id}/attachments/{i}/download",
                        'key': str(i),
                        'fileData': file_data,  # Include actual file data
                        'size': file_size,
                        'type': 'file',
                        'has_data': bool(file_data),  # FIXED: Flag to indicate if file has real data
                        'is_manual_ticket_attachment': is_manual,  # FIXED: Flag to identify manual ticket attachments
                        'ticket_index': i  # FIXED: Add ticket index for proper download URL generation
                    })
                    
                    if file_data:
                        app.logger.info(f"ðŸ“Ž âœ… ADDED MAIN ATTACHMENT WITH DATA: {filename} (data: {len(file_data)} chars, size: {file_size} bytes, manual: {is_manual})")
                    else:
                        app.logger.warning(f"ðŸ“Ž âš ï¸ ADDED MAIN ATTACHMENT WITHOUT DATA: {filename} (manual: {is_manual})")
                else:
                    app.logger.info(f"ðŸ“Ž SKIPPING MAIN ATTACHMENT: {filename} (no filename)")
        else:
            app.logger.info(f"ðŸ“Ž NO MAIN TICKET ATTACHMENTS FOUND")
        
        # ENHANCED DUPLICATE REMOVAL: Remove any duplicate attachments by name, path, and content to prevent showing the same file twice
        seen_names = set()
        seen_paths = set()
        seen_content_hashes = set()
        unique_attachments = []
        
        app.logger.info(f"ðŸ“Ž PROCESSING {len(ticket_attachments)} ATTACHMENTS FOR ENHANCED DUPLICATE REMOVAL")
        
        for att in ticket_attachments:
            name = att['name']
            path = att['file_path']
            file_data = att.get('fileData', '')
            
            # Create a content hash for duplicate detection
            content_hash = f"{len(file_data)}_{att.get('size', 0)}"
            
            # Check for exact name duplicates
            if name in seen_names:
                app.logger.info(f"ðŸ“Ž REMOVING DUPLICATE BY NAME: {name} (already exists)")
                continue
                
            # Check for path duplicates (same file, different name)
            if path in seen_paths:
                app.logger.info(f"ðŸ“Ž REMOVING DUPLICATE BY PATH: {name} (path already exists: {path})")
                continue
                
            # Check for content duplicates (same file content, different name/path)
            if content_hash in seen_content_hashes and file_data:
                app.logger.info(f"ðŸ“Ž REMOVING DUPLICATE BY CONTENT: {name} (same content as existing file)")
                continue
                
            # Check for similar names (e.g., "image.jpg" vs "image (1).jpg")
            is_similar = False
            for seen_name in seen_names:
                # Remove common suffixes like (1), (2), _copy, etc.
                base_name = seen_name.lower().replace(' (1)', '').replace(' (2)', '').replace('_copy', '').replace('_copy1', '').replace('_copy2', '')
                current_base = name.lower().replace(' (1)', '').replace(' (2)', '').replace('_copy', '').replace('_copy1', '').replace('_copy2', '')
                
                # Check if base names are similar (allowing for small differences)
                if base_name == current_base or base_name in current_base or current_base in base_name:
                    app.logger.info(f"ðŸ“Ž REMOVING SIMILAR DUPLICATE: {name} (similar to: {seen_name})")
                    is_similar = True
                    break
            
            if is_similar:
                continue
                
            # Add to unique attachments
            seen_names.add(name)
            seen_paths.add(path)
            if file_data:
                seen_content_hashes.add(content_hash)
            unique_attachments.append(att)
            app.logger.info(f"ðŸ“Ž ADDING UNIQUE ATTACHMENT: {name}")
        
        app.logger.info(f"ðŸ“Ž ENHANCED DUPLICATE REMOVAL COMPLETE: {len(unique_attachments)}/{len(ticket_attachments)} attachments kept")
        ticket_attachments = unique_attachments
        
        # Only add metadata attachments for manually created tickets (not email-created tickets)
        if not is_email_ticket:
            # FIXED: Enhanced metadata attachment processing for manual tickets
            app.logger.info(f"ðŸ“Ž PROCESSING METADATA ATTACHMENTS FOR MANUAL TICKET {ticket_id}")
            metadata = db.get_ticket_metadata(ticket_id)
            app.logger.info(f"ðŸ“Ž FOUND {len(metadata)} METADATA ENTRIES")
            
            for meta in metadata:
                if meta.get('key', '').startswith('attachment_'):
                    try:
                        app.logger.info(f"ðŸ“Ž PROCESSING METADATA KEY: {meta.get('key')}")
                        attachment_data = json.loads(meta.get('value', '{}'))
                        if attachment_data and isinstance(attachment_data, dict):
                            app.logger.info(f"ðŸ“Ž ATTACHMENT DATA KEYS: {list(attachment_data.keys())}")
                            
                            # FIXED: Enhanced file data retrieval with multiple fallback methods
                            file_data = ""
                            file_size = 0
                            attachment_name = attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File'))
                            
                            # PRIORITY 1: Use base64 data if available in metadata
                            if attachment_data.get('data'):
                                file_data = attachment_data.get('data')
                                try:
                                    file_size = len(base64.b64decode(file_data)) if file_data else 0
                                    app.logger.info(f"ðŸ“Ž âœ… USING METADATA BASE64 DATA: {attachment_name} ({len(file_data)} chars, {file_size} bytes)")
                                except Exception as e:
                                    app.logger.warning(f"ðŸ“Ž âš ï¸ INVALID BASE64 DATA FOR {attachment_name}: {e}")
                                    file_data = ""
                                    file_size = 0
                            
                            # PRIORITY 2: If no base64 data, try to read from file path
                            if not file_data and attachment_data.get('path'):
                                file_path_from_meta = attachment_data.get('path')
                                app.logger.info(f"ðŸ“Ž ðŸ” ATTEMPTING TO READ FILE FROM PATH: {file_path_from_meta}")
                                
                                # Try multiple possible path combinations
                                possible_paths = [
                                    os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                    os.path.join(os.getcwd(), file_path_from_meta),
                                    file_path_from_meta,
                                    os.path.join(UPLOAD_FOLDER, file_path_from_meta)
                                ]
                                
                                for path_attempt in possible_paths:
                                    app.logger.info(f"ðŸ“Ž ðŸ” TRYING PATH: {path_attempt}")
                                    if os.path.exists(path_attempt):
                                        try:
                                            with open(path_attempt, 'rb') as f:
                                                file_content = f.read()
                                                file_data = base64.b64encode(file_content).decode('utf-8')
                                                file_size = len(file_content)
                                            app.logger.info(f"ðŸ“Ž âœ… SUCCESSFULLY READ FILE FROM PATH: {attachment_name} ({len(file_data)} chars, {file_size} bytes)")
                                            break
                                        except Exception as e:
                                            app.logger.warning(f"ðŸ“Ž âš ï¸ FAILED TO READ FILE FROM {path_attempt}: {e}")
                                            continue
                                    else:
                                        app.logger.info(f"ðŸ“Ž ðŸ” PATH NOT FOUND: {path_attempt}")
                                else:
                                    app.logger.warning(f"ðŸ“Ž âŒ ALL FILE PATHS FAILED FOR: {attachment_name}")
                            
                            # PRIORITY 3: If still no data, try to find in main ticket attachments
                            if not file_data and ticket.get('has_attachments', False) and 'attachments' in ticket:
                                app.logger.info(f"ðŸ“Ž ðŸ” SEARCHING MAIN TICKET ATTACHMENTS FOR: {attachment_name}")
                                for i, att in enumerate(ticket['attachments']):
                                    if (att.get('filename') == attachment_data.get('filename') or 
                                        att.get('original_name') == attachment_data.get('original_name') or
                                        att.get('filename') == attachment_name or
                                        att.get('original_name') == attachment_name):
                                        
                                        if att.get('data'):
                                            file_data = att.get('data')
                                            try:
                                                file_size = len(base64.b64decode(file_data)) if file_data else 0
                                                app.logger.info(f"ðŸ“Ž âœ… FOUND DATA IN MAIN ATTACHMENTS: {attachment_name} ({len(file_data)} chars, {file_size} bytes)")
                                                break
                                            except Exception as e:
                                                app.logger.warning(f"ðŸ“Ž âš ï¸ INVALID DATA IN MAIN ATTACHMENTS FOR {attachment_name}: {e}")
                                                continue
                            
                            # Include all metadata attachments without filtering by name prefix
                            if attachment_name:
                                # Determine the correct file path for the attachment
                                attachment_index = None
                                if ticket.get('has_attachments', False) and 'attachments' in ticket:
                                    for i, att in enumerate(ticket['attachments']):
                                        if (att.get('filename') == attachment_data.get('filename') or 
                                            att.get('original_name') == attachment_data.get('original_name')):
                                            attachment_index = i
                                            break
                                
                                if attachment_index is not None:
                                    file_path = f"/api/tickets/{ticket_id}/attachments/{attachment_index}/download"
                                else:
                                    # Fallback: use the metadata key as index
                                    file_path = f"/api/tickets/{ticket_id}/attachments/{len(ticket_attachments)}/download"
                                
                                # Add attachment to the list
                                ticket_attachments.append({
                                    'name': attachment_name,
                                    'file_path': file_path,
                                    'key': str(attachment_index) if attachment_index is not None else str(len(ticket_attachments)),
                                    'fileData': file_data,  # Include actual file data
                                    'size': file_size,
                                    'type': 'file',
                                    'has_data': bool(file_data),  # FIXED: Flag to indicate if file has real data
                                    'is_manual_ticket_attachment': True  # FIXED: Flag to identify manual ticket attachments
                                })
                                
                                if file_data:
                                    app.logger.info(f"ðŸ“Ž âœ… ADDED METADATA ATTACHMENT WITH DATA: {attachment_name} (data: {len(file_data)} chars, size: {file_size} bytes)")
                                else:
                                    app.logger.warning(f"ðŸ“Ž âš ï¸ ADDED METADATA ATTACHMENT WITHOUT DATA: {attachment_name}")
                            else:
                                app.logger.info(f"ðŸ“Ž SKIPPING METADATA ATTACHMENT: {attachment_name} (no attachment name)")
                    except (json.JSONDecodeError, TypeError) as e:
                        app.logger.warning(f"ðŸ“Ž âŒ FAILED TO PARSE METADATA FOR KEY {meta.get('key')}: {e}")
                        continue
            
            # ðŸš€ FIXED: REMOVED COMMON DOCUMENTS FROM EMAIL TEMPLATE
            # Common documents are ONLY for conversation module drag & drop
            # Email template should ONLY show original ticket attachments
            app.logger.info(f"ðŸ“„ SKIPPING COMMON DOCUMENTS FOR EMAIL TEMPLATE - They are only for conversation module")
        
        if n8n_draft:
            # Use n8n-generated draft
            app.logger.info(f" USING N8N DRAFT - Ticket: {ticket_id}, Draft length: {len(n8n_draft)}")
            
            # Create subject from ticket subject or generate one
            if ticket_subject:
                draft_subject = f"Re: {ticket_subject}"
            else:
                draft_subject = replace_email_placeholders(
                    f"Response to your inquiry - <Ticket Number> | Auto Assist Group", 
                    ticket_id
                )
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
            ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
            enhanced_draft_body = ticket_id_header + n8n_draft
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            
                    # FINAL COMPREHENSIVE DUPLICATE CHECK: Ensure no duplicates remain before returning
        final_attachments = []
        final_seen_names = set()
        final_seen_paths = set()
        final_seen_content = set()
        
        app.logger.info(f"ðŸ“Ž FINAL COMPREHENSIVE DUPLICATE CHECK: Processing {len(ticket_attachments)} attachments")
        
        for att in ticket_attachments:
            name = att['name']
            path = att['file_path']
            file_data = att.get('fileData', '')
            content_hash = f"{len(file_data)}_{att.get('size', 0)}"
            
            # Check for any type of duplicate
            is_duplicate = False
            
            if name in final_seen_names:
                app.logger.warning(f"ðŸš¨ FINAL DUPLICATE REMOVAL: {name} - duplicate name detected!")
                is_duplicate = True
            elif path in final_seen_paths:
                app.logger.warning(f"ðŸš¨ FINAL DUPLICATE REMOVAL: {name} - duplicate path detected: {path}")
                is_duplicate = True
            elif file_data and content_hash in final_seen_content:
                app.logger.warning(f"ðŸš¨ FINAL DUPLICATE REMOVAL: {name} - duplicate content detected!")
                is_duplicate = True
            
            if not is_duplicate:
                final_attachments.append(att)
                final_seen_names.add(name)
                final_seen_paths.add(path)
                if file_data:
                    final_seen_content.add(content_hash)
                app.logger.info(f"ðŸ“Ž FINAL CHECK PASSED: {name}")
            else:
                app.logger.warning(f"ðŸš¨ FINAL CHECK FAILED: {name} - removed as duplicate")
        
        app.logger.info(f"ðŸ“Ž FINAL COMPREHENSIVE CHECK COMPLETE: {len(final_attachments)}/{len(ticket_attachments)} attachments kept")
        
        # ðŸš€ CRITICAL DEBUGGING: Log exactly what we're returning
        app.logger.info(f"ðŸš€ CRITICAL DEBUG: About to return {len(final_attachments)} attachments to frontend")
        for i, att in enumerate(final_attachments):
            app.logger.info(f"ðŸš€ CRITICAL DEBUG - Attachment {i}: {att}")
            app.logger.info(f"  - Name: {att.get('name')}")
            app.logger.info(f"  - Type: {att.get('type')}")
            app.logger.info(f"  - File Path: {att.get('file_path')}")
            app.logger.info(f"  - Has Data: {att.get('has_data')}")
            app.logger.info(f"  - File Data Length: {len(att.get('fileData', ''))}")
            app.logger.info(f"  - All Keys: {list(att.keys())}")
        
        # Enhanced logging for debugging ticket attachments
        for i, att in enumerate(final_attachments):
            app.logger.info(f"ðŸ“Ž FINAL ATTACHMENT {i}: {att.get('name')} (has_data: {att.get('has_data', False)}, size: {att.get('size', 0)}, type: {att.get('type', 'unknown')})")
            if att.get('is_manual_ticket_attachment'):
                app.logger.info(f"ðŸ“Ž   -> MANUAL TICKET ATTACHMENT: {att.get('name')}")
        
        if n8n_draft:
            # Use n8n-generated draft
            app.logger.info(f"ðŸ“ USING N8N DRAFT - Ticket: {ticket_id}, Draft length: {len(n8n_draft)}")
            
            # Create subject from ticket subject or generate one
            if ticket_subject:
                draft_subject = f"Re: {ticket_subject}"
            else:
                draft_subject = replace_email_placeholders(
                    f"Response to your inquiry - <Ticket Number> | Auto Assist Group", 
                    ticket_id
                )
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
            ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
            enhanced_draft_body = ticket_id_header + n8n_draft
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            
            return jsonify({
                'status': 'success',
                'template': {
                    'subject': draft_subject,
                    'body': enhanced_draft_body,
                    'attachments': final_attachments,
                    'has_draft': True,
                    'content_source': 'draft',
                    'source_info': 'n8n-generated draft response (with ticket ID header)'
                }
            })
        
        # ðŸš€ ENHANCED: If no draft found, try to generate one based on ticket data
        elif ticket.get('processing_method') == 'n8n_tickets_api' or ticket.get('processing_method') == 'n8n_email_processor':
            app.logger.info(f"ðŸ“ NO DRAFT FOUND - Generating contextual draft for N8N ticket {ticket_id}")
            
            # Generate contextual draft based on ticket data
            contextual_draft = generate_email_draft_response(ticket)
            
            if contextual_draft and contextual_draft.strip():
                app.logger.info(f"ðŸ“ GENERATED CONTEXTUAL DRAFT for ticket {ticket_id}: {contextual_draft[:200]}...")
                
                # ðŸ”§ REPLACE PLACEHOLDERS in the contextual draft
                contextual_draft = replace_email_placeholders(contextual_draft, ticket_id)
                app.logger.info(f"ðŸ”§ REPLACED PLACEHOLDERS in contextual draft for ticket {ticket_id}")
                
                # Create subject from ticket subject or generate one
                if ticket_subject:
                    draft_subject = f"Re: {ticket_subject}"
                else:
                    draft_subject = replace_email_placeholders(
                        f"Response to your inquiry - <Ticket Number> | Auto Assist Group", 
                        ticket_id
                    )
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
                ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
                enhanced_draft_body = ticket_id_header + contextual_draft
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO CONTEXTUAL DRAFT - Ticket: {ticket_id}")
                
                return jsonify({
                    'status': 'success',
                    'template': {
                        'subject': draft_subject,
                        'body': enhanced_draft_body,
                        'attachments': final_attachments,
                        'has_draft': True,
                        'content_source': 'generated_contextual',
                        'source_info': 'contextual draft generated for N8N ticket (with ticket ID header)'
                    }
                })
        
        else:
            # Fallback to default template with same schema
            app.logger.info(f"ðŸ“ USING FALLBACK TEMPLATE - Ticket: {ticket_id} (no n8n draft found)")
            app.logger.error(f"ðŸš¨ DEBUG: Why is no draft found?")
            app.logger.error(f"ðŸš¨ DEBUG: n8n_draft = '{n8n_draft}'")
            app.logger.error(f"ðŸš¨ DEBUG: ticket.get('draft') = '{ticket.get('draft', 'NOT_FOUND')}'")
            app.logger.error(f"ðŸš¨ DEBUG: ticket.get('draft_body') = '{ticket.get('draft_body', 'NOT_FOUND')}'")
            app.logger.error(f"ðŸš¨ DEBUG: ticket.get('n8n_draft') = '{ticket.get('n8n_draft', 'NOT_FOUND')}'")
            app.logger.error(f"ðŸš¨ DEBUG: processing_method = '{ticket.get('processing_method', 'NOT_FOUND')}'")
            
            # Generate fallback template matching n8n draft schema
            if template_type == 'warranty_claim':
                # Use warranty template
                subject = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['subject'], ticket_id)
                body = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['body'], ticket_id)
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF WARRANTY EMAIL BODY
                ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
                enhanced_body = ticket_id_header + body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO WARRANTY EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
                
                return jsonify({
                    'status': 'success',
                    'template': {
                        'subject': subject,
                        'body': enhanced_body,
                        'attachments': final_attachments,
                        'has_draft': False,
                        'content_source': 'default_warranty',
                        'source_info': 'default warranty template (with ticket ID header)'
                    }
                })
            else:
                # Generate smart fallback based on ticket data
                customer_name = ticket.get('name', 'Valued Customer')
                first_name = customer_name.split()[0] if customer_name else 'Customer'
                
                subject = replace_email_placeholders(
                    f"Your inquiry - <Ticket Number> | Auto Assist Group", 
                    ticket_id
                )
                
                # Generate contextual response using the same logic as n8n
                body = generate_email_draft_response(ticket)
                if not body.strip():
                    # Ultimate fallback
                    body = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your inquiry and our team is reviewing the details. We will respond to your request within 1-2 business days.

If you have any urgent questions in the meantime, please don't hesitate to contact us.

Best regards,
Auto Assist Group - Customer Service Team

(Ticket ID: {ticket_id})"""
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
                ticket_id_header = f""
                enhanced_body =  body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO FALLBACK EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            
            return jsonify({
                'status': 'success',
                'template': {
                    'subject': subject,
                    'body': enhanced_body,
                    'attachments': final_attachments,
                    'has_draft': False,
                    'content_source': 'template',
                    'source_info': 'Auto-generated template with ticket ID header (no n8n draft available)'
                }
            })
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR LOADING EMAIL TEMPLATE - Ticket: {ticket_id}, Error: {str(e)}")
        return jsonify({'status': 'error', 'message': f'Error loading template: {str(e)}'}), 500

@app.route('/api/debug/attachments/<ticket_id>')
def debug_attachments(ticket_id):
    """Debug endpoint to inspect attachment processing for a specific ticket"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Get all attachment sources
        main_attachments = ticket.get('attachments', [])
        metadata = db.get_ticket_metadata(ticket_id)
        metadata_attachments = []
        
        for meta in metadata:
            if meta.get('key', '').startswith('attachment_'):
                try:
                    attachment_data = json.loads(meta.get('value', '{}'))
                    if attachment_data and isinstance(attachment_data, dict):
                        metadata_attachments.append({
                            'key': meta.get('key'),
                            'data': attachment_data,
                            'parsed_successfully': True
                        })
                except (json.JSONDecodeError, TypeError):
                    metadata_attachments.append({
                        'key': meta.get('key'),
                        'data': meta.get('value'),
                        'parsed_successfully': False
                    })
        
        # Get replies and their attachments
        replies = db.get_replies_by_ticket(ticket_id)
        reply_attachments = []
        for reply in replies:
            reply_attachments.append({
                'reply_id': str(reply.get('_id', '')),
                'attachments_count': len(reply.get('attachments', [])),
                'attachments': reply.get('attachments', []),
                'created_at': reply.get('created_at', ''),
                'source': reply.get('source', 'unknown')
            })
        
        # Get common documents
        common_documents = []
        try:
            common_docs = db.get_all_common_documents()
            for doc in common_docs:
                common_documents.append({
                    'id': str(doc.get('_id', '')),
                    'name': doc.get('name', 'Unknown'),
                    'filename': doc.get('file_name', doc.get('filename', 'unknown'))
                })
        except Exception as e:
            common_documents = [{'error': str(e)}]
        
        debug_info = {
            'ticket_id': ticket_id,
            'ticket_has_attachments': ticket.get('has_attachments', False),
            'main_attachments_count': len(main_attachments),
            'main_attachments': main_attachments,
            'metadata_attachments_count': len(metadata_attachments),
            'metadata_attachments': metadata_attachments,
            'replies_count': len(replies),
            'reply_attachments': reply_attachments,
            'common_documents_count': len(common_documents),
            'common_documents': common_documents,
            'ticket_source': {
                'is_email_ticket': ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id'),
                'processing_method': ticket.get('processing_method', 'unknown'),
                'has_warranty': ticket.get('has_warranty', False)
            }
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info
        })
        
    except Exception as e:
        app.logger.error(f"Debug attachments error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500





@app.route('/api/email/preview-template', methods=['POST'])
def preview_template():
    """Preview email template with placeholders replaced"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        ticket_id = data.get('ticket_id')
        template_type = data.get('template_type', 'warranty')
        
        if not ticket_id:
            return jsonify({'status': 'error', 'message': 'Ticket ID required'}), 400
        
        # Get template and replace placeholders
        if template_type == 'warranty':
            subject = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['subject'], ticket_id)
            body = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['body'], ticket_id)
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF PREVIEW EMAIL BODY
            ticket_id_header = f""
            enhanced_body = ticket_id_header + body
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO PREVIEW EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
        else:
            subject = replace_email_placeholders('<Ticket Number> - Follow Up', ticket_id)
            body = replace_email_placeholders('Dear <First Name> <Surname>,\n\nRegarding your ticket <Ticket Number>...\n\nBest regards,\nAuto Assist Group', ticket_id)
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF PREVIEW EMAIL BODY
            ticket_id_header = f""
            enhanced_body = ticket_id_header + body
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO PREVIEW EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
        
        return jsonify({
            'status': 'success',
            'subject': subject,
            'body': enhanced_body,
            'template_name': DEFAULT_WARRANTY_TEMPLATE['name']
        })
        
    except Exception as e:
        app.logger.error(f"Error previewing template: {str(e)}")
        return jsonify({'status': 'error', 'message': 'Error previewing template'}), 500

# ============ ROLES MANAGEMENT API ENDPOINTS ============

@app.route('/api/roles', methods=['GET', 'POST'])
def handle_roles():
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 403
    
    if request.method == 'GET':
        try:
            roles = db.get_all_roles()
            # Convert ObjectIds to strings for JSON serialization
            for role in roles:
                role['_id'] = str(role['_id'])
                role['id'] = role['_id']  # Add 'id' field for frontend compatibility
            return jsonify({'status': 'success', 'roles': roles})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500
    
    elif request.method == 'POST':
        try:
            data = request.json
            required_fields = ['name', 'description']
            
            if not all(field in data for field in required_fields):
                return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400
            
            role_data = {
                'name': data['name'],
                'description': data['description'],
                'permissions': data.get('permissions', []),
                'level': data.get('level', 3),
                'color': data.get('color', '#6b7280'),
                'is_default': False
            }
            
            db.create_role(role_data)
            return jsonify({'status': 'success', 'message': 'Role created successfully'})
        except ValueError as e:
            return jsonify({'status': 'error', 'message': str(e)}), 400
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500

# Status Management API Endpoints (Missing from original)
@app.route('/api/admin/statuses', methods=['GET', 'POST'])
def manage_statuses():
    """Manage ticket statuses (GET all statuses, POST new status)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        
        if request.method == 'GET':
            # Get all statuses
            statuses = db.get_all_ticket_statuses()
            
            # Convert ObjectId to string for JSON serialization
            for status in statuses:
                status['_id'] = str(status['_id'])
            
            return jsonify({
                'status': 'success',
                'statuses': statuses
            })
        
        elif request.method == 'POST':
            # Create new status
            data = request.get_json()
            
            # Validate required fields
            if not data.get('name'):
                return jsonify({'status': 'error', 'message': 'Status name is required'}), 400
            
            status_data = {
                'name': data['name'],
                'color': data.get('color', '#6b7280'),
                'description': data.get('description', ''),
                'is_active': True
            }
            
            status_id = db.create_ticket_status(status_data)
            return jsonify({
                'status': 'success',
                'message': 'Status created successfully',
                'status_id': str(status_id)
            })
            
    except Exception as e:
        logging.error(f"Error managing statuses: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/statuses/<status_id>', methods=['PUT', 'DELETE'])
def manage_status(status_id):
    """Update or delete specific status"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        
        if request.method == 'PUT':
            # Update status
            data = request.get_json()
            update_data = {}
            
            if 'name' in data:
                update_data['name'] = data['name']
            if 'color' in data:
                update_data['color'] = data['color']
            if 'description' in data:
                update_data['description'] = data['description']
            
            result = db.update_ticket_status_config(status_id, update_data)
            
            if result.modified_count > 0:
                return jsonify({'status': 'success', 'message': 'Status updated successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Status not found or no changes made'}), 404
                
        elif request.method == 'DELETE':
            # Deactivate status (soft delete)
            result = db.deactivate_ticket_status(status_id)
            
            if result.modified_count > 0:
                return jsonify({'status': 'success', 'message': 'Status deactivated successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Status not found'}), 404
                
    except Exception as e:
        logging.error(f"Error managing status {status_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/roles/<role_id>', methods=['PUT', 'DELETE'])
def manage_role(role_id):
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 403
    
    if request.method == 'PUT':
        try:
            data = request.json
            update_data = {}
            
            if 'name' in data:
                update_data['name'] = data['name']
            if 'description' in data:
                update_data['description'] = data['description']
            if 'permissions' in data:
                update_data['permissions'] = data['permissions']
            if 'level' in data:
                update_data['level'] = data['level']
            if 'color' in data:
                update_data['color'] = data['color']
            
            if db.update_role(role_id, update_data):
                return jsonify({'status': 'success', 'message': 'Role updated successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Role not found or no changes made'}), 404
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500
    
    elif request.method == 'DELETE':
        try:
            if db.delete_role(role_id):
                return jsonify({'status': 'success', 'message': 'Role deleted successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Role not found'}), 404
        except ValueError as e:
            return jsonify({'status': 'error', 'message': str(e)}), 400
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/replies/<reply_id>/attachments/<int:attachment_index>/download')
def download_reply_attachment(reply_id, attachment_index):
    """Download attachment from a specific reply"""
    try:
        # Check authentication
        if 'member_id' not in session:
            return jsonify({'error': 'Authentication required'}), 401
        
        db = get_db()
        
        # Get the reply
        reply = db.replies.find_one({'_id': ObjectId(reply_id)})
        if not reply:
            return jsonify({'error': 'Reply not found'}), 404
        
        # Check if user has access to this ticket
        ticket = db.tickets.find_one({'ticket_id': reply['ticket_id']})
        if not ticket:
            return jsonify({'error': 'Associated ticket not found'}), 404
        
        # Get attachments from reply
        attachments = reply.get('attachments', [])
        
        # FIXED: Map filtered index to actual attachment index
        # The frontend passes filtered indices, but we need to find the actual downloadable attachment
        downloadable_attachments = []
        for i, att in enumerate(attachments):
            # Enhanced detection: check for type, source, or fileData presence
            is_downloadable = (
                att.get('type') == 'file' or 
                att.get('source') in ['webhook_base64', 'webhook', 'simple_attachments'] or 
                att.get('fileData') or  # Check for fileData (base64 content)
                att.get('data') or      # Check for data field
                not att.get('type')     # Fallback for attachments without type
            )
            
            if is_downloadable:
                downloadable_attachments.append((i, att))  # Store (original_index, attachment)
        
        # Check if the requested filtered index is valid
        if attachment_index >= len(downloadable_attachments):
            app.logger.error(f" FILTERED ATTACHMENT INDEX OUT OF RANGE: Requested {attachment_index}, but only {len(downloadable_attachments)} downloadable attachments exist")
            available_filtered_indices = list(range(len(downloadable_attachments)))
            app.logger.error(f" Available filtered indices: {available_filtered_indices}")
            return jsonify({
                'error': 'Filtered attachment index out of range',
                'requested_index': attachment_index,
                'total_downloadable_attachments': len(downloadable_attachments),
                'total_attachments': len(attachments),
                'available_filtered_indices': available_filtered_indices,
                'attachment_types': [att.get('type') for att in attachments],
                'attachment_sources': [att.get('source') for att in attachments]
            }), 404
        
        # Get the actual attachment using the filtered index
        original_index, attachment = downloadable_attachments[attachment_index]
        
        # Enhanced attachment type checking for webhook attachments
        attachment_type = attachment.get('type')
        if attachment_type == 'text_reference':
            # Handle text reference attachments - these are not downloadable files
            return jsonify({
                'error': 'This is a text reference attachment, not a downloadable file',
                'attachment_info': {
                    'type': 'text_reference',
                    'name': attachment.get('name', 'Document Reference'),
                    'description': attachment.get('description', '')
                }
            }), 400
        elif attachment_type not in ['file', 'webhook_base64'] and not attachment.get('fileData') and not attachment.get('data'):
            # Only reject if no fileData or data is present
            app.logger.error(f" Invalid attachment type: {attachment_type}. Expected 'file' or 'webhook_base64' or attachment with fileData")
            app.logger.error(f" Full attachment data: {attachment}")
            return jsonify({'error': f'Invalid attachment type: {attachment_type}'}), 400
        
        # Get file information - handle both webhook and regular attachments
        filename = attachment.get('filename') or attachment.get('name', 'unknown_file')
        file_path = attachment.get('path', '')
        # Check for base64 data in multiple possible fields
        base64_data = attachment.get('data', '') or attachment.get('fileData', '')
        

        
        # FIXED: Priority 1 - Use base64 data if available (most reliable)
        if base64_data and len(base64_data) > 10:
            try:
                app.logger.info(f"ðŸ“Ž Using base64 data for reply attachment: {filename} ({len(base64_data)} chars)")
                file_content = base64.b64decode(base64_data)
                
                # Create response with file content
                response = make_response(file_content)
                response.headers['Content-Type'] = get_mime_type(filename)
                response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
                response.headers['Content-Length'] = str(len(file_content))
                return response
                
            except Exception as e:
                app.logger.error(f"ðŸ“Ž Error decoding base64 data for {filename}: {e}")
                # Fall back to file path method
        
        # FIXED: Priority 2 - Try to serve the file from disk
        if file_path and os.path.exists(file_path):
            # File exists at original path
            app.logger.info(f" Serving file from original path: {file_path}")
            return send_file(
                file_path,
                as_attachment=True,
                download_name=filename,
                mimetype=get_mime_type(filename)
            )
        else:
            # Try uploads directory
            upload_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path) if file_path else filename)
            app.logger.info(f" Trying uploads directory: {upload_path}")
            
            if os.path.exists(upload_path):
                app.logger.info(f" Serving file from uploads: {upload_path}")
                return send_file(
                    upload_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            else:
                app.logger.error(f"ðŸ“Ž Reply attachment file not found: {file_path} or {upload_path}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER: {UPLOAD_FOLDER}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER exists: {os.path.exists(UPLOAD_FOLDER)}")
                if os.path.exists(UPLOAD_FOLDER):
                    app.logger.error(f"ðŸ“Ž Files in UPLOAD_FOLDER: {os.listdir(UPLOAD_FOLDER)}")
                
                # FIXED: Enhanced error response with attachment details
                return jsonify({
                    'error': 'File not found on server',
                    'attachment_info': {
                        'filename': filename,
                        'type': attachment_type,
                        'has_base64_data': bool(base64_data),
                        'file_path': file_path,
                        'upload_path': upload_path
                    }
                }), 404
        
    except Exception as e:
        app.logger.error(f" Error downloading reply attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Failed to download attachment'}), 500

@app.route('/api/replies/<reply_id>/attachments/<int:attachment_index>/preview')
def preview_reply_attachment(reply_id, attachment_index):
    """Preview attachment from a specific reply (for images, PDFs, etc.)"""
    try:
        # Check authentication
        if 'member_id' not in session:
            return jsonify({'error': 'Authentication required'}), 401
        
        db = get_db()
        
        # Get the reply
        reply = db.replies.find_one({'_id': ObjectId(reply_id)})
        if not reply:
            return jsonify({'error': 'Reply not found'}), 404
        
        # Check if user has access to this ticket
        ticket = db.tickets.find_one({'ticket_id': reply['ticket_id']})
        if not ticket:
            return jsonify({'error': 'Associated ticket not found'}), 404
        
        # Get attachments from reply
        attachments = reply.get('attachments', [])
        
        # FIXED: Map filtered index to actual attachment index
        # The frontend passes filtered indices, but we need to find the actual downloadable attachment
        downloadable_attachments = []
        for i, att in enumerate(attachments):
            # Enhanced detection: check for type, source, or fileData presence
            is_downloadable = (
                att.get('type') == 'file' or 
                att.get('source') in ['webhook_base64', 'webhook', 'simple_attachments'] or 
                att.get('fileData') or  # Check for fileData (base64 content)
                att.get('data') or      # Check for data field
                not att.get('type')     # Fallback for attachments without type
            )
            
            if is_downloadable:
                downloadable_attachments.append((i, att))  # Store (original_index, attachment)
        
        # Check if the requested filtered index is valid
        if attachment_index >= len(downloadable_attachments):
            app.logger.error(f" PREVIEW FILTERED ATTACHMENT INDEX OUT OF RANGE: Requested {attachment_index}, but only {len(downloadable_attachments)} downloadable attachments exist")
            available_filtered_indices = list(range(len(downloadable_attachments)))
            app.logger.error(f" Available filtered indices: {available_filtered_indices}")
            return jsonify({
                'error': 'Filtered attachment index out of range',
                'requested_index': attachment_index,
                'total_downloadable_attachments': len(downloadable_attachments),
                'total_attachments': len(attachments),
                'available_filtered_indices': available_filtered_indices,
                'attachment_types': [att.get('type') for att in attachments],
                'attachment_sources': [att.get('source') for att in attachments]
            }), 404
        
        # Get the actual attachment using the filtered index
        original_index, attachment = downloadable_attachments[attachment_index]
        
        # Enhanced attachment type checking for webhook attachments
        attachment_type = attachment.get('type')
        if attachment_type == 'text_reference':
            # Handle text reference attachments - these are not previewable files
            return jsonify({
                'error': 'This is a text reference attachment, not a previewable file',
                'attachment_info': {
                    'type': 'text_reference',
                    'name': attachment.get('name', 'Document Reference'),
                    'description': attachment.get('description', '')
                }
            }), 400
        elif attachment_type not in ['file', 'webhook_base64'] and not attachment.get('fileData') and not attachment.get('data'):
            # Only reject if no fileData or data is present
            app.logger.error(f" Invalid attachment type: {attachment_type}. Expected 'file' or 'webhook_base64' or attachment with fileData")
            app.logger.error(f" Full attachment data: {attachment}")
            return jsonify({'error': f'Invalid attachment type: {attachment_type}'}), 400
        
        # Get file information - handle both webhook and regular attachments
        filename = attachment.get('filename') or attachment.get('name', 'unknown_file')
        file_path = attachment.get('path', '')
        # Check for base64 data in multiple possible fields
        base64_data = attachment.get('data', '') or attachment.get('fileData', '')
        
        # Check if file is previewable
        preview_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.txt', '.md']
        file_ext = os.path.splitext(filename.lower())[1]
        
        if file_ext not in preview_extensions:
            app.logger.error(f"ðŸ“Ž File type not previewable: {file_ext}")
            return jsonify({'error': f'File type {file_ext} not previewable'}), 400
        

        
        # FIXED: Priority 1 - Use base64 data if available (most reliable)
        if base64_data and len(base64_data) > 10:
            try:
                app.logger.info(f"ðŸ“Ž Using base64 data for reply attachment preview: {filename} ({len(base64_data)} chars)")
                file_content = base64.b64decode(base64_data)
                
                # Create response with file content for preview
                response = make_response(file_content)
                response.headers['Content-Type'] = get_mime_type(filename)
                response.headers['Content-Length'] = str(len(file_content))
                return response
                
            except Exception as e:
                app.logger.error(f"ðŸ“Ž Error decoding base64 data for preview {filename}: {e}")
                # Fall back to file path method
        
        # FIXED: Priority 2 - Try to serve the file from disk for preview
        if file_path and os.path.exists(file_path):
            # File exists at original path
            app.logger.info(f" Serving preview from original path: {file_path}")
            return send_file(
                file_path,
                as_attachment=False,  # Display inline for preview
                mimetype=get_mime_type(filename)
            )
        else:
            # Try uploads directory
            upload_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path) if file_path else filename)
            app.logger.info(f" Trying uploads directory for preview: {upload_path}")
            
            if os.path.exists(upload_path):
                app.logger.info(f" Serving preview from uploads: {upload_path}")
                return send_file(
                    upload_path,
                    as_attachment=False,  # Display inline for preview
                    mimetype=get_mime_type(filename)
                )
            else:
                app.logger.error(f"ðŸ“Ž Reply attachment file not found for preview: {file_path} or {upload_path}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER: {UPLOAD_FOLDER}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER exists: {os.path.exists(UPLOAD_FOLDER)}")
                if os.path.exists(UPLOAD_FOLDER):
                    app.logger.error(f"ðŸ“Ž Files in UPLOAD_FOLDER: {os.listdir(UPLOAD_FOLDER)}")
                
                # FIXED: Enhanced error response with attachment details
                return jsonify({
                    'error': 'File not found on server',
                    'attachment_info': {
                        'filename': filename,
                        'type': attachment_type,
                        'has_base64_data': bool(base64_data),
                        'file_path': file_path,
                        'upload_path': upload_path
                    }
                }), 404
        
    except Exception as e:
        app.logger.error(f" Error previewing reply attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Failed to preview attachment'}), 500

@app.route('/api/tickets/<ticket_id>/reply-count', methods=['GET'])
def get_reply_count(ticket_id):
    """Get the current reply count for a ticket (for auto-refresh functionality)"""
    try:
        db = get_db()
        
        # Get ticket to verify it exists
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Count replies for this ticket
        reply_count = db.replies.count_documents({'ticket_id': ticket_id})
        
        return jsonify({
            'status': 'success',
            'ticket_id': ticket_id,
            'reply_count': reply_count
        })
        
    except Exception as e:
        app.logger.error(f"Error getting reply count for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to get reply count'}), 500



@app.route('/webhook/reply', methods=['POST'])
def webhook_reply():
    """Webhook endpoint for external systems (like n8n) to send ticket replies"""
    try:
        # Get data for processing
        raw_data = request.get_data()
        
        if not raw_data:
            response = jsonify({
                'success': False,
                'message': 'No data received',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        # Handle both JSON and form data
        if request.is_json:
            data = request.get_json()
            if isinstance(data, list) and len(data) > 0:
                data = data[0]
            
            ticket_id = data.get('ticket_id', '').strip()
            response_text = data.get('response', '').strip() or data.get('message', '').strip()
            attachments_data = data.get('attachments', {})
        else:
            ticket_id = request.form.get('ticket_id', '').strip()
            response_text = request.form.get('response', '').strip() or request.form.get('message', '').strip()
            attachments_data = {}
        
        # Validation
        if not ticket_id:
            response = jsonify({
                'success': False,
                'message': 'Missing ticket_id',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        if not response_text:
            response = jsonify({
                'success': False,
                'message': 'Missing response text',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        if len(response_text) > 10000:
            response = jsonify({
                'success': False,
                'message': 'Response text too long (max 10000 characters)',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        try:
            db = get_db()
            ticket = db.tickets.find_one({'ticket_id': ticket_id})
            
            if not ticket:
                response = jsonify({
                    'success': False,
                    'message': f'Ticket {ticket_id} not found',
                    'timestamp': datetime.now().isoformat(),
                    'status': 'error'
                })
                response.headers['Content-Type'] = 'application/json'
                response.headers['Access-Control-Allow-Origin'] = '*'
                return response, 404
            
            # Save reply to database
            reply_data = {
                'ticket_id': ticket_id,
                'thread_id': ticket['thread_id'],
                'message': response_text,
                'sender': 'customer'
            }
            
            reply_id = db.create_reply(reply_data)
            
            # Process attachments
            attachments = []
            file_attachments = []
            
            # Process JSON attachments from webhook data
            if attachments_data and isinstance(attachments_data, dict):
                for attachment_key, attachment_info in attachments_data.items():
                    if isinstance(attachment_info, dict):
                        filename = attachment_info.get('fileName', 'unknown_file')
                        base64_data = attachment_info.get('data', '')
                        mime_type = attachment_info.get('mimeType', 'application/octet-stream')
                        
                        if base64_data and filename:
                            try:
                                # Create attachment object with proper structure
                                attachment = {
                                    'type': 'file',  # âœ… Set as file type
                                    'name': filename,
                                    'filename': filename,
                                    'data': base64_data,  # âœ… Store base64 data
                                    'has_data': True,
                                    'mime_type': mime_type,
                                    'source': 'webhook_base64',  # âœ… Mark source
                                    'size': len(base64_data) * 3 // 4,  # Approximate size
                                    'uploaded_at': datetime.now()
                                }
                                attachments.append(attachment)
                                
                                app.logger.info(f"âœ… Processed webhook attachment: {filename} ({len(base64_data)} chars)")
                                
                            except Exception as e:
                                app.logger.error(f"âŒ Error processing webhook attachment {filename}: {e}")
                                # Add as text reference if processing fails
                                attachments.append({
                                    'type': 'text_reference',
                                    'name': filename,
                                    'description': f'Error processing: {str(e)}'
                                })
            
            # Handle file uploads
            if request.files:
                for file_key, file_obj in request.files.items():
                    if file_obj and file_obj.filename:
                        try:
                            if not UPLOAD_FOLDER:
                                attachments.append({
                                    'type': 'text_reference',
                                    'name': file_obj.filename,
                                    'description': 'Upload folder not configured'
                                })
                                continue
                            
                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                            safe_filename = secure_filename(file_obj.filename)
                            unique_filename = f"{timestamp}_{safe_filename}"
                            
                            try:
                                if not os.path.exists(UPLOAD_FOLDER):
                                    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
                                
                                upload_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                                file_obj.save(upload_path)
                                
                                with open(upload_path, 'rb') as f:
                                    file_content = f.read()
                                    base64_data = base64.b64encode(file_content).decode('utf-8')
                                
                                file_attachment = {
                                    'type': 'file',
                                    'name': file_obj.filename,
                                    'path': upload_path,
                                    'size': os.path.getsize(upload_path),
                                    'uploaded_at': datetime.now(),
                                    'data': base64_data,
                                    'has_data': True,
                                    'filename': file_obj.filename,
                                    'source': 'file_upload'  # Add source for better identification
                                }
                                file_attachments.append(file_attachment)
                                
                            except OSError as e:
                                if 'Read-only file system' in str(e) or 'Permission denied' in str(e):
                                    attachments.append({
                                        'type': 'text_reference',
                                        'name': file_obj.filename,
                                        'description': 'File system is read-only'
                                    })
                                else:
                                    raise
                                    
                        except Exception as e:
                            app.logger.error(f"Error processing file {file_obj.filename}: {e}")
                            attachments.append({
                                'type': 'text_reference',
                                'name': file_obj.filename,
                                'description': f'Error: {str(e)}'
                            })
            
            # Save attachments to reply
            all_attachments = attachments + file_attachments
            if all_attachments:
                db.replies.update_one(
                    {'_id': reply_id},
                    {'$set': {'attachments': all_attachments}}
                )
            
            # Update ticket status
            update_data = {
                'status': 'Open',
                'draft_body': '',
                'updated_at': datetime.now(),
                'has_unread_reply': True
            }
            db.update_ticket(ticket_id, update_data)
            
            app.logger.info(f"Webhook reply processed successfully for ticket: {ticket_id}")
            app.logger.info(f"Total attachments processed: {len(attachments)} (Files: {len(file_attachments)})")
            
            # Return the actual processed data in the format expected
            response = jsonify([{
                'ticket_id': ticket_id,
                'response': response_text,
                'attachments': attachments_data
            }])
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response
            
        except Exception as bg_error:
            app.logger.error(f"Background processing error: {bg_error}")
            response = jsonify({
                'success': False,
                'message': f'Error processing webhook data: {str(bg_error)}',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 500
        
    except Exception as e:
        app.logger.error(f"Webhook endpoint error: {str(e)}")
        response = jsonify({
            'success': False,
            'message': f'Error processing webhook: {str(e)}',
            'timestamp': datetime.now().isoformat(),
            'status': 'error'
        })
        response.headers['Content-Type'] = 'application/json'
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response, 500

@app.route('/api/attachment/<attachment_id>')
def get_simple_attachment(attachment_id):
    """
    [TARGET] SIMPLE APP STYLE: Serve attachment file exactly like the simple app
    attachment_id format: "ticket_id_index" (e.g., "706393_R122412_0")
    """
    try:
        app.logger.info(f"? Attachment request: {attachment_id}")
        
        # Parse attachment_id to get ticket_id and index
        parts = attachment_id.rsplit('_', 1)
        if len(parts) != 2:
            app.logger.error(f"Invalid attachment ID format: {attachment_id}")
            return jsonify({'error': 'Invalid attachment ID format'}), 400
        
        ticket_id = parts[0]
        try:
            attachment_index = int(parts[1])
        except ValueError:
            app.logger.error(f"Invalid attachment index: {parts[1]}")
            return jsonify({'error': 'Invalid attachment index'}), 400
        
        app.logger.info(f"? Looking for ticket: {ticket_id}, attachment: {attachment_index}")
        
        db = get_db()
        
        # Get ticket data
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            app.logger.error(f"Ticket not found: {ticket_id}")
            return jsonify({'error': 'Ticket not found'}), 404
        
        app.logger.info(f"[SUCCESS] Found ticket, has_attachments: {ticket.get('has_attachments', False)}")
        
        # Get attachments from ticket (same as simple app logic)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            attachments = ticket['attachments']
            app.logger.info(f"? Found {len(attachments)} attachments")
            
            if attachment_index < len(attachments):
                attachment = attachments[attachment_index]
                filename = attachment.get('filename', 'unknown_file')
                file_data = attachment.get('data', '')
                
                app.logger.info(f"? Processing attachment: {filename}, data length: {len(file_data)}")
                
                if file_data:
                    try:
                        # [FIX] ENHANCED: Fix base64 padding if needed
                        # Add padding if missing (base64 strings must be multiple of 4)
                        missing_padding = len(file_data) % 4
                        if missing_padding:
                            file_data += '=' * (4 - missing_padding)
                            app.logger.info(f"Added {4 - missing_padding} padding characters")
                        
                        # Validate base64 before decoding
                        if not file_data.replace('+', '').replace('/', '').replace('=', '').isalnum():
                            app.logger.error("Base64 data contains invalid characters")
                            return jsonify({'error': 'Invalid base64 data format'}), 500
                        
                        # Decode base64 data
                        decoded_data = base64.b64decode(file_data, validate=True)
                        app.logger.info(f"[SUCCESS] Successfully decoded {len(decoded_data)} bytes")
                        
                        # Create a BytesIO object
                        file_stream = io.BytesIO(decoded_data)
                        
                        # Guess MIME type from filename
                        mime_type, _ = mimetypes.guess_type(filename)
                        if not mime_type:
                            # Try to detect from data headers
                            if decoded_data.startswith(b'\xFF\xD8\xFF'):
                                mime_type = 'image/jpeg'
                            elif decoded_data.startswith(b'\x89PNG'):
                                mime_type = 'image/png'
                            elif decoded_data.startswith(b'%PDF'):
                                mime_type = 'application/pdf'
                            else:
                                mime_type = 'application/octet-stream'
                        
                        app.logger.info(f"[TARGET] Serving file: {filename}, MIME: {mime_type}")
                        
                        # For preview, don't force download
                        if request.args.get('preview') == 'true':
                            return send_file(
                                file_stream,
                                mimetype=mime_type
                            )
                        else:
                            return send_file(
                                file_stream,
                                mimetype=mime_type,
                                as_attachment=True,
                                download_name=filename
                            )
                            
                    except base64.binascii.Error as e:
                        app.logger.error(f"Base64 decoding error: {e}")
                        return jsonify({'error': f'Base64 decode error: {str(e)}'}), 500
                    except Exception as e:
                        app.logger.error(f"Failed to process attachment data: {e}")
                        return jsonify({'error': f'Attachment processing error: {str(e)}'}), 500
                else:
                    app.logger.error("No file data found in attachment")
                    return jsonify({'error': 'No file data available'}), 404
            else:
                app.logger.error(f"Attachment index {attachment_index} out of range (max: {len(attachments)-1})")
                return jsonify({'error': f'Attachment index out of range'}), 404
        else:
            app.logger.error("No attachments found in ticket")
            return jsonify({'error': 'No attachments found'}), 404
        
    except Exception as e:
        app.logger.error(f"Error serving attachment: {str(e)}")
        import traceback
        app.logger.error(f"Full traceback: {traceback.format_exc()}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/attachments/<int:attachment_index>/download')
def download_attachment(ticket_id, attachment_index):
    """
    [ENHANCED] Download attachments from multiple sources:
    1. Direct ticket attachments (base64 data)
    2. Reply attachments (webhook files)
    3. Metadata attachments (file uploads)
    """
    try:
        db = get_db()
        
        # Get ticket data
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        app.logger.info(f" Download request for ticket {ticket_id}, attachment {attachment_index}")
        
        # METHOD 1: Check for direct attachments in ticket (n8n email tickets and manual tickets)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            attachments = ticket['attachments']
            app.logger.info(f"Found {len(attachments)} direct attachments in ticket")
            
            if attachment_index < len(attachments):
                attachment = attachments[attachment_index]
                filename = attachment.get('filename', attachment.get('original_name', 'unknown_file'))
                
                # FIXED: PRIORITY 1 - Check for base64 data first (most reliable)
                file_data = attachment.get('data', '')
                if file_data:
                    app.logger.info(f" Downloading base64 attachment: {filename} (base64: {len(file_data)} chars)")
                    try:
                        decoded_data = base64.b64decode(file_data)
                        return send_file(
                            io.BytesIO(decoded_data),
                            as_attachment=True,
                            download_name=filename,
                            mimetype=get_mime_type(filename)
                        )
                    except Exception as e:
                        app.logger.error(f"Failed to decode base64 data: {e}")
                        # Fall back to file path method
                        app.logger.warning(f"Falling back to file path method for {filename}")
                
                # FIXED: PRIORITY 2 - Check if this is a manual ticket attachment (has file path)
                if attachment.get('path') and os.path.exists(attachment['path']):
                    app.logger.info(f" Downloading manual ticket attachment from disk: {filename} from {attachment['path']}")
                    return send_file(
                        attachment['path'],
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                
                # FIXED: PRIORITY 3 - Try to find file in uploads directory for manual tickets
                if filename:
                    upload_path = os.path.join(UPLOAD_FOLDER, ticket_id, filename)
                    if os.path.exists(upload_path):
                        app.logger.info(f" Found manual ticket attachment in uploads: {upload_path}")
                        return send_file(
                            upload_path,
                            as_attachment=True,
                            download_name=filename,
                            mimetype=get_mime_type(filename)
                        )
                    else:
                        app.logger.warning(f" Manual ticket attachment not found: {upload_path}")
                        # List files in uploads directory for debugging
                        upload_dir = os.path.join(UPLOAD_FOLDER, ticket_id)
                        if os.path.exists(upload_dir):
                            upload_files = os.listdir(upload_dir)
                            app.logger.info(f"FOLDER Files in uploads/{ticket_id}: {upload_files}")
                        else:
                            app.logger.warning(f" Uploads directory for ticket {ticket_id} does not exist")
        
        # METHOD 1.5: Check for simple_attachments (conversation section attachments)
        if ticket.get('simple_attachments'):
            simple_attachments = ticket['simple_attachments']
            app.logger.info(f"Found {len(simple_attachments)} simple attachments in ticket")
            
            if attachment_index < len(simple_attachments):
                attachment = simple_attachments[attachment_index]
                filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
                file_path = attachment.get('file_path', '')
                
                app.logger.info(f" Simple attachment: {attachment}")
                
                # Try to serve the file from the file_path
                if file_path and os.path.exists(file_path):
                    app.logger.info(f" FOUND SIMPLE ATTACHMENT FILE: {file_path}")
                    return send_file(
                        file_path,
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                else:
                    app.logger.warning(f" Simple attachment file not found: {file_path}")
                    # Try to find the file in uploads directory
                    if filename:
                        upload_path = os.path.join(UPLOAD_FOLDER, filename)
                        if os.path.exists(upload_path):
                            app.logger.info(f" FOUND SIMPLE ATTACHMENT IN UPLOADS: {upload_path}")
                            return send_file(
                                upload_path,
                                as_attachment=True,
                                download_name=filename,
                                mimetype=get_mime_type(filename)
                            )
                        else:
                            app.logger.warning(f" Simple attachment not found in uploads: {upload_path}")
                            # List files in uploads directory for debugging
                            if os.path.exists(UPLOAD_FOLDER):
                                upload_files = os.listdir(UPLOAD_FOLDER)
                                app.logger.info(f"FOLDER Files in uploads directory: {upload_files}")
                            else:
                                app.logger.warning(f" Uploads directory {UPLOAD_FOLDER} does not exist")
        
        # METHOD 2: Check reply attachments (webhook files)
        replies = db.replies.find({'ticket_id': ticket_id}).sort('created_at', -1)
        all_reply_attachments = []
        
        for reply in replies:
            if reply.get('attachments'):
                for att in reply['attachments']:
                    if att.get('type') == 'file':
                        all_reply_attachments.append(att)
        
        app.logger.info(f"Found {len(all_reply_attachments)} reply attachments")
        
        if attachment_index < len(all_reply_attachments):
            attachment = all_reply_attachments[attachment_index]
            filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
            file_path = attachment.get('path', '')
            
            if file_path and os.path.exists(file_path):
                app.logger.info(f" FOUND REPLY FILE: {file_path}")
                return send_file(
                    file_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            else:
                app.logger.warning(f" Reply file not found: {file_path}")
        
        # METHOD 3: Check metadata collection for file attachments (both email and manual tickets)
        ticket_metadata = db.get_ticket_metadata(ticket_id)
        attachment_files = []
        
        for metadata_entry in ticket_metadata:
            if metadata_entry['key'].startswith('attachment_'):
                try:
                    attachment_data = json.loads(metadata_entry['value'])
                    attachment_files.append(attachment_data)
                except:
                    continue
        
        app.logger.info(f"Found {len(attachment_files)} metadata attachments")
        
        if attachment_index < len(attachment_files):
            attachment = attachment_files[attachment_index]
            filename = attachment.get('original_name', attachment.get('filename', 'unknown_file'))
            
            # FIXED: PRIORITY 1 - Check for base64 data first (most reliable for manual tickets)
            file_data = attachment.get('data', '')
            if file_data:
                app.logger.info(f" FOUND BASE64 DATA: {filename} (base64: {len(file_data)} chars)")
                try:
                    decoded_data = base64.b64decode(file_data)
                    return send_file(
                        io.BytesIO(decoded_data),
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                except Exception as e:
                    app.logger.error(f"Failed to decode base64 data from metadata: {e}")
                    # Fall back to file path method
                    app.logger.warning(f"Falling back to file path method for {filename}")
            
            # FIXED: PRIORITY 2 - Try saved file path (EMAIL TICKETS with disk saves)
            saved_file_path = attachment.get('file_path')
            if saved_file_path and os.path.exists(saved_file_path):
                app.logger.info(f" FOUND SAVED FILE: {saved_file_path}")
                return send_file(
                    saved_file_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            
            # FIXED: PRIORITY 3 - Try uploads directory (MANUAL TICKETS)
            file_path = os.path.join('uploads', filename)
            if os.path.exists(file_path):
                app.logger.info(f" FOUND UPLOAD FILE: {filename}")
                return send_file(
                    file_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            
            # FIXED: PRIORITY 4 - Try base64 data from metadata (FALLBACK - moved to top priority)
            elif 'data' in attachment and attachment['data']:
                app.logger.info(f" FALLBACK TO BASE64: {filename}")
                try:
                    decoded_data = base64.b64decode(attachment.get('data', ''))
                    return send_file(
                        io.BytesIO(decoded_data),
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                except Exception as e:
                    app.logger.error(f"Failed to decode metadata base64: {e}")
                    return jsonify({'error': 'Invalid attachment data'}), 500
            else:
                app.logger.warning(f" NO DATA SOURCE for attachment {filename}")
                app.logger.warning(f"   - file_path: {saved_file_path}")
                app.logger.warning(f"   - upload_path: {file_path}")
                app.logger.warning(f"   - has_base64: {bool(attachment.get('data'))}")
        
        # If we get here, attachment not found
        app.logger.warning(f" Attachment {attachment_index} not found for ticket {ticket_id}")
        app.logger.warning(f"   - Direct attachments: {len(ticket.get('attachments', []))}")
        app.logger.warning(f"   - Reply attachments: {len(all_reply_attachments)}")
        app.logger.warning(f"   - Metadata attachments: {len(attachment_files)}")
        
        # FIXED: Enhanced error response with debugging information
        return jsonify({
            'error': 'Attachment not found',
            'ticket_id': ticket_id,
            'attachment_index': attachment_index,
            'debug_info': {
                'ticket_has_attachments': ticket.get('has_attachments', False),
                'ticket_attachments_count': len(ticket.get('attachments', [])),
                'simple_attachments_count': len(ticket.get('simple_attachments', [])),
                'metadata_attachments_count': len(attachment_files),
                'reply_attachments_count': len(all_reply_attachments),
                'suggestion': 'Check if manual ticket attachments have base64 data stored in database'
            }
        }), 404
        
    except Exception as e:
        app.logger.error(f"Error downloading attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Failed to download attachment'}), 500

def get_mime_type(filename):
    """Get MIME type based on file extension"""
    ext = filename.lower().split('.')[-1] if '.' in filename else ''
    
    mime_types = {
        'pdf': 'application/pdf',
        'jpg': 'image/jpeg',
        'jpeg': 'image/jpeg', 
        'png': 'image/png',
        'gif': 'image/gif',
        'txt': 'text/plain',
        'doc': 'application/msword',
        'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        'xls': 'application/vnd.ms-excel',
        'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        'zip': 'application/zip',
        'rar': 'application/x-rar-compressed'
    }
    
    return mime_types.get(ext, 'application/octet-stream')

@app.route('/api/tickets/<ticket_id>/attachments')
def get_ticket_attachments(ticket_id):
    """
    Get all attachments for a ticket with enhanced metadata
    """
    try:
        db = get_db()
        
        # Get ticket with attachments
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Return attachment information
        attachments = ticket.get('attachments', [])
        
        # Enhanced attachment metadata
        enhanced_attachments = []
        for i, att in enumerate(attachments):
            enhanced_att = {
                'index': i,
                'filename': att.get('filename', 'unknown_file'),
                'size': att.get('size', 0),
                'size_formatted': att.get('size_formatted', format_file_size(att.get('size', 0))),
                'is_warranty': att.get('is_warranty', False),
                'file_type': att.get('file_type', 'unknown'),
                'file_category': att.get('file_category', 'unknown'),
                'file_extension': att.get('file_extension', ''),
                'from': att.get('from', ''),
                'processed_at': att.get('processed_at', ''),
                'download_url': f'/api/tickets/{ticket_id}/attachments/{i}/download'
            }
            enhanced_attachments.append(enhanced_att)
        
        return jsonify({
            'ticket_id': ticket_id,
            'has_attachments': len(enhanced_attachments) > 0,
            'total_attachments': len(enhanced_attachments),
            'warranty_forms_count': sum(1 for att in enhanced_attachments if att.get('is_warranty', False)),
            'total_size': sum(att.get('size', 0) for att in enhanced_attachments),
            'total_size_formatted': format_file_size(sum(att.get('size', 0) for att in enhanced_attachments)),
            'attachments': enhanced_attachments
        })
        
    except Exception as e:
        app.logger.error(f"Error getting ticket attachments: {str(e)}")
        return jsonify({'error': 'Failed to get attachments'}), 500

@app.route('/api/tickets/<ticket_id>/attachments/warranty-analysis')
def analyze_warranty_attachments(ticket_id):
    """
    Analyze attachments for warranty-related content
    """
    try:
        db = get_db()
        
        # Get ticket with attachments
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        attachments = ticket.get('attachments', [])
        
        # Analyze warranty attachments
        warranty_analysis = {
            'total_attachments': len(attachments),
            'warranty_forms_detected': 0,
            'warranty_confidence': 0,
            'detected_keywords': [],
            'warranty_attachments': [],
            'non_warranty_attachments': []
        }
        
        all_keywords = set()
        warranty_attachments = []
        
        for i, att in enumerate(attachments):
            filename = att.get('filename', '')
            is_warranty = att.get('is_warranty', False)
            
            if is_warranty:
                warranty_analysis['warranty_forms_detected'] += 1
                
                # Extract keywords that were detected
                warranty_keywords = [
                    'warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante', 'warrantie',
                    'dpf', 'diesel', 'emission', 'claim', 'form', 'customer',
                    'repair', 'service', 'defect', 'malfunction', 'issue', 'fault'
                ]
                
                filename_lower = filename.lower()
                detected_in_file = [kw for kw in warranty_keywords if kw in filename_lower]
                all_keywords.update(detected_in_file)
                
                warranty_info = {
                    'index': i,
                    'filename': filename,
                    'size_formatted': att.get('size_formatted', ''),
                    'detected_keywords': detected_in_file,
                    'download_url': f'/api/tickets/{ticket_id}/attachments/{i}/download'
                }
                warranty_analysis['warranty_attachments'].append(warranty_info)
                warranty_attachments.append(att)
            else:
                non_warranty_info = {
                    'index': i,
                    'filename': filename,
                    'size_formatted': att.get('size_formatted', ''),
                    'file_type': att.get('file_type', 'unknown'),
                    'download_url': f'/api/tickets/{ticket_id}/attachments/{i}/download'
                }
                warranty_analysis['non_warranty_attachments'].append(non_warranty_info)
        
        # Calculate confidence
        if len(attachments) > 0:
            warranty_analysis['warranty_confidence'] = min(
                (warranty_analysis['warranty_forms_detected'] / len(attachments)) * 100, 
                95
            )
        
        warranty_analysis['detected_keywords'] = sorted(list(all_keywords))
        warranty_analysis['recommendation'] = (
            'High Priority - Warranty forms detected' if warranty_analysis['warranty_forms_detected'] > 0 
            else 'Standard Priority - No warranty forms detected'
        )
        
        return jsonify(warranty_analysis)
        
    except Exception as e:
        app.logger.error(f"Error analyzing warranty attachments: {str(e)}")
        return jsonify({'error': 'Failed to analyze attachments'}), 500

@app.route('/api/tickets/<ticket_id>', methods=['GET'])
def get_single_ticket(ticket_id):
    """Get a single ticket by ID for admin panel and frontend"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Convert ObjectId to string for JSON serialization
        ticket['_id'] = str(ticket['_id'])
        
        # Get ticket metadata for additional info
        ticket_metadata = db.get_ticket_metadata(ticket_id)
        if ticket_metadata:
            ticket['metadata'] = ticket_metadata
        
        return jsonify({
            'status': 'success',
            'ticket': ticket
        })
        
    except Exception as e:
        app.logger.error(f"Error fetching ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Failed to fetch ticket: {str(e)}'}), 500

@app.route('/api/tickets', methods=['GET'])
def get_all_tickets():
    """
    [TARGET] GET ALL TICKETS ENDPOINT - For frontend display
    Returns all tickets with attachment data for dashboard
    """
    try:
        db = get_db()
        
        # Get all tickets with attachment info
        tickets = list(db.tickets.find({}).sort([('_id', -1)]).limit(50))
        
        # Convert to frontend-friendly format
        formatted_tickets = []
        for ticket in tickets:
            # Convert ObjectId to string
            ticket['_id'] = str(ticket['_id'])
            
            # [FIX] ENHANCED FIX: Handle both email attachments (stored in ticket) and manual attachments (in metadata)
            attachments = []
            
            # METHOD 1: Check for direct attachments in ticket (n8n email tickets)
            if ticket.get('has_attachments', False) and 'attachments' in ticket:
                direct_attachments = ticket['attachments']
                app.logger.info(f"Found {len(direct_attachments)} direct attachments in ticket {ticket['ticket_id']}")
                
                for i, att in enumerate(direct_attachments):
                    attachment = {
                        'index': i,
                        'filename': att.get('filename', 'unknown_file'),
                        'size': att.get('size', 0),
                        'is_warranty': att.get('is_warranty', False),
                        'file_type': att.get('file_type', 'unknown'),
                        'download_url': f"/api/tickets/{ticket['ticket_id']}/attachments/{i}/download",
                        'source': 'email'  # Mark as email attachment
                    }
                    attachments.append(attachment)
            
            # METHOD 2: Also check metadata collection (manual tickets)
            ticket_metadata = db.get_ticket_metadata(ticket['ticket_id'])
            metadata_attachments = []
            
            for metadata_entry in ticket_metadata:
                if metadata_entry['key'].startswith('attachment_'):
                    try:
                        attachment_data = json.loads(metadata_entry['value'])
                        # Convert metadata back to attachment format
                        attachment = {
                            'index': len(attachments) + len(metadata_attachments),
                            'filename': attachment_data.get('original_name', attachment_data.get('filename', 'unknown')),
                            'size': attachment_data.get('size', 0),
                            'is_warranty': attachment_data.get('is_warranty', False),
                            'file_path': attachment_data.get('file_path', ''),
                            'key': attachment_data.get('key', ''),
                            'download_url': f"/api/tickets/{ticket['ticket_id']}/attachments/{len(attachments) + len(metadata_attachments)}/download",
                            'source': 'manual'  # Mark as manual attachment
                        }
                        metadata_attachments.append(attachment)
                    except (json.JSONDecodeError, KeyError) as e:
                        app.logger.warning(f"Failed to parse attachment metadata for {ticket['ticket_id']}: {e}")
            
            # Combine both types of attachments
            attachments.extend(metadata_attachments)
            
            # Set proper attachment fields
            ticket['attachments'] = attachments
            ticket['has_attachments'] = len(attachments) > 0
            ticket['has_warranty'] = any(att.get('is_warranty', False) for att in attachments)
            ticket['total_attachments'] = len(attachments)
            ticket['email_attachments'] = len([a for a in attachments if a.get('source') == 'email'])
            ticket['manual_attachments'] = len([a for a in attachments if a.get('source') == 'manual'])
            
            # Format created date
            if 'created_at' in ticket and ticket['created_at']:
                try:
                    if isinstance(ticket['created_at'], datetime):
                        ticket['formatted_date'] = ticket['created_at'].strftime("%b %d, %I:%M %p")
                    else:
                        created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                except:
                    ticket['formatted_date'] = 'Unknown'
            else:
                ticket['formatted_date'] = 'Unknown'
            
            formatted_tickets.append(ticket)
        
        return jsonify({
            'success': True,
            'tickets': formatted_tickets,
            'total': len(formatted_tickets),
            'attachments_summary': {
                'total_with_attachments': len([t for t in formatted_tickets if t.get('has_attachments')]),
                'total_with_warranty': len([t for t in formatted_tickets if t.get('has_warranty')])
            }
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error getting tickets: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'tickets': []
        }), 500



# AI Response Display API Endpoint
@app.route('/api/ai/display-response', methods=['POST'])
def display_ai_response():
    """
    Display AI response in ticket reply conversation textarea
    Accepts POST request with ticket_id and ai_response from n8n
    """
    try:
        data = request.get_json()
        
        # Extract only required fields
        ticket_id = data.get('ticket_id', '')
        ai_response = data.get('ai_response', '')
        
        # Validate required fields
        if not ticket_id:
            return jsonify({
                'success': False,
                'error': 'ticket_id is required'
            }), 400
            
        if not ai_response:
            return jsonify({
                'success': False,
                'error': 'ai_response is required'
            }), 400
        
        # Store AI response in database for retrieval
        try:
            db = get_db()
            # Store in ticket metadata for easy retrieval
            db.set_ticket_metadata(ticket_id, 'ai_response', ai_response)
            db.set_ticket_metadata(ticket_id, 'ai_response_timestamp', datetime.now().isoformat())
        except Exception as e:
            app.logger.warning(f"Could not store AI response in metadata: {e}")
        
        # Create URL for displaying the AI response
        import urllib.parse
        encoded_response = urllib.parse.quote(ai_response)
        # Use the actual domain from the request
        base_url = request.host_url.rstrip('/')
        display_url = f"{base_url}/ai-response/{ticket_id}?response={encoded_response}"
        
        # Return the AI response ready for textarea display
        return jsonify({
            'success': True,
            'ticket_id': ticket_id,
            'ai_response': ai_response,
            'display_url': display_url,
            'message': 'AI response ready for textarea display. Use display_url to show in textarea.',
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error displaying AI response: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'ai_response': 'I apologize, but I encountered an error while processing your request. Please try again or contact support directly.'
        }), 500

# AI Response Display Frontend Endpoint
@app.route('/ai-response/<ticket_id>')
def show_ai_response(ticket_id):
    """
    Frontend endpoint to display AI response in textarea
    This will redirect to the ticket detail page with AI response pre-filled
    """
    try:
        # Get the AI response from the request parameters
        ai_response = request.args.get('response', '')
        
        if not ai_response:
            return "No AI response provided", 400
        
        # Create a simple HTML page that will populate the textarea
        html_content = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>AI Response - Ticket {ticket_id}</title>
            <script>
                console.log('ðŸ¤– AI Response Debug - Page loaded');
                console.log('ðŸŽ« Ticket ID:', '{ticket_id}');
                console.log('ðŸ’¬ AI Response Length:', {len(ai_response)});
                
                function populateTextarea() {{
                    console.log('ðŸ”§ Attempting to populate textarea...');
                    
                    // Method 1: Try parent window
                    if (window.opener) {{
                        console.log('ðŸ‘† Found parent window, looking for textarea...');
                        const textarea = window.opener.document.getElementById('response');
                        if (textarea) {{
                            console.log('âœ… Found textarea in parent window!');
                            textarea.value = `{ai_response.replace('`', '\\`')}`;
                            console.log('ðŸ“ Textarea populated with:', textarea.value.substring(0, 100) + '...');
                            
                            // Trigger auto-expand
                            if (window.opener.autoExpandTextarea) {{
                                window.opener.autoExpandTextarea(textarea);
                            }}
                            
                            // Trigger input event
                            textarea.dispatchEvent(new Event('input', {{ bubbles: true }}));
                            
                            console.log('ðŸŽ‰ Success! Closing window...');
                            window.close();
                            return;
                        }}
                    }}
                    
                    // Method 2: Try current window
                    console.log('ðŸ” Trying current window...');
                    const textarea = document.getElementById('response');
                    if (textarea) {{
                        console.log('âœ… Found textarea in current window!');
                        textarea.value = `{ai_response.replace('`', '\\`')}`;
                        console.log('ðŸ“ Textarea populated with:', textarea.value.substring(0, 100) + '...');
                        
                        if (window.autoExpandTextarea) {{
                            window.autoExpandTextarea(textarea);
                        }}
                        
                        textarea.dispatchEvent(new Event('input', {{ bubbles: true }}));
                        console.log('ðŸŽ‰ Success!');
                        return;
                    }}
                    
                    // Method 3: Redirect to ticket page
                    console.log('ðŸ”„ No textarea found, redirecting to ticket page...');
                    window.location.href = '/ticket/{ticket_id}?ai_response={ai_response.replace(' ', '%20')}';
                }}
                
                // Run immediately
                populateTextarea();
            </script>
        </head>
        <body style="font-family: Arial, sans-serif; padding: 20px; text-align: center;">
            <h2>ðŸ¤– AI Response Ready</h2>
            <p>Ticket: {ticket_id}</p>
            <p>Loading AI response into textarea...</p>
            <button onclick="populateTextarea()" style="padding: 10px 20px; margin: 10px;">Retry</button>
            <button onclick="window.close()" style="padding: 10px 20px; margin: 10px;">Close</button>
        </body>
        </html>
        """
        
        return html_content
        
    except Exception as e:
        app.logger.error(f"Error showing AI response: {str(e)}")
        return f"Error: {str(e)}", 500

# AI Response API Endpoint for JavaScript
@app.route('/api/ai/get-response/<ticket_id>')
def get_ai_response(ticket_id):
    """
    Get AI response for a ticket (for JavaScript to use)
    """
    try:
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        
        ai_response = None
        for meta in metadata:
            if meta.get('key') == 'ai_response':
                ai_response = meta.get('value')
                break
        
        if ai_response:
            return jsonify({
                'success': True,
                'ai_response': ai_response,
                'ticket_id': ticket_id
            })
        else:
            return jsonify({
                'success': False,
                'message': 'No AI response found for this ticket'
            })
            
    except Exception as e:
        app.logger.error(f"Error getting AI response: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def generate_support_response(ticket_id, subject, body, customer_name, customer_email, status, priority):
    """
    Generate AI-powered support response based on ticket content
    """
    try:
        # Basic AI response generation logic
        response_parts = []
        
        # Greeting
        if customer_name:
            response_parts.append(f"Hello {customer_name},")
        else:
            response_parts.append("Hello,")
        
        response_parts.append("")
        response_parts.append("Thank you for contacting AutoAssistGroup support.")
        response_parts.append("")
        
        # Analyze ticket content for appropriate response
        if 'warranty' in body.lower() or 'warranty' in subject.lower():
            response_parts.append("I can see you're inquiring about a warranty claim. Let me help you with that.")
            response_parts.append("")
            response_parts.append("To process your warranty claim efficiently, I'll need the following information:")
            response_parts.append("â€¢ Original purchase receipt or invoice")
            response_parts.append("â€¢ Warranty registration details")
            response_parts.append("â€¢ Clear photos of the issue/defect")
            response_parts.append("â€¢ Description of when the problem first occurred")
            response_parts.append("")
            response_parts.append("Once I receive this information, I'll review your claim and provide you with the next steps.")
            
        elif 'repair' in body.lower() or 'fix' in body.lower() or 'broken' in body.lower():
            response_parts.append("I understand you're experiencing issues that require repair assistance.")
            response_parts.append("")
            response_parts.append("To better assist you, could you please provide:")
            response_parts.append("â€¢ A detailed description of the problem")
            response_parts.append("â€¢ When the issue first started")
            response_parts.append("â€¢ Any error messages or symptoms you've noticed")
            response_parts.append("â€¢ Photos or videos if applicable")
            response_parts.append("")
            response_parts.append("I'll review this information and coordinate with our technical team to resolve your issue.")
            
        elif 'appointment' in body.lower() or 'schedule' in body.lower() or 'visit' in body.lower():
            response_parts.append("I can help you schedule an appointment with our technical team.")
            response_parts.append("")
            response_parts.append("Please let me know:")
            response_parts.append("â€¢ Your preferred date and time")
            response_parts.append("â€¢ The nature of the service required")
            response_parts.append("â€¢ Your location/address")
            response_parts.append("â€¢ Any specific requirements or notes")
            response_parts.append("")
            response_parts.append("I'll check our availability and confirm your appointment.")
            
        elif 'status' in body.lower() or 'update' in body.lower():
            response_parts.append("I'll check the current status of your ticket and provide you with an update.")
            response_parts.append("")
            response_parts.append(f"Current Status: {status}")
            response_parts.append(f"Priority: {priority}")
            response_parts.append("")
            response_parts.append("I'm reviewing your case and will provide you with detailed information shortly.")
            
        else:
            # Generic helpful response
            response_parts.append("I've received your message and I'm here to help you.")
            response_parts.append("")
            response_parts.append("To provide you with the best assistance, I may need some additional information:")
            response_parts.append("â€¢ More details about your specific concern")
            response_parts.append("â€¢ Any relevant documentation or photos")
            response_parts.append("â€¢ Your preferred method of contact")
            response_parts.append("")
            response_parts.append("I'll work to resolve your inquiry as quickly as possible.")
        
        # Add closing
        response_parts.append("")
        response_parts.append("If you have any questions or need immediate assistance, please don't hesitate to contact us.")
        response_parts.append("")
        response_parts.append("Best regards,")
        response_parts.append("AutoAssistGroup Support Team")
        
        # Join all parts with newlines
        ai_response = "\n".join(response_parts)
        
        return ai_response
        
    except Exception as e:
        app.logger.error(f"Error in AI response generation: {str(e)}")
        return "Thank you for contacting AutoAssistGroup support. I'm currently reviewing your request and will provide you with a detailed response shortly. If you need immediate assistance, please contact our support team directly."

# Ticket Deletion API Endpoints  
@app.route('/api/tickets/<ticket_id>', methods=['DELETE'])
def delete_ticket(ticket_id):
    """Delete a ticket completely (hard delete) - Admin only"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can delete tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        result = db.delete_ticket(ticket_id)
        
        if result['success']:
            return jsonify({
                'status': 'success',
                'message': result['message']
            })
        else:
            return jsonify({
                'status': 'error', 
                'message': result['message']
            }), 404
            
    except Exception as e:
        logging.error(f"Error deleting ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/ticket/<ticket_id>/delete', methods=['POST', 'GET'])
def delete_ticket_html(ticket_id):
    """HTML-friendly delete that redirects after deletion (Admin only)."""
    if 'member_id' not in session:
        return redirect(url_for('portal'))

    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

    try:
        db = get_db()
        result = db.delete_ticket(ticket_id)
        if result.get('success'):
            return redirect(url_for('dashboard'))
        else:
            return redirect(url_for('ticket_detail', ticket_id=ticket_id))
    except Exception as e:
        logging.error(f"HTML delete error for ticket {ticket_id}: {e}")
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

@app.route('/api/tickets/<ticket_id>/soft-delete', methods=['POST'])
def soft_delete_ticket(ticket_id):
    """Soft delete a ticket (mark as deleted) - Admin only"""  
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can soft delete tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        deleted_by = session.get('member_id')
        result = db.soft_delete_ticket(ticket_id, deleted_by)
        
        if result['success']:
            return jsonify({
                'status': 'success',
                'message': result['message']
            })
        else:
            return jsonify({
                'status': 'error',
                'message': result['message']
            }), 404
            
    except Exception as e:
        logging.error(f"Error soft deleting ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/ticket/<ticket_id>/archive', methods=['POST', 'GET'])
def archive_ticket_html(ticket_id):
    """HTML-friendly soft delete that redirects (Admin only)."""
    if 'member_id' not in session:
        return redirect(url_for('portal'))

    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

    try:
        db = get_db()
        deleted_by = session.get('member_id')
        result = db.soft_delete_ticket(ticket_id, deleted_by)
        if result.get('success'):
            return redirect(url_for('dashboard'))
        else:
            return redirect(url_for('ticket_detail', ticket_id=ticket_id))
    except Exception as e:
        logging.error(f"HTML soft delete error for ticket {ticket_id}: {e}")
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

@app.route('/api/tickets/<ticket_id>/restore', methods=['POST'])
def restore_ticket(ticket_id):
    """Restore a soft-deleted ticket - Admin only"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can restore tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        result = db.restore_ticket(ticket_id)
        
        if result['success']:
            return jsonify({
                'status': 'success',
                'message': result['message']
            })
        else:
            return jsonify({
                'status': 'error',
                'message': result['message']
            }), 404
            
    except Exception as e:
        logging.error(f"Error restoring ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/tickets/deleted', methods=['GET'])
def get_deleted_tickets():
    """Get all soft-deleted tickets - Admin only"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can view deleted tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        deleted_tickets = db.get_deleted_tickets()
        
        # Convert ObjectId to string for JSON serialization
        for ticket in deleted_tickets:
            ticket['_id'] = str(ticket['_id'])
        
        return jsonify({
            'status': 'success',
            'tickets': deleted_tickets
        })
        
    except Exception as e:
        logging.error(f"Error getting deleted tickets: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# System Settings API Endpoints
@app.route('/api/admin/settings', methods=['GET', 'POST'])
def manage_system_settings():
    """Manage system settings"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        
        if request.method == 'GET':
            # Get system settings
            settings = db.db.system_settings.find_one({'type': 'general'})
            if not settings:
                # Create default settings if none exist
                default_settings = {
                    'type': 'general',
                    'auto_assign_enabled': False,
                    'email_notifications': True,
                    'webhook_notifications': True,
                    'max_file_size': '10MB',
                    'allowed_file_types': ['pdf', 'doc', 'docx', 'jpg', 'png', 'xlsx'],
                    'created_at': datetime.now()
                }
                db.db.system_settings.insert_one(default_settings)
                settings = default_settings
            
            # Convert ObjectId to string
            if '_id' in settings:
                settings['_id'] = str(settings['_id'])
            
            return jsonify({
                'status': 'success',
                'settings': settings
            })
        
        elif request.method == 'POST':
            # Update system settings
            data = request.get_json()
            
            update_data = {
                'updated_at': datetime.now(),
                'updated_by': session.get('member_id')
            }
            
            # Update allowed settings
            allowed_keys = ['auto_assign_enabled', 'email_notifications', 'webhook_notifications', 
                          'max_file_size', 'allowed_file_types']
            for key in allowed_keys:
                if key in data:
                    update_data[key] = data[key]
            
            result = db.db.system_settings.update_one(
                {'type': 'general'},
                {'$set': update_data},
                upsert=True
            )
            
            return jsonify({
                'status': 'success',
                'message': 'System settings updated successfully'
            })
            
    except Exception as e:
        logging.error(f"Error managing system settings: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/cleanup', methods=['POST'])
def cleanup_old_data():
    """Cleanup old data from the system"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        data = request.get_json()
        days = data.get('days', 365)
        
        # Calculate cutoff date
        cutoff_date = datetime.now() - timedelta(days=days)
        
        deleted_count = 0
        
        # Clean up old ticket metadata
        result = db.ticket_metadata.delete_many({
            'created_at': {'$lt': cutoff_date}
        })
        deleted_count += result.deleted_count
        
        # Clean up old replies for deleted tickets
        result = db.replies.delete_many({
            'created_at': {'$lt': cutoff_date},
            'ticket_id': {'$regex': '^deleted_'}
        })
        deleted_count += result.deleted_count
        
        # Clean up old session data (if any)
        # This is just a placeholder - implement as needed
        
        logging.info(f"Cleanup completed - removed {deleted_count} old records")
        
        return jsonify({
            'status': 'success',
            'message': f'Cleanup completed successfully',
            'deleted_count': deleted_count
        })
        
    except Exception as e:
        logging.error(f"Error during cleanup: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/export', methods=['POST'])
def export_system_data():
    """Export system data to CSV files"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        import csv
        import io
        import zipfile
        
        db = get_db()
        
        # Create a zip file in memory
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            
            # Export tickets
            tickets = list(db.get_all_tickets())
            if tickets:
                csv_buffer = io.StringIO()
                if tickets:  # Check if we have tickets
                    fieldnames = tickets[0].keys()
                    writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
                    writer.writeheader()
                    for ticket in tickets:
                        # Convert ObjectId to string for CSV
                        clean_ticket = {}
                        for key, value in ticket.items():
                            if hasattr(value, '__str__'):
                                clean_ticket[key] = str(value)
                            else:
                                clean_ticket[key] = value
                        writer.writerow(clean_ticket)
                zip_file.writestr('tickets.csv', csv_buffer.getvalue())
            
            # Export members
            members = list(db.get_all_members())
            if members:
                csv_buffer = io.StringIO()
                if members:
                    fieldnames = ['name', 'user_id', 'role', 'gender', 'created_at']
                    writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
                    writer.writeheader()
                    for member in members:
                        clean_member = {key: str(member.get(key, '')) for key in fieldnames}
                        writer.writerow(clean_member)
                zip_file.writestr('members.csv', csv_buffer.getvalue())
            
            # Export technicians
            technicians = list(db.get_all_technicians())
            if technicians:
                csv_buffer = io.StringIO()
                if technicians:
                    fieldnames = ['name', 'role', 'is_active', 'created_at']
                    writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
                    writer.writeheader()
                    for tech in technicians:
                        clean_tech = {key: str(tech.get(key, '')) for key in fieldnames}
                        writer.writerow(clean_tech)
                zip_file.writestr('technicians.csv', csv_buffer.getvalue())
        
        zip_buffer.seek(0)
        
        # Return the zip file
        return send_file(
            io.BytesIO(zip_buffer.getvalue()),
            mimetype='application/zip',
            as_attachment=True,
            download_name=f'system-export-{datetime.now().strftime("%Y-%m-%d")}.zip'
        )
        
    except Exception as e:
        logging.error(f"Error during data export: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/debug/assignment/<ticket_id>')
def debug_assignment_status(ticket_id):
    """DEBUG: Check assignment status for JavaScript verification"""
    try:
        db = get_db()
        
        # Get assignment data directly
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        # Get dashboard ticket data
        tickets_with_assignments = db.get_tickets_with_assignments()
        target_ticket = None
        for t in tickets_with_assignments:
            if t.get('ticket_id') == ticket_id:
                target_ticket = t
                break
        
        debug_data = {
            'ticket_id': ticket_id,
            'assignment_exists': assignment is not None,
            'assignment_data': str(assignment) if assignment else None,
            'dashboard_shows_assignment': target_ticket is not None and len(target_ticket.get('assignment', [])) > 0,
            'assigned_to': target_ticket.get('assigned_to') if target_ticket else None,
            'assigned_member_data': target_ticket.get('assigned_member', []) if target_ticket else [],
            'assignment_count': len(target_ticket.get('assignment', [])) if target_ticket else 0,
            'member_count': len(target_ticket.get('assigned_member', [])) if target_ticket else 0,
            'timestamp': datetime.now().isoformat(),
            'badge_will_show': target_ticket is not None and target_ticket.get('assigned_to') is not None
        }
        
        app.logger.info(f"[DEBUG] Assignment check for {ticket_id}: exists={assignment is not None}, dashboard={debug_data['dashboard_shows_assignment']}")
        return jsonify(debug_data)
        
    except Exception as e:
        app.logger.error(f"[DEBUG] Error checking assignment: {e}")
        return jsonify({
            'error': str(e),
            'assignment_exists': False,
            'ticket_id': ticket_id
        }), 500

# Add debug endpoint for technicians
@app.route('/debug/technicians')
def debug_technicians():
    """Debug endpoint to check technicians in database"""
    try:
        import traceback
        db = get_db()
        
        # Get all technicians (including inactive)
        all_technicians = list(db.technicians.find({}))
        active_technicians = list(db.technicians.find({"is_active": True}))
        
        # Get technicians using the function
        function_technicians = db.get_all_technicians()
        
        debug_info = {
            'total_technicians_in_collection': len(all_technicians),
            'active_technicians_in_collection': len(active_technicians),
            'function_technicians_count': len(function_technicians),
            'all_technicians': [],
            'active_technicians': [],
            'function_technicians': []
        }
        
        # Format all technicians
        for tech in all_technicians:
            debug_info['all_technicians'].append({
                'id': str(tech['_id']),
                'name': tech.get('name', 'No Name'),
                'role': tech.get('role', 'No Role'),
                'email': tech.get('email', 'No Email'),
                'is_active': tech.get('is_active', False),
                'created_at': str(tech.get('created_at', 'No Date'))
            })
        
        # Format active technicians
        for tech in active_technicians:
            debug_info['active_technicians'].append({
                'id': str(tech['_id']),
                'name': tech.get('name', 'No Name'),
                'role': tech.get('role', 'No Role'),
                'email': tech.get('email', 'No Email'),
                'is_active': tech.get('is_active', False),
                'created_at': str(tech.get('created_at', 'No Date'))
            })
        
        # Format function technicians
        for tech in function_technicians:
            debug_info['function_technicians'].append({
                'id': str(tech['_id']),
                'name': tech.get('name', 'No Name'),
                'role': tech.get('role', 'No Role'),
                'email': tech.get('email', 'No Email'),
                'is_active': tech.get('is_active', False),
                'created_at': str(tech.get('created_at', 'No Date'))
            })
        
        return jsonify(debug_info)
        
    except Exception as e:
        return jsonify({'error': str(e), 'traceback': traceback.format_exc()}), 500

@app.route('/debug/warranty-tickets')
def debug_warranty_tickets():
    """
    Debug endpoint to check warranty tickets
    """
    try:
        db = get_db()
        tickets = db.get_tickets_with_assignments()
        
        warranty_tickets = []
        all_classifications = {}
        
        for ticket in tickets:
            classification = ticket.get('classification', 'Unknown')
            has_warranty = ticket.get('has_warranty', False)
            
            # Count all classifications
            all_classifications[classification] = all_classifications.get(classification, 0) + 1
            
            # Check if this is a warranty ticket
            is_warranty_related = (
                has_warranty or 
                'warranty' in classification.lower() or
                'warranty' in ticket.get('subject', '').lower()
            )
            
            if is_warranty_related:
                warranty_tickets.append({
                    'ticket_id': ticket.get('ticket_id'),
                    'classification': classification,
                    'has_warranty': has_warranty,
                    'priority': ticket.get('priority'),
                    'subject': ticket.get('subject', '')[:100]
                })
        
        return """
        <h1> Warranty Tickets Debug</h1>
        <h2>ðŸ“Š Summary</h2>
        <p><strong>Total tickets:</strong> {len(tickets)}</p>
        <p><strong>Warranty tickets found:</strong> {len(warranty_tickets)}</p>
        
        <h2> Warranty Tickets</h2>
        {'<p> No warranty tickets found!</p>' if not warranty_tickets else ''}
        {''.join([f'''
        <div style="border: 1px solid #ccc; margin: 10px 0; padding: 10px;">
            <strong>ID:</strong> {t['ticket_id']}<br>
            <strong>ID:</strong> {t['ticket_id']}<br>
            <strong>Classification:</strong> "{t['classification']}"<br>
            <strong>Has Warranty:</strong> {t['has_warranty']}<br>
            <strong>Priority:</strong> {t['priority']}<br>
            <strong>Subject:</strong> {t['subject']}<br>
        </div>
        ''' for t in warranty_tickets])}
        
        <h2>ðŸ“‹ All Classifications</h2>
        {''.join([f'<p><strong>{cls}:</strong> {count} tickets</p>' for cls, count in sorted(all_classifications.items())])}
        """
        
    except Exception as e:
        return f" Error: {e}"

@app.route('/debug/ticket-ids')
def debug_ticket_ids_page():
    """Debug page for ticket ID mismatches"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if user is admin or has debug access
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member.get('role') not in ['Administrator', 'IT']:
        flash('Access denied. Only administrators and IT staff can access debug tools.', 'error')
        return redirect(url_for('dashboard'))
    
    return render_template('debug_ticket_ids.html')

@app.route('/api/debug/ticket-id-mismatches')
def debug_ticket_id_mismatches():
    """Debug endpoint to identify and fix ticket ID mismatches"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Find all tickets and check for mismatches
        all_tickets = list(db.tickets.find({}))
        mismatches = []
        fixed_count = 0
        
        for ticket in all_tickets:
            ticket_id = ticket.get('_id')
            ticket_id_field = ticket.get('ticket_id')
            
            if ticket_id and ticket_id_field:
                # Check if there's a mismatch between _id and ticket_id
                if str(ticket_id) != str(ticket_id_field):
                    mismatches.append({
                        'ticket_id': str(ticket_id),
                        'ticket_id_field': ticket_id_field,
                        'subject': ticket.get('subject', 'No Subject'),
                        'status': ticket.get('status', 'Unknown'),
                        'created_at': str(ticket.get('created_at', 'Unknown'))
                    })
                    
                    # Fix the mismatch by updating the ticket_id field
                    try:
                        db.tickets.update_one(
                            {'_id': ticket_id},
                            {'$set': {'ticket_id': str(ticket_id)}}
                        )
                        fixed_count += 1
                        app.logger.info(f"ðŸ”§ FIXED TICKET ID MISMATCH - Ticket {ticket_id}: updated ticket_id field to {ticket_id}")
                    except Exception as e:
                        app.logger.error(f"âŒ FAILED TO FIX TICKET ID MISMATCH - Ticket {ticket_id}: {e}")
        
        return jsonify({
            'status': 'success',
            'total_tickets_checked': len(all_tickets),
            'mismatches_found': len(mismatches),
            'mismatches_fixed': fixed_count,
            'mismatch_details': mismatches,
            'message': f'Found {len(mismatches)} mismatches and fixed {fixed_count}'
        })
        
    except Exception as e:
        app.logger.error(f"Error in debug_ticket_id_mismatches: {e}")
        return jsonify({'status': 'error', 'message': f'Error: {str(e)}'}), 500

def regenerate_attachment_base64_data(ticket_id):
    """Utility function to regenerate base64 data for existing manual ticket attachments"""
    try:
        app.logger.info(f"ðŸ”„ REGENERATING BASE64 DATA FOR TICKET {ticket_id}")
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            app.logger.error(f"âŒ TICKET NOT FOUND: {ticket_id}")
            return False
        
        # Check if this is a manual ticket
        is_email_ticket = ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id')
        if is_email_ticket:
            app.logger.info(f"ðŸ“§ SKIPPING EMAIL TICKET: {ticket_id}")
            return False
        
        app.logger.info(f"ðŸ“Ž PROCESSING MANUAL TICKET ATTACHMENTS: {ticket_id}")
        
        # Get metadata attachments
        metadata = db.get_ticket_metadata(ticket_id)
        updated_count = 0
        
        for meta in metadata:
            if meta.get('key', '').startswith('attachment_'):
                try:
                    attachment_data = json.loads(meta.get('value', '{}'))
                    if attachment_data and isinstance(attachment_data, dict):
                        attachment_name = attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File'))
                        
                        # Skip if already has base64 data
                        if attachment_data.get('data'):
                            app.logger.info(f"ðŸ“Ž SKIPPING {attachment_name} - already has base64 data")
                            continue
                        
                        # Try to read file from path and regenerate base64 data
                        if attachment_data.get('path'):
                            file_path_from_meta = attachment_data.get('path')
                            app.logger.info(f"ðŸ“Ž ðŸ”„ REGENERATING BASE64 FOR: {attachment_name} from {file_path_from_meta}")
                            
                            # Try multiple possible path combinations
                            possible_paths = [
                                os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                os.path.join(os.getcwd(), file_path_from_meta),
                                file_path_from_meta,
                                os.path.join(UPLOAD_FOLDER, file_path_from_meta)
                            ]
                            
                            for path_attempt in possible_paths:
                                if os.path.exists(path_attempt):
                                    try:
                                        with open(path_attempt, 'rb') as f:
                                            file_content = f.read()
                                            base64_data = base64.b64encode(file_content).decode('utf-8')
                                        
                                        # Update the attachment data with base64
                                        attachment_data['data'] = base64_data
                                        attachment_data['size'] = len(file_content)
                                        
                                        # Update metadata in database
                                        db.add_ticket_metadata(ticket_id, meta['key'], json.dumps(attachment_data))
                                        
                                        app.logger.info(f"ðŸ“Ž âœ… REGENERATED BASE64 FOR: {attachment_name} ({len(base64_data)} chars)")
                                        updated_count += 1
                                        break
                                        
                                    except Exception as e:
                                        app.logger.warning(f"ðŸ“Ž âš ï¸ FAILED TO READ FILE FROM {path_attempt}: {e}")
                                        continue
                                else:
                                    app.logger.info(f"ðŸ“Ž ðŸ” PATH NOT FOUND: {path_attempt}")
                            else:
                                app.logger.warning(f"ðŸ“Ž âŒ COULD NOT REGENERATE BASE64 FOR: {attachment_name}")
                        else:
                            app.logger.warning(f"ðŸ“Ž âš ï¸ NO FILE PATH FOR: {attachment_name}")
                            
                except (json.JSONDecodeError, TypeError) as e:
                    app.logger.warning(f"ðŸ“Ž âŒ FAILED TO PARSE METADATA FOR KEY {meta.get('key')}: {e}")
                    continue
        
        app.logger.info(f"ðŸ”„ COMPLETED: Regenerated base64 data for {updated_count} attachments in ticket {ticket_id}")
        return updated_count > 0
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR REGENERATING BASE64 DATA FOR TICKET {ticket_id}: {e}")
        return False

@app.route('/api/tickets/<ticket_id>/regenerate-attachments', methods=['POST'])
def regenerate_ticket_attachments(ticket_id):
    """API endpoint to regenerate base64 data for existing manual ticket attachments"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        success = regenerate_attachment_base64_data(ticket_id)
        if success:
            return jsonify({
                'status': 'success', 
                'message': f'Successfully regenerated attachment data for ticket {ticket_id}'
            })
        else:
            return jsonify({
                'status': 'warning', 
                'message': f'No attachments needed regeneration for ticket {ticket_id}'
            })
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR IN REGENERATE ATTACHMENTS API: {e}")
        return jsonify({
            'status': 'error', 
            'message': f'Failed to regenerate attachments: {str(e)}'
        }), 500

def fix_malformed_base64_data(base64_string):
    """Utility function to fix common base64 encoding issues"""
    try:
        if not base64_string:
            return None, "Empty base64 string"
        
        # Clean the string
        cleaned = base64_string.strip()
        
        # Remove any non-base64 characters
        import re
        cleaned = re.sub(r'[^A-Za-z0-9+/=]', '', cleaned)
        
        # Check if padding is needed
        padding_needed = len(cleaned) % 4
        if padding_needed:
            cleaned += '=' * (4 - padding_needed)
        
        # Test decode
        try:
            decoded = base64.b64decode(cleaned)
            return cleaned, None  # Return cleaned string and no error
        except Exception as e:
            return None, f"Base64 decode failed: {str(e)}"
            
    except Exception as e:
        return None, f"Error fixing base64: {str(e)}"

@app.route('/api/tickets/<ticket_id>/regenerate-webhook-attachments', methods=['POST'])
def regenerate_webhook_attachments(ticket_id):
    """API endpoint to regenerate missing webhook attachments for existing replies"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get all replies for this ticket
        replies = list(db.replies.find({'ticket_id': ticket_id}))
        app.logger.info(f"ðŸ”„ Found {len(replies)} replies for ticket {ticket_id}")
        
        regenerated_count = 0
        
        for reply in replies:
            reply_id = reply['_id']
            attachments = reply.get('attachments', [])
            
            # Check if this reply has attachments but they're missing data
            if attachments:
                app.logger.info(f"ðŸ”„ Checking reply {reply_id} with {len(attachments)} attachments")
                
                for i, attachment in enumerate(attachments):
                    if attachment.get('type') == 'file':
                        # Check if attachment has malformed base64 data or is missing data
                        existing_data = attachment.get('data', '')
                        file_path = attachment.get('path', '')
                        
                        if existing_data:
                            # Try to fix malformed base64 data
                            try:
                                # Test if existing data is valid
                                base64.b64decode(existing_data)
                                app.logger.info(f"âœ… Attachment {i} in reply {reply_id} has valid base64 data")
                            except Exception as base64_error:
                                app.logger.warning(f"âš ï¸ Attachment {i} in reply {reply_id} has malformed base64 data: {base64_error}")
                                
                                # Try to fix the malformed data
                                fixed_data, error = fix_malformed_base64_data(existing_data)
                                if fixed_data:
                                    # Update with fixed base64 data
                                    db.replies.update_one(
                                        {'_id': reply_id, f'attachments.{i}.path': file_path},
                                        {'$set': {
                                            f'attachments.{i}.data': fixed_data,
                                            f'attachments.{i}.has_data': True
                                        }}
                                    )
                                    app.logger.info(f"âœ… Fixed malformed base64 data for attachment {i} in reply {reply_id}")
                                    regenerated_count += 1
                                else:
                                    app.logger.error(f"âŒ Could not fix malformed base64 data for attachment {i}: {error}")
                        
                        elif file_path and os.path.exists(file_path):
                            # This attachment is missing base64 data, try to regenerate it
                            try:
                                # Read file and convert to base64
                                with open(file_path, 'rb') as f:
                                    file_content = f.read()
                                    base64_data = base64.b64encode(file_content).decode('utf-8')
                                
                                # Update attachment with base64 data
                                db.replies.update_one(
                                    {'_id': reply_id, f'attachments.{i}.path': file_path},
                                    {'$set': {
                                        f'attachments.{i}.data': base64_data,
                                        f'attachments.{i}.has_data': True,
                                        f'attachments.{i}.size': len(file_content)
                                    }}
                                )
                                
                                app.logger.info(f"âœ… Regenerated base64 data for attachment {i} in reply {reply_id}")
                                regenerated_count += 1
                                
                            except Exception as e:
                                app.logger.error(f"âŒ Failed to regenerate attachment {i} in reply {reply_id}: {e}")
                        else:
                            app.logger.warning(f"âš ï¸ File not found for attachment {i} in reply {reply_id}: {file_path}")
        
        if regenerated_count > 0:
            return jsonify({
                'status': 'success',
                'message': f'Successfully regenerated {regenerated_count} webhook attachments for ticket {ticket_id}'
            })
        else:
            return jsonify({
                'status': 'warning',
                'message': f'No webhook attachments needed regeneration for ticket {ticket_id}'
            })
            
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR IN REGENERATE WEBHOOK ATTACHMENTS API: {e}")
        import traceback
        app.logger.error(f"ðŸ’¥ Full traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Failed to regenerate webhook attachments: {str(e)}'
        }), 500

@app.route('/api/debug/fix-base64', methods=['POST'])
def debug_fix_base64():
    """Debug endpoint to test and fix base64 data"""
    try:
        data = request.get_json()
        base64_string = data.get('base64_data', '')
        
        if not base64_string:
            return jsonify({'status': 'error', 'message': 'No base64 data provided'}), 400
        
        app.logger.info(f"ðŸ”§ Testing base64 data: length={len(base64_string)}")
        app.logger.info(f"ðŸ”§ First 50 chars: {base64_string[:50]}...")
        app.logger.info(f"ðŸ”§ Last 50 chars: {base64_string[-50:]}...")
        app.logger.info(f"ðŸ”§ Length % 4: {len(base64_string) % 4}")
        
        # Check for common issues
        has_invalid_chars = any(c not in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=' for c in base64_string)
        has_padding = '=' in base64_string
        app.logger.info(f"ðŸ”§ Has invalid chars: {has_invalid_chars}")
        app.logger.info(f"ðŸ”§ Has padding: {has_padding}")
        
        # Try to fix the base64 data
        fixed_data, error = fix_malformed_base64_data(base64_string)
        
        if fixed_data:
            try:
                # Test decode the fixed data
                decoded = base64.b64decode(fixed_data)
                app.logger.info(f"ðŸ”§ Successfully decoded {len(decoded)} bytes")
                
                response_data = {
                    'status': 'success',
                    'message': 'Base64 data fixed successfully',
                    'original_length': len(base64_string),
                    'fixed_length': len(fixed_data),
                    'decoded_bytes': len(decoded),
                    'original_data_preview': base64_string[:100] + '...' if len(base64_string) > 100 else base64_string,
                    'fixed_data_preview': fixed_data[:100] + '...' if len(fixed_data) > 100 else fixed_data,
                    'analysis': {
                        'original_length_mod_4': len(base64_string) % 4,
                        'fixed_length_mod_4': len(fixed_data) % 4,
                        'has_invalid_chars': has_invalid_chars,
                        'has_padding': has_padding
                    }
                }
                
                app.logger.info(f"ðŸ”§ Returning success response: {response_data}")
                return jsonify(response_data)
                
            except Exception as e:
                app.logger.error(f"ðŸ”§ Fixed data still invalid: {e}")
                return jsonify({
                    'status': 'error',
                    'message': f'Fixed data still invalid: {str(e)}',
                    'error': str(e),
                    'original_length': len(base64_string),
                    'fixed_length': len(fixed_data) if fixed_data else 0
                }), 400
        else:
            app.logger.error(f"ðŸ”§ Could not fix base64 data: {error}")
            return jsonify({
                'status': 'error',
                'message': f'Could not fix base64 data: {error}',
                'error': error,
                'original_length': len(base64_string),
                'analysis': {
                    'length_mod_4': len(base64_string) % 4,
                    'has_invalid_chars': has_invalid_chars,
                    'has_padding': has_padding
                }
            }), 400
            
    except Exception as e:
        app.logger.error(f"ðŸ”§ Error in debug fix base64: {e}")
        import traceback
        app.logger.error(f"ðŸ”§ Full traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Internal error: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


# Webhook cleanup and maintenance functions
def cleanup_old_webhook_metadata():
    """
    Clean up old webhook metadata to prevent database bloat
    Removes webhook records older than 30 days
    """
    try:
        db = get_db()
        cutoff_date = datetime.now() - timedelta(days=30)
        
        # Get all webhook metadata
        all_metadata = db.get_all_ticket_metadata()
        cleaned_count = 0
        
        for meta in all_metadata:
            if meta['key'] in ['webhook_triggered', 'webhook_url', 'webhook_method', 'referred_by']:
                # Check if this is old metadata
                if 'created_at' in meta and meta['created_at'] < cutoff_date:
                    # Remove old webhook metadata
                    db.remove_ticket_metadata(meta['ticket_id'], meta['key'])
                    cleaned_count += 1
        
        if cleaned_count > 0:
            app.logger.info(f"[CLEANUP] Cleaned up {cleaned_count} old webhook metadata records")
        
        return cleaned_count
        
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to cleanup webhook metadata: {e}")
        return 0


def get_webhook_health_status():
    """
    Get overall health status of the webhook system
    Returns statistics and any issues found
    """
    try:
        db = get_db()
        
        # Count active reminders
        active_reminders = 0
        cancelled_reminders = 0
        failed_webhooks = 0
        
        all_metadata = db.get_all_ticket_metadata()
        
        for meta in all_metadata:
            if meta['key'] == 'webhook_triggered':
                active_reminders += 1
            elif meta['key'] == 'reminder_cancelled':
                cancelled_reminders += 1
            elif meta['key'] == 'webhook_error':
                failed_webhooks += 1
        
        return {
            'active_reminders': active_reminders,
            'cancelled_reminders': cancelled_reminders,
            'failed_webhooks': failed_webhooks,
            'total_webhook_operations': active_reminders + cancelled_reminders + failed_webhooks,
            'health_score': 'good' if failed_webhooks < active_reminders * 0.1 else 'warning'
        }
        
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to get webhook health status: {e}")
        return {'error': str(e)}


if __name__ == '__main__':
    # Development server configuration
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
"""
AutoAssistGroup Support Ticket Management System

This Flask application provides a comprehensive support ticket management system with:
- User authentication and role-based access control
- Ticket creation, assignment, and tracking
- Email integration and automated processing
- File attachment handling with warranty detection
- Real-time dashboard with analytics
- MongoDB backend with optimized queries
- Serverless deployment support

CRITICAL FIX (2025-01-26): N8N Ticket ID Preservation
- Issue: N8N ticket IDs (e.g., GS5160) were being replaced with generated IDs (e.g., EO5267)
- Root Cause: Ticket ID extraction logic was not properly handling nested data structures
- Solution: Enhanced ticket ID preservation with multiple fallback extraction methods
- Added comprehensive debugging to identify data structure issues
- New debug endpoint: /api/tickets/debug-n8n for troubleshooting

Author: AutoAssistGroup Development Team
Version: 2.0
"""

from flask import Flask, render_template, jsonify, redirect, request, url_for, send_from_directory, session, flash, Response, make_response, render_template_string
from flask_cors import CORS
import os
import logging
from datetime import datetime, timedelta
import uuid
import re
import json
import requests
import atexit
import csv
import io
import smtplib
import threading
import time
import random
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from werkzeug.security import generate_password_hash, check_password_hash
from werkzeug.utils import secure_filename
from collections import defaultdict
from database import get_db
from bson.objectid import ObjectId
import base64
import mimetypes
import hashlib
from flask import send_file
import html

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # dotenv not available, skip loading
    pass

app = Flask(__name__)

# Enable CORS for all routes
CORS(app)

# Configure logging properly
is_production = os.environ.get('FLASK_ENV') == 'production'
log_level = logging.INFO if is_production else logging.DEBUG

logging.basicConfig(
    level=log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

# Only add file handler in development
if not is_production:
    file_handler = logging.FileHandler('app.log')
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logging.getLogger().addHandler(file_handler)

# Reduce verbose logging from external libraries
logging.getLogger('werkzeug').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)

app.logger.setLevel(logging.INFO)

# Security configuration
app.secret_key = os.environ.get('SECRET_KEY', os.urandom(32).hex())
if not os.environ.get('SECRET_KEY'):
    app.logger.warning("SECRET_KEY not set in environment, using generated key (not suitable for production)")

# Enhanced session configuration for better stability and longer sessions
app.config['SESSION_COOKIE_SECURE'] = False  # Set to True only in production with HTTPS
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
app.config['SESSION_REFRESH_EACH_REQUEST'] = True
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=30)  # 30 days - very permissive for better user experience
app.config['SESSION_COOKIE_MAX_AGE'] = 30 * 24 * 60 * 60  # 30 days in seconds

# Simple session configuration
# Minimal security headers - more permissive for better user experience
@app.after_request
def set_security_headers(response):
    """Add minimal security headers to all responses"""
    response.headers['X-Content-Type-Options'] = 'nosniff'
    # Removed strict security headers to prevent session issues
    return response

# Enhanced session timeout configuration
app.permanent_session_lifetime = timedelta(days=30)  # 30 days - very permissive for better user experience

def check_session_timeout():
    """No session timeout - sessions are permanent"""
    # Sessions never expire - always return False
    return False

def refresh_session():
    """Aggressive session refresh - force session to persist"""
    try:
        if 'member_id' in session:
            # Force session to be permanent and never expire
            session.permanent = True
            session.modified = True
            
            # Add persistence markers
            session['_last_refresh'] = datetime.now().isoformat()
            session['_refresh_count'] = session.get('_refresh_count', 0) + 1
            
            # Force session to be saved immediately
            session['_force_persist'] = True
            
            app.logger.info(f"Session aggressively refreshed for user {session.get('member_id', 'unknown')} - Refresh #{session['_refresh_count']}")
            return True
        else:
            app.logger.warning("Cannot refresh session - no member_id found")
            return False
    except Exception as e:
        app.logger.error(f"Error refreshing session: {e}")
        return False
        
def restore_user_session():
    """Simple session restoration - just try to get user_id from database"""
    try:
        # If session already has member_id, no need to restore
        if 'member_id' in session:
            return True
            
        app.logger.info(f"Attempting session restoration. Session keys: {list(session.keys())}")
        
        # Try to restore from user_id in session
        if 'user_id' in session:
            try:
                db = get_db()
                user = db.get_member_by_user_id(session['user_id'])
                if user:
                    # Simple restoration
                    session['member_id'] = str(user['_id'])
                    session['member_name'] = user.get('name', 'Unknown')
                    session['member_role'] = user.get('role', 'Member')
                    session.permanent = True
                    session.modified = True
                    
                    app.logger.info(f"Session restored for user {user.get('name', 'Unknown')}")
                    return True
                else:
                    app.logger.warning(f"User {session['user_id']} not found in database")
            except Exception as e:
                app.logger.error(f"Failed to restore session: {e}")
        
        return False
        
    except Exception as e:
        app.logger.error(f"Error in session restoration: {e}")
        return False

def check_and_restore_session():
    """Check if session is valid and try to restore if needed"""
    try:
        # If session has member_id, it's valid
        if 'member_id' in session:
            return True
            
        # Try to restore the session
        if restore_user_session():
            return True
            
        # If restoration failed, session is truly invalid
        return False
        
    except Exception as e:
        app.logger.error(f"Error checking/restoring session: {e}")
        return False

def safe_member_lookup():
    """Safely get member data with automatic session restoration"""
    try:
        if 'member_id' not in session:
            # Try to restore session first
            if check_and_restore_session():
                app.logger.info("Session restored during member lookup")
            else:
                return None
        
        # Now try to get member data
        db = get_db()
        current_member = db.get_member_by_id(session['member_id'])
        
        if not current_member:
            app.logger.warning(f"Member {session.get('member_id')} not found in database")
            return None
            
        return current_member
        
    except Exception as e:
        app.logger.error(f"Error in safe_member_lookup: {e}")
        return None

# Enhanced before_request with better session management
@app.before_request
def before_request():
    """Enhanced request preprocessing with better session handling"""
    protected_routes = ['dashboard', 'ticket_detail', 'create_ticket', 'admin', 'members', 'technicians']
    
    # Also check API routes that require authentication
    api_routes_requiring_auth = [
        'manage_members', 'manage_member', 'get_technicians', 'create_technician', 
        'update_technician', 'deactivate_technician', 'get_single_ticket',
        'delete_ticket', 'assign_ticket', 'update_ticket_status', 'send_reply',
        'dashboard_updates'  # Add this line to protect the dashboard updates API
    ]
    
    # Skip session checks for static files and non-protected routes
    if request.endpoint in ['static', 'favicon'] or request.path.startswith('/static/'):
        return None
    
    # Skip session checks for health check and session heartbeat endpoints
    if request.endpoint in ['health_check', 'session_heartbeat']:
        return None
    
    # Simple session management - always try to restore if needed
    if 'member_id' not in session:
        # Try to restore session without redirecting
        if check_and_restore_session():
            app.logger.info(f"Session restored for {request.endpoint}")
        else:
            app.logger.warning(f"Session restoration failed for {request.endpoint}")
            # Don't redirect - let the endpoint handle it
    
    # If we have member_id, just refresh it
    if 'member_id' in session:
        try:
            refresh_session()
            app.logger.debug(f"Session refreshed for user {session.get('member_id')}")
        except Exception as e:
            app.logger.error(f"Error refreshing session: {e}")
    
    # Sessions are permanent - no timeout checks
    # Users stay logged in forever

# Configuration
WEBHOOK_URL = os.environ.get('WEBHOOK_URL', 'https://ffxtrading.app.n8n.cloud/webhook/fb4af014-26e6-4477-821f-917fc9b3ee96')

# Email Configuration
EMAIL_HOST = os.environ.get('EMAIL_HOST', 'smtp.gmail.com')
EMAIL_PORT = int(os.environ.get('EMAIL_PORT', '587'))
EMAIL_USERNAME = os.environ.get('EMAIL_USERNAME', '')
EMAIL_PASSWORD = os.environ.get('EMAIL_PASSWORD', '')
EMAIL_USE_TLS = os.environ.get('EMAIL_USE_TLS', 'True').lower() == 'true'
EMAIL_FROM = os.environ.get('EMAIL_FROM', EMAIL_USERNAME)

# Input validation and sanitization helpers
def sanitize_input(text):
    """Sanitize user input to prevent XSS attacks"""
    if not text:
        return ""
    return html.escape(str(text).strip())

def validate_email(email):
    """Validate email format"""
    import re
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(pattern, email) is not None

def validate_ticket_id(ticket_id):
    """Validate ticket ID format"""
    if not ticket_id or len(str(ticket_id)) > 50:
        return False
    return str(ticket_id).replace(' ', '') == str(ticket_id)  # No spaces allowed

def rate_limit_check(key, limit=10, window=60):
    """Simple in-memory rate limiting (for production, use Redis)"""
    import time
    current_time = time.time()
    
    # For simplicity, using a global dict (in production, use proper cache)
    if not hasattr(rate_limit_check, 'cache'):
        rate_limit_check.cache = {}
    
    if key not in rate_limit_check.cache:
        rate_limit_check.cache[key] = []
    
    # Remove old entries
    rate_limit_check.cache[key] = [
        timestamp for timestamp in rate_limit_check.cache[key] 
        if current_time - timestamp < window
    ]
    
    if len(rate_limit_check.cache[key]) >= limit:
        return False
    
    rate_limit_check.cache[key].append(current_time)
    return True

# Simple caching mechanism (in production, use Redis/Memcached)
def cache_get(key, default=None):
    """Get value from cache"""
    if not hasattr(cache_get, 'cache'):
        cache_get.cache = {}
    
    if key in cache_get.cache:
        value, expires = cache_get.cache[key]
        if time.time() < expires:
            return value
        else:
            del cache_get.cache[key]
    
    return default

def cache_set(key, value, expires_in=300):
    """Set value in cache with expiration (default 5 minutes)"""
    import time
    if not hasattr(cache_get, 'cache'):
        cache_get.cache = {}
    
    expires_at = time.time() + expires_in
    cache_get.cache[key] = (value, expires_at)

# File upload configuration for serverless environments
if is_production:
    # For serverless/production, use /tmp directory (ephemeral)
    UPLOAD_FOLDER = '/tmp/uploads'
    try:
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        logging.info(f"SUCCESS: Created upload directory: {UPLOAD_FOLDER}")
    except OSError as e:
        logging.warning(f"Could not create upload directory: {e}")
        # Fallback to /tmp if /tmp/uploads fails
        UPLOAD_FOLDER = '/tmp'
        logging.info(f" Fallback upload directory: {UPLOAD_FOLDER}")
else:
    # For development - use absolute path to avoid read-only issues
    UPLOAD_FOLDER = os.environ.get('UPLOAD_FOLDER', os.path.join(os.getcwd(), 'uploads'))
    try:
        os.makedirs('static', exist_ok=True)
        os.makedirs('templates', exist_ok=True)
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        logging.info(f"SUCCESS: Created directories including: {UPLOAD_FOLDER}")
    except OSError as e:
        logging.warning(f"Could not create directories: {e}")
        # Fallback to system temp directory if current directory is read-only
        import tempfile
        UPLOAD_FOLDER = os.path.join(tempfile.gettempdir(), 'autoassist_uploads')
        try:
            os.makedirs(UPLOAD_FOLDER, exist_ok=True)
            logging.info(f"SUCCESS: Created fallback upload directory: {UPLOAD_FOLDER}")
        except OSError as fallback_error:
            logging.error(f"CRITICAL: Could not create any upload directory: {fallback_error}")
            UPLOAD_FOLDER = None

# Log upload folder configuration
        logging.info(f"UPLOAD_FOLDER configured as: {UPLOAD_FOLDER}")
        logging.info(f"UPLOAD_FOLDER exists: {os.path.exists(UPLOAD_FOLDER) if UPLOAD_FOLDER else False}")

app.config['DEBUG'] = os.environ.get('FLASK_ENV') != 'production'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Add these constants after existing app configuration
ALLOWED_EXTENSIONS = {'pdf', 'doc', 'docx', 'jpg', 'jpeg', 'png', 'txt', 'csv'}

# Note: Upload directory creation is now handled above based on environment

# Email Service Class
class EmailService:
    """Email service for sending notifications"""
    
    def __init__(self):
        self.host = EMAIL_HOST
        self.port = EMAIL_PORT
        self.username = EMAIL_USERNAME
        self.password = EMAIL_PASSWORD
        self.use_tls = EMAIL_USE_TLS
        self.from_email = EMAIL_FROM
    
    def send_email(self, to_email, subject, body, html_body=None, attachments=None):
        """Send email with optional HTML body and attachments
        
        Args:
            to_email: Recipient email address
            subject: Email subject
            body: Email body text
            html_body: Optional HTML body
            attachments: List of attachments. Each attachment can be:
                - String (file path)
                - Dict with keys: 'filename', 'data' (base64), 'content_type' (optional)
        """
        try:
            # Skip sending if email is not configured
            if not self.username or not self.password:
                app.logger.warning("Email not configured - would send email:")
                app.logger.info(f"To: {to_email}")
                app.logger.info(f"Subject: {subject}")
                app.logger.info(f"Body: {body}")
                if attachments:
                    app.logger.info(f"Attachments: {len(attachments)} files")
                return True
            
            # Create message
            msg = MIMEMultipart('alternative')
            msg['From'] = self.from_email
            msg['To'] = to_email
            msg['Subject'] = subject
            
            # Add text body
            text_part = MIMEText(body, 'plain')
            msg.attach(text_part)
            
            # Add HTML body if provided
            if html_body:
                html_part = MIMEText(html_body, 'html')
                msg.attach(html_part)
            
            # Add attachments if provided
            if attachments:
                for attachment in attachments:
                    try:
                        if isinstance(attachment, str):
                            # Handle file path attachment (original behavior)
                            if os.path.exists(attachment):
                                with open(attachment, 'rb') as attachment_file:
                                    part = MIMEBase('application', 'octet-stream')
                                    part.set_payload(attachment_file.read())
                                
                                encoders.encode_base64(part)
                                part.add_header(
                                    'Content-Disposition',
                                            f'attachment; filename="{os.path.basename(attachment)}"'
                                )
                                msg.attach(part)
                                app.logger.info(f" Added file attachment: {os.path.basename(attachment)}")
                            else:
                                app.logger.warning(f" Attachment file not found: {attachment}")
                        
                        elif isinstance(attachment, dict):
                            # Handle base64 data attachment (new functionality)
                            filename = attachment.get('filename', attachment.get('fileName', 'attachment'))
                            file_data = attachment.get('data', attachment.get('fileData', ''))
                            content_type = attachment.get('content_type', 'application/octet-stream')
                            
                            if file_data:
                                # Decode base64 data
                                try:
                                    decoded_data = base64.b64decode(file_data)
                                    
                                    # Determine MIME type
                                    mime_type = content_type
                                    if mime_type == 'application/octet-stream':
                                        import mimetypes
                                        guessed_type, _ = mimetypes.guess_type(filename)
                                        if guessed_type:
                                            mime_type = guessed_type
                                    
                                    # Create attachment part
                                    maintype, subtype = mime_type.split('/', 1)
                                    part = MIMEBase(maintype, subtype)
                                    part.set_payload(decoded_data)
                                    encoders.encode_base64(part)
                                    part.add_header(
                                        'Content-Disposition',
                                        f'attachment; filename="{filename}"'
                                    )
                                    msg.attach(part)
                                    app.logger.info(f" Added base64 attachment: {filename} ({len(decoded_data)} bytes)")
                                    
                                except Exception as decode_error:
                                    app.logger.error(f" Failed to decode base64 attachment {filename}: {decode_error}")
                            else:
                                app.logger.warning(f" No data provided for attachment: {filename}")
                        
                        else:
                            app.logger.warning(f" Invalid attachment format: {type(attachment)}")
                            
                    except Exception as att_error:
                        app.logger.error(f" Error processing attachment: {att_error}")
                        continue
            
            # Send email
            server = smtplib.SMTP(self.host, self.port)
            if self.use_tls:
                server.starttls()
            server.login(self.username, self.password)
            server.send_message(msg)
            server.quit()
            
            app.logger.info(f"ðŸ“§ Email sent successfully to {to_email} with {len(attachments) if attachments else 0} attachments")
            return True
            
        except Exception as e:
            app.logger.error(f"ðŸ’¥ Failed to send email to {to_email}: {e}")
            return False

# Initialize email service
email_service = EmailService()

# Add function to check allowed file extensions
def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# Note: Manual ticket creation route removed - ticket numbers are auto-generated
# Tickets are created automatically through:
# 1. Email integration (/api/tickets)
# 2. Warranty form submissions (/api/warranty-form-submission)
# 3. Other automated processes

# Note: Manual ticket creation API removed since ticket numbers are auto-generated
# Tickets are created automatically through existing automated endpoints

# ===============================
# SMART DETECTION & PARSING UTILITIES
# ===============================
def detect_warranty_form(filename, file_data=None):
    """
    Intelligent warranty form detection based on filename and content
    Enhanced with comprehensive keyword matching and future content analysis capability
    """
    # Comprehensive warranty keywords including common misspellings
    warranty_keywords = [
        'warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante', 'garentee',
        'extended', 'protection', 'coverage', 'service_plan', 'service_contract',
        'maintenance_agreement', 'care_plan', 'support_plan', 'repair_coverage',
        'product_protection', 'extended_service', 'service_warranty', 
        'manufacturer_warranty', 'factory_warranty', 'vehicle_warranty',
        'bumper_to_bumper', 'powertrain', 'drivetrain', 'comprehensive_coverage'
    ]
    
    filename_lower = filename.lower()
    
    # Check filename for warranty keywords
    for keyword in warranty_keywords:
        if keyword in filename_lower:
            app.logger.info(f"Warranty form detected via filename keyword: {keyword} in {filename}")
            return True
    
    # Future enhancement: Content-based analysis
    if file_data:
        # Framework for content analysis (OCR, text extraction, etc.)
        # Can be extended to analyze file contents for warranty-related text
        pass
    
    return False

def get_enhanced_file_type_info(filename, file_size=0):
    """
    Advanced file type detection with comprehensive MIME type mapping
    Returns detailed file information including icons, colors, and capabilities
    """
    extension = filename.split('.').pop().lower()
    
    file_type_mapping = {
        # Document types
        'pdf': {
            'icon': 'fas fa-file-pdf', 
            'color': 'text-red-600', 
            'type': 'PDF Document',
            'mime': 'application/pdf',
            'viewable': True,
            'category': 'document'
        },
        'doc': {
            'icon': 'fas fa-file-word', 
            'color': 'text-blue-600', 
            'type': 'Word Document',
            'mime': 'application/msword',
            'viewable': False,
            'category': 'document'
        },
        'docx': {
            'icon': 'fas fa-file-word', 
            'color': 'text-blue-600', 
            'type': 'Word Document',
            'mime': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            'viewable': False,
            'category': 'document'
        },
        'xls': {
            'icon': 'fas fa-file-excel', 
            'color': 'text-green-600', 
            'type': 'Excel Spreadsheet',
            'mime': 'application/vnd.ms-excel',
            'viewable': False,
            'category': 'spreadsheet'
        },
        'xlsx': {
            'icon': 'fas fa-file-excel', 
            'color': 'text-green-600', 
            'type': 'Excel Spreadsheet',
            'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            'viewable': False,
            'category': 'spreadsheet'
        },
        'ppt': {
            'icon': 'fas fa-file-powerpoint', 
            'color': 'text-orange-600', 
            'type': 'PowerPoint Presentation',
            'mime': 'application/vnd.ms-powerpoint',
            'viewable': False,
            'category': 'presentation'
        },
        'pptx': {
            'icon': 'fas fa-file-powerpoint', 
            'color': 'text-orange-600', 
            'type': 'PowerPoint Presentation',
            'mime': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            'viewable': False,
            'category': 'presentation'
        },
        # Image types
        'jpg': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'JPEG Image',
            'mime': 'image/jpeg',
            'viewable': True,
            'category': 'image'
        },
        'jpeg': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'JPEG Image',
            'mime': 'image/jpeg',
            'viewable': True,
            'category': 'image'
        },
        'png': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'PNG Image',
            'mime': 'image/png',
            'viewable': True,
            'category': 'image'
        },
        'gif': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'GIF Image',
            'mime': 'image/gif',
            'viewable': True,
            'category': 'image'
        },
        'webp': {
            'icon': 'fas fa-file-image', 
            'color': 'text-purple-600', 
            'type': 'WebP Image',
            'mime': 'image/webp',
            'viewable': True,
            'category': 'image'
        },
        # Archive types
        'zip': {
            'icon': 'fas fa-file-archive', 
            'color': 'text-yellow-600', 
            'type': 'ZIP Archive',
            'mime': 'application/zip',
            'viewable': False,
            'category': 'archive'
        },
        'rar': {
            'icon': 'fas fa-file-archive', 
            'color': 'text-yellow-600', 
            'type': 'RAR Archive',
            'mime': 'application/vnd.rar',
            'viewable': False,
            'category': 'archive'
        },
        '7z': {
            'icon': 'fas fa-file-archive', 
            'color': 'text-yellow-600', 
            'type': '7-Zip Archive',
            'mime': 'application/x-7z-compressed',
            'viewable': False,
            'category': 'archive'
        },
        # Text types
        'txt': {
            'icon': 'fas fa-file-alt', 
            'color': 'text-gray-600', 
            'type': 'Text File',
            'mime': 'text/plain',
            'viewable': True,
            'category': 'text'
        },
        'csv': {
            'icon': 'fas fa-file-csv', 
            'color': 'text-green-600', 
            'type': 'CSV File',
            'mime': 'text/csv',
            'viewable': True,
            'category': 'data'
        },
        'json': {
            'icon': 'fas fa-file-code', 
            'color': 'text-indigo-600', 
            'type': 'JSON File',
            'mime': 'application/json',
            'viewable': True,
            'category': 'data'
        },
        'xml': {
            'icon': 'fas fa-file-code', 
            'color': 'text-indigo-600', 
            'type': 'XML File',
            'mime': 'application/xml',
            'viewable': True,
            'category': 'data'
        }
    }
    
    file_info = file_type_mapping.get(extension, {
        'icon': 'fas fa-file', 
        'color': 'text-gray-600', 
        'type': 'File',
        'mime': 'application/octet-stream',
        'viewable': False,
        'category': 'unknown'
    })
    
    # Add file size information
    file_info['size'] = file_size
    file_info['extension'] = extension.upper()
    
    return file_info

# ===============================
# ENHANCED EMAIL PROCESSING FUNCTIONS
# ===============================

def enhanced_detect_warranty_form(filename, file_data=None):
    """
    Enhanced warranty form detection with comprehensive keyword matching
    Detects warranty forms based on filename patterns and content analysis
    """
    # Enhanced warranty keywords with common misspellings and variations
    warranty_keywords = [
        'warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante', 'warrantie',
        'dpf', 'diesel', 'emission', 'claim', 'form', 'customer',
        'repair', 'service', 'defect', 'malfunction', 'issue', 'fault',
        'warranty_form', 'warranty_claim', 'claim_form', 'service_form',
        'dpf_form', 'emission_form', 'diesel_form', 'repair_form',
        'customer_form', 'complaint_form', 'warranty_application'
    ]
    
    filename_lower = filename.lower()
    
    app.logger.info(f" CHECKING WARRANTY in filename: '{filename}' â†’ '{filename_lower}'")
    
    # Check filename for warranty keywords
    keyword_matches = 0
    detected_keywords = []
    
    for keyword in warranty_keywords:
        if keyword in filename_lower:
            keyword_matches += 1
            detected_keywords.append(keyword)
            app.logger.info(f"     FOUND KEYWORD: '{keyword}'")
    
    app.logger.info(f" Total keyword matches: {keyword_matches}, Keywords found: {detected_keywords}")
    
    # Higher confidence with multiple keyword matches
    if keyword_matches >= 2:
        app.logger.info(f" Multi-keyword warranty detection: {filename} - Keywords: {detected_keywords}")
        return True
    elif keyword_matches == 1:
        # Single keyword match - check for high-confidence patterns
        high_confidence_keywords = ['warranty_form', 'warranty_claim', 'claim_form', 'dpf_form']
        for keyword in high_confidence_keywords:
            if keyword in filename_lower:
                app.logger.info(f" High-confidence warranty detection: {filename} - Keyword: {keyword}")
                return True
        app.logger.info(f" Single keyword match but not high-confidence: {detected_keywords[0]}")
    
    # Check for common warranty file patterns
    warranty_patterns = [
        'warranty', 'claim', 'dpf', 'emission', 'diesel'
    ]
    
    for pattern in warranty_patterns:
        if pattern in filename_lower and ('form' in filename_lower or 'pdf' in filename_lower):
            app.logger.info(f"Pattern-based warranty detection: {filename} - Pattern: {pattern}")
            return True
    
    return False

def generate_email_draft_response(ticket_data):
    """
    Generate contextual draft response for email tickets
    Creates intelligent draft based on email content, warranty status, and classification
    """
    try:
        customer_name = ticket_data.get('name', '').strip()
        first_name = customer_name.split()[0] if customer_name else 'Customer'
        
        subject = ticket_data.get('subject', '').lower()
        body = ticket_data.get('body', '').lower()
        classification = ticket_data.get('classification', 'General').lower()
        has_warranty = ticket_data.get('has_warranty', False)
        has_attachments = ticket_data.get('has_attachments', False)
        
        # ðŸš€ SMART DRAFT GENERATION based on content analysis
        app.logger.info(f"ðŸ¤– GENERATING SMART DRAFT for ticket - Classification: {classification}, Warranty: {has_warranty}, Attachments: {has_attachments}")
        
        # Warranty-related responses
        if has_warranty or 'warranty' in subject or 'warranty' in body or 'claim' in subject or classification == 'warranty claim':
            app.logger.info(f" WARRANTY DRAFT - Generating warranty claim response")
            draft = """Dear {first_name},

Thank you for contacting Auto Assist Group regarding your warranty inquiry.

We have received your warranty claim and our Aftercare Team is reviewing the details. To process your claim efficiently, we may need some additional information:

â€¢ Vehicle registration number
â€¢ Current mileage reading (with dashboard photo)
â€¢ Any new fault codes or error messages
â€¢ Details of any recent services or repairs

Our warranty claim form is available at: https://autoassistgroup.com/report/claims

We will review your case within 2-3 business days and contact you with next steps. If your claim is approved, we will arrange the necessary remedial work at no cost to you.

If you have any questions in the meantime, please don't hesitate to contact us.

Best regards,
Auto Assist Group - Aftercare Team"""

        # DPF/Technical issues
        elif 'dpf' in subject or 'dpf' in body or 'filter' in subject or 'regen' in subject or classification == 'technical support':
            app.logger.info(f"ðŸ”§ TECHNICAL DRAFT - Generating DPF/technical support response")
            draft = """Dear {first_name},

Thank you for reaching out regarding your DPF/technical issue.

We've received your inquiry and our technical team is reviewing the details. Based on the information provided, we will:

1. Assess the technical requirements for your vehicle
2. Provide you with a detailed solution and quote
3. Schedule the work at your convenience

Our technical specialists will contact you within 24 hours to discuss:
â€¢ Diagnostic findings and recommendations
â€¢ Service options and pricing
â€¢ Appointment availability

In the meantime, if you experience any urgent issues with your vehicle, please contact us immediately at 01234 567890.

Best regards,
Auto Assist Group - Technical Support Team"""

        # Customer service/General inquiries
        elif classification == 'customer service' or 'service' in subject or 'appointment' in subject or 'booking' in subject:
            app.logger.info(f"ðŸ“ž SERVICE DRAFT - Generating customer service response")
            draft = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your inquiry and appreciate you choosing our services. Our customer service team is reviewing your request and will respond within 24 hours.

For immediate assistance, you can reach us at:
â€¢ Phone: 01234 567890 (Mon-Fri 8AM-6PM)
â€¢ Email: support@autoassistgroup.com

If you're looking to book a service, you can also use our online booking system at: https://autoassistgroup.com/book

We look forward to assisting you with your automotive needs.

Kind regards,
Auto Assist Group Customer Service Team"""

        # File/Document submissions
        elif has_attachments or 'document' in subject or 'file' in subject or 'upload' in body:
            app.logger.info(f"ðŸ“Ž DOCUMENT DRAFT - Generating file/document response")
            draft = """Dear {first_name},

Thank you for submitting your documentation to Auto Assist Group.

We have received your files and our team is currently reviewing them. You can expect:

â€¢ Document verification within 24-48 hours
â€¢ A follow-up call or email with next steps
â€¢ Any additional requirements if needed

If your submission is related to a warranty claim, our Aftercare Team will prioritize the review process.

Your reference number is: {ticket_data.get('ticket_id', 'N/A')}

Thank you for your patience. We will contact you soon with an update.

Best regards,
Auto Assist Group Support Team"""
        # General/Default response
        else:
            app.logger.info(f"ðŸ’¬ GENERAL DRAFT - Generating standard response")
            draft = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your message and our team is reviewing your inquiry. We aim to respond to all customer communications within 24 hours.

If your inquiry is urgent, please contact us directly at:
â€¢ Phone: 01234 567890
â€¢ Email: support@autoassistgroup.com

Your reference number is: {ticket_data.get('ticket_id', 'N/A')}

We appreciate your business and look forward to assisting you.

Kind regards,
Auto Assist Group Support Team"""        
        app.logger.info(f" DRAFT GENERATED - Length: {len(draft)} characters for ticket {ticket_data.get('ticket_id', 'Unknown')}")
        return draft.strip()
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ DRAFT GENERATION FAILED: {e}")
        # Fallback draft
        customer_name = ticket_data.get('name', 'Customer')
        first_name = customer_name.split()[0] if customer_name else 'Customer'
        
        fallback_draft = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your message and will respond as soon as possible.

Best regards,
Auto Assist Group Support Team"""
        
        app.logger.info(f"ðŸ”„ USING FALLBACK DRAFT for ticket {ticket_data.get('ticket_id', 'Unknown')}")
        return fallback_draft.strip()

def enhanced_process_email_attachments(attachments_data):
    """
    Enhanced attachment processing with base64 handling and warranty detection
    Updated to handle complex n8n data structures properly
    """
    processed_attachments = []
    warranty_detected = False
    
    if not attachments_data:
        return processed_attachments, warranty_detected
    
    # Handle the complex n8n data structure
    app.logger.info(f"Processing {len(attachments_data)} attachment items")
    for i, att_data in enumerate(attachments_data):
        app.logger.info(f"Attachment item {i}: {type(att_data)} - Keys: {list(att_data.keys()) if isinstance(att_data, dict) else 'Not a dict'}")
        
        if isinstance(att_data, dict):
            # Case 1: Handle data array with nested attachments (n8n format)
            if 'data' in att_data and isinstance(att_data['data'], list):
                app.logger.info(f"Case 1: Found nested data array with {len(att_data['data'])} items")
                for j, nested_item in enumerate(att_data['data']):
                    app.logger.info(f"Nested item {j}: {type(nested_item)} - Keys: {list(nested_item.keys()) if isinstance(nested_item, dict) else 'Not a dict'}")
                    if isinstance(nested_item, dict):
                        # Handle nested JSON string data
                        if 'data' in nested_item and isinstance(nested_item['data'], str):
                            app.logger.info(f"Case 1a: Found JSON string data")
                            try:
                                parsed_att = json.loads(nested_item['data'])
                                app.logger.info(f"Parsed attachment data: {list(parsed_att.keys()) if isinstance(parsed_att, dict) else 'Not a dict'}")
                                attachment = process_single_attachment(parsed_att)
                                if attachment:
                                    app.logger.info(f"Created attachment: {attachment.get('filename', 'unknown')}")
                                    processed_attachments.append(attachment)
                                    if attachment.get('is_warranty', False):
                                        warranty_detected = True
                            except json.JSONDecodeError as e:
                                app.logger.error(f"JSON decode error: {e}")
                                continue
                        else:
                            # Direct nested attachment data
                            app.logger.info(f"Case 1b: Direct nested attachment data")
                            attachment = process_single_attachment(nested_item)
                            if attachment:
                                app.logger.info(f"Created attachment: {attachment.get('filename', 'unknown')}")
                                processed_attachments.append(attachment)
                                if attachment.get('is_warranty', False):
                                    warranty_detected = True
            
            # Case 2: Handle JSON string data
            elif 'data' in att_data and isinstance(att_data['data'], str):
                try:
                    parsed_att = json.loads(att_data['data'])
                    attachment = process_single_attachment(parsed_att)
                    if attachment:
                        processed_attachments.append(attachment)
                        if attachment.get('is_warranty', False):
                            warranty_detected = True
                except json.JSONDecodeError:
                    attachment = process_single_attachment(att_data)
                    if attachment:
                        processed_attachments.append(attachment)
                        if attachment.get('is_warranty', False):
                            warranty_detected = True
            
            # Case 3: Direct attachment data
            else:
                attachment = process_single_attachment(att_data)
            if attachment:
                processed_attachments.append(attachment)
                if attachment.get('is_warranty', False):
                    warranty_detected = True
    
    # Final debugging summary
    app.logger.info(f"[TARGET] Enhanced attachment processing complete:")
    app.logger.info(f"  - Input items: {len(attachments_data)}")
    app.logger.info(f"  - Processed attachments: {len(processed_attachments)}")
    app.logger.info(f"  - Warranty detected: {warranty_detected}")
    if processed_attachments:
        app.logger.info(f"  - Attachment filenames: {[att.get('filename', 'unknown') for att in processed_attachments]}")
    else:
        app.logger.warning(f"  - [WARNING]  NO ATTACHMENTS PROCESSED from {len(attachments_data)} input items!")
    
    return processed_attachments, warranty_detected

def process_single_attachment(att_data):
    """
    Process a single attachment with enhanced metadata
    """
    app.logger.info(f"Processing single attachment: {type(att_data)} - Keys: {list(att_data.keys()) if isinstance(att_data, dict) else 'Not a dict'}")
    
    if not isinstance(att_data, dict):
        app.logger.warning(f"Attachment data is not a dict: {type(att_data)}")
        return None
    
    # Handle different field name variations from n8n
    filename = (att_data.get('fileName') or 
                att_data.get('filename') or 
                att_data.get('name') or 
                'unknown_file')
    
    file_data = (att_data.get('fileData') or 
                 att_data.get('data') or 
                 att_data.get('content') or 
                 '')
    
    if not filename or filename == 'unknown_file':
        app.logger.warning(f"No valid filename found. Available keys: {list(att_data.keys())}")
        if not file_data:
            app.logger.warning(f"No file data either. Skipping this attachment.")
            return None
        else:
            filename = 'attachment_without_name'
    
    app.logger.info(f"[SUCCESS] Processing attachment: {filename} (has_data: {bool(file_data)})")
    
    # Calculate file size
    file_size = 0
    if file_data:
        try:
            file_size = len(base64.b64decode(file_data))
        except:
            file_size = 0
    
    # Enhanced warranty detection
    is_warranty = enhanced_detect_warranty_form(filename)
    
    # DEBUG: Log warranty detection result
    app.logger.info(f" WARRANTY CHECK: {filename} â†’ {' WARRANTY DETECTED' if is_warranty else ' No warranty detected'}")
    
    attachment = {
        'filename': filename,
        'data': file_data,
        'is_warranty': is_warranty,
        'size': file_size,
        'size_formatted': format_file_size(file_size),
        'from': att_data.get('from', ''),
        'ticket_no': att_data.get('ticketNo', att_data.get('ticket_id', '')),
        'index': att_data.get('index', 0),
        'processed_at': datetime.now().isoformat()
    }
    
    # Add file type analysis
    try:
        file_type_info = get_enhanced_file_type_info(filename, file_size)
        attachment.update({
        'file_type': file_type_info.get('type', 'unknown'),
        'file_category': file_type_info.get('category', 'unknown'),
        'file_extension': file_type_info.get('extension', ''),
        'type_confidence': file_type_info.get('confidence', 0)
        })
    except Exception as e:
        app.logger.error(f"Error analyzing file type for {filename}: {e}")
        attachment.update({
            'file_type': 'unknown',
            'file_category': 'unknown',
            'file_extension': os.path.splitext(filename)[1].lower() if filename else '',
            'type_confidence': 0
    })
    
    return attachment

def format_file_size(size_bytes):
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def enhanced_process_complex_email_data(raw_data):
    """
    Enhanced email processing combining Gmail frontend capabilities with AutoAssistGroup features
    """
    processed_tickets = []
    attachments_list = []
    main_ticket = None
    warranty_detected = False
    
    app.logger.info(f"Enhanced processing email data: {type(raw_data)}")
    
    try:
        # Handle case where data is a list (n8n often sends arrays)
        if isinstance(raw_data, list):
            app.logger.info(f"Processing array with {len(raw_data)} items")
            for i, item in enumerate(raw_data):
                app.logger.info(f"Processing list item {i}: {type(item)} - Keys: {list(item.keys()) if isinstance(item, dict) else 'Not a dict'}")
                
                if isinstance(item, dict):
                    # Check for attachment data with enhanced parsing
                    if 'data' in item and isinstance(item['data'], list):
                        app.logger.info(f"Found attachment data array with {len(item['data'])} items")
                        # Process attachments route data
                        processed_atts, warranty_found = enhanced_process_email_attachments(item['data'])
                        app.logger.info(f"Processed {len(processed_atts)} attachments, warranty found: {warranty_found}")
                        attachments_list.extend(processed_atts)
                        if warranty_found:
                            warranty_detected = True
                    
                    # Check if this is main ticket data (text route)
                    elif 'ticket_id' in item or 'threadI' in item or 'body' in item:
                        main_ticket = item
                        
                    # Check if item has direct data field with JSON
                    elif 'data' in item and isinstance(item['data'], str):
                        try:
                            parsed_data = json.loads(item['data'])
                            if 'fileName' in parsed_data:
                                attachment = process_single_attachment(parsed_data)
                                if attachment:
                                    attachments_list.append(attachment)
                                    if attachment.get('is_warranty', False):
                                        warranty_detected = True
                            else:
                                main_ticket = parsed_data
                        except json.JSONDecodeError:
                            pass
                    
                    # [FIX] CRITICAL FIX: Check for flat attachment structure BEFORE treating as main ticket
                    elif 'fileName' in item and 'fileData' in item:
                        # This is a flat attachment structure
                        attachment = process_single_attachment(item)
                        if attachment:
                            attachments_list.append(attachment)
                            if attachment.get('is_warranty', False):
                                warranty_detected = True
                                app.logger.info(f"Warranty detected in flat attachment: {item['fileName']}")
                        app.logger.info(f"Detected flat attachment: {item['fileName']}")
                            
                    # Direct ticket data without nesting (fallback)
                    else:
                        if not main_ticket:  # Only set if we don't have one yet
                            main_ticket = item
        else:
            # Single item case
            if isinstance(raw_data, dict):
                if 'ticket_id' in raw_data or 'threadI' in raw_data or 'body' in raw_data:
                    main_ticket = raw_data
                else:
                    processed_tickets.append(enhanced_process_single_email_item(raw_data))
        
        # Combine main ticket with attachments
        if main_ticket:
            combined_ticket = main_ticket.copy()
            combined_ticket['attachments'] = attachments_list
            combined_ticket['has_attachments'] = len(attachments_list) > 0
            combined_ticket['has_warranty'] = warranty_detected
            combined_ticket['warranty_forms_count'] = sum(1 for att in attachments_list if att.get('is_warranty', False))
            
            # Enhanced ticket metadata
            combined_ticket['processed_at'] = datetime.now().isoformat()
            combined_ticket['processing_method'] = 'enhanced_email_processor'
            combined_ticket['total_attachments'] = len(attachments_list)
            combined_ticket['attachment_total_size'] = sum(att.get('size', 0) for att in attachments_list)
            
            # Enhanced debugging
            app.logger.info(f"[DEBUG] Enhanced processing summary:")
            app.logger.info(f"  - Attachments found: {len(attachments_list)}")
            app.logger.info(f"  - Has attachments: {combined_ticket.get('has_attachments')}")
            app.logger.info(f"  - Total attachments: {combined_ticket.get('total_attachments')}")
            app.logger.info(f"  - Warranty detected: {warranty_detected}")
            if attachments_list:
                app.logger.info(f"  - Attachment details: {[att.get('filename', 'unknown') for att in attachments_list]}")
                for idx, att in enumerate(attachments_list):
                    app.logger.info(f"    ðŸ“Ž Attachment {idx}: {att.get('filename', 'no_name')} | Size: {att.get('size', 0)} | Warranty: {att.get('is_warranty', False)} | HasData: {bool(att.get('data'))}")
            else:
                app.logger.warning(f" NO ATTACHMENTS FOUND in email processing!")
            
            # Set priority based on warranty detection
            if warranty_detected:
                combined_ticket['priority'] = 'High'
                combined_ticket['classification'] = 'Warranty Claim'
                app.logger.info(f" WARRANTY CLASSIFICATION SET: Ticket {combined_ticket.get('ticket_id', 'UNKNOWN')} marked as High priority and 'Warranty Claim' classification due to warranty form detection")
            
            processed_tickets.append(combined_ticket)
        
        # If we have attachments but no main ticket, create tickets from attachments
        elif attachments_list:
            for att in attachments_list:
                # Enhanced collision-resistant ID generation for attachment-only tickets
                timestamp = datetime.now()
                ticket_id = att.get('ticket_no', 
                    f"ATTCH{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12])
                ticket = {
                    'ticket_id': ticket_id,
                    'name': 'Unknown',
                    'from': att.get('from', ''),
                    'subject': f"Attachment: {att.get('filename', 'unknown')}",
                    'body': f"Ticket created from attachment: {att.get('filename', 'unknown')}",
                    'date': datetime.now().isoformat(),
                    'Priority': 'High' if att.get('is_warranty') else 'Medium',
                    'Classification': 'Warranty Claim' if att.get('is_warranty') else 'General',
                    'draft': '',
                    'attachments': [att],
                    'has_attachments': True,
                    'has_warranty': att.get('is_warranty', False),
                    'warranty_forms_count': 1 if att.get('is_warranty') else 0,
                    'total_attachments': 1,  # Fix: Add missing total_attachments
                    'attachment_total_size': att.get('size', 0),  # Fix: Add missing attachment_total_size
                    'processed_at': datetime.now().isoformat(),
                    'processing_method': 'attachment_only_processor'
                }
                processed_tickets.append(ticket)
        
        app.logger.info(f"Enhanced processing completed: {len(processed_tickets)} tickets, {len(attachments_list)} attachments, warranty detected: {warranty_detected}")
        
    except Exception as e:
        app.logger.error(f"Enhanced email processing error: {str(e)}")
        return []
    
    return processed_tickets

def enhanced_process_single_email_item(item):
    """
    Enhanced processing of single email items with warranty detection
    """
    ticket = {}
    
    if isinstance(item, dict) and 'data' in item:
        # Parse the data field if it's a JSON string
        data_content = item['data']
        if isinstance(data_content, str):
            try:
                parsed_data = json.loads(data_content)
                ticket.update(parsed_data)
            except json.JSONDecodeError:
                ticket['raw_data'] = data_content
        else:
            ticket.update(data_content)
            
        # Add index if available
        if 'index' in item:
            ticket['attachment_index'] = item['index']
    else:
        ticket.update(item)
    
    # Enhanced attachment processing
    if 'fileName' in ticket and 'fileData' in ticket:
        attachment = process_single_attachment(ticket)
        if attachment:
            ticket['attachments'] = [attachment]
            ticket['has_attachments'] = True
            ticket['has_warranty'] = attachment.get('is_warranty', False)
            ticket['warranty_forms_count'] = 1 if attachment.get('is_warranty') else 0
    else:
        ticket['has_attachments'] = False
        ticket['has_warranty'] = False
        ticket['warranty_forms_count'] = 0
        ticket['attachments'] = []
    
    # Enhanced metadata with collision-resistant ID
    if 'ticket_id' not in ticket:
        timestamp = datetime.now()
        ticket['ticket_id'] = f"EPROC{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
    ticket.setdefault('date', datetime.now().isoformat())
    ticket.setdefault('Priority', 'High' if ticket.get('has_warranty') else 'Medium')
    ticket.setdefault('Classification', 'Warranty Claim' if ticket.get('has_warranty') else 'General')
    ticket.setdefault('processed_at', datetime.now().isoformat())
    ticket.setdefault('processing_method', 'single_item_processor')
    
    return ticket

def process_complex_email_data(raw_data):
    """
    Ultra-sophisticated email data parsing for complex nested n8n structures
    Handles multiple data formats, nested JSON, and fragmented information
    """
    processed_tickets = []
    attachments_list = []
    main_ticket = None
    warranty_detected = False
    
    app.logger.info(f"Processing complex email data: {type(raw_data)}")
    
    try:
        # Handle case where data is a list (n8n often sends arrays)
        if isinstance(raw_data, list):
            for item in raw_data:
                app.logger.info(f"Processing list item: {type(item)}")
                
                if isinstance(item, dict):
                    # Check for attachment data with nested structure
                    if 'data' in item and isinstance(item['data'], list):
                        # This is the attachments route data
                        for att_data in item['data']:
                            if isinstance(att_data, dict):
                                if 'data' in att_data and isinstance(att_data['data'], str):
                                    # Parse JSON string data
                                    try:
                                        parsed_att = json.loads(att_data['data'])
                                        if 'fileName' in parsed_att:
                                            attachments_list.append(parsed_att)
                                            # Check for warranty form
                                            if detect_warranty_form(parsed_att['fileName']):
                                                warranty_detected = True
                                                app.logger.info(f"Warranty detected in attachment: {parsed_att['fileName']}")
                                    except json.JSONDecodeError as e:
                                        app.logger.error(f"JSON decode error: {e}")
                                elif 'fileName' in att_data:
                                    # Direct attachment data
                                    attachments_list.append(att_data)
                                    if detect_warranty_form(att_data['fileName']):
                                        warranty_detected = True
                    
                    # Check if this is main ticket data
                    elif 'ticket_id' in item or 'threadI' in item or 'body' in item:
                        main_ticket = item
                        
                    # Check if item has direct data field with JSON
                    elif 'data' in item and isinstance(item['data'], str):
                        try:
                            parsed_data = json.loads(item['data'])
                            if 'fileName' in parsed_data:
                                attachments_list.append(parsed_data)
                                if detect_warranty_form(parsed_data['fileName']):
                                    warranty_detected = True
                            else:
                                main_ticket = parsed_data
                        except json.JSONDecodeError:
                            pass
                    
                    # [FIX] CRITICAL FIX: Check for flat attachment structure BEFORE treating as main ticket
                    elif 'fileName' in item and 'fileData' in item:
                        # This is a flat attachment structure
                        attachments_list.append(item)
                        if detect_warranty_form(item['fileName']):
                            warranty_detected = True
                            app.logger.info(f"Warranty detected in flat attachment: {item['fileName']}")
                        app.logger.info(f"Detected flat attachment: {item['fileName']}")
                            
                    # Direct ticket data without nesting (fallback)
                    else:
                        if not main_ticket:  # Only set if we don't have one yet
                            main_ticket = item
        else:
            # Single item case
            if isinstance(raw_data, dict):
                if 'ticket_id' in raw_data or 'threadI' in raw_data or 'body' in raw_data:
                    main_ticket = raw_data
                else:
                    processed_tickets.append(process_single_email_item(raw_data))
        
        # Combine main ticket with attachments
        if main_ticket:
            combined_ticket = main_ticket.copy()
            combined_ticket['attachments'] = []
            combined_ticket['has_attachments'] = len(attachments_list) > 0
            combined_ticket['has_warranty'] = warranty_detected
            
            for att in attachments_list:
                attachment = {
                    'filename': att.get('fileName', 'unknown_file'),
                    'data': att.get('fileData', ''),
                    'is_warranty': detect_warranty_form(att.get('fileName', '')),
                    'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0,
                    'file_type': get_enhanced_file_type_info(att.get('fileName', ''))
                }
                combined_ticket['attachments'].append(attachment)
            
            processed_tickets.append(combined_ticket)
        
        # If we have attachments but no main ticket, create a basic ticket
        elif attachments_list:
            for att in attachments_list:
                # Generate collision-resistant ID for attachment tickets
                timestamp = datetime.now()
                default_ticket_id = f"OATTCH{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                ticket = {
                    'ticket_id': att.get('ticketNo', att.get('ticket_id', default_ticket_id)),
                    'name': 'Unknown',
                    'from': att.get('from', ''),
                    'subject': att.get('subject', 'Attachment Only'),
                    'body': f"Ticket created from attachment: {att.get('fileName', 'unknown')}",
                    'date': datetime.now().isoformat(),
                    'Priority': 'Medium',
                    'Classification': 'General',
                    'draft': '',
                    'attachments': [{
                        'filename': att.get('fileName', 'unknown_file'),
                        'data': att.get('fileData', ''),
                        'is_warranty': detect_warranty_form(att.get('fileName', '')),
                        'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0,
                        'file_type': get_enhanced_file_type_info(att.get('fileName', ''))
                    }],
                    'has_attachments': True,
                    'has_warranty': detect_warranty_form(att.get('fileName', ''))
                }
                processed_tickets.append(ticket)
        
        app.logger.info(f"Processed {len(processed_tickets)} tickets, warranty detected: {warranty_detected}")
        return processed_tickets
        
    except Exception as e:
        app.logger.error(f"Error in complex email data processing: {str(e)}")
        return []

def process_single_email_item(item):
    """
    Process a single email item with intelligent content analysis
    """
    ticket = {}
    
    if isinstance(item, dict) and 'data' in item:
        # Parse the data field if it's a JSON string
        data_content = item['data']
        if isinstance(data_content, str):
            try:
                parsed_data = json.loads(data_content)
                ticket.update(parsed_data)
            except json.JSONDecodeError:
                ticket['raw_data'] = data_content
        else:
            ticket.update(data_content)
            
        # Add index if available
        if 'index' in item:
            ticket['attachment_index'] = item['index']
    else:
        ticket.update(item)
    
    # Process attachments if present
    if 'fileName' in ticket and 'fileData' in ticket:
        file_type_info = get_enhanced_file_type_info(ticket['fileName'])
        attachment = {
            'filename': ticket['fileName'],
            'data': ticket['fileData'],
            'is_warranty': detect_warranty_form(ticket['fileName']),
            'size': len(base64.b64decode(ticket['fileData'])) if ticket['fileData'] else 0,
            'file_type': file_type_info
        }
        ticket['attachments'] = [attachment]
        ticket['has_attachments'] = True
        ticket['has_warranty'] = attachment.get('is_warranty', False)
    else:
        ticket['has_attachments'] = False
        ticket['has_warranty'] = False
        ticket['attachments'] = []
    
    # Ensure required fields with collision-resistant ID
    if 'ticket_id' not in ticket:
        timestamp = datetime.now()
        ticket['ticket_id'] = f"OPROC{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
    ticket.setdefault('date', datetime.now().isoformat())
    ticket.setdefault('Priority', 'Medium')
    ticket.setdefault('Classification', 'General')
    
    return ticket

# ===============================
# API ENDPOINTS
# ===============================

# Add API endpoint for automatic ticket creation from warranty form submissions
@app.route('/api/n8n/email-tickets', methods=['POST'])
def n8n_email_tickets():
    """
    New endpoint specifically designed for n8n email data with proper attachment handling
    """
    try:
        # Get JSON data from request
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400
        
        app.logger.info(f"N8N Email Tickets endpoint received data: {type(data)}")
        
        # Process the email data using enhanced processing
        try:
            processed_tickets = enhanced_process_complex_email_data(data)
            app.logger.info(f"Enhanced processing returned {len(processed_tickets) if processed_tickets else 0} tickets")
            
            # Debug: Log the processed ticket structure
            for i, ticket in enumerate(processed_tickets or []):
                attachments = ticket.get('attachments', [])
                app.logger.info(f" [DEBUG] Processed ticket {i}:")
                app.logger.info(f"  - has_attachments: {ticket.get('has_attachments')}")
                app.logger.info(f"  - has_warranty: {ticket.get('has_warranty')}")
                app.logger.info(f"  - total_attachments: {ticket.get('total_attachments')} (type: {type(ticket.get('total_attachments'))})")
                app.logger.info(f"  - attachments_count: {len(attachments)}")
                app.logger.info(f"  - subject: {ticket.get('subject', 'No subject')}")
                app.logger.info(f"  - from: {ticket.get('from', 'No sender')}")
                if attachments:
                    for j, att in enumerate(attachments):
                        app.logger.info(f"    ðŸ“Ž Attachment {j}: {att.get('filename', 'unknown')} (warranty: {att.get('is_warranty', False)}) (data_length: {len(att.get('data', ''))})")
                else:
                    app.logger.warning(f"     NO ATTACHMENTS in this ticket!")
                
        except Exception as processing_error:
            app.logger.error(f"Error in enhanced_process_complex_email_data: {processing_error}")
            return jsonify({
                'status': 'error',
                'message': f'Error processing email data: {str(processing_error)}',
                'data_received': data
            }), 500
        
        if not processed_tickets:
            return jsonify({
                'status': 'error',
                'message': 'No valid ticket data found in request',
                'data_received': data,
                'debug_info': 'enhanced_process_complex_email_data returned empty list'
            }), 400
        
        db = get_db()
        created_tickets = []
        
        for ticket in processed_tickets:
            try:
                # [FIX] Use n8n provided ticket_id if available, otherwise generate one
                n8n_ticket_id = ticket.get('ticket_id', '').strip()
                
                if n8n_ticket_id:
                    # Use n8n ticket ID EXACTLY as provided (no formatting, no prefixes)
                    if not db.ticket_id_exists(n8n_ticket_id):
                        # Use n8n ticket ID exactly as-is
                        ticket_id = n8n_ticket_id
                        app.logger.info(f"[N8N_TICKET_ID] Using n8n ticket ID exactly as provided: {ticket_id}")
                    else:
                        app.logger.warning(f"[N8N_TICKET_ID] N8N ticket ID {n8n_ticket_id} already exists, using generated ID")
                        # Fall through to generate new ID
                        ticket_id = None
                if not ticket_id:
                    # Generate unique ticket ID with collision protection as fallback
                    max_attempts = 20
                    ticket_id = None
                    
                    for attempt in range(max_attempts):
                        # Generate unique ticket ID
                        timestamp = datetime.now()
                        potential_id = f"N8N{timestamp.strftime('%H%M%S')}{random.randint(1000, 9999)}"
                        
                        # Check if ID already exists
                        if not db.ticket_id_exists(potential_id):
                            ticket_id = potential_id
                            break
                        app.logger.debug(f"Ticket ID collision {potential_id}, retrying...")
                    
                    if n8n_ticket_id:
                        app.logger.warning(f"[N8N_TICKET_ID] N8N ticket ID {n8n_ticket_id} already exists, using generated ID: {ticket_id}")
                    else:
                        app.logger.info(f"[N8N_TICKET_ID] No n8n ticket ID provided, using generated ID: {ticket_id}")
                    
                    if not ticket_id:
                        app.logger.error(f"Failed to generate unique ticket ID after {max_attempts} attempts")
                        continue
                
                # Prepare ticket data for database (matching database schema)
                # Fix total_attachments calculation issue - always use actual attachment count
                total_attachments = ticket.get('total_attachments')
                attachments_array = ticket.get('attachments', [])
                
                # Always recalculate from actual attachments to fix inconsistency
                if attachments_array:
                    total_attachments = len(attachments_array)
                    app.logger.info(f"[FIX] Recalculated total_attachments from {ticket.get('total_attachments')} to {total_attachments}")
                elif total_attachments is None:
                    total_attachments = 0
                
                # Debug logging
                app.logger.info(f"[INFO] Ticket {ticket_id} - has_attachments: {ticket.get('has_attachments')}, total_attachments: {total_attachments}, attachments array length: {len(attachments_array)}")
                
                # Generate unique thread_id to avoid conflicts (never use incoming threadI data)
                thread_id = f"THREAD_{ticket_id}_{timestamp.strftime('%Y%m%d_%H%M%S')}_{random.randint(100, 999)}"
                
                # AUTO-CONFIRM WARRANTY: If warranty detected in email, set status directly to "Warranty Form Received"
                has_warranty = ticket.get('has_warranty', False)
                auto_confirmed_status = 'Warranty Form Received' if has_warranty else 'New'
                
                if has_warranty:
                    app.logger.info(f"ðŸŽ¯ AUTO-CONFIRMED WARRANTY: Ticket {ticket_id} status set to '{auto_confirmed_status}' (no manual confirmation needed)")
                else:
                    app.logger.info(f"â„¹ NO WARRANTY DETECTED: Ticket {ticket_id} status set to '{auto_confirmed_status}'")
                
                ticket_data = {
                    'ticket_id': ticket_id,
                    'thread_id': thread_id,  # Add unique thread_id
                    'name': ticket.get('name', 'Unknown'),
                    'email': ticket.get('from', ''),
                    'subject': ticket.get('subject', 'No Subject'),
                    'body': ticket.get('body', ''),
                    'status': auto_confirmed_status,  # Auto-confirm warranty, no manual confirmation needed
                    'priority': ticket.get('Priority', 'Medium'),
                    'classification': ticket.get('Classification', 'General'),
                    'is_important': False,
                    'has_unread_reply': False,
                    'has_warranty': has_warranty,
                    'has_attachments': total_attachments > 0,  # Fix: base this on actual attachment count
                    'warranty_forms_count': ticket.get('warranty_forms_count', 0) or 0,
                    'total_attachments': total_attachments or 0,
                    'attachment_total_size': ticket.get('attachment_total_size', 0) or 0,
                    'processing_method': 'n8n_email_processor'
                }
                
                # ðŸš€ FIX: Store N8N-provided draft in ticket data
                n8n_provided_draft = ticket.get('draft', '').strip()
                if n8n_provided_draft:
                    app.logger.info(f"ðŸ“ FOUND N8N PROVIDED DRAFT: {n8n_provided_draft[:200]}...")
                    ticket_data['draft'] = n8n_provided_draft
                    ticket_data['draft_body'] = n8n_provided_draft
                    ticket_data['n8n_draft'] = n8n_provided_draft
                    app.logger.info(f"ðŸ“ STORED N8N DRAFT in multiple fields for compatibility")
                else:
                    app.logger.info(f"ðŸ“ NO N8N DRAFT PROVIDED - will generate one")
                
                # Remove any conflicting threadI data from incoming ticket to avoid conflicts
                if 'threadI' in ticket:
                    app.logger.info(f"Removing incoming threadI data to avoid conflicts: {ticket['threadI']}")
                    ticket.pop('threadI', None)
                
                app.logger.info(f"Creating ticket {ticket_id} with thread_id {thread_id}")
                app.logger.info(f"Ticket data keys: {list(ticket_data.keys())}")
                app.logger.info(f"Total attachments: {ticket_data['total_attachments']}, Has attachments: {ticket_data['has_attachments']}")
                
                # ðŸš€ GENERATE DRAFT RESPONSE for email tickets (only if no N8N draft)
                if not n8n_provided_draft:
                    app.logger.info(f"ðŸ¤– GENERATING DRAFT for email ticket {ticket_id}")
                    app.logger.info(f"ðŸ” DEBUG: ticket_data['ticket_id'] = {ticket_data.get('ticket_id')} (should be formatted like EO980494)")
                    draft_response = generate_email_draft_response(ticket_data)
                    ticket_data['draft_body'] = draft_response
                    app.logger.info(f"ðŸ“ DRAFT GENERATED for ticket {ticket_id}: {draft_response[:200]}..." if len(draft_response) > 200 else f"ðŸ“ DRAFT GENERATED: {draft_response}")
                else:
                    app.logger.info(f"ðŸ“ USING N8N PROVIDED DRAFT - no need to generate new one")
                
                # Create ticket in database
                try:
                    created_id = db.create_ticket(ticket_data)
                    app.logger.info(f"[SUCCESS] Successfully created ticket {ticket_id} in database with ID: {created_id}")
                except ValueError as val_error:
                    app.logger.error(f"Validation error creating ticket {ticket_id}: {val_error}")
                    # Try with completely new ticket ID and thread ID
                    retry_timestamp = datetime.now()
                    retry_ticket_id = f"N8N{retry_timestamp.strftime('%H%M%S')}{random.randint(10000, 99999)}"
                    retry_thread_id = f"THREAD_{retry_ticket_id}_{retry_timestamp.strftime('%Y%m%d_%H%M%S')}"
                    
                    ticket_data['ticket_id'] = retry_ticket_id
                    ticket_data['thread_id'] = retry_thread_id
                    
                    try:
                        created_id = db.create_ticket(ticket_data)
                        ticket_id = retry_ticket_id  # Update ticket_id for later use
                        app.logger.info(f"Successfully created ticket {ticket_id} on retry with new thread_id")
                    except Exception as retry_error:
                        app.logger.error(f"Failed to create ticket even on retry: {retry_error}")
                        # Last resort: create without thread_id
                        ticket_data_no_thread = ticket_data.copy()
                        ticket_data_no_thread.pop('thread_id', None)
                        try:
                            created_id = db.create_ticket(ticket_data_no_thread)
                            app.logger.info(f"Successfully created ticket {ticket_id} without thread_id")
                        except Exception as final_error:
                            app.logger.error(f"Final attempt failed: {final_error}")
                            raise final_error
                except Exception as db_error:
                    app.logger.error(f"Database error creating ticket {ticket_id}: {db_error}")
                    app.logger.error(f"Ticket data causing error: {ticket_data}")
                    import traceback
                    app.logger.error(f"Full traceback: {traceback.format_exc()}")
                    raise db_error
                
                # Process and SAVE attachments to disk for proper download
                total_ticket_attachments = ticket.get('attachments', [])
                app.logger.info(f"FOLDER PROCESSING {len(total_ticket_attachments)} ATTACHMENTS for ticket {ticket_id}")
                
                if total_ticket_attachments:
                    for i, attachment in enumerate(total_ticket_attachments):
                        try:
                            filename = attachment.get('filename', f'attachment_{i}')
                            file_data = attachment.get('data', '')
                            is_warranty = attachment.get('is_warranty', False)
                            
                            app.logger.info(f"ðŸ’¾ PROCESSING ATTACHMENT {i+1}/{len(total_ticket_attachments)}: {filename} (warranty: {is_warranty})")
                            
                            # SAVE FILE TO DISK for download functionality
                            file_path = None
                            if file_data:
                                try:
                                    # Decode base64 and save to uploads directory
                                    decoded_data = base64.b64decode(file_data)
                                    safe_filename = secure_filename(filename)
                                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                    unique_filename = f"{timestamp}_{ticket_id}_{safe_filename}"
                                    
                                    file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                                    with open(file_path, 'wb') as f:
                                        f.write(decoded_data)
                                    
                                    app.logger.info(f" SAVED ATTACHMENT to disk: {file_path} ({len(decoded_data)} bytes)")
                                    
                                except Exception as save_error:
                                    app.logger.error(f" Failed to save attachment {filename}: {save_error}")
                                    file_path = None
                            else:
                                app.logger.warning(f" NO FILE DATA for attachment {filename}")
                            
                            # Store both metadata AND file path for download
                            attachment_metadata = {
                                'key': f'attachment_{i}',
                                'filename': filename,
                                'file_path': file_path,  # ADD: Path to saved file
                                'data': file_data,       # Keep base64 data as backup
                                'is_warranty': attachment.get('is_warranty', False),
                                'size': attachment.get('size', 0),
                                'file_type': attachment.get('file_type', 'unknown'),
                                'saved_to_disk': bool(file_path)  # Track if file was saved
                            }
                            db.add_ticket_metadata(ticket_id, f'attachment_{i}', json.dumps(attachment_metadata))
                            app.logger.info(f"COMPLETE: Saved attachment {filename} - disk:{bool(file_path)} metadata:âœ“")
                            
                        except Exception as att_error:
                            app.logger.error(f"Error processing attachment {i}: {att_error}")
                
                created_tickets.append({
                    'ticket_id': ticket_id,
                    'has_attachments': total_attachments > 0,  # Fix: use calculated value
                    'has_warranty': ticket.get('has_warranty', False),
                    'total_attachments': total_attachments,  # Fix: use calculated value
                    'warranty_forms_count': ticket.get('warranty_forms_count', 0),
                    'priority': ticket.get('Priority', 'Medium')
                })
                
                app.logger.info(f"Successfully processed ticket {ticket_id} with {total_attachments} attachments")
                
            except Exception as e:
                app.logger.error(f"Error creating ticket: {e}")
                continue
        
        if not created_tickets:
            # Enhanced error reporting
            error_details = []
            for i, ticket in enumerate(processed_tickets):
                error_details.append({
                    'ticket_index': i,
                    'ticket_data': {
                        'has_attachments': ticket.get('has_attachments'),
                        'total_attachments': ticket.get('total_attachments'),
                        'has_warranty': ticket.get('has_warranty'),
                        'subject': ticket.get('subject'),
                        'from': ticket.get('from')
                    }
                })
            
            return jsonify({
                'status': 'error',
                'message': 'Failed to create any tickets',
                'processed_data': processed_tickets,
                'error_details': error_details,
                'debug_info': f'Processed {len(processed_tickets)} ticket(s) but none were created successfully'
            }), 500
        
        return jsonify({
            'status': 'success',
            'message': f'Successfully created {len(created_tickets)} email ticket(s) with enhanced processing',
            'count': len(created_tickets),
            'tickets': created_tickets,
            'total_attachments': sum(t.get('total_attachments', 0) for t in created_tickets),
            'warranty_forms_detected': sum(t.get('warranty_forms_count', 0) for t in created_tickets)
        })
        
    except Exception as e:
        app.logger.error(f"N8N Email Tickets endpoint error: {e}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Server error: {str(e)}'
        }), 500

@app.route('/api/n8n/simple-test', methods=['POST'])
def n8n_simple_test():
    """
    Simple test endpoint to verify database connectivity and basic ticket creation
    """
    try:
        data = request.json
        app.logger.info(f"Simple test endpoint received: {data}")
        
        db = get_db()
        
        # Create a simple test ticket
        test_ticket_data = {
            'ticket_id': f"TEST{random.randint(100000, 999999)}",
            'name': 'Test User',
            'email': 'test@example.com',
            'subject': 'Test Ticket',
            'body': 'This is a test ticket',
            'status': 'New',
            'priority': 'Medium',
            'classification': 'General',
            'is_important': False,
            'has_unread_reply': False,
            'has_warranty': False,
            'has_attachments': False,
            'warranty_forms_count': 0,
            'total_attachments': 0,
            'attachment_total_size': 0,
            'processing_method': 'test_processor'
        }
        
        app.logger.info(f"Creating test ticket: {test_ticket_data}")
        created_id = db.create_ticket(test_ticket_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Test ticket created successfully',
            'ticket_id': test_ticket_data['ticket_id'],
            'created_id': str(created_id),
            'data_received': data
        })
        
    except Exception as e:
        app.logger.error(f"Simple test error: {e}")
        import traceback
        app.logger.error(f"Test traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Test failed: {str(e)}',
            'data_received': data
        }), 500

@app.route('/api/warranty-form-submission', methods=['POST'])
def warranty_form_submission():
    """Create a ticket automatically from a warranty form submission"""
    db = None
    try:
        # Get JSON data from request
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400
        
        # Extract required fields
        name = data.get('customer_name')
        email = data.get('customer_email')
        phone = data.get('customer_phone', '')
        registration = data.get('vehicle_registration', '')
        warranty_details = data.get('warranty_details', '')
        
        # Validate required fields
        if not all([name, email]):
            return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400
        
        # Create subject and body from warranty details
        subject = f"Warranty Claim - {registration}"
        body = warranty_details
        
        # Connect to database first
        db = get_db()
        
        # Create unique warranty ticket ID with race condition protection
        max_attempts = 50
        ticket_id = None
        # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
        thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
        
        for attempt in range(max_attempts):
            potential_id = f"W{str(uuid.uuid4())[:5].upper()}"
            
            try:
                # Try to create ticket with this ID - will fail if duplicate
                ticket_data = {
                    'ticket_id': potential_id,
                    'email': email,
                    'name': name,
                    'phone': phone,
                    'subject': subject,
                    'body': body,
                    'classification': 'Warranty Claim',
                    'priority': 'Medium',
                    'status': 'Open',
                    'thread_id': thread_id,
                    'creation_method': 'email'
                }
                
                # ðŸš€ GENERATE DRAFT RESPONSE for warranty email tickets  
                app.logger.info(f"ðŸ¤– GENERATING DRAFT for warranty email ticket {potential_id}")
                draft_response = generate_email_draft_response(ticket_data)
                ticket_data['draft_body'] = draft_response
                app.logger.info(f" DRAFT GENERATED for warranty ticket {potential_id} - Length: {len(draft_response)} chars")
                
                # This will throw ValueError if ticket ID already exists (race condition safe)
                db.create_ticket(ticket_data)
                ticket_id = potential_id
                app.logger.info(f"Successfully created warranty ticket with ID: {ticket_id} on attempt {attempt + 1}")
                break
                
            except ValueError as e:
                if "Ticket ID already exists" in str(e):
                    app.logger.debug(f"Warranty ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                    continue  # Try next ID
                else:
                    # Different error, re-raise
                    raise e
        
        if not ticket_id:
            return jsonify({'status': 'error', 'message': 'Failed to generate unique ticket ID. Please try again.'}), 500
        
        # Store vehicle registration
        if registration:
            db.add_ticket_metadata(ticket_id, 'vehicle_registration', registration)
        
        # Store any additional form fields as metadata
        for key, value in data.items():
            if key not in ['customer_name', 'customer_email', 'customer_phone', 'vehicle_registration', 'warranty_details']:
                db.add_ticket_metadata(ticket_id, key, str(value))
        
        # Create a reply indicating this was an automatic submission
        reply_data = {
            'ticket_id': ticket_id,
            'thread_id': thread_id,
            'message': "This ticket was created automatically from an online warranty form submission.",
            'sender': 'system'
        }
        db.create_reply(reply_data)
        
        return jsonify({
            'status': 'success',
            'message': f'Warranty claim created successfully! Your Customer Number is: {ticket_id}',
            'ticket_id': ticket_id,
            'customer_number': ticket_id,
            'reference_message': f'Please save Customer Number {ticket_id} for tracking your warranty claim.'
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


# Initialize database connection on startup (with error handling)
# Note: Skip database initialization in serverless to avoid import issues
if os.environ.get('FLASK_ENV') != 'production':
    try:
        # Test database connection early to catch configuration issues
        if os.environ.get('MONGODB_URI'):
            db_test = get_db()
            app.logger.info("Database connection established successfully")
            
            # [FIX] Run consistency check on startup in development
            try:
                fixed_count = fix_ticket_status_consistency()
                if fixed_count > 0:
                    app.logger.info(f"[FIX] STARTUP CONSISTENCY CHECK - Fixed {fixed_count} tickets")
                else:
                    app.logger.info("[SUCCESS] STARTUP CONSISTENCY CHECK - No issues found")
            except Exception as consistency_error:
                app.logger.warning(f"Startup consistency check failed: {consistency_error}")
        else:
            app.logger.warning("MONGODB_URI not set - database features will not work")
    except Exception as e:
        app.logger.error(f"Database initialization failed: {e}")
        # Continue running to allow health checks and debugging
else:
    app.logger.info("Production mode - database will be initialized on first request")

def cleanup():
    """Cleanup function for application exit"""
    # Application shutting down
    pass

atexit.register(cleanup)

# Add a health check route for debugging
@app.route('/health')
def health_check():
    """Health check endpoint for debugging serverless deployment"""
    try:
        # Test database connection
        db = get_db()
        db.client.admin.command('ping')
        
        return jsonify({
            'status': 'ok',
            'message': 'Application is running',
            'environment': os.environ.get('FLASK_ENV', 'development'),
            'database': 'connected',
            'upload_folder': UPLOAD_FOLDER,
            'version': 'v2.0-comprehensive-assignment',  # Added version tag
            'last_updated': '2025-07-26'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e),
            'environment': os.environ.get('FLASK_ENV', 'development'),
            'database': 'disconnected'
        }), 500

# Enhanced session heartbeat endpoint to prevent timeouts
@app.route('/api/session/heartbeat', methods=['POST'])
def session_heartbeat():
    """Enhanced session heartbeat with better error handling and session validation"""
    try:
        if 'member_id' not in session:
            app.logger.warning("Session heartbeat failed - no member_id in session")
            return jsonify({'status': 'error', 'message': 'No active session'}), 401
        
        # Validate session data integrity
        member_id = session.get('member_id')
        member_name = session.get('member_name')
        member_role = session.get('member_role')
        
        if not all([member_id, member_name, member_role]):
            app.logger.warning(f"Session heartbeat failed - incomplete session data for user {member_id}")
            session.clear()
            return jsonify({'status': 'error', 'message': 'Invalid session data'}), 401
        
        # Refresh session with enhanced error handling
        if refresh_session():
            app.logger.debug(f"Session heartbeat successful for user {member_id}")
            return jsonify({
                'status': 'success', 
                'message': 'Session refreshed',
                'user_id': member_id,
                'user_name': member_name,
                'user_role': member_role,
                'session_lifetime': app.permanent_session_lifetime.total_seconds()
            })
        else:
            app.logger.error(f"Session heartbeat failed - refresh_session returned False for user {member_id}")
            return jsonify({'status': 'error', 'message': 'Failed to refresh session'}), 500
            
    except Exception as e:
        app.logger.error(f"Session heartbeat error: {e}")
        # Clear corrupted session
        session.clear()
        return jsonify({'status': 'error', 'message': 'Session error occurred'}), 500

# Session refresh endpoint
@app.route('/api/session/refresh', methods=['POST'])
def session_refresh():
    """Proactively refresh the current session to prevent timeouts"""
    try:
        if 'member_id' not in session:
            app.logger.warning("Session refresh failed - no member_id in session")
            return jsonify({'status': 'error', 'message': 'No active session'}), 401
        
        # Validate session data integrity
        member_id = session.get('member_id')
        member_name = session.get('member_name')
        member_role = session.get('member_role')
        
        if not all([member_id, member_name, member_role]):
            app.logger.warning(f"Session refresh failed - incomplete session data for user {member_id}")
            session.clear()
            return jsonify({'status': 'error', 'message': 'Invalid session data'}), 401
        
        # Refresh session
        if refresh_session():
            app.logger.info(f"Session refreshed successfully for user {member_id}")
            return jsonify({
                'status': 'success', 
                'message': 'Session refreshed successfully',
                'user_id': member_id,
                'user_name': member_name,
                'user_role': member_role,
                'session_lifetime': app.permanent_session_lifetime.total_seconds()
            })
        else:
            app.logger.error(f"Session refresh failed for user {member_id}")
            return jsonify({'status': 'error', 'message': 'Failed to refresh session'}), 500
            
    except Exception as e:
        app.logger.error(f"Session refresh error: {e}")
        # Clear corrupted session
        session.clear()
        return jsonify({'status': 'error', 'message': 'Session error occurred'}), 500

# Session status check endpoint
@app.route('/api/session/status', methods=['GET'])
def session_status():
    """Check current session status and health with enhanced information"""
    try:
        # Debug: Log all session data
        app.logger.info(f"Session status check - Session keys: {list(session.keys())}")
        app.logger.info(f"Session data: {dict(session)}")
        
        if 'member_id' not in session:
            return jsonify({
                'status': 'error',
                'message': 'No active session',
                'authenticated': False,
                'session_keys': list(session.keys()),
                'debug_info': 'Session restoration may be needed'
            }), 401
        
        # Get session info
        member_id = session.get('member_id')
        member_name = session.get('member_name')
        member_role = session.get('member_role')
        last_activity = session.get('last_activity')
        
        # Calculate session age
        session_age = 0
        if last_activity:
            try:
                last_activity_dt = datetime.fromisoformat(last_activity)
                session_age = (datetime.now() - last_activity_dt).total_seconds()
            except:
                session_age = 0
        
        # Calculate remaining time
        max_lifetime = app.permanent_session_lifetime.total_seconds()
        remaining_time = max(0, max_lifetime - session_age)
        
        # Enhanced session health calculation
        hours_remaining = remaining_time / 3600
        if hours_remaining > 12:
            health = 'excellent'
        elif hours_remaining > 6:
            health = 'good'
        elif hours_remaining > 2:
            health = 'warning'
        elif hours_remaining > 0.5:  # 30 minutes
            health = 'critical'
        else:
            health = 'expired'
        
        # Activity-based session extension info
        activity_extension = False
        if session_age < 21600:  # 6 hours
            activity_extension = True
        
        return jsonify({
            'status': 'success',
            'authenticated': True,
            'user_id': member_id,
            'user_name': member_name,
            'user_role': member_role,
            'session_age_seconds': session_age,
            'remaining_time_seconds': remaining_time,
            'max_lifetime_seconds': max_lifetime,
            'hours_remaining': round(hours_remaining, 2),
            'session_health': health,
            'activity_extension_active': activity_extension,
            'session_lifetime_hours': 24,
            'auto_extend_threshold_hours': 6
        })
        
    except Exception as e:
        app.logger.error(f"Session status check error: {e}")
        return jsonify({
            'status': 'error',
            'message': 'Error checking session status',
            'authenticated': False
        }), 500

# Session test endpoint for debugging
@app.route('/api/session/test', methods=['GET'])
def session_test():
    """Simple session test endpoint for debugging session issues"""
    try:
        app.logger.info(f"Session test endpoint called - Session keys: {list(session.keys())}")
        app.logger.info(f"Session data: {dict(session)}")
        app.logger.info(f"Request endpoint: {request.endpoint}")
        app.logger.info(f"Request path: {request.path}")
        
        # Check session health
        session_health = {
            'has_member_id': 'member_id' in session,
            'is_permanent': session.permanent,
            'refresh_count': session.get('_refresh_count', 0),
            'restore_count': session.get('_restore_count', 0),
            'request_count': session.get('_request_count', 0),
            'last_refresh': session.get('_last_refresh'),
            'last_restored': session.get('_last_restored'),
            'last_request': session.get('_last_request')
        }
        
        return jsonify({
            'status': 'success',
            'message': 'Session test completed',
            'session_keys': list(session.keys()),
            'session_data': dict(session),
            'session_health': session_health,
            'request_endpoint': request.endpoint,
            'request_path': request.path,
            'debug_info': 'Check logs for detailed session information'
        })
        
    except Exception as e:
        app.logger.error(f"Session test error: {e}")
        return jsonify({
            'status': 'error',
            'message': f'Session test failed: {str(e)}',
            'debug_info': 'Check server logs for details'
        }), 500

# Session extension endpoint
@app.route('/api/session/extend', methods=['POST'])
def extend_session():
    """Extend user session by refreshing activity timestamp"""
    try:
        if 'member_id' not in session:
            return jsonify({
                'status': 'error',
                'message': 'No active session'
            }), 401
        
        # Refresh session
        if refresh_session():
            member_id = session.get('member_id')
            member_name = session.get('member_name')
            
            app.logger.info(f"Session extended for user {member_name} ({member_id})")
            
            return jsonify({
                'status': 'success',
                'message': 'Session extended successfully',
                'user_id': member_id,
                'user_name': member_name,
                'extended_at': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'Failed to extend session'
            }), 500
            
    except Exception as e:
        app.logger.error(f"Session extension error: {e}")
        return jsonify({
            'status': 'error',
            'message': 'Error extending session'
        }), 500



# Add a simple test route
@app.route('/test')
def test_route():
    """Simple test route"""
    return jsonify({
        'message': 'Flask app is working!',
        'environment': os.environ.get('FLASK_ENV', 'development')
    })

@app.route('/test', methods=['POST'])
def add_test_data():
    """Add sample test data"""
    try:
        # Create a sample PDF content (minimal PDF)
        sample_pdf_base64 = "JVBERi0xLjQKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUgo+PgplbmRvYmoKMiAwIG9iago8PAovQmFzZUZ4Kc3RhcnR4cmVmCjIyNDcKJSVFT0YK"
        
        # Sample ticket data
        sample_tickets = [
            {
                'id': str(uuid.uuid4())[:8],
                'threadId': 'sample-thread-123',
                'name': 'John Doe',
                'email': 'john.doe@example.com',
                'subject': 'Sample Ticket - System Issue',
                'body': 'I am experiencing issues with the dashboard loading slowly. Could you please help?',
                'draft': 'Dear John Doe,\n\nThank you for contacting us regarding the dashboard performance issue. We are looking into this matter and will provide an update soon.\n\nBest regards,\nSupport Team',
                'classification': 'Technical Support',
                'priority': 'High',
                'date': datetime.now().isoformat(),
                'messageId': 'msg-sample-123',
                'attachments': [{
                    'fileName': 'sample_report.pdf',
                    'fileData': sample_pdf_base64,
                    'id': str(uuid.uuid4())
                }],
                'created_at': datetime.now().isoformat()
            },
            {
                'id': str(uuid.uuid4())[:8],
                'threadId': 'sample-thread-456',
                'name': 'Jane Smith',
                'email': 'jane.smith@company.com',
                'subject': 'Billing Inquiry',
                'body': 'I have a question about my recent invoice. The amount seems incorrect.',
                'draft': 'Dear Jane Smith,\n\nThank you for your billing inquiry. We will review your account and get back to you within 24 hours with a detailed explanation.\n\nBest regards,\nBilling Department',
                'classification': 'Billing',
                'priority': 'Medium',
                'date': datetime.now().isoformat(),
                'messageId': 'msg-sample-456',
                'attachments': [],
                'created_at': datetime.now().isoformat()
            }
        ]
        
        # Add to database
        db = get_db()
        created_count = 0
        
        for ticket in sample_tickets:
            try:
                # Convert to database format
                ticket_data = {
                    'ticket_id': ticket['id'],
                    'threadId': ticket['threadId'],
                    'from': ticket['email'],
                    'name': ticket['name'],
                    'subject': ticket['subject'],
                    'body': ticket['body'],
                    'draft': ticket['draft'],
                    'classification': ticket['classification'],
                    'priority': ticket['priority'],
                    'date': ticket['date'],
                    'messageid': ticket['messageId'],
                    'attachments': [att['fileData'] for att in ticket['attachments']],
                    'attachment_names': [att['fileName'] for att in ticket['attachments']],
                    'has_attachment': len(ticket['attachments']) > 0
                }
                
                created_id = db.create_ticket(ticket_data)
                if created_id:
                    created_count += 1
                    # Add attachment metadata if present
                    if ticket_data['has_attachment']:
                        for i, attachment in enumerate(ticket['attachments']):
                            attachment_metadata = {
                                'filename': attachment['fileName'],
                                'data': attachment['fileData'],
                                'type': 'email_attachment',
                                'id': attachment['id']
                            }
                            db.add_ticket_metadata(ticket_data['ticket_id'], f'attachment_{i}', json.dumps(attachment_metadata))
                            
            except Exception as e:
                app.logger.error(f"Error creating ticket: {str(e)}")
        
        return jsonify({
            'success': True,
            'message': f'Added {created_count} test tickets to database',
            'tickets_added': created_count
        }), 200
        
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error adding test data: {str(e)}'
        }), 500

@app.route('/api/attachment/<attachment_id>')
def get_attachment(attachment_id):
    """Serve attachment file"""
    try:
        # Find attachment in all tickets
        attachment = None
        for ticket in tickets_storage:
            for att in ticket['attachments']:
                if att['id'] == attachment_id:
                    attachment = att
                    break
            if attachment:
                break
        
        if not attachment:
            return jsonify({'error': 'Attachment not found'}), 404
        
        # Decode base64 data
        file_data = base64.b64decode(attachment['fileData'])
        
        # Create a BytesIO object
        file_stream = io.BytesIO(file_data)
        
        # Guess MIME type
        mime_type, _ = mimetypes.guess_type(attachment['fileName'])
        if not mime_type:
            mime_type = 'application/octet-stream'
        
        return send_file(
            file_stream,
            mimetype=mime_type
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/add-real-data', methods=['POST'])
def add_real_data():
    """Add the real JSON data from your n8n workflow"""
    try:
        # Your real JSON data
        real_data = [
            {
                "complete": "{\"result\":false,\"fileName\":\"warranty_dashboard_report_20250726_112229.pdf\",\"fileData\":\"JVBERi0xLjQKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUgo+PgplbmRvYmoKMiAwIG9iago8PAovQmFzZUZ4Kc3RhcnR4cmVmCjIyNDcKJSVFT0YK\"}"
            },
            {
                "complete": "{\"threadId\":\"AQQkADAwATM3ZmYBLTljMmQtMmQ5ZS0wMAItMDAKABAA62jpB7tOGUO0IrhdiiKqQg==\",\"name\":\"muhammad zeeshan liaqat\",\"body\":\"The mails\",\"Classification\":\"Others\",\"Priority\":\"Low\",\"ticket_id\":\"706393\",\"from\":\"fa22-bse-061@outlook.com\",\"date\":\"2025-08-07T20:52:53Z\",\"draft\":\"Dear muhammad zeeshan liaqat,\\n\\nThank you for your message regarding the test emails. We have noted your communication and will keep it on record.\\n\\nIf you have any specific inquiries or need further assistance, please feel free to reach out.\\n\\n(Ticket ID: 706393)\\n\\nSincerely,\\nCustomer Services\",\"messageid\":\"AQMkADAwATM3AAAADdI5CgAAAA==\",\"\":\"\"}"
            }
        ]
        
        # Parse the JSON data
        attachments = []
        ticket_info = None
        
        for item in real_data:
            if 'complete' in item:
                # Clean JSON before parsing
                clean_json = item['complete'].strip()
                if clean_json.endswith(',}'):
                    clean_json = clean_json[:-2] + '}'
                elif clean_json.endswith(',]'):
                    clean_json = clean_json[:-2] + ']'
                parsed_data = json.loads(clean_json)
                
                # Check if this is attachment data
                if 'fileName' in parsed_data and 'fileData' in parsed_data:
                    attachments.append({
                        'fileName': parsed_data['fileName'],
                        'fileData': parsed_data['fileData'],
                        'id': str(uuid.uuid4())
                    })
                # Check if this is ticket info
                elif 'ticket_id' in parsed_data:
                    ticket_info = parsed_data
        
        if ticket_info:
            # Create complete ticket with attachment
            ticket = {
                'id': ticket_info['ticket_id'],
                'threadId': ticket_info.get('threadId', ''),
                'name': ticket_info.get('name', 'Unknown'),
                'email': ticket_info.get('from', 'unknown@example.com'),
                'subject': f"Ticket #{ticket_info['ticket_id']} - {ticket_info.get('body', 'No subject')}",
                'body': ticket_info.get('body', ''),
                'draft': ticket_info.get('draft', '').replace('\\n', '\n'),  # Fix newlines
                'classification': ticket_info.get('Classification', 'General'),
                'priority': ticket_info.get('Priority', 'Medium'),
                'date': ticket_info.get('date', datetime.now().isoformat()),
                'messageId': ticket_info.get('messageid', ''),
                'attachments': attachments,
                'created_at': datetime.now().isoformat()
            }
            
            # Add to database
            db = get_db()
            created_id = db.create_ticket(ticket)
            if created_id and attachments:
                # Add attachment metadata
                for i, attachment in enumerate(attachments):
                    db.add_ticket_metadata(ticket['id'], f'attachment_{i}', json.dumps(attachment))
            
            return jsonify({
                'success': True,
                'message': f'Added real ticket {ticket_info["ticket_id"]} with {len(attachments)} attachments',
                'ticket_id': ticket_info['ticket_id'],
                'attachments_count': len(attachments)
            }), 200
        else:
            return jsonify({
                'success': False,
                'message': 'No valid ticket information found in data'
            }), 400
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error adding real data: {str(e)}'
        }), 500

@app.route('/api/test/action-buttons', methods=['GET', 'POST'])
def test_action_buttons():
    """Test endpoint for action button functionality"""
    return jsonify({
        'status': 'success',
        'message': 'Action buttons backend is working!',
        'session_valid': 'member_id' in session,
        'member_id': session.get('member_id', 'None'),
        'member_name': session.get('member_name', 'None'),
        'timestamp': datetime.now().isoformat(),
        'available_endpoints': [
            '/api/tickets/{ticket_id}/assign',
            '/api/tickets/{ticket_id}/tech-director',
            '/api/tickets/{ticket_id}/close'
        ]
    })

# ===============================
# ADVANCED N8N INTEGRATION ENDPOINTS
# ===============================

@app.route('/api/n8n/quick', methods=['POST'])
def n8n_quick_response():
    """
    Quick response endpoint for n8n - responds immediately to prevent timeouts
    Processes data in background to avoid hanging n8n workflows
    """
    try:
        # Send immediate response to prevent n8n timeout
        response_data = {
            'success': True,
            'message': 'Data received and queued for processing',
            'timestamp': datetime.now().isoformat(),
            'status': 'accepted'
        }
        
        # Get data quickly
        raw_data = request.get_data()
        
        # Create immediate response
        response = jsonify(response_data)
        response.headers['Content-Type'] = 'application/json'
        response.headers['Access-Control-Allow-Origin'] = '*'
        
        # Background processing after sending response
        try:
            if raw_data:
                if request.is_json:
                    data = request.get_json(force=True)
                else:
                    data = json.loads(raw_data.decode('utf-8'))
                
                # Process with enhanced sophisticated parsing
                processed_tickets = enhanced_process_complex_email_data(data)
                
                if processed_tickets:
                    db = get_db()
                    
                    for ticket_data in processed_tickets:
                        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
                        n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
                        
                        if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                            # Use n8n provided ticket ID if it doesn't exist in database
                            ticket_id = n8n_ticket_id
                            app.logger.info(f"[N8N_QUICK] Using n8n provided ticket ID: {ticket_id}")
                            
                            # Prepare ticket data
                            ticket = {
                                'ticket_id': ticket_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                # Add to database
                                db.create_ticket(ticket)
                                app.logger.info(f"N8N quick processing created ticket {ticket_id} using n8n ID, warranty: {ticket.get('has_warranty')}")
                            except ValueError as e:
                                app.logger.error(f"Failed to create ticket with n8n ID {ticket_id}: {e}")
                        else:
                            # Create ticket in database with warranty detection and collision protection  
                            timestamp = datetime.now()
                            base_ticket_id = f"N8NQ{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                            
                            # Collision-resistant ticket creation (similar to warranty tickets)
                            max_attempts = 10
                            ticket_id = None
                            
                            if n8n_ticket_id:
                                app.logger.warning(f"[N8N_QUICK] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                            else:
                                app.logger.info(f"[N8N_QUICK] No n8n ticket ID provided, generating new ID")
                            
                            for attempt in range(max_attempts):
                                # Generate unique ID with attempt suffix if needed
                                potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                                
                                # Prepare ticket data
                                ticket = {
                                    'ticket_id': potential_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                # Add to database - will throw ValueError if ID exists
                                db.create_ticket(ticket)
                                ticket_id = potential_id
                                app.logger.info(f"N8N quick processing created ticket {ticket_id} (attempt {attempt + 1}), warranty: {ticket.get('has_warranty')}")
                                break
                                
                            except ValueError as e:
                                if "Ticket ID already exists" in str(e):
                                    app.logger.debug(f"N8N ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                                    continue  # Try next ID
                                else:
                                    raise e  # Re-raise unexpected errors
                        
        except Exception as bg_error:
            app.logger.error(f"Background processing error (non-critical): {bg_error}")
        
        return response
        
    except Exception as e:
        app.logger.error(f"Quick endpoint error: {str(e)}")
        # Still return immediate response even on error to prevent hanging
        return jsonify({
            'success': False,
            'message': 'Error occurred but request acknowledged',
            'timestamp': datetime.now().isoformat(),
            'status': 'error_acknowledged'
        })

@app.route('/api/n8n/minimal', methods=['POST'])
def n8n_minimal_response():
    """
    Minimal acknowledgment endpoint - ultra-fast response for slow n8n scenarios
    Returns acknowledgment immediately, processes data separately
    """
    try:
        # Ultra-fast acknowledgment
        timestamp = datetime.now().isoformat()
        
        # Store raw data for background processing
        raw_data = request.get_data()
        
        # Process data if available (but don't wait for completion)
        if raw_data:
            try:
                if request.is_json:
                    data = request.get_json(force=True)
                else:
                    data = json.loads(raw_data.decode('utf-8'))
                
                # Quick background processing with enhanced sophisticated parsing
                processed_tickets = enhanced_process_complex_email_data(data)
                
                if processed_tickets:
                    db = get_db()
                    
                    for ticket_data in processed_tickets:
                        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
                        n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
                        
                        if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                            # Use n8n provided ticket ID if it doesn't exist in database
                            ticket_id = n8n_ticket_id
                            app.logger.info(f"[N8N_MINIMAL] Using n8n provided ticket ID: {ticket_id}")
                            
                            ticket = {
                                'ticket_id': ticket_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                # Add to database
                                db.create_ticket(ticket)
                                app.logger.info(f"N8N minimal processing created ticket {ticket_id} using n8n ID, warranty: {ticket.get('has_warranty')}")
                            except ValueError as e:
                                app.logger.error(f"Failed to create ticket with n8n ID {ticket_id}: {e}")
                        else:
                            # Create ticket with collision protection as fallback
                            timestamp = datetime.now()
                            base_ticket_id = f"N8NM{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                            
                            # Collision-resistant ticket creation
                            max_attempts = 10
                            ticket_id = None
                            
                            if n8n_ticket_id:
                                app.logger.warning(f"[N8N_MINIMAL] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                            else:
                                app.logger.info(f"[N8N_MINIMAL] No n8n ticket ID provided, generating new ID")
                            
                            for attempt in range(max_attempts):
                                # Generate unique ID with attempt suffix if needed
                                potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                                
                                ticket = {
                                    'ticket_id': potential_id,
                                'name': ticket_data.get('name', 'Unknown'),
                                'email': ticket_data.get('from', ''),
                                'phone': '',
                                'vin': '',
                                'description': ticket_data.get('body', ''),
                                'priority': ticket_data.get('Priority', 'Medium'),
                                'classification': ticket_data.get('Classification', 'General'),
                                'date_created': datetime.now().isoformat(),
                                'has_warranty': ticket_data.get('has_warranty', False),
                                'has_attachments': ticket_data.get('has_attachments', False)
                            }
                            
                            try:
                                db.create_ticket(ticket)
                                ticket_id = potential_id
                                app.logger.info(f"N8N minimal processing created ticket {ticket_id} (attempt {attempt + 1})")
                                break
                                
                            except ValueError as e:
                                if "Ticket ID already exists" in str(e):
                                    app.logger.debug(f"N8N minimal ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                                    continue  # Try next ID
                                else:
                                    raise e  # Re-raise unexpected errors
                        
            except Exception as process_error:
                app.logger.error(f"Minimal endpoint processing error: {process_error}")
        
        # Return minimal response immediately
        return jsonify({'ok': True, 'timestamp': timestamp})
        
    except Exception as e:
        app.logger.error(f"Minimal endpoint error: {str(e)}")
        return jsonify({'ok': False, 'error': str(e), 'timestamp': datetime.now().isoformat()})

@app.route('/api/n8n/status', methods=['GET'])
def n8n_processing_status():
    """
    Check processing status and system health for n8n integration monitoring
    """
    try:
        db = get_db()
        
        # Get recent tickets count
        recent_tickets = db.get_tickets_with_assignments()[:10] if hasattr(db, 'get_tickets_with_assignments') else []
        warranty_count = sum(1 for ticket in recent_tickets if ticket.get('has_warranty', False))
        
        return jsonify({
            'status': 'operational',
            'timestamp': datetime.now().isoformat(),
            'recent_tickets_count': len(recent_tickets),
            'warranty_forms_detected': warranty_count,
            'system_health': 'good',
            'endpoints': {
                'standard': '/api/tickets',
                'quick': '/api/n8n/quick', 
                'minimal': '/api/n8n/minimal'
            }
        })
        
    except Exception as e:
        app.logger.error(f"Status check error: {str(e)}")
        return jsonify({
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'error': str(e)
        }), 500

@app.route('/api/email/process', methods=['POST'])
def process_email_integration():
    """
    Advanced email processing endpoint with sophisticated parsing and warranty detection
    Handles complex n8n data structures and automatically detects warranty forms
    """
    try:
        # Get raw email data
        raw_data = request.get_data()
        
        if request.is_json:
            data = request.get_json(force=True)
        else:
            data = json.loads(raw_data.decode('utf-8'))
        
        app.logger.info(f"Processing email integration data: {type(data)}")
        
        # Use sophisticated email parsing
        processed_tickets = process_complex_email_data(data)
        
        if not processed_tickets:
            return jsonify({
                'success': False,
                'message': 'No valid ticket data found',
                'count': 0
            }), 400
        
        db = get_db()
        created_tickets = []
        
        for ticket_data in processed_tickets:
            # [FIX] Use n8n provided ticket_id if available, otherwise generate one
            n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
            customer_email = ticket_data.get('from', '')
            customer_name = ticket_data.get('name', 'Unknown')
            
            if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                # Use n8n provided ticket ID if it doesn't exist in database
                ticket_id = n8n_ticket_id
                app.logger.info(f"[EMAIL_PROCESS] Using n8n provided ticket ID: {ticket_id}")
                
                # Prepare comprehensive ticket data
                ticket = {
                    'ticket_id': ticket_id,
                    'name': customer_name,
                    'email': customer_email,
                    'phone': '',
                    'vin': '',
                    'description': ticket_data.get('body', ''),
                    'priority': ticket_data.get('Priority', 'Medium'),
                    'classification': ticket_data.get('Classification', 'General'),
                    'date_created': datetime.now().isoformat(),
                    'status': 'Open',
                    'has_warranty': ticket_data.get('has_warranty', False),
                    'has_attachments': ticket_data.get('has_attachments', False),
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                    'message_id': ticket_data.get('messageid', ''),
                    'draft_body': ticket_data.get('draft', '')
                }
                
                try:
                    # Add to database
                    db.create_ticket(ticket)
                    app.logger.info(f"Email processing created ticket {ticket_id} using n8n ID")
                except ValueError as e:
                    app.logger.error(f"Failed to create ticket with n8n ID {ticket_id}: {e}")
                    continue
            else:
                # Generate ticket ID with collision protection as fallback
                timestamp = datetime.now()
                base_ticket_id = f"EMAPI{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                
                # Collision-resistant ticket creation
                max_attempts = 10
                ticket_id = None
                
                if n8n_ticket_id:
                    app.logger.warning(f"[EMAIL_PROCESS] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                else:
                    app.logger.info(f"[EMAIL_PROCESS] No n8n ticket ID provided, generating new ID")
                
                for attempt in range(max_attempts):
                    # Generate unique ID with attempt suffix if needed
                    potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                    
                    # Prepare comprehensive ticket data
                    ticket = {
                        'ticket_id': potential_id,
                    'name': customer_name,
                    'email': customer_email,
                    'phone': '',
                    'vin': '',
                    'description': ticket_data.get('body', ''),
                    'priority': ticket_data.get('Priority', 'Medium'),
                    'classification': ticket_data.get('Classification', 'General'),
                    'date_created': datetime.now().isoformat(),
                    'status': 'Open',
                    'has_warranty': ticket_data.get('has_warranty', False),
                    'has_attachments': ticket_data.get('has_attachments', False),
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                    'message_id': ticket_data.get('messageid', ''),
                    'draft_body': ticket_data.get('draft', '')
                }
                
                try:
                    # Add to database - will throw ValueError if ID exists
                    db.create_ticket(ticket)
                    ticket_id = potential_id
                    app.logger.info(f"Email processing created ticket {ticket_id} (attempt {attempt + 1})")
                    break
                    
                except ValueError as e:
                    if "Ticket ID already exists" in str(e):
                        app.logger.debug(f"Email ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                        continue  # Try next ID
                    else:
                        raise e  # Re-raise unexpected errors
            
            # Process attachments if present
            if ticket_data.get('attachments'):
                for i, attachment in enumerate(ticket_data['attachments']):
                    # Handle base64 attachments from email
                    if attachment.get('data'):
                        # Save base64 data as file
                        try:
                            file_data = base64.b64decode(attachment.get('data', ''))
                            filename = attachment.get('filename', 'unknown_file')
                            safe_filename = secure_filename(filename)
                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                            unique_filename = f"{timestamp}_{safe_filename}"
                            
                            # Save to uploads directory
                            file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                            with open(file_path, 'wb') as f:
                                f.write(file_data)
                            
                            # Add attachment metadata
                            attachment_key = 'warranty_form' if attachment.get('is_warranty') else f'other_file_{i+1}'
                            attachment_metadata = {
                                'key': attachment_key,
                                'file_path': unique_filename,
                                'original_name': filename,
                                'size': attachment.get('size', len(file_data)),
                                'is_warranty': attachment.get('is_warranty', False),
                                'file_type': attachment.get('file_type', {})
                            }
                            
                            db.add_ticket_metadata(ticket_id, attachment_key, json.dumps(attachment_metadata))
                            
                            app.logger.info(f"Saved email attachment: {filename} ({'warranty' if attachment.get('is_warranty') else 'regular'} file)")
                            
                        except Exception as att_error:
                            app.logger.error(f"Error saving attachment {attachment.get('filename', 'unknown')}: {att_error}")
            
            created_tickets.append({
                'ticket_id': ticket_id,
                'has_warranty': ticket.get('has_warranty'),
                'has_attachments': ticket.get('has_attachments'),
                'customer': customer_name,
                'email': customer_email
            })
            
            app.logger.info(f"Email integration created ticket {ticket_id} - Warranty: {ticket.get('has_warranty')}, Attachments: {ticket.get('has_attachments')}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully processed {len(created_tickets)} tickets',
            'count': len(created_tickets),
            'tickets': created_tickets,
            'warranty_detected': sum(1 for t in created_tickets if t['has_warranty']),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Email integration processing error: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'success': False,
            'error': f'Email processing failed: {str(e)}',
            'timestamp': datetime.now().isoformat()
        }), 500

# Add webhook debug endpoint
@app.route('/debug/webhook-test')
def debug_webhook_test():
    """Debug endpoint to test webhook configuration"""
    try:
        webhook_url = os.environ.get('TECH_DIRECTOR_REMINDER_WEBHOOK', 'NOT_SET')
        
        # Test payload
        test_payload = {
            'ticket_id': 'DEBUG123',
            'subject': 'Debug Test',
            'customer_name': 'Test Customer',
            'priority': 'Medium',
            'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
            'reminder_context': 'This is a debug test from the webhook system'
        }
        
        if webhook_url == 'NOT_SET':
            return jsonify({
                'status': 'error',
                'message': 'TECH_DIRECTOR_REMINDER_WEBHOOK environment variable is not set',
                'webhook_url': webhook_url
            })
        
        # Try to send test webhook
        response = requests.post(webhook_url, json=test_payload, timeout=10)
        response.raise_for_status()
        
        return jsonify({
            'status': 'success',
            'message': 'Test webhook sent successfully!',
            'webhook_url': webhook_url,
            'response_status': response.status_code,
            'test_payload': test_payload
        })
        
    except requests.exceptions.RequestException as e:
        return jsonify({
            'status': 'error',
            'message': f'Webhook request failed: {str(e)}',
            'webhook_url': webhook_url,
            'error_details': str(e)
        }), 500
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Debug test failed: {str(e)}',
            'webhook_url': webhook_url
        }), 500



# Add debug endpoint for session data
@app.route('/debug/session')
def debug_session():
    """Debug endpoint to check session data"""
    try:
        session_info = {
            'session_exists': bool(session),
            'session_keys': list(session.keys()) if session else [],
            'member_id': session.get('member_id'),
            'member_name': session.get('member_name'),
            'member_role': session.get('member_role'),
            'selected_portal': session.get('selected_portal'),
            'last_activity': session.get('last_activity'),
            'session_permanent': session.get('_permanent', False),
            'session_modified': session.get('_modified', False),
            'session_new': session.get('_new', False),
            'session_id': session.get('_id', None),
            'current_time': datetime.now().isoformat(),
            'session_lifetime': str(app.permanent_session_lifetime),
            'is_production': is_production
        }
        
        # Sessions are permanent - no timeout checks needed
        if 'member_id' in session:
            session_info['session_timeout_check'] = False  # Never timeout
            session_info['session_refresh_result'] = refresh_session()
        
        return jsonify(session_info)
    except Exception as e:
        return jsonify({'error': str(e), 'session_exists': bool(session)})

# Add ticket inspection endpoint
@app.route('/debug/inspect-referred-tickets')
def debug_inspect_referred_tickets():
    """Debug endpoint to inspect all tickets referred to Tech Director"""
    try:
        db = get_db()
        
        # Get all tickets with "Referred to Tech Director" status
        referred_tickets = db.get_tickets_by_status("Referred to Tech Director")
        
        inspection_results = []
        for ticket in referred_tickets:
            ticket_id = ticket['ticket_id']
            assignment = db.get_assignment_by_ticket(ticket_id)
            
            result = {
                'ticket_id': ticket_id,
                'status': ticket.get('status'),
                'priority': ticket.get('priority'),
                'created_at': str(ticket.get('created_at')),
                'has_assignment': assignment is not None
            }
            
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    result.update({
                        'assigned_member_name': assigned_member.get('name', 'Unknown') if assigned_member else 'None',
                        'assigned_member_role': assigned_member.get('role', 'Unknown') if assigned_member else 'None',
                        'is_forwarded': assignment.get('is_forwarded', False),
                        'assignment_created_at': str(assignment.get('created_at', 'Unknown'))
                    })
                else:
                    result.update({
                        'assigned_member_name': 'Error: No member_id',
                        'assigned_member_role': 'Error: No member_id',
                        'is_forwarded': False,
                        'assignment_created_at': 'Error: No member_id'
                    })
            else:
                result.update({
                    'assigned_member_name': None,
                    'assigned_member_role': None,
                    'is_forwarded': False,
                    'assignment_created_at': None
                })
            
            inspection_results.append(result)
        
        return jsonify({
            'status': 'success',
            'total_referred_tickets': len(referred_tickets),
            'tickets': inspection_results
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Inspection failed: {str(e)}'
        }), 500

# Add consistency check endpoint
@app.route('/debug/fix-status-consistency')
def debug_fix_status_consistency():
    """Debug endpoint to fix status consistency issues"""
    try:
        fixed_count = fix_ticket_status_consistency()
        return jsonify({
            'status': 'success',
            'message': f'Consistency check completed',
            'fixed_tickets': fixed_count,
            'details': f'Fixed {fixed_count} tickets with inconsistent status/assignment'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Consistency check failed: {str(e)}'
        }), 500

# Add specific ticket fix endpoint  
@app.route('/debug/fix-ticket/<ticket_id>')
def debug_fix_specific_ticket(ticket_id):
    """Debug endpoint to fix a specific ticket's consistency"""
    try:
        db = get_db()
        
        # Get ticket and assignment
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        current_status = ticket.get('status')
        fix_applied = False
        
        if assignment:
            # [FIX] Ensure member_id is valid before calling get_member_by_id
            member_id = assignment.get('member_id')
            if member_id:
                assigned_member = db.get_member_by_id(member_id)
                
                if assigned_member:
                    # Check for inconsistency
                    if (current_status == 'Referred to Tech Director' and 
                        assigned_member.get('role') != 'Technical Director'):
                        
                        # Fix the status
                        target_role = assigned_member.get('role', 'Support')
                        if target_role == 'Administrator':
                            corrected_status = 'Open'
                        elif target_role in ['Support', 'Engineer', 'IT']:
                            corrected_status = 'Under Review'
                        else:
                            corrected_status = 'Open'
                        
                        db.update_ticket(ticket_id, {
                            'status': corrected_status,
                            'updated_at': datetime.now(),
                            'status_manually_fixed': f'Debug fix - assigned to {assigned_member.get("name", "Unknown")}',
                            'previous_inconsistent_status': current_status
                        })
                        
                        fix_applied = True
                        
                        return jsonify({
                            'status': 'success',
                            'message': f'Ticket {ticket_id} fixed',
                            'old_status': current_status,
                            'new_status': corrected_status,
                            'assigned_to': assigned_member.get('name'),
                            'assigned_role': target_role
                        })
            else:
                app.logger.error(f"[ERROR] TICKET {ticket_id} has assignment but no member_id")
        
        if not fix_applied:
            return jsonify({
                'status': 'info',
                'message': f'Ticket {ticket_id} appears consistent',
                'current_status': current_status,
                'assignment_info': {
                    'assigned_to': assigned_member.get('name') if assignment and assigned_member else 'None',
                    'assigned_role': assigned_member.get('role') if assignment and assigned_member else 'None',
                    'is_forwarded': assignment.get('is_forwarded') if assignment else False
                } if assignment else None
            })
            
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'Failed to fix ticket {ticket_id}: {str(e)}'
        }), 500

# Error handlers
@app.errorhandler(404)
def not_found_error(error):
    if request.path.startswith('/api/'):
        return jsonify({'error': 'Endpoint not found'}), 404
    try:
        return render_template('error.html', error="Page not found"), 404
    except:
        return f"404 - Page not found: {request.path}", 404

@app.errorhandler(500)
def internal_error(error):
    app.logger.error(f"Internal server error: {error}")
    if request.path.startswith('/api/'):
        return jsonify({'error': 'Internal server error'}), 500
    try:
        return render_template('error.html', error="Internal server error"), 500
    except:
        return "500 - Internal server error", 500

@app.errorhandler(Exception)
def handle_exception(e):
    """Handle all unhandled exceptions"""
    app.logger.error(f"Unhandled exception: {e}", exc_info=True)
    if request.path.startswith('/api/'):
        return jsonify({'error': 'An unexpected error occurred'}), 500
    try:
        return render_template('error.html', error="An unexpected error occurred"), 500
    except:
        return f"Error: {str(e)}", 500

def extract_email(raw_email):
    """Extract email address from possible formatted string"""
    match = re.search(r'<([^>]+)>', raw_email)
    return match.group(1) if match else raw_email

def get_classification_code(classification):
    """Get single-letter code for email ticket classifications"""
    mapping = {
        'Technical Issue': 'T',
        'Technical': 'T',
        'Payment': 'P', 
        'Support': 'S',
        'Account': 'A',
        'Spam': 'X',  # Changed from 'S' to 'X' to avoid conflict with Support
        'Warranty Claim': 'W',
        'General': 'G',
        'Other': 'O'
    }
    return mapping.get(classification, 'G')  # Default to 'G' for General

def get_priority_code(priority):
    """Get single-letter code for email ticket priorities"""
    mapping = {
        'Urgent': 'U',
        'Fast': 'F', 
        'Medium': 'M',
        'Low': 'L'
    }
    return mapping.get(priority, 'M')  # Default to 'M' for Medium

def get_email_classification_code(classification):
    """
    Get classification code for EMAIL tickets (similar to manual ticket type codes)
    Format: E{classification_code}{4 digits} - matches manual ticket format M{type_code}{4 digits}
    """
    classification_mapping = {
        'Technical Support': 'T',
        'Technical': 'T',
        'Billing': 'B', 
        'General': 'G',
        'Others': 'O',
        'Other': 'O',
        'Warranty': 'W',
        'DPF Related': 'D',
        'Parts': 'P',
        'Complaint': 'C',
        'Inquiry': 'I',
        'Installation': 'N',
        'Support': 'S'
    }
    return classification_mapping.get(classification, 'G')  # Default to General

def generate_email_ticket_id(email, name, classification, db):
    """
    [TARGET] Generate email ticket ID in SAME format as manual tickets: E{type_code}{4 digits}
    Uses identical deterministic calculation as manual tickets for consistency
    """
    # Get classification code (similar to manual ticket type codes)
    type_code = get_email_classification_code(classification)
    
    max_attempts = 100
    ticket_id = None
    
    app.logger.info(f"[TARGET] Generating email ticket ID for: {email}, classification: {classification} -> {type_code}")
    
    for attempt in range(max_attempts):
        # Generate 4-digit code using SAME logic as manual tickets
        seed_string = f"{email}{name}{datetime.now().isoformat()}"
        
        # Calculate sum of character codes (identical to manual ticket logic)
        sum_chars = 0
        for char in seed_string:
            sum_chars += ord(char)
        
        # Generate 4-digit number (same as manual: sum % 10000)
        four_digit_code = sum_chars % 10000
        four_digit_str = f"{four_digit_code:04d}"  # Ensure 4 digits with leading zeros
        
        potential_id = f"E{type_code}{four_digit_str}"  # Exactly 6 chars: E + 1 + 4 digits
        
        app.logger.info(f"? Attempting email ticket ID: {potential_id} (attempt {attempt + 1}/{max_attempts})")
        app.logger.debug(f"? Email calculation: seed='{seed_string[:50]}...', sum_chars={sum_chars}, 4-digit={four_digit_code}")
        
        # Check if ID already exists (same check as manual tickets)
        if not db.ticket_id_exists(potential_id):
            ticket_id = potential_id
            app.logger.info(f"[SUCCESS] Generated unique email ticket ID: {ticket_id}")
            break
        else:
            app.logger.debug(f"[RETRY] Email ticket ID collision: {potential_id}, retrying...")
            # Add small random variation to avoid infinite loops with same data
            import time
            time.sleep(0.001)  # 1ms delay to change timestamp
    
    if not ticket_id:
        app.logger.error(f"[ERROR] Failed to generate unique email ticket ID after {max_attempts} attempts")
        raise Exception(f"Failed to generate unique email ticket ID after {max_attempts} attempts")
    
    return ticket_id

def fix_ticket_status_consistency():
    """Fix any existing tickets with inconsistent status vs assignment"""
    try:
        db = get_db()
        
        # Find tickets with "Referred to Tech Director" status
        referred_tickets = list(db.tickets.find({"status": "Referred to Tech Director"}))
        
        fixed_count = 0
        for ticket in referred_tickets:
            ticket_id = ticket['ticket_id']
            
            # Check current assignment
            assignment = db.get_assignment_by_ticket(ticket_id)
            
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    
                    # If assigned to non-TD member but status still shows "Referred to Tech Director"
                    if (assigned_member and 
                        assigned_member.get('role') != 'Technical Director' and 
                        assignment.get('is_forwarded', False)):
                        
                        # Fix the status based on assigned member's role
                        target_role = assigned_member.get('role', 'Support')
                        if target_role == 'Administrator':
                            new_status = 'Open'
                        elif target_role in ['Support', 'Engineer', 'IT']:
                            new_status = 'Under Review'
                        else:
                            new_status = 'Open'
                        
                        # Update the ticket status
                        db.update_ticket(ticket_id, {
                            'status': new_status,
                            'updated_at': datetime.now(),
                            'status_auto_fixed': f'Corrected inconsistency - assigned to {assigned_member.get("name", "Unknown")} ({target_role})',
                            'previous_inconsistent_status': 'Referred to Tech Director'
                        })
                        
                        app.logger.info(f"[FIX] FIXED INCONSISTENCY - Ticket {ticket_id}: status changed from 'Referred to Tech Director' to '{new_status}' (assigned to {assigned_member.get('name')})")
                        fixed_count += 1
                else:
                    app.logger.error(f"[ERROR] TICKET {ticket_id} has assignment but no member_id")
        
        if fixed_count > 0:
            app.logger.info(f"[SUCCESS] CONSISTENCY CHECK COMPLETE - Fixed {fixed_count} inconsistent tickets")
        else:
            app.logger.info(f"[SUCCESS] CONSISTENCY CHECK COMPLETE - No inconsistencies found")
            
        return fixed_count
        
    except Exception as e:
        app.logger.error(f"Error in consistency check: {e}")
        return 0

def identify_ticket_origin(ticket):
    """Identify ticket origin and format information for display"""
    ticket_id = ticket.get('ticket_id', '')
    creation_method = ticket.get('creation_method', 'unknown')
    
    if creation_method == 'manual':
        # Manual tickets: M{type_code}{4_digits}
        if ticket_id.startswith('M'):
            type_code = ticket_id[1:2] if len(ticket_id) > 1 else 'Unknown'
            four_digits = ticket_id[2:6] if len(ticket_id) >= 6 else 'Unknown'
            
            type_mapping = {
                'P': 'DPF Clean - Premium',
                'S': 'DPF Clean - Standard', 
                'J': 'Part Job',
                'O': 'Other',
                'K': 'Workshop Job'
            }
            
            return {
                'origin': 'Manual',
                'origin_icon': 'fas fa-user-edit',
                'origin_color': 'blue',
                'type': type_mapping.get(type_code, 'Unknown'),
                'format': f'M{type_code}{four_digits}',
                'description': f'Manual ticket created for {type_mapping.get(type_code, "Unknown")} (Code: {four_digits})'
            }
    
    elif creation_method == 'email':
        # Email tickets: {class_code}{priority_code}{4_digits}
        if len(ticket_id) >= 6:
            class_code = ticket_id[0:1]
            priority_code = ticket_id[1:2] 
            four_digits = ticket_id[2:6]
            
            class_mapping = {
                'T': 'Technical Issue',
                'P': 'Payment', 
                'S': 'Support',
                'A': 'Account',
                'X': 'Spam',
                'W': 'Warranty Claim',
                'G': 'General',
                'O': 'Other'
            }
            
            priority_mapping = {
                'U': 'Urgent',
                'F': 'Fast',
                'M': 'Medium', 
                'L': 'Low'
            }
            
            return {
                'origin': 'Email',
                'origin_icon': 'fas fa-envelope',
                'origin_color': 'green',
                'classification': class_mapping.get(class_code, 'Unknown'),
                'priority': priority_mapping.get(priority_code, 'Unknown'),
                'format': f'{class_code}{priority_code}{four_digits}',
                'description': f'Email ticket - {class_mapping.get(class_code, "Unknown")} / {priority_mapping.get(priority_code, "Unknown")} (Code: {four_digits})'
            }
    
    elif creation_method == 'warranty' or ticket_id.startswith('W'):
        # Warranty tickets: W{5_digits}
        return {
            'origin': 'Warranty',
            'origin_icon': 'fas fa-shield-alt',
            'origin_color': 'purple',
            'format': ticket_id,
            'description': f'Warranty claim ticket (ID: {ticket_id})'
        }
    
    # Fallback for unknown tickets
    return {
        'origin': 'Unknown',
        'origin_icon': 'fas fa-question-circle',
        'origin_color': 'gray',
        'format': ticket_id,
        'description': f'Unknown ticket type (ID: {ticket_id})'
    }



def safe_datetime_parse(value):
    """Safely parse datetime from either datetime object or string"""
    if isinstance(value, datetime):
        return value
    elif value:
        try:
            return datetime.strptime(str(value), "%Y-%m-%d %H:%M:%S")
        except:
            try:
                # Try alternative format
                return datetime.fromisoformat(str(value).replace('Z', '+00:00'))
            except:
                return None
    return None

def safe_date_format(value, format_str="%b %d, %I:%M %p"):
    """Safely format datetime to string"""
    parsed_date = safe_datetime_parse(value)
    if parsed_date:
        return parsed_date.strftime(format_str)
    return str(value) if value else ""

def group_tickets_by_date(tickets):
    """Group tickets by date categories (Today, Yesterday, etc.)"""
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)
    this_week_start = today - timedelta(days=today.weekday())
    
    tickets_grouped = defaultdict(list)
    
    for ticket in tickets:
        # Handle both datetime objects (from MongoDB) and string dates
        if isinstance(ticket['created_at'], datetime):
            ticket_date = ticket['created_at'].date()
        else:
            try:
                ticket_date = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S").date()
            except:
                # If we can't parse the date, put it in a default group
                tickets_grouped["Unknown Date"].append(ticket)
                continue
        
        if ticket_date == today:
            date_group = "Today"
        elif ticket_date == yesterday:
            date_group = "Yesterday"
        elif ticket_date >= this_week_start:
            date_group = "This Week"
        else:
            date_group = ticket_date.strftime("%B %d, %Y")
            
        tickets_grouped[date_group].append(ticket)
    

    
    return tickets_grouped



@app.route('/')
def dashboard():
    """Main dashboard showing all tickets"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get current user's role
        current_member = db.get_member_by_id(session['member_id'])
        if not current_member:
            return redirect(url_for('portal'))
        current_user_role = current_member['role']
        
        # Redirect Technical Director to their specific dashboard
        if current_user_role == 'Technical Director':
            return redirect(url_for('tech_director_dashboard'))
        
        # CRITICAL FIX: Ensure all tickets have has_unread_reply field before processing
        try:
            db.migrate_has_unread_reply_field()
            app.logger.info("[DASHBOARD] has_unread_reply field migration completed")
        except Exception as migration_error:
            app.logger.warning(f"[DASHBOARD] has_unread_reply migration failed: {migration_error}")
        
        # Get pagination parameters
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status_filter = request.args.get('status', 'All')
        priority_filter = request.args.get('priority', 'All')
        search_query = request.args.get('search', '')
        
        # Get paginated tickets with assignment info
        tickets = db.get_tickets_with_assignments(
            page=page, 
            per_page=per_page, 
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # Get total count for pagination
        total_tickets = db.get_tickets_count(
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # DEBUG: Check important ticket sorting
        important_count = sum(1 for t in tickets if t.get('is_important', False))
        app.logger.info(f"[DASHBOARD] Total tickets: {len(tickets)}, Important tickets: {important_count}")
        if important_count > 0:
            first_five = tickets[:5]
            for i, t in enumerate(first_five):
                app.logger.info(f"[DASHBOARD] Position {i+1}: Ticket {t.get('ticket_id')} - Important: {t.get('is_important', False)}, Classification: {t.get('classification', 'None')}")
        
        # Separate forwarded tickets for current user
        forwarded_tickets = []
        regular_tickets = []
        
        # Convert to dict format and format dates
        formatted_tickets = []
        for ticket in tickets:
            # Convert ObjectId to string for template compatibility
            ticket['_id'] = str(ticket['_id'])
            
            # Handle assignment info - ENHANCED DEBUGGING
            ticket_id = ticket.get('ticket_id')
            assignment_data = ticket.get('assignment', [])
            assigned_member_data = ticket.get('assigned_member', [])
            
            app.logger.info(f"[DASHBOARD] Processing ticket {ticket_id}: assignment_count={len(assignment_data)}, member_count={len(assigned_member_data)}")
            
            if assignment_data and len(assignment_data) > 0:
                assignment = assignment_data[0]
                app.logger.info(f"[DASHBOARD] Ticket {ticket_id} has assignment: member_id={assignment.get('member_id')}, is_forwarded={assignment.get('is_forwarded', False)}")
                
                if assigned_member_data and len(assigned_member_data) > 0:
                    member = assigned_member_data[0]
                    ticket['assigned_to'] = member.get('name')
                    ticket['assigned_to_gender'] = member.get('gender')
                    app.logger.info(f"[DASHBOARD] Ticket {ticket_id}: ASSIGNED TO {ticket['assigned_to']} (member_id={member.get('_id')})")
                else:
                    app.logger.error(f"[BADGE_ISSUE] Ticket {ticket_id}: Has assignment (member_id={assignment.get('member_id')}) but no member data found in aggregation!")
                    app.logger.error(f"[BADGE_ISSUE] Assignment data: {assignment}")
                    
                    # ENHANCED FALLBACK: Handle ObjectId conversion properly
                    try:
                        member_id = assignment.get('member_id')
                        app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: member_id={member_id}, type={type(member_id).__name__}")
                        
                        if member_id:
                            # Convert to string if it's ObjectId
                            member_id_str = str(member_id)
                            app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: Converted to string: {member_id_str}")
                            
                            member = db.get_member_by_id(member_id_str)
                            if member:
                                ticket['assigned_to'] = member.get('name')
                                ticket['assigned_to_gender'] = member.get('gender')
                                app.logger.info(f"[BADGE_FALLBACK] Ticket {ticket_id}: Found member via direct lookup: {ticket['assigned_to']}")
                            else:
                                app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: Member {member_id_str} not found in database!")
                                # DEBUG: Check what members exist
                                all_members = list(db.members.find({}, {'_id': 1, 'name': 1}).limit(5))
                                app.logger.error(f"[BADGE_FALLBACK] Available members: {[(str(m['_id']), m.get('name')) for m in all_members]}")
                                ticket['assigned_to'] = None
                        else:
                            app.logger.error(f"[BADGE_FALLBACK] Ticket {ticket_id}: member_id is None or empty")
                            ticket['assigned_to'] = None
                    except Exception as fallback_error:
                        app.logger.error(f"[BADGE_FALLBACK] Error during fallback lookup: {fallback_error}")
                        ticket['assigned_to'] = None
                
                # Handle forwarding information
                ticket['assigned_at'] = assignment.get('assigned_at')
                ticket['is_forwarded'] = assignment.get('is_forwarded', False)
                
                # Get forwarded from member info
                if ticket['is_forwarded'] and ticket.get('forwarded_from_member') and len(ticket['forwarded_from_member']) > 0:
                    forwarded_member = ticket['forwarded_from_member'][0]
                    ticket['forwarded_from_name'] = forwarded_member.get('name')
                    app.logger.debug(f"[DASHBOARD] Ticket {ticket_id}: Forwarded from {ticket['forwarded_from_name']}")
                else:
                    ticket['forwarded_from_name'] = 'Unknown'
                    app.logger.debug(f"[DASHBOARD] Ticket {ticket_id}: No forwarded_from_member data, setting to Unknown")
            else:
                app.logger.debug(f"[DASHBOARD] Ticket {ticket_id}: No assignment data")
                ticket['assigned_to'] = None
                ticket['is_forwarded'] = False

            
            # Format date
            if 'created_at' in ticket and ticket['created_at']:
                if isinstance(ticket['created_at'], datetime):
                    ticket['formatted_date'] = ticket['created_at'].strftime("%b %d, %I:%M %p")
                else:
                    try:
                        created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                    except:
                        ticket['formatted_date'] = str(ticket['created_at'])
            
            # Get technician information for this ticket
            ticket_id = ticket.get('ticket_id')
            if ticket_id:
                try:
                    # Check if database is actually working
                    if not hasattr(db, 'ticket_metadata') or not db.ticket_metadata:
                        app.logger.warning(f"Database not properly initialized for ticket {ticket_id}")
                        ticket['technician_name'] = None
                        ticket['technician_id'] = None
                    else:
                        metadata = db.get_ticket_metadata(ticket_id)
                        app.logger.info(f" Retrieved metadata for ticket {ticket_id}: {metadata}")
                        if metadata:
                            app.logger.info(f"Found {len(metadata)} metadata entries for ticket {ticket_id}")
                            for meta in metadata:
                                app.logger.info(f"  - Key: '{meta.get('key')}', Value: '{meta.get('value')}'")
                                if meta.get('key') == 'technician_name':
                                    ticket['technician_name'] = meta.get('value')
                                    app.logger.info(f" Set technician_name to: {meta.get('value')}")
                                    break
                                elif meta.get('key') == 'technician_id':
                                    ticket['technician_id'] = meta.get('value')
                                    app.logger.info(f" Set technician_id to: {meta.get('value')}")
                                    break
                        else:
                            app.logger.info(f" No metadata found for ticket {ticket_id}")
                            ticket['technician_name'] = None
                            ticket['technician_id'] = None
                        
                        # Ensure technician fields are explicitly set to None if not found
                        if 'technician_name' not in ticket or ticket['technician_name'] is None:
                            ticket['technician_name'] = None
                            app.logger.info(f"ðŸ”§ Explicitly set technician_name to None for ticket {ticket_id}")
                        if 'technician_id' not in ticket or ticket['technician_id'] is None:
                            ticket['technician_id'] = None
                            app.logger.info(f"ðŸ”§ Explicitly set technician_id to None for ticket {ticket_id}")
                except Exception as e:
                    app.logger.debug(f"Error getting technician info for ticket {ticket_id}: {e}")
                    ticket['technician_name'] = None
                    ticket['technician_id'] = None
                
                # Final fallback: ensure technician fields are always set
                if 'technician_name' not in ticket:
                    ticket['technician_name'] = None
                if 'technician_id' not in ticket:
                    ticket['technician_id'] = None
            
            # Check if this ticket is forwarded to current user
            is_forwarded_to_current_user = (
                ticket.get('is_forwarded', False) and 
                ticket.get('assigned_to') == current_member['name']
            )
            
            if is_forwarded_to_current_user:
                forwarded_tickets.append(ticket)
            else:
                regular_tickets.append(ticket)
            
            formatted_tickets.append(ticket)
            
            # CRITICAL FIX: Validate has_unread_reply field for each ticket
            if 'has_unread_reply' not in ticket:
                ticket['has_unread_reply'] = False
                app.logger.warning(f"[DASHBOARD] Ticket {ticket_id} missing has_unread_reply field, setting to False")
            elif not isinstance(ticket['has_unread_reply'], bool):
                ticket['has_unread_reply'] = bool(ticket['has_unread_reply'])
                app.logger.warning(f"[DASHBOARD] Ticket {ticket_id} has invalid has_unread_reply type, converted to {ticket['has_unread_reply']}")
            
            # Log unread reply status for debugging
            if ticket.get('has_unread_reply'):
                app.logger.info(f"[DASHBOARD] ðŸš¨ Ticket {ticket_id} has UNREAD REPLY - will show red dot alert")
            else:
                app.logger.debug(f"[DASHBOARD] Ticket {ticket_id} has no unread replies")
            
            # Log final ticket data for debugging
            if ticket.get('technician_name'):
                app.logger.info(f" Ticket {ticket_id} has technician: {ticket['technician_name']}")
            else:
                app.logger.info(f" Ticket {ticket_id} has NO technician assigned")
            
            # Additional debugging for technician fields
            app.logger.info(f" Final technician data for ticket {ticket_id}: technician_name='{ticket.get('technician_name')}', technician_id='{ticket.get('technician_id')}'")
            app.logger.info(f" Ticket {ticket_id} keys: {list(ticket.keys())}")
            
            # Double-check: if we still don't have technician data, try one more time
            if not ticket.get('technician_name') and not ticket.get('technician_id'):
                app.logger.warning(f" Ticket {ticket_id} still missing technician data, trying one more retrieval...")
                try:
                    final_metadata = db.get_ticket_metadata(ticket_id)
                    for meta in final_metadata:
                        if meta.get('key') == 'technician_name':
                            ticket['technician_name'] = meta.get('value')
                            app.logger.info(f"ðŸ”„ Final attempt: Set technician_name to: {meta.get('value')}")
                            break
                except Exception as e:
                    app.logger.error(f" Final attempt failed for ticket {ticket_id}: {e}")
        
        #  DYNAMIC WARRANTY CLASSIFICATION: Update classification for tickets with warranty attachments
        for ticket_dict in formatted_tickets:
            ticket_id = ticket_dict.get('ticket_id')
            if ticket_id:
                try:
                    # Check if ticket has warranty attachments
                    metadata = db.get_ticket_metadata(ticket_id)
                    has_warranty_attachment = False
                    
                    if metadata:
                        for meta in metadata:
                            try:
                                # Ensure meta is a dictionary
                                if not isinstance(meta, dict):
                                    continue
                                
                                meta_value = meta.get('value')
                                if isinstance(meta_value, str):
                                    # Handle potential malformed JSON
                                    if meta_value.strip() and meta_value.strip() not in ['{}', '']:
                                        try:
                                            # Clean JSON before parsing
                                            clean_json = meta_value.strip()
                                            # Remove trailing commas and fix common JSON issues
                                            if clean_json.endswith(',}'):
                                                clean_json = clean_json[:-2] + '}'
                                            elif clean_json.endswith(',]'):
                                                clean_json = clean_json[:-2] + ']'
                                            # Remove any leading/trailing whitespace and quotes
                                            clean_json = clean_json.strip().strip('"\'')
                                            # Skip if still empty after cleaning
                                            if not clean_json or clean_json in ['{}', '[]', 'null', 'undefined']:
                                                meta_data = {}
                                            else:
                                                meta_data = json.loads(clean_json)
                                        except json.JSONDecodeError as json_err:
                                            # Only log if it's actually malformed, not just empty
                                            if meta_value.strip() and meta_value.strip() not in ['{}', '[]', 'null', 'undefined', '']:
                                                app.logger.debug(f"Skipping malformed JSON in metadata: {json_err} - Value: {meta_value[:50]}")
                                            meta_data = {}
                                    else:
                                        meta_data = {}
                                elif isinstance(meta_value, dict):
                                    meta_data = meta_value
                                else:
                                    meta_data = {}
                                
                                # Check if this attachment is warranty-related
                                if isinstance(meta_data, dict):
                                    is_warranty = meta_data.get('is_warranty', False)
                                    if is_warranty:
                                        has_warranty_attachment = True
                                        break
                            except (json.JSONDecodeError, TypeError, AttributeError) as e:
                                app.logger.warning(f"Error processing metadata for ticket {ticket_id}: {e}")
                                continue
                    
                    # Also check direct has_warranty flag on ticket
                    has_warranty_flag = ticket_dict.get('has_warranty', False)
                    
                    # If ticket has warranty attachments or warranty flag, ensure classification is "Warranty Claim"
                    if has_warranty_attachment or has_warranty_flag:
                        original_classification = ticket_dict.get('classification')
                        ticket_dict['classification'] = 'Warranty Claim'
                        
                        if original_classification != 'Warranty Claim':
                            app.logger.info(f" DYNAMIC WARRANTY CLASSIFICATION: Ticket {ticket_id} updated from '{original_classification}' to 'Warranty Claim' (warranty_attachment: {has_warranty_attachment}, warranty_flag: {has_warranty_flag})")
                
                except Exception as e:
                    app.logger.error(f"Error checking warranty status for ticket {ticket_id}: {e}")
        
        # Group tickets by date
        tickets_grouped = group_tickets_by_date(formatted_tickets)
        
        # Get counts for stats - FIXED: Use database total, not paginated count
        # total_tickets is already set correctly from database.get_tickets_count()
        open_tickets = len([t for t in formatted_tickets if t.get('status') == 'Open'])
        resolved_tickets = len([t for t in formatted_tickets if t.get('status') == 'Resolved'])
        waiting_tickets = len([t for t in formatted_tickets if t.get('status') == 'Waiting for Response'])
        
        # CRITICAL FIX: Count tickets with unread replies for debugging
        unread_reply_count = sum(1 for t in formatted_tickets if t.get('has_unread_reply'))
        app.logger.info(f"[DASHBOARD] FINAL SUMMARY: {unread_reply_count} tickets have unread replies out of {len(formatted_tickets)} total tickets")
        
        # Get priority and type breakdowns
        priorities = {
            'Urgent': len([t for t in formatted_tickets if t.get('priority') == 'Urgent']),
            'Fast': len([t for t in formatted_tickets if t.get('priority') == 'Fast']),
            'Medium': len([t for t in formatted_tickets if t.get('priority') == 'Medium']),
            'Low': len([t for t in formatted_tickets if t.get('priority') == 'Low'])
        }
        
        classifications = {}
        for ticket in formatted_tickets:
            cls = ticket.get('classification')
            if cls:
                classifications[cls] = classifications.get(cls, 0) + 1
        
        # Calculate pagination info
        total_pages = (total_tickets + per_page - 1) // per_page
        has_prev = page > 1
        has_next = page < total_pages
        prev_page = page - 1 if has_prev else None
        next_page = page + 1 if has_next else None
        
        pagination_info = {
            'current_page': page,
            'per_page': per_page,
            'total_tickets': total_tickets,
            'total_pages': total_pages,
            'has_prev': has_prev,
            'has_next': has_next,
            'prev_page': prev_page,
            'next_page': next_page,
            'status_filter': status_filter,
            'priority_filter': priority_filter,
            'search_query': search_query
        }
        
        return render_template('index.html', 
                            tickets_grouped=tickets_grouped,
                            tickets=formatted_tickets,  # Add this line for template compatibility
                            forwarded_tickets=forwarded_tickets,
                            total_tickets=total_tickets,
                            open_tickets=open_tickets,
                            resolved_tickets=resolved_tickets,
                            waiting_tickets=waiting_tickets,
                            priorities=priorities,
                            classifications=classifications,
                            current_user=session.get('member_name'),
                            current_user_role=current_user_role,
                            pagination=pagination_info)
    except Exception as e:
        return render_template('error.html', error=f"Database error: {e}"), 500





@app.route('/portal')
def portal():
    return render_template('portal.html')



@app.route('/login', methods=['GET', 'POST'])
def login():
    # Get role parameter from URL
    selected_role = request.args.get('role', 'general')
    
    # Get filtered members based on selected portal
    db = get_db()
    all_members = db.get_all_members()
    
    # Filter members based on selected portal
    filtered_members = []
    if selected_role == 'admin':
        filtered_members = [m for m in all_members if m.get('role') == 'Administrator']
    elif selected_role == 'tech-director':
        filtered_members = [m for m in all_members if m.get('role') == 'Technical Director']
    elif selected_role == 'user':
        # User portal accessible by all roles except Administrator and Technical Director
        filtered_members = [m for m in all_members if m.get('role') not in ['Administrator', 'Technical Director']]
    else:
        filtered_members = all_members
    
    # Convert ObjectIds to strings for template
    for member in filtered_members:
        member['_id'] = str(member['_id'])
    
    if request.method == 'POST':
        try:
            # Check if using member selection or manual input
            member_id = request.form.get('member_id')
            user_id = request.form.get('user_id', '').strip()
            password = request.form.get('password', '')
            
            # Basic input validation
            if not password:
                flash('Please enter password', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            if len(password) > 100:  # Reasonable limits
                flash('Invalid credentials', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            # Get member either by selection or user_id
            member = None
            if member_id and member_id != '':
                member = db.get_member_by_id(member_id)
            elif user_id:
                member = db.get_member_by_user_id(user_id)
            
            # Check if user exists
            if not member:
                flash('User ID not found. Please check your User ID or select an account from the list above.', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            # Check password
            if not check_password_hash(member.get('password_hash', ''), password):
                flash('Incorrect password. Please try again.', 'error')
                return render_template('login.html', selected_role=selected_role, members=filtered_members)
            
            # Validate role access
            user_role = member.get('role', 'User')
            
            # Role validation based on portal selection
            role_access_valid = True
            if selected_role == 'admin' and user_role != 'Administrator':
                role_access_valid = False
                flash('Access denied. Administrator credentials required.', 'error')
            elif selected_role == 'tech-director' and user_role != 'Technical Director':
                role_access_valid = False
                flash('Access denied. Technical Director credentials required.', 'error')
            elif selected_role == 'user' and user_role in ['Administrator', 'Technical Director']:
                role_access_valid = False
                flash('Access denied. This portal is for users only.', 'error')
            
            if role_access_valid:
                # Make session permanent and set initial activity
                session.permanent = True
                session['member_id'] = str(member['_id'])
                session['member_name'] = member['name']
                session['member_role'] = user_role
                session['selected_portal'] = selected_role
                session['last_activity'] = datetime.now().isoformat()
                
                # Store additional data for session restoration
                session['user_id'] = member.get('user_id', '')
                session['login_timestamp'] = datetime.now().isoformat()
                session['client_ip'] = request.remote_addr
                
                app.logger.info(f"Successful login for user: {member.get('user_id', 'unknown')}, role: {user_role}, portal: {selected_role}")
                
                # Redirect based on role
                if user_role == 'Technical Director':
                    return redirect(url_for('tech_director_dashboard'))
                else:
                    return redirect(url_for('dashboard'))
        except Exception as e:
            app.logger.warning(f"Failed login attempt for portal: {selected_role}")
            flash('Invalid credentials', 'error')
    
    return render_template('login.html', selected_role=selected_role, members=filtered_members)

@app.route('/logout')
def logout():
    """Enhanced logout with proper session cleanup and logging"""
    try:
        user_id = session.get('member_id', 'unknown')
        user_name = session.get('member_name', 'unknown')
        app.logger.info(f"User {user_name} ({user_id}) logging out")
        
        # Clear all session data
        session.clear()
        
        # Show success message and redirect to portal
        flash('You have been successfully logged out.', 'success')
        return redirect(url_for('portal'))
        
    except Exception as e:
        app.logger.error(f"Error during logout: {e}")
        # Clear session anyway and redirect
        session.clear()
        return redirect(url_for('portal'))



@app.route('/favicon.ico')
@app.route('/favicon.png')  
def favicon():
    """Handle favicon requests to prevent 404 errors"""
    try:
        return send_from_directory('static', 'logo.png')
    except:
        return '', 404

@app.route('/members')
def member_management():
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    db = get_db()
    # Check if current user is admin - Technical Director NOT allowed
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        # Redirect Technical Director to their dashboard
        if current_member and current_member['role'] == 'Technical Director':
            return redirect(url_for('tech_director_dashboard'))
        return redirect(url_for('dashboard'))
    
    members = db.get_all_members()
    # Convert ObjectIds to strings for template
    for member in members:
        member['_id'] = str(member['_id'])
    
    return render_template('members.html', 
                         members=members,
                         current_user=session.get('member_name'),
                         current_user_role=current_member['role'])

@app.route('/admin')
def admin_panel():
    """Admin panel for managing technicians and system settings"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if current user is admin - Technical Director NOT allowed
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return render_template('error.html', error="Access denied. Administrator access required."), 403
    
    try:
        db = get_db()
        
        # Initialize default statuses if needed
        db.initialize_default_statuses()
        
        tickets = db.get_all_tickets()
        members = db.get_all_members()
        statuses = db.get_all_ticket_statuses()
        technicians = db.get_all_technicians()
        all_roles = db.get_all_roles()
        
        #  FILTER TO ONLY 3 CORE ROLES FOR ADMIN PANEL
        allowed_role_names = ['Administrator', 'Technical Director', 'User']
        roles = [role for role in all_roles if role.get('name') in allowed_role_names]
        
        # Convert ObjectId to string for JSON serialization
        for ticket in tickets:
            ticket['_id'] = str(ticket['_id'])
        
        for member in members:
            member['_id'] = str(member['_id'])
        
        for status in statuses:
            status['_id'] = str(status['_id'])
            
        for tech in technicians:
            tech['_id'] = str(tech['_id'])
            
        for role in roles:
            role['_id'] = str(role['_id'])
        
        # Calculate stats - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(tickets)
        total_tickets = db.get_tickets_count()
        open_tickets = len([t for t in tickets if t.get('status') == 'Open'])
        resolved_tickets = len([t for t in tickets if t.get('status') == 'Resolved'])
        
        # Priority breakdown
        priorities = {}
        for ticket in tickets:
            priority = ticket.get('priority', 'Medium')
            priorities[priority] = priorities.get(priority, 0) + 1
        
        # Classification breakdown
        classifications = {}
        for ticket in tickets:
            classification = ticket.get('classification', 'General')
            classifications[classification] = classifications.get(classification, 0) + 1
        
        return render_template('admin.html',
                             tickets=tickets,
                             members=members,
                             statuses=statuses,
                             technicians=technicians,
                             roles=roles,
                             total_tickets=total_tickets,
                             open_tickets=open_tickets,
                             resolved_tickets=resolved_tickets,
                             priorities=priorities,
                             classifications=classifications,
                             current_user=session.get('member_name', 'Unknown'),
                             current_user_role=member_role)
    except Exception as e:
        app.logger.error(f"Error loading admin panel: {e}")
        return render_template('error.html', error="Failed to load admin panel"), 500

@app.route('/api/members', methods=['GET', 'POST'])
def manage_members():
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 403
    
    if request.method == 'GET':
        # Fetch all members for admin panel
        try:
            members = db.get_all_members()
            # Convert ObjectIds to strings for JSON serialization
            for member in members:
                member['_id'] = str(member['_id'])
            return jsonify({
                'status': 'success',
                'members': members
            })
        except Exception as e:
            app.logger.error(f"Error fetching members: {e}")
            return jsonify({'status': 'error', 'message': 'Failed to fetch members'}), 500
    
    elif request.method == 'POST':
        # Add new member
        data = request.json
        required_fields = ['name', 'role', 'gender', 'user_id', 'password']
        
        if not all(field in data for field in required_fields):
            return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400
            
        if data['password'] != data.get('confirm_password', ''):
            return jsonify({'status': 'error', 'message': 'Passwords do not match'}), 400
            
        try:
            # Check if user_id already exists
            existing_member = db.get_member_by_user_id(data['user_id'])
            if existing_member:
                return jsonify({'status': 'error', 'message': 'User ID already exists'}), 400
            
            member_data = {
                'name': data['name'],
                'role': data['role'],
                'gender': data['gender'],
                'user_id': data['user_id'],
                'password_hash': generate_password_hash(data['password'])
            }
            
            db.create_member(member_data)
            return jsonify({'status': 'success'})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/members/<member_id>', methods=['PUT', 'DELETE'])
def manage_member(member_id):
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    # Check admin permissions using session role (consistent with admin panel)
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    # Get database connection
    db = get_db()
    
    if request.method == 'PUT':
        data = request.json
        try:
            update_data = {
                'name': data['name'],
                'role': data['role'],
                'gender': data['gender']
            }
            
            if 'password' in data and data['password']:
                if data['password'] != data.get('confirm_password', ''):
                    return jsonify({'status': 'error', 'message': 'Passwords do not match'}), 400
                update_data['password_hash'] = generate_password_hash(data['password'])
            
            db.members.update_one(
                {'_id': ObjectId(member_id)},
                {'$set': update_data}
            )
            return jsonify({'status': 'success'})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500
            
    elif request.method == 'DELETE':
        try:
            app.logger.info(f"[DELETE] Attempting to delete member {member_id}")
            app.logger.info(f"[DELETE] Current user role: {member_role}")
            app.logger.info(f"[DELETE] Database connection: {db is not None}")
            
            # Validate member_id format
            try:
                ObjectId(member_id)
            except Exception as e:
                app.logger.error(f"[DELETE] Invalid ObjectId format: {member_id}")
                return jsonify({'status': 'error', 'message': 'Invalid member ID format'}), 400
            
            # Check if this is a protected user (additional backend protection)
            member_to_delete = db.members.find_one({'_id': ObjectId(member_id)})
            if member_to_delete and member_to_delete.get('user_id') in ['admin001', 'marc001']:
                app.logger.warning(f"[DELETE] Attempted to delete protected user: {member_to_delete.get('user_id')}")
                return jsonify({'status': 'error', 'message': 'Cannot delete protected administrator or technical director accounts'}), 403
            
            result = db.members.delete_one({'_id': ObjectId(member_id)})
            if result.deleted_count > 0:
                app.logger.info(f"[DELETE] Successfully deleted member {member_id}")
                return jsonify({'status': 'success', 'message': 'Member deleted successfully'})
            else:
                app.logger.warning(f"[DELETE] No member found with ID {member_id}")
                return jsonify({'status': 'error', 'message': 'Member not found'}), 404
        except Exception as e:
            app.logger.error(f"[DELETE] Error deleting member {member_id}: {e}")
            app.logger.error(f"[DELETE] Error type: {type(e).__name__}")
            import traceback
            app.logger.error(f"[DELETE] Traceback: {traceback.format_exc()}")
            return jsonify({'status': 'error', 'message': str(e)}), 500

# Add API endpoint to get technicians dynamically
@app.route('/api/technicians', methods=['GET'])
def get_technicians():
    """Get all active technicians from standalone technician collection"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        all_technicians = db.get_all_technicians()
        
        # Convert ObjectIds to strings and format response
        technicians = []
        for technician in all_technicians:
            technicians.append({
                'id': str(technician['_id']),
                'name': technician['name'],
                'is_active': technician.get('is_active', True),
                'created_at': technician.get('created_at', '')
            })
        
        return jsonify({
            'status': 'success',
            'technicians': technicians
        })
    except Exception as e:
        app.logger.error(f"Error getting technicians: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Add API endpoints for technician management
@app.route('/api/admin/technicians', methods=['POST'])
def create_technician():
    """Create a new technician (Admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin permissions
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    try:
        data = request.json
        name = data.get('name', '').strip()
        role = data.get('role', '').strip()
        email = data.get('email', '').strip()
        
        # Validate required fields
        if not name:
            return jsonify({'status': 'error', 'message': 'Technician name is required'}), 400
        if not role:
            return jsonify({'status': 'error', 'message': 'Technician role is required'}), 400
        if not email:
            return jsonify({'status': 'error', 'message': 'Technician email is required'}), 400
            
        # Validate email format
        import re
        if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
            return jsonify({'status': 'error', 'message': 'Invalid email format'}), 400
        
        db = get_db()
        technician_data = {
            'name': name,
            'role': role, 
            'email': email
        }
        technician_id = db.create_technician(technician_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Technician created successfully',
            'technician_id': str(technician_id)
        })
    except Exception as e:
        app.logger.error(f"Error creating technician: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/technicians/<technician_id>', methods=['PUT'])
def update_technician(technician_id):
    """Update a technician (Admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin permissions
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    try:
        data = request.json
        name = data.get('name', '').strip()
        role = data.get('role', '').strip()
        email = data.get('email', '').strip()
        is_active = data.get('is_active')
        
        db = get_db()
        update_data = {}
        
        # Handle field updates
        if name:
            update_data['name'] = name
        if role:
            update_data['role'] = role
        if email:
            # Validate email format if provided
            import re
            if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
                return jsonify({'status': 'error', 'message': 'Invalid email format'}), 400
            
            # Check for duplicate email (excluding current technician)
            from bson.objectid import ObjectId
            existing = db.technicians.find_one({"email": email, "_id": {"$ne": ObjectId(technician_id)}})
            if existing:
                return jsonify({'status': 'error', 'message': 'A technician with this email already exists'}), 400
                
            update_data['email'] = email
        
        # Handle activation/deactivation
        if is_active is not None:
            update_data['is_active'] = is_active
        
        if not update_data:
            return jsonify({'status': 'error', 'message': 'No data to update'}), 400
        
        result = db.update_technician(technician_id, update_data)
        
        if result.matched_count == 0:
            return jsonify({'status': 'error', 'message': 'Technician not found'}), 404
        
        action = 'activated' if is_active else 'updated'
        return jsonify({
            'status': 'success',
            'message': f'Technician {action} successfully'
        })
    except Exception as e:
        app.logger.error(f"Error updating technician {technician_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/technicians/<technician_id>/deactivate', methods=['POST'])
def deactivate_technician(technician_id):
    """Deactivate a technician (Admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin permissions
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
    
    try:
        db = get_db()
        result = db.deactivate_technician(technician_id)
        
        if result.matched_count == 0:
            return jsonify({'status': 'error', 'message': 'Technician not found'}), 404
        
        return jsonify({
            'status': 'success',
            'message': 'Technician deactivated successfully'
        })
    except Exception as e:
        app.logger.error(f"Error deactivating technician {technician_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500



# Add AI-based warranty form detection
@app.route('/api/detect-warranty-form', methods=['POST'])
def detect_warranty_form():
    """AI-based warranty form detection with manual confirmation"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        # This is a placeholder implementation
        # In production, you would integrate with an AI service or use ML models
        
        data = request.json
        file_content = data.get('file_content', '')
        file_name = data.get('file_name', '')
        ticket_id = data.get('ticket_id', '')
        
        # Simple keyword-based detection (placeholder for AI)
        warranty_keywords = [
            'warranty', 'claim', 'dpf', 'diesel particulate filter',
            'vehicle registration', 'mileage', 'fault codes',
            'auto assist group', 'aftercare'
        ]
        
        keyword_matches = 0
        for keyword in warranty_keywords:
            if keyword.lower() in file_content.lower():
                keyword_matches += 1
        
        # Calculate confidence score
        confidence = min((keyword_matches / len(warranty_keywords)) * 100, 95)
        
        is_warranty_form = confidence > 30  # Threshold for detection
        
        if is_warranty_form:
            # Log the detection for manual review
            app.logger.info(f"Potential warranty form detected for ticket {ticket_id}: {file_name} (confidence: {confidence}%)")
            
            return jsonify({
                'status': 'success',
                'detected': True,
                'confidence': confidence,
                'message': f'Potential warranty form detected with {confidence:.1f}% confidence',
                'requires_manual_confirmation': True,
                'detected_keywords': [kw for kw in warranty_keywords if kw.lower() in file_content.lower()]
            })
        else:
            return jsonify({
                'status': 'success',
                'detected': False,
                'confidence': confidence,
                'message': 'This does not appear to be a warranty form',
                'requires_manual_confirmation': False
            })
            
    except Exception as e:
        app.logger.error(f"Error in warranty form detection: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Async webhook function for real-time behavior
def trigger_tech_director_webhook_async(ticket_id, ticket_data, assignment_method='referral', referred_by=None):
    """
    Asynchronous webhook trigger - runs in background thread for real-time behavior
    Does not block user interface - fires and forgets with retry logic
    """
    def webhook_worker():
        """Background worker for webhook call with retry logic"""
        max_retries = 3
        retry_delay = 1  # seconds
        
        for attempt in range(max_retries):
            try:
                # Prepare webhook payload
                db = get_db()
                metadata = db.get_ticket_metadata(ticket_id)
                vehicle_registration = 'Not specified'
                for meta in metadata:
                    if meta['key'] == 'vehicle_registration':
                        vehicle_registration = meta['value']
                        break
                
                app_domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
                if not app_domain.startswith('http'):
                    app_domain = f"https://{app_domain}"
                
                webhook_payload = {
                    'ticket_id': ticket_id,
                    'action': 'schedule_reminder',
                    'subject': ticket_data.get('subject', 'No Subject'),
                    'customer_name': ticket_data.get('name', 'Unknown Customer'),
                    'customer_email': ticket_data.get('email', ''),
                    'vehicle_registration': vehicle_registration,
                    'priority': ticket_data.get('priority', 'Medium'),
                    'classification': ticket_data.get('classification', 'General'),
                    'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
                    'app_domain': app_domain,
                    'ticket_url': f"{app_domain}/ticket/{ticket_id}",
                    'dashboard_url': f"{app_domain}/tech-director",
                    'referral_date': datetime.now().strftime('%B %d, %Y at %I:%M %p'),
                    'referred_by': referred_by or 'Support Team',
                    'assignment_method': assignment_method,
                    'reminder_context': f"This ticket requires your technical expertise and assessment. Please review ticket #{ticket_id} for {ticket_data.get('name', 'customer')} regarding '{ticket_data.get('subject', 'technical issue')}' (Vehicle: {vehicle_registration}). Priority: {ticket_data.get('priority', 'Medium')}"
                }
                
                WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
                
                app.logger.error(f"[LAUNCH] ASYNC WEBHOOK (Attempt {attempt + 1}/{max_retries}) - Ticket {ticket_id}")
                app.logger.error(f"[WEBHOOK] WEBHOOK URL: {WEBHOOK_URL}")
                app.logger.error(f"[PAYLOAD] WEBHOOK PAYLOAD: {webhook_payload}")
                
                # Fast webhook call optimized for production
                response = requests.post(
                    WEBHOOK_URL, 
                    json=webhook_payload, 
                    timeout=5,  # Reduced timeout for faster response
                    headers={'Content-Type': 'application/json'},
                    verify=True
                )
                
                response.raise_for_status()
                
                app.logger.info(f"[SUCCESS] ASYNC WEBHOOK SUCCESS - Ticket {ticket_id} (Attempt {attempt + 1})")
                app.logger.info(f"[SUCCESS] Response: {response.status_code} - {response.text[:100]}...")
                
                # Store success metadata
                db.add_ticket_metadata(ticket_id, 'async_webhook_triggered', datetime.now().isoformat())
                db.add_ticket_metadata(ticket_id, 'webhook_attempts', str(attempt + 1))
                db.add_ticket_metadata(ticket_id, 'webhook_method', assignment_method)
                
                return  # Success - exit retry loop
                
            except Exception as e:
                app.logger.warning(f"[WARNING] ASYNC WEBHOOK ATTEMPT {attempt + 1} FAILED - Ticket {ticket_id}: {e}")
                
                if attempt < max_retries - 1:  # Not the last attempt
                    app.logger.info(f"[RETRY] RETRYING in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    # Final attempt failed
                    app.logger.error(f"[ERROR] ASYNC WEBHOOK FINAL FAILURE - Ticket {ticket_id} after {max_retries} attempts")
                    try:
                        db.add_ticket_metadata(ticket_id, 'async_webhook_failed', datetime.now().isoformat())
                        db.add_ticket_metadata(ticket_id, 'webhook_attempts', str(max_retries))
                        db.add_ticket_metadata(ticket_id, 'webhook_error', str(e))
                    except:
                        pass  # Don't fail if metadata storage fails
    
    # Start background thread for async webhook
    webhook_thread = threading.Thread(target=webhook_worker, daemon=True)
    webhook_thread.start()
    
    app.logger.info(f"[LAUNCH] ASYNC WEBHOOK QUEUED - Ticket {ticket_id} (Background thread started)")
    return True  # Always return True for async - actual result happens in background


# Check if reminder is already scheduled for a ticket
def is_reminder_already_scheduled(ticket_id):
    """
    Check if a Tech Director reminder is already scheduled for this ticket
    Prevents duplicate webhooks and automatic replies
    """
    try:
        app.logger.info(f"[DEBUG] Checking reminder status for ticket {ticket_id}")
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        
        app.logger.info(f"[DEBUG] Found {len(metadata)} metadata entries for ticket {ticket_id}")
        
        for meta in metadata:
            app.logger.info(f"[DEBUG] Checking metadata key: {meta.get('key')} = {meta.get('value')}")
            if meta['key'] == 'webhook_triggered':
                # Check if webhook was triggered recently (within last 24 hours)
                try:
                    webhook_time = datetime.fromisoformat(meta['value'])
                    time_diff = datetime.now() - webhook_time
                    
                    app.logger.info(f"[DEBUG] Webhook was triggered at {webhook_time}, {time_diff.total_seconds()} seconds ago")
                    
                    # If webhook was triggered within 24 hours, don't send another
                    if time_diff.total_seconds() < 86400:  # 24 hours in seconds
                        app.logger.info(f"[WEBHOOK] Reminder already scheduled for ticket {ticket_id} within 24 hours")
                        return True
                    else:
                        app.logger.info(f"[DEBUG] Webhook was triggered more than 24 hours ago, allowing new webhook")
                except ValueError:
                    # If timestamp parsing fails, assume it's old and allow new webhook
                    app.logger.warning(f"[WEBHOOK] Failed to parse webhook timestamp for ticket {ticket_id}")
                    pass
        
        app.logger.info(f"[DEBUG] No existing webhook found for ticket {ticket_id}, allowing new webhook")
        return False
        
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to check reminder status for ticket {ticket_id}: {e}")
        # If we can't check, allow the webhook to proceed
        return False

# Centralized webhook trigger for Tech Director referrals (Synchronous for immediate feedback)
def trigger_tech_director_webhook(ticket_id, ticket_data, assignment_method='referral', referred_by=None):
    """
    Centralized function to trigger n8n webhook when ticket is referred to Tech Director
    
    Args:
        ticket_id: The ticket ID
        ticket_data: Complete ticket data
        assignment_method: How the ticket was referred ('referral', 'status_change', 'assignment')
        referred_by: Who referred the ticket
    """
    try:
        # Get database connection
        db = get_db()
        
        # Get vehicle registration from metadata if available
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Prepare app domain
        app_domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not app_domain.startswith('http'):
            app_domain = f"https://{app_domain}"
        
        # Prepare webhook payload for n8n
        webhook_payload = {
            'ticket_id': ticket_id,
            'action': 'schedule_reminder',
            'subject': ticket_data.get('subject', 'No Subject'),
            'customer_name': ticket_data.get('name', 'Unknown Customer'),
            'customer_email': ticket_data.get('email', ''),
            'vehicle_registration': vehicle_registration,
            'priority': ticket_data.get('priority', 'Medium'),
            'classification': ticket_data.get('classification', 'General'),
            'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
            'app_domain': app_domain,
            'ticket_url': f"{app_domain}/ticket/{ticket_id}",
            'dashboard_url': f"{app_domain}/tech-director",
            'referral_date': datetime.now().strftime('%B %d, %Y at %I:%M %p'),
            'referred_by': referred_by or session.get('member_name', 'Support Team'),
            'assignment_method': assignment_method,
            'reminder_context': f"This ticket requires your technical expertise and assessment. Please review ticket #{ticket_id} for {ticket_data.get('name', 'customer')} regarding '{ticket_data.get('subject', 'technical issue')}' (Vehicle: {vehicle_registration}). Priority: {ticket_data.get('priority', 'Medium')}"
        }
        
        # Check if reminder is already scheduled to prevent duplicates
        app.logger.info(f"[DEBUG] Checking if reminder already scheduled for ticket {ticket_id}")
        if is_reminder_already_scheduled(ticket_id):
            app.logger.info(f"[WEBHOOK] Skipping webhook for ticket {ticket_id} - reminder already scheduled")
            return True
        
        app.logger.info(f"[DEBUG] No existing reminder found - proceeding with webhook for ticket {ticket_id}")
        
        # n8n webhook URL - using the working production URL
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.info(f"[LAUNCH] TRIGGERING TECH DIRECTOR WEBHOOK for ticket {ticket_id}")
        app.logger.info(f"[WEBHOOK] Webhook URL: {WEBHOOK_URL}")
        app.logger.info(f"[WEBHOOK] Payload: {webhook_payload}")
        
        # Send webhook request to n8n with production-optimized configuration
        app.logger.info(f"[DEBUG] Sending webhook request to {WEBHOOK_URL}")
        response = requests.post(
            WEBHOOK_URL, 
            json=webhook_payload, 
            timeout=8,  # Reduced timeout for production
            headers={'Content-Type': 'application/json'},
            verify=True
        )
        
        app.logger.info(f"[DEBUG] Webhook request completed with status {response.status_code}")
        
        # Log detailed response info before raising for status
        app.logger.info(f"[WEBHOOK] WEBHOOK RESPONSE STATUS: {response.status_code}")
        app.logger.info(f"[WEBHOOK] WEBHOOK RESPONSE HEADERS: {dict(response.headers)}")
        app.logger.info(f"[WEBHOOK] WEBHOOK RESPONSE CONTENT: {response.text[:500]}...")  # First 500 chars
        
        response.raise_for_status()
        
        # Log success
        app.logger.info(f"[SUCCESS] WEBHOOK SUCCESS: Tech Director reminder scheduled for ticket {ticket_id}")
        app.logger.info(f"[SUCCESS] n8n Response: {response.status_code} - {response.text[:200]}")
        
        # Store webhook metadata
        app.logger.info(f"[DEBUG] Storing webhook metadata for ticket {ticket_id}")
        db.add_ticket_metadata(ticket_id, 'webhook_triggered', datetime.now().isoformat())
        db.add_ticket_metadata(ticket_id, 'webhook_url', WEBHOOK_URL)
        db.add_ticket_metadata(ticket_id, 'webhook_method', assignment_method)
        db.add_ticket_metadata(ticket_id, 'referred_by', webhook_payload['referred_by'])
        
        app.logger.info(f"[DEBUG] Webhook metadata stored successfully for ticket {ticket_id}")
        return True
        
    except requests.exceptions.RequestException as e:
        app.logger.error(f"[ERROR] WEBHOOK REQUEST FAILED for ticket {ticket_id}: {e}")
        app.logger.error(f"[ERROR] WEBHOOK URL: {WEBHOOK_URL}")
        app.logger.error(f"[ERROR] WEBHOOK PAYLOAD: {webhook_payload}")
        if hasattr(e, 'response') and e.response is not None:
            app.logger.error(f"[ERROR] Response status: {e.response.status_code}")
            app.logger.error(f"[ERROR] Response content: {e.response.text}")
            app.logger.error(f"[ERROR] Response headers: {dict(e.response.headers)}")
        else:
            app.logger.error(f"[ERROR] No response received - connection/timeout error")
        return False
        
    except Exception as e:
        app.logger.error(f"[ERROR] WEBHOOK UNEXPECTED ERROR for ticket {ticket_id}: {e}")
        app.logger.error(f"[ERROR] Error type: {type(e).__name__}")
        import traceback
        app.logger.error(f"[ERROR] Traceback: {traceback.format_exc()}")
        return False


# Cancel Tech Director reminder when ticket is no longer referred
def cancel_tech_director_reminder(ticket_id):
    """
    Cancel Tech Director reminder when ticket status changes away from 'Referred to Tech Director'
    Prevents unnecessary reminders for resolved tickets
    """
    try:
        # Prepare cancellation payload
        cancellation_payload = {
            'ticket_id': ticket_id,
            'action': 'cancel_reminder',
            'reason': 'Ticket status changed',
            'responded_by': 'System',
            'cancelled_at': datetime.now().isoformat()
        }
        
        # n8n webhook URL for cancellation
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.info(f"[CANCEL] Cancelling Tech Director reminder for ticket {ticket_id}")
        
        # Send cancellation webhook
        response = requests.post(
            WEBHOOK_URL,
            json=cancellation_payload,
            timeout=5,
            headers={'Content-Type': 'application/json'},
            verify=True
        )
        
        if response.ok:
            app.logger.info(f"[SUCCESS] Reminder cancelled for ticket {ticket_id}")
            # Update metadata to indicate cancellation
            db = get_db()
            db.add_ticket_metadata(ticket_id, 'reminder_cancelled', datetime.now().isoformat())
            return True
        else:
            app.logger.warning(f"[WARNING] Failed to cancel reminder for ticket {ticket_id}: {response.status_code}")
            return False
            
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to cancel reminder for ticket {ticket_id}: {e}")
        return False


# Add Technical Director referral email notification
def send_tech_director_referral_email(ticket_id, ticket_data):
    """Send email notification to Technical Director when ticket is referred"""
    try:
        # Technical Director email
        tech_director_email = os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com')
        
        # Get domain for links (fallback for local development)
        domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not domain.startswith('http'):
            domain = f"https://{domain}"
        
        subject = f"? URGENT: Technical Review Required - Ticket #{ticket_id}"
        
        # Get vehicle registration from metadata if available
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Plain text body
        body = """Dear Marc,

A support ticket has been escalated and requires your immediate technical review.

? TICKET DETAILS:
???????????????????
? Ticket ID: #{ticket_id}
? Subject: {ticket_data.get('subject', 'No Subject')}
? Customer: {ticket_data.get('name', 'Unknown')}
? Email: {ticket_data.get('email', 'Not provided')}
? Vehicle Registration: {vehicle_registration}
? Priority: {ticket_data.get('priority', 'Medium')}
? Classification: {ticket_data.get('classification', 'General')}

? QUICK ACTIONS:
???????????????????
? Review Ticket: {domain}/ticket/{ticket_id}
? Tech Director Portal: {domain}/tech-director

? This ticket requires your technical expertise and assessment.
Please review and provide your recommendations as soon as possible.

Best regards,
AutoAssistGroup Support System
        """

        # HTML body for better formatting
        html_body = """
        <html>
        <body style="font-family: Arial, sans-serif; line-height: 1.6; color: #333;">
            <div style="max-width: 600px; margin: 0 auto; padding: 20px;">
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px 10px 0 0;">
                    <h1 style="margin: 0; font-size: 24px;">? Technical Review Required</h1>
                    <p style="margin: 5px 0 0 0; opacity: 0.9;">Ticket #{ticket_id} needs your expertise</p>
                </div>
                
                <div style="background: #f8f9fa; padding: 25px; border-radius: 0 0 10px 10px; border: 1px solid #e9ecef;">
                    <div style="background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h2 style="color: #495057; margin-top: 0;">? Ticket Information</h2>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Ticket ID:</td><td style="padding: 8px 0;">#{ticket_id}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Subject:</td><td style="padding: 8px 0;">{ticket_data.get('subject', 'No Subject')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Customer:</td><td style="padding: 8px 0;">{ticket_data.get('name', 'Unknown')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Email:</td><td style="padding: 8px 0;">{ticket_data.get('email', 'Not provided')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Vehicle Reg:</td><td style="padding: 8px 0;">{vehicle_registration}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Priority:</td><td style="padding: 8px 0;"><span style="background: #ff6b6b; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px;">{ticket_data.get('priority', 'Medium')}</span></td></tr>
                        </table>
                    </div>
                    
                    <div style="text-align: center; margin: 25px 0;">
                        <a href="{domain}/ticket/{ticket_id}" style="background: #28a745; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">? Review Ticket</a>
                        <a href="{domain}/tech-director" style="background: #17a2b8; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">?? Dashboard</a>
                    </div>
                    
                    <div style="background: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 6px; margin-top: 20px;">
                        <p style="margin: 0; color: #856404;"><strong>? Action Required:</strong> This ticket requires your immediate technical assessment and recommendations.</p>
                    </div>
                </div>
                
                <div style="text-align: center; margin-top: 20px; color: #6c757d; font-size: 12px;">
                    <p>AutoAssistGroup Support System | Automated Notification</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Send the email using our email service
        success = email_service.send_email(
            to_email=tech_director_email,
            subject=subject,
            body=body,
            html_body=html_body
        )
        
        if success:
            app.logger.info(f"Tech Director referral email sent successfully to {tech_director_email} for ticket {ticket_id}")
            
            # [LAUNCH] NEW: Trigger async webhook for real-time reminder scheduling
            # ðŸš¨ TEMPORARILY DISABLED: Tech Director webhook causing automatic replies
            # webhook_queued = trigger_tech_director_webhook_async(ticket_id, ticket_data, 'email_referral')
            webhook_queued = False
            app.logger.warning(f"ðŸš¨ TECH DIRECTOR WEBHOOK DISABLED - Ticket {ticket_id} to prevent automatic replies")
            app.logger.info(f"[SUCCESS] Tech Director async webhook queued for ticket {ticket_id}")
            
        else:
            app.logger.error(f"Failed to send tech director referral email for ticket {ticket_id}")
        
        return success
    except Exception as e:
        app.logger.error(f"Failed to send tech director referral email: {e}")
        return False


# New API endpoint for Tech Director referral button
@app.route('/api/tickets/<ticket_id>/tech-director', methods=['POST'])
def refer_to_tech_director(ticket_id):
    """Dedicated endpoint to refer ticket to Tech Director and trigger webhook"""
    
    # Enhanced error handling and debugging
    app.logger.info(f"[TARGET] TECH DIRECTOR REFERRAL - Ticket: {ticket_id}")
    
    if 'member_id' not in session:
        app.logger.warning(f"[ERROR] UNAUTHORIZED - No session for tech director referral {ticket_id}")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in'}), 401
    
    try:
        db = get_db()
        
        # Get the ticket
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Enhanced validation for referral with consistency check
        current_status = ticket.get('status')
        
        # Check if ticket is already referred to tech director
        if current_status == 'Referred to Tech Director':
            # Check if it's truly with tech director or has assignment conflicts
            assignment = db.get_assignment_by_ticket(ticket_id)
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    if (assigned_member and 
                        assigned_member.get('role') != 'Technical Director' and 
                        assignment.get('is_forwarded', False)):
                        # Status is wrong - this ticket was forwarded back but status not updated
                        app.logger.warning(f"[FIX] FIXING STATUS INCONSISTENCY - Ticket {ticket_id} shows 'Referred to Tech Director' but is assigned to {assigned_member.get('name', 'Unknown')}")
                        
                        # Fix the status automatically based on assigned member role
                        target_role = assigned_member.get('role', 'Support')
                        if target_role == 'Administrator':
                            corrected_status = 'Open'
                        elif target_role in ['Support', 'Engineer', 'IT']:
                            corrected_status = 'Under Review'
                        else:
                            corrected_status = 'Open'
                        
                        db.update_ticket(ticket_id, {
                            'status': corrected_status,
                            'updated_at': datetime.now(),
                            'status_auto_fixed': f'Corrected from forwarded state - assigned to {assigned_member.get("name", "Unknown")}',
                            'previous_inconsistent_status': 'Referred to Tech Director'
                        })
                        
                        app.logger.info(f"[SUCCESS] AUTO-FIXED INCONSISTENCY - Ticket {ticket_id} status corrected to '{corrected_status}' (assigned to {assigned_member.get('name')})")
                        
                        # Now proceed with the referral since status is fixed
                    else:
                        # Ticket is genuinely with tech director
                        return jsonify({'status': 'error', 'message': 'Ticket is already referred to Tech Director'}), 400
                else:
                    app.logger.error(f"[ERROR] TICKET {ticket_id} has assignment but no member_id")
            else:
                # No assignment but status shows referred - this is also inconsistent
                app.logger.warning(f"[FIX] FIXING ORPHANED STATUS - Ticket {ticket_id} shows 'Referred to Tech Director' but has no assignment")
                # Allow the referral to proceed and fix the issue
        
        # Get referrer information
        referrer_name = session.get('member_name', 'Support Team')
        referrer_id = session.get('member_id')
        
        # [FIX] CRITICAL FIX: Clear any existing assignments when making direct referral
        # FIXED: Preserve assignments when referring to Tech Director
        existing_assignment = db.get_assignment_by_ticket(ticket_id)
        if existing_assignment:
            assigned_member_id = existing_assignment.get('member_id')
            app.logger.info(f"[PRESERVE] KEEPING ASSIGNMENT - Ticket {ticket_id} has assignment, preserving during Tech Director referral")
            # DON'T remove assignment - user can still work on it while Tech Director reviews
        
        # Update ticket status to "Referred to Tech Director"
        db.update_ticket(ticket_id, {
            'status': 'Referred to Tech Director',
            'updated_at': datetime.now(),
            'referred_to_tech_director_by': referrer_name,
            'referred_to_tech_director_at': datetime.now(),
            'referral_method': 'direct_button',
            'old_assignment_cleared': existing_assignment is not None
        })
        
        app.logger.info(f"[TARGET] MANUAL TECH DIRECTOR REFERRAL - Ticket {ticket_id} referred by {referrer_name}")
        
        # Send email notification to Tech Director
        email_success = send_tech_director_referral_email(ticket_id, ticket)
        if email_success:
            app.logger.info(f"[SUCCESS] Tech Director referral email sent for ticket {ticket_id}")
        else:
            app.logger.warning(f"[WARNING] Tech Director referral email failed for ticket {ticket_id}")
        
        # âœ… RE-ENABLED: Tech Director webhook with duplicate prevention
        webhook_queued = trigger_tech_director_webhook(ticket_id, ticket, 'manual_referral', referrer_name)
        if webhook_queued:
            app.logger.info(f"âœ… TECH DIRECTOR WEBHOOK ENABLED - Reminder scheduled for ticket {ticket_id}")
        else:
            app.logger.info(f"â„¹ï¸ TECH DIRECTOR WEBHOOK SKIPPED - Reminder already exists for ticket {ticket_id}")
        
        # Note: webhook_queued is always True for async - actual result happens in background
        
        # Add metadata to track the referral
        db.add_ticket_metadata(ticket_id, 'referred_by_manual_button', referrer_name)
        db.add_ticket_metadata(ticket_id, 'referral_method', 'manual_button')
        db.add_ticket_metadata(ticket_id, 'referral_timestamp', datetime.now().isoformat())
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket successfully referred to Tech Director',
            'ticket_id': ticket_id,
            'referred_by': referrer_name,
            'email_sent': email_success,
            'webhook_queued': webhook_queued,
            'real_time_mode': True,
            'note': 'Webhook running in background - check logs for completion status'
        })
        
    except Exception as e:
        app.logger.error(f"Error referring ticket {ticket_id} to Tech Director: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to refer ticket to Tech Director'}), 500


# Real-time webhook status endpoint
@app.route('/api/tickets/<ticket_id>/webhook-status', methods=['GET'])
def get_webhook_status(ticket_id):
    """Get real-time status of async webhook for a ticket"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get webhook-related metadata
        metadata = db.get_ticket_metadata(ticket_id)
        webhook_data = {}
        
        for meta in metadata:
            if meta['key'] in ['async_webhook_triggered', 'async_webhook_failed', 'webhook_attempts', 'webhook_method', 'webhook_error']:
                webhook_data[meta['key']] = meta['value']
        
        # Determine status
        if 'async_webhook_triggered' in webhook_data:
            status = 'completed'
            message = 'Webhook completed successfully'
        elif 'async_webhook_failed' in webhook_data:
            status = 'failed'
            message = f"Webhook failed: {webhook_data.get('webhook_error', 'Unknown error')}"
        else:
            status = 'pending'
            message = 'Webhook still processing in background'
        
        return jsonify({
            'status': 'success',
            'webhook_status': status,
            'message': message,
            'attempts': webhook_data.get('webhook_attempts', '0'),
            'method': webhook_data.get('webhook_method', 'unknown'),
            'details': webhook_data
        })
        
    except Exception as e:
        app.logger.error(f"Error getting webhook status for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to get webhook status'}), 500


# Webhook health monitoring endpoint
@app.route('/api/webhook/health', methods=['GET'])
def webhook_health():
    """Get overall health status of the webhook system"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        health_status = get_webhook_health_status()
        
        return jsonify({
            'status': 'success',
            'webhook_health': health_status,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error getting webhook health: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to get webhook health'}), 500


# Webhook cleanup endpoint (admin only)
@app.route('/api/webhook/cleanup', methods=['POST'])
def webhook_cleanup():
    """Clean up old webhook metadata (admin only)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        # Check if user is admin
        db = get_db()
        member = db.get_member_by_id(session['member_id'])
        if not member or member.get('role') != 'Administrator':
            return jsonify({'status': 'error', 'message': 'Admin access required'}), 403
        
        cleaned_count = cleanup_old_webhook_metadata()
        
        return jsonify({
            'status': 'success',
            'message': f'Cleaned up {cleaned_count} old webhook metadata records',
            'cleanup_count': cleaned_count,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error in webhook cleanup: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to cleanup webhook metadata'}), 500


# Debug endpoint for Tech Director referral issues
@app.route('/api/debug/tech-director-tickets', methods=['GET'])
def debug_tech_director_tickets():
    """Debug endpoint to check Tech Director ticket filtering"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get all tickets with "Referred to Tech Director" status
        all_referred = db.get_tickets_by_status("Referred to Tech Director")
        
        # Get tickets with assignments
        tickets_with_assignments = db.get_tickets_with_assignments()
        referred_with_assignments = [t for t in tickets_with_assignments if t.get('status') == "Referred to Tech Director"]
        
        debug_info = {
            'total_referred_tickets': len(all_referred),
            'referred_with_assignments': len(referred_with_assignments),
            'tickets': []
        }
        
        for ticket in all_referred:
            ticket_info = {
                'ticket_id': ticket.get('ticket_id'),
                'status': ticket.get('status'),
                'subject': ticket.get('subject'),
                'created_at': str(ticket.get('created_at')),
                'has_assignment': bool(db.get_assignment_by_ticket(ticket.get('ticket_id')))
            }
            debug_info['tickets'].append(ticket_info)
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info
        })
        
    except Exception as e:
        app.logger.error(f"Error in debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Debug endpoint for testing re-referral functionality
@app.route('/api/debug/re-referral-test/<ticket_id>', methods=['GET'])
def debug_re_referral_test(ticket_id):
    """Debug endpoint to test re-referral to Tech Director functionality"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get current user info
        current_user = session.get('member_name', 'Unknown')
        current_role = session.get('member_role', 'Unknown')
        
        # Get ticket info
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Get assignment info
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        # Check if ticket was forwarded back from Tech Director
        was_forwarded_back = False
        if assignment and assignment.get('is_forwarded', False) and assignment.get('forwarded_from_tech_director', False):
            was_forwarded_back = True
        
        # Check if ticket can be re-referred
        can_re_refer = (ticket.get('status') != 'Referred to Tech Director' and 
                       ticket.get('status') != 'Closed' and 
                       ticket.get('status') != 'Resolved')
        
        debug_info = {
            'ticket_id': ticket_id,
            'ticket_status': ticket.get('status'),
            'current_user': current_user,
            'current_role': current_role,
            'assignment': assignment,
            'was_forwarded_back': was_forwarded_back,
            'can_re_refer': can_re_refer,
            'referred_to_tech_director_by': ticket.get('referred_to_tech_director_by'),
            'referred_to_tech_director_at': str(ticket.get('referred_to_tech_director_at')) if ticket.get('referred_to_tech_director_at') else None,
            'forwarded_from_tech_director': ticket.get('forwarded_from_tech_director'),
            'forwarded_from_tech_director_to': ticket.get('forwarded_from_tech_director_to')
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info,
            'message': f'Re-referral test data for ticket {ticket_id}'
        })
        
    except Exception as e:
        app.logger.error(f"Error in re-referral test debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Debug endpoint for testing forward functionality
@app.route('/api/debug/forward-test/<ticket_id>', methods=['GET'])
def debug_forward_test(ticket_id):
    """Debug endpoint to test forward functionality"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get current user info
        current_user = session.get('member_name', 'Unknown')
        current_role = session.get('member_role', 'Unknown')
        
        # Get ticket assignment info
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        # Get all members for testing
        all_members = db.get_all_members()
        
        debug_info = {
            'ticket_id': ticket_id,
            'current_user': current_user,
            'current_role': current_role,
            'current_assignment': assignment,
            'available_members': [
                {
                    'id': str(member.get('_id')),
                    'name': member.get('name'),
                    'role': member.get('role')
                } for member in all_members
            ]
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info,
            'message': f'Forward test data for ticket {ticket_id}'
        })
        
    except Exception as e:
        app.logger.error(f"Error in forward test debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Debug endpoint specifically for user referral testing
@app.route('/api/debug/user-referral-test', methods=['GET'])
def debug_it_member_referral_test():
    """Debug endpoint to test user referral functionality"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    try:
        db = get_db()
        
        # Get current user info
        current_user = session.get('member_name', 'Unknown')
        current_role = session.get('member_role', 'Unknown')
        
        # Get all tickets with "Referred to Tech Director" status
        all_referred = db.get_tickets_by_status("Referred to Tech Director")
        
        # Check which tickets were referred by users
        it_member_referrals = []
        for ticket in all_referred:
            # Check if ticket has referral metadata
            metadata = db.get_ticket_metadata(ticket.get('ticket_id'))
            referred_by = None
            for meta in metadata:
                if isinstance(meta, dict) and meta.get('key') == 'referred_by_manual_button':
                    referred_by = meta.get('value')
                    break
            
            if referred_by:
                it_member_referrals.append({
                    'ticket_id': ticket.get('ticket_id'),
                    'subject': ticket.get('subject'),
                    'referred_by': referred_by,
                    'status': ticket.get('status'),
                    'created_at': str(ticket.get('created_at'))
                })
        
        debug_info = {
            'current_user': current_user,
            'current_role': current_role,
            'total_referred_tickets': len(all_referred),
            'it_member_referrals': it_member_referrals,
            'it_member_referral_count': len(it_member_referrals)
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info,
            'message': f'Found {len(it_member_referrals)} tickets referred by users'
        })
        
    except Exception as e:
        app.logger.error(f"Error in user referral debug endpoint: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Test endpoint for n8n webhook connection
@app.route('/api/test-webhook', methods=['POST', 'GET'])
def test_webhook():
    """Test the n8n webhook connection directly"""
    
    # Check if user is authenticated
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Not authenticated'}), 401
    
    # Check if user has permission (admin or support team)
    try:
        db = get_db()
        member = db.get_member_by_id(session['member_id'])
        if not member or member.get('role') not in ['Administrator', 'Support Team', 'Technical Director']:
            return jsonify({'status': 'error', 'message': 'Insufficient permissions'}), 403
    except Exception as e:
        app.logger.error(f"Error checking user permissions: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to verify permissions'}), 500
    try:
        # Test payload
        test_payload = {
            'ticket_id': 'TEST123',
            'action': 'test_connection',
            'test_timestamp': datetime.now().isoformat(),
            'message': 'This is a test webhook call from the AutoAssist system',
            'customer_name': 'Test Customer',
            'customer_email': 'test@example.com',
            'subject': 'Test Webhook Connection',
            'priority': 'Medium',
            'classification': 'Test',
            'referred_by': 'System Test',
            'assignment_method': 'webhook_test'
        }
        
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.info(f"? TESTING WEBHOOK CONNECTION")
        app.logger.info(f"[WEBHOOK] URL: {WEBHOOK_URL}")
        app.logger.info(f"[PAYLOAD] Test Payload: {test_payload}")
        
        # Send test webhook request
        response = requests.post(WEBHOOK_URL, json=test_payload, timeout=15)
        
        app.logger.info(f"[SUCCESS] Webhook Response Status: {response.status_code}")
        app.logger.info(f"[SUCCESS] Webhook Response Content: {response.text}")
        app.logger.info(f"[SUCCESS] Webhook Response Headers: {dict(response.headers)}")
        
        response.raise_for_status()
        
        # Test the duplicate prevention system
        test_ticket_id = 'TEST_WEBHOOK_123'
        
        # First call should succeed
        first_call = trigger_tech_director_webhook(test_ticket_id, {
            'subject': 'Test Webhook Duplicate Prevention',
            'name': 'Test Customer',
            'email': 'test@example.com',
            'priority': 'High',
            'classification': 'Test'
        }, 'webhook_test', 'System Test')
        
        # Second call should be prevented (duplicate)
        second_call = trigger_tech_director_webhook(test_ticket_id, {
            'subject': 'Test Webhook Duplicate Prevention - Second Call',
            'name': 'Test Customer',
            'email': 'test@example.com',
            'priority': 'High',
            'classification': 'Test'
        }, 'webhook_test', 'System Test')
        
        # Clean up test metadata
        try:
            db = get_db()
            db.remove_ticket_metadata(test_ticket_id, 'webhook_triggered')
            db.remove_ticket_metadata(test_ticket_id, 'webhook_url')
            db.remove_ticket_metadata(test_ticket_id, 'webhook_method')
            db.remove_ticket_metadata(test_ticket_id, 'referred_by')
        except Exception as cleanup_error:
            app.logger.warning(f"Failed to cleanup test metadata: {cleanup_error}")
        
        return jsonify({
            'status': 'success',
            'message': 'Webhook test successful with duplicate prevention',
            'webhook_url': WEBHOOK_URL,
            'response_status': response.status_code,
            'response_content': response.text,
            'payload_sent': test_payload,
            'duplicate_prevention_test': {
                'first_call_success': first_call,
                'second_call_prevented': not second_call,
                'duplicate_prevention_working': first_call and not second_call
            }
        })
        
    except requests.exceptions.RequestException as e:
        error_details = {
            'error_type': 'RequestException',
            'error_message': str(e),
            'webhook_url': WEBHOOK_URL
        }
        
        if hasattr(e, 'response') and e.response is not None:
            error_details.update({
                'response_status': e.response.status_code,
                'response_content': e.response.text,
                'response_headers': dict(e.response.headers)
            })
            app.logger.error(f"[ERROR] WEBHOOK TEST FAILED - Status: {e.response.status_code}, Content: {e.response.text}")
        else:
            error_details['connection_error'] = 'No response received - connection/timeout error'
            app.logger.error(f"[ERROR] WEBHOOK TEST FAILED - Connection error")
        
        app.logger.error(f"[ERROR] WEBHOOK TEST ERROR: {e}")
        
        return jsonify({
            'status': 'error',
            'message': 'Webhook test failed',
            'error_details': error_details
        }), 500
        
    except Exception as e:
        app.logger.error(f"[ERROR] WEBHOOK TEST UNEXPECTED ERROR: {e}")
        import traceback
        app.logger.error(f"[ERROR] Traceback: {traceback.format_exc()}")
        
        return jsonify({
            'status': 'error',
            'message': 'Webhook test failed with unexpected error',
            'error_type': type(e).__name__,
            'error_message': str(e)
        }), 500

# Add Support team notification when Tech Director responds
def send_support_team_notification(ticket_id, ticket_data, feedback_data):
    """Send email notification to Support team when Tech Director provides feedback"""
    try:
        # Support team email (can be multiple recipients)
        support_emails = os.environ.get('SUPPORT_TEAM_EMAILS', 'support@autoassistgroup.com').split(',')
        
        # Get domain for links
        domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not domain.startswith('http'):
            domain = f"https://{domain}"
        
        subject = f"[SUCCESS] Technical Assessment Complete - Ticket #{ticket_id}"
        
        # Get vehicle registration from metadata if available
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Plain text body
        body = """Support Team,

The Technical Director has completed their assessment for ticket #{ticket_id}.

? TICKET DETAILS:
???????????????????
? Ticket ID: #{ticket_id}
? Subject: {ticket_data.get('subject', 'No Subject')}
? Customer: {ticket_data.get('name', 'Unknown')}
? Vehicle Registration: {vehicle_registration}

? TECHNICAL ASSESSMENT:
???????????????????????
? Assessment Category: {feedback_data.get('assessment_category', 'Not specified')}
? Reviewed by: {feedback_data.get('reviewer', 'Technical Director')}
? Date: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}

[NOTE] TECHNICAL NOTES:
???????????????????
{feedback_data.get('tech_director_notes', 'No notes provided')}

{f"[FIX] RECOMMENDED ACTION:\n{feedback_data.get('recommended_action')}\n" if feedback_data.get('recommended_action') else ''}

? NEXT STEPS:
???????????????????
? Review the assessment: {domain}/ticket/{ticket_id}
? Follow up with customer as needed
? Implement recommended actions

This ticket is now ready for Support team follow-up action.

Best regards,
AutoAssistGroup Support System
"""

        # HTML body for better formatting
        html_body = """
        <html>
        <body style="font-family: Arial, sans-serif; line-height: 1.6; color: #333;">
            <div style="max-width: 600px; margin: 0 auto; padding: 20px;">
                <div style="background: linear-gradient(135deg, #28a745 0%, #20c997 100%); color: white; padding: 20px; border-radius: 10px 10px 0 0;">
                    <h1 style="margin: 0; font-size: 24px;">[SUCCESS] Technical Assessment Complete</h1>
                    <p style="margin: 5px 0 0 0; opacity: 0.9;">Ticket #{ticket_id} ready for follow-up</p>
                </div>
                
                <div style="background: #f8f9fa; padding: 25px; border-radius: 0 0 10px 10px; border: 1px solid #e9ecef;">
                    <div style="background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h2 style="color: #495057; margin-top: 0;">? Ticket Information</h2>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Ticket ID:</td><td style="padding: 8px 0;">#{ticket_id}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Subject:</td><td style="padding: 8px 0;">{ticket_data.get('subject', 'No Subject')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Customer:</td><td style="padding: 8px 0;">{ticket_data.get('name', 'Unknown')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Vehicle Reg:</td><td style="padding: 8px 0;">{vehicle_registration}</td></tr>
                        </table>
                    </div>
                    
                    <div style="background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <h2 style="color: #495057; margin-top: 0;">? Technical Assessment</h2>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Category:</td><td style="padding: 8px 0;"><span style="background: #17a2b8; color: white; padding: 2px 8px; border-radius: 12px; font-size: 12px;">{feedback_data.get('assessment_category', 'Not specified')}</span></td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Reviewed by:</td><td style="padding: 8px 0;">{feedback_data.get('reviewer', 'Technical Director')}</td></tr>
                            <tr><td style="padding: 8px 0; font-weight: bold; color: #6c757d;">Date:</td><td style="padding: 8px 0;">{datetime.now().strftime('%B %d, %Y at %I:%M %p')}</td></tr>
                        </table>
                        
                        <div style="margin-top: 15px;">
                            <h3 style="color: #495057; margin-bottom: 10px;">[NOTE] Technical Notes:</h3>
                            <div style="background: #f8f9fa; padding: 15px; border-radius: 6px; border-left: 4px solid #17a2b8;">
                                <p style="margin: 0; white-space: pre-wrap;">{feedback_data.get('tech_director_notes', 'No notes provided')}</p>
                            </div>
                        </div>
                        
                        {f'''<div style="margin-top: 15px;">
                            <h3 style="color: #495057; margin-bottom: 10px;">[FIX] Recommended Action:</h3>
                            <div style="background: #fff3cd; padding: 15px; border-radius: 6px; border-left: 4px solid #ffc107;">
                                <p style="margin: 0; white-space: pre-wrap; color: #856404;">{feedback_data.get('recommended_action')}</p>
                            </div>
                        </div>''' if feedback_data.get('recommended_action') else ''}
                    </div>
                    
                    <div style="text-align: center; margin: 25px 0;">
                        <a href="{domain}/ticket/{ticket_id}" style="background: #28a745; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">? Review Ticket</a>
                        <a href="{domain}/" style="background: #6f42c1; color: white; padding: 12px 25px; text-decoration: none; border-radius: 6px; font-weight: bold; margin: 0 10px; display: inline-block;">?? Dashboard</a>
                    </div>
                    
                    <div style="background: #d1ecf1; border: 1px solid #bee5eb; padding: 15px; border-radius: 6px; margin-top: 20px;">
                        <p style="margin: 0; color: #0c5460;"><strong>[SUCCESS] Ready for Action:</strong> This ticket has been assessed and is ready for your follow-up action.</p>
                    </div>
                </div>
                
                <div style="text-align: center; margin-top: 20px; color: #6c757d; font-size: 12px;">
                    <p>AutoAssistGroup Support System | Technical Assessment Notification</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # Send emails to all support team members
        success_count = 0
        for email in support_emails:
            email = email.strip()
            if email:
                success = email_service.send_email(
                    to_email=email,
                    subject=subject,
                    body=body,
                    html_body=html_body
                )
                if success:
                    success_count += 1
        
        if success_count > 0:
            app.logger.info(f"Support team notification sent successfully to {success_count} recipients for ticket {ticket_id}")
            return True
        else:
            app.logger.error(f"Failed to send support team notification for ticket {ticket_id}")
            return False
        
    except Exception as e:
        app.logger.error(f"Failed to send support team notification: {e}")
        return False

# Add ticket status update API endpoint
@app.route('/api/tickets/<ticket_id>/status', methods=['POST'])
def update_ticket_status(ticket_id):
    """Update ticket status - Available for ALL users including Technical Director"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401

    
    try:
        data = request.json
        new_status = data.get('status')
        
        if not new_status:
            return jsonify({'status': 'error', 'message': 'Status is required'}), 400
        
        db = get_db()
        
        # Get current ticket data for email notification
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Prepare update data
        update_data = {'status': new_status}
        
        # Handle technical director assessment data
        tech_director_notes = data.get('tech_director_notes')
        assessment_category = data.get('assessment_category')
        
        if tech_director_notes:
            update_data['tech_director_notes'] = tech_director_notes
        
        if assessment_category:
            update_data['assessment_category'] = assessment_category
            # Also store as metadata for better tracking
            db.add_ticket_metadata(ticket_id, 'tech_director_assessment', assessment_category)
            if tech_director_notes:
                db.add_ticket_metadata(ticket_id, 'tech_director_notes', tech_director_notes)
        
        # Update the ticket with all data
        db.update_ticket(ticket_id, update_data)
        
        # [LAUNCH] WEBHOOK TRIGGER: Special handling for Technical Director referral
        if new_status == "Referred to Tech Director":
            app.logger.info(f"[TARGET] STATUS CHANGE TO TECH DIRECTOR - Processing referral for ticket {ticket_id}")
            
            # Send email notification (existing functionality)
            send_tech_director_referral_email(ticket_id, ticket)
            
            # âœ… RE-ENABLED: Tech Director webhook with duplicate prevention
            webhook_queued = trigger_tech_director_webhook(ticket_id, ticket, 'status_change', session.get('member_name', 'Support Team'))
            if webhook_queued:
                app.logger.info(f"âœ… STATUS CHANGE WEBHOOK ENABLED - Reminder scheduled for ticket {ticket_id}")
            else:
                app.logger.info(f"â„¹ï¸ STATUS CHANGE WEBHOOK SKIPPED - Reminder already exists for ticket {ticket_id}")
        
        # [CANCEL] Cancel Tech Director reminder when status changes away from referral
        elif new_status != "Referred to Tech Director":
            # Check if ticket was previously referred to Tech Director
            db = get_db()
            metadata = db.get_ticket_metadata(ticket_id)
            was_referred = any(meta['key'] == 'webhook_triggered' for meta in metadata)
            
            if was_referred:
                app.logger.info(f"[CANCEL] Status changed from 'Referred to Tech Director' - Cancelling reminder for ticket {ticket_id}")
                cancel_tech_director_reminder(ticket_id)
        
        return jsonify({'status': 'success', 'message': f'Status updated to: {new_status}'})
        
    except Exception as e:
        app.logger.error(f"Error updating ticket status: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to update status'}), 500

# Quick webhook test endpoint
@app.route('/api/urgent-webhook-test/<ticket_id>')
def urgent_webhook_test(ticket_id):
    """URGENT: Quick webhook test"""
    try:
        test_payload = {
            'ticket_id': ticket_id,
            'action': 'test_reminder',
            'subject': 'TEST - Webhook Verification',
            'customer_name': 'Test Customer',
            'priority': 'High',
            'test': True,
            'timestamp': datetime.now().isoformat()
        }
        
        WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        app.logger.error(f"[ALERT] TESTING WEBHOOK NOW - Ticket: {ticket_id}")
        app.logger.error(f"[WEBHOOK] URL: {WEBHOOK_URL}")
        app.logger.error(f"[PAYLOAD] PAYLOAD: {test_payload}")
        
        response = requests.post(
            WEBHOOK_URL, 
            json=test_payload, 
            timeout=10,
            headers={'Content-Type': 'application/json'}
        )
        
        app.logger.error(f"[WEBHOOK] TEST RESPONSE: {response.status_code}")
        app.logger.error(f"[WEBHOOK] TEST CONTENT: {response.text}")
        
        return jsonify({
            'status': 'success' if response.status_code == 200 else 'error',
            'webhook_status': response.status_code,
            'webhook_response': response.text,
            'message': f'Webhook test complete for {ticket_id}'
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] WEBHOOK TEST ERROR: {e}")
        return jsonify({'status': 'error', 'error': str(e)})

# Add Technical Director dashboard
@app.route('/tech-director')
def tech_director_dashboard():
    """Special dashboard for Technical Director to view referred tickets"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if user has permission - only Technical Director (not Admin)
    member_role = session.get('member_role', '')
    if member_role != 'Technical Director':
        return render_template('error.html', error="Access denied. Technical Director access required."), 403
    
    try:
        db = get_db()
        
        # [FIX] Use direct status query instead of complex aggregation
        all_referred_tickets = db.get_tickets_by_status("Referred to Tech Director")
        
        # [ALERT] CRITICAL DEBUG - Log exactly what we found
        try:
            count_referred = len(all_referred_tickets)
        except Exception:
            count_referred = 0
        app.logger.error(f"[ALERT] TD DASHBOARD DEBUG - Found {count_referred} tickets with status 'Referred to Tech Director'")
        
        # Ensure iterable type
        if not isinstance(all_referred_tickets, list):
            try:
                all_referred_tickets = list(all_referred_tickets) if all_referred_tickets else []
            except Exception:
                all_referred_tickets = []
        
        # Debug each ticket found safely
        for i, ticket in enumerate(all_referred_tickets):
            if isinstance(ticket, dict):
                app.logger.error(f"[ALERT] TICKET {i+1}: ID={ticket.get('ticket_id')}, Status='{ticket.get('status')}', Priority={ticket.get('priority')}")
            else:
                app.logger.error(f"[ALERT] TICKET {i+1}: Invalid ticket type {type(ticket).__name__}")
        
        # [FIX] REMOVED AUTO-FIX LOGIC - Don't change ticket statuses automatically
        # This was causing issues with tickets referred by users
        app.logger.info(f"[INFO] TD DASHBOARD - No auto-fixing applied, showing all referred tickets as-is")
        
        # [FIX] ULTRA-SIMPLIFIED: Show ALL tickets with "Referred to Tech Director" status - NO FILTERING
        active_referred_tickets = []
        app.logger.info(f"[INFO] TD DASHBOARD - Processing {len(all_referred_tickets)} tickets with 'Referred to Tech Director' status")
        
        for ticket in all_referred_tickets:
            if not isinstance(ticket, dict):
                app.logger.warning(f"[SKIP] Non-dict ticket encountered: type={type(ticket).__name__}")
                continue
                
            ticket_dict = dict(ticket)
            ticket_id = ticket_dict.get('ticket_id', 'Unknown')
            
            # [FIX] INCLUDE ALL TICKETS - No assignment checking, no filtering
            # This ensures tickets referred by users (like zeeshan) are always shown
            active_referred_tickets.append(ticket_dict)
            app.logger.info(f"[INCLUDE] Ticket {ticket_id}: Added to Tech Director dashboard (no filtering applied)")
        
        app.logger.info(f"[SUCCESS] TD DASHBOARD - {len(active_referred_tickets)} tickets will be shown to Tech Director (ALL included)")
        
        # Format tickets for display
        formatted_tickets = []
        for ticket_dict in active_referred_tickets:
            if not isinstance(ticket_dict, dict):
                app.logger.error(f"[SKIP] Non-dict ticket in active list: type={type(ticket_dict).__name__}")
                continue
            # Format created_at
            created_at_value = ticket_dict.get('created_at')
            if isinstance(created_at_value, datetime):
                ticket_dict['formatted_date'] = created_at_value.strftime("%b %d, %Y %I:%M %p")
            else:
                try:
                    created_at = datetime.strptime(str(created_at_value), "%Y-%m-%d %H:%M:%S")
                    ticket_dict['formatted_date'] = created_at.strftime("%b %d, %Y %I:%M %p")
                except Exception:
                    ticket_dict['formatted_date'] = str(created_at_value)
            
            # Get vehicle registration from metadata
            metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
            ticket_dict['vehicle_registration'] = 'Not specified'
            has_warranty_attachment = False
            
            for meta in metadata:
                try:
                    if isinstance(meta, dict):
                        meta_key = meta.get('key')
                        meta_value = meta.get('value')
                    else:
                        meta_key = None
                        meta_value = None
                except (AttributeError, TypeError):
                    meta_key = None
                    meta_value = None

                if meta_key == 'vehicle_registration':
                    ticket_dict['vehicle_registration'] = meta_value if isinstance(meta_value, str) else str(meta_value)
                
                #  DYNAMIC WARRANTY CLASSIFICATION: Check for warranty attachments
                try:
                    if isinstance(meta_value, str):
                        # Clean JSON before parsing
                        clean_json = meta_value.strip()
                        # Remove trailing commas and fix common JSON issues
                        if clean_json.endswith(',}'):
                            clean_json = clean_json[:-2] + '}'
                        elif clean_json.endswith(',]'):
                            clean_json = clean_json[:-2] + ']'
                        # Remove any leading/trailing whitespace and quotes
                        clean_json = clean_json.strip().strip('"\'')
                        # Skip if still empty after cleaning
                        if not clean_json or clean_json in ['{}', '[]', 'null', 'undefined']:
                            meta_data = {}
                        else:
                            meta_data = json.loads(clean_json)
                    elif isinstance(meta_value, dict):
                        meta_data = meta_value
                    else:
                        meta_data = {}
                    
                    # Check if this attachment is warranty-related
                    is_warranty = meta_data.get('is_warranty', False) if isinstance(meta_data, dict) else False
                    if is_warranty:
                        has_warranty_attachment = True
                except (json.JSONDecodeError, TypeError, ValueError) as e:
                    # Only log if it's actually malformed, not just empty
                    if isinstance(meta_value, str) and meta_value.strip() and meta_value.strip() not in ['{}', '[]', 'null', 'undefined', '']:
                        app.logger.debug(f"JSON parse error in TD dashboard: {e} - Value: {meta_value[:50]}")
                    meta_data = {}
            
            # Update classification if warranty attachment found
            if has_warranty_attachment or ticket_dict.get('has_warranty', False):
                original_classification = ticket_dict.get('classification')
                ticket_dict['classification'] = 'Warranty Claim'
                
                if original_classification != 'Warranty Claim':
                    app.logger.info(f" TD DASHBOARD WARRANTY CLASSIFICATION: Ticket {ticket_dict['ticket_id']} updated from '{original_classification}' to 'Warranty Claim'")
            
            # Get assignment info for display
            assignment = db.get_assignment_by_ticket(ticket_dict['ticket_id'])
            if assignment is not None and not isinstance(assignment, dict):
                app.logger.error(f"[WARN] Non-dict assignment for ticket {ticket_dict.get('ticket_id')} during formatting: type={type(assignment).__name__}")
                assignment = None
            if assignment:
                # [FIX] Ensure member_id is valid before calling get_member_by_id
                member_id = assignment.get('member_id')
                if member_id:
                    assigned_member = db.get_member_by_id(member_id)
                    if assigned_member:
                        ticket_dict['assignment_info'] = {
                            'assigned_to': assigned_member.get('name', 'Unknown'),
                            'assigned_at': assignment.get('assigned_at'),
                            'is_forwarded': assignment.get('is_forwarded', False),
                            'notes': assignment.get('notes', '')
                        }
            
            # Get forwarded_from information for "Referred from [Username]" display
            # First check if this is a direct referral to tech director (stored in ticket document)
            if ticket_dict.get('referred_to_tech_director_by'):
                ticket_dict['forwarded_from_name'] = ticket_dict['referred_to_tech_director_by']
            elif ticket_dict.get('is_forwarded') and ticket_dict.get('forwarded_from_member') and len(ticket_dict['forwarded_from_member']) > 0:
                # For forwarded tickets, use the forwarded_from_member data
                forwarded_member = ticket_dict['forwarded_from_member'][0]
                ticket_dict['forwarded_from_name'] = forwarded_member.get('name', 'Unknown')
            else:
                # For direct referrals (not forwarded), try to get the referring user from assignment
                if assignment and assignment.get('forwarded_from'):
                    try:
                        from bson.objectid import ObjectId
                        forwarded_from_id = assignment.get('forwarded_from')
                        if ObjectId.is_valid(str(forwarded_from_id)):
                            forwarded_member = db.get_member_by_id(forwarded_from_id)
                            if forwarded_member:
                                ticket_dict['forwarded_from_name'] = forwarded_member.get('name', 'Unknown')
                            else:
                                ticket_dict['forwarded_from_name'] = 'Unknown'
                        else:
                            ticket_dict['forwarded_from_name'] = 'Unknown'
                    except Exception as e:
                        app.logger.error(f"Error getting forwarded_from member for ticket {ticket_dict['ticket_id']}: {e}")
                        ticket_dict['forwarded_from_name'] = 'Unknown'
                else:
                    ticket_dict['forwarded_from_name'] = 'Unknown'
            
            formatted_tickets.append(ticket_dict)
        
        # Calculate statistics for dashboard
        total_referred_count = len(all_referred_tickets)
        active_tickets_count = len(formatted_tickets) 
        forwarded_count = total_referred_count - active_tickets_count
        
        app.logger.info(f"Tech Director Dashboard: {total_referred_count} total referred, {active_tickets_count} active, {forwarded_count} forwarded to others")
        
        return render_template('tech_director_dashboard.html', 
                             tickets=formatted_tickets,
                             total_referred=active_tickets_count,
                             total_originally_referred=total_referred_count,
                             forwarded_to_others=forwarded_count,
                             current_user=session.get('member_name'),
                             current_user_role=session.get('member_role'))
        
    except Exception as e:
        app.logger.error(f"Error loading tech director dashboard: {e}")
        return render_template('error.html', error="Failed to load dashboard"), 500

# Add Technical Director reminder scheduling endpoint
@app.route('/api/tech-director/schedule-reminder/<ticket_id>', methods=['POST'])
def schedule_tech_director_reminder(ticket_id):
    """Schedule reminder for Technical Director referral via n8n webhook"""
    try:
        # Get ticket data
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket or ticket.get('status') != 'Referred to Tech Director':
            return jsonify({'status': 'error', 'message': 'Invalid ticket for reminder scheduling'}), 400
        
        # Get vehicle registration from metadata if available
        metadata = db.get_ticket_metadata(ticket_id)
        vehicle_registration = 'Not specified'
        for meta in metadata:
            if meta['key'] == 'vehicle_registration':
                vehicle_registration = meta['value']
                break
        
        # Prepare reminder payload for your n8n workflow  
        app_domain = os.environ.get('APP_DOMAIN', 'auto-assit-group.vercel.app')
        if not app_domain.startswith('http'):
            app_domain = f"https://{app_domain}"
            
        reminder_payload = {
            'ticket_id': ticket_id,
            'subject': ticket.get('subject', 'No Subject'),
            'customer_name': ticket.get('name', 'Unknown Customer'),
            'customer_email': ticket.get('email', ''),
            'vehicle_registration': vehicle_registration,
            'priority': ticket.get('priority', 'Medium'),
            'classification': ticket.get('classification', 'General'),
            'tech_director_email': os.environ.get('TECH_DIRECTOR_EMAIL', 'marc@autoassistgroup.com'),
            'app_domain': app_domain,
            'ticket_url': f"{app_domain}/ticket/{ticket_id}",
            'dashboard_url': f"{app_domain}/tech-director",
            'referral_date': datetime.now().strftime('%B %d, %Y at %I:%M %p'),
            'reminder_context': f"This ticket requires your technical expertise and assessment. Please review ticket #{ticket_id} for {ticket.get('name', 'customer')} regarding '{ticket.get('subject', 'technical issue')}' (Vehicle: {vehicle_registration}). Priority: {ticket.get('priority', 'Medium')}"
        }
        
        # Send to n8n reminder webhook
        REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        response = requests.post(REMINDER_WEBHOOK_URL, json=reminder_payload, timeout=10)
        response.raise_for_status()
        
        # Log successful scheduling
        app.logger.info(f"Reminder scheduled for Technical Director - Ticket: {ticket_id}, Webhook: {REMINDER_WEBHOOK_URL}")
        
        # Store reminder scheduling info as metadata
        db.add_ticket_metadata(ticket_id, 'reminder_scheduled', datetime.now().isoformat())
        db.add_ticket_metadata(ticket_id, 'reminder_webhook_url', REMINDER_WEBHOOK_URL)
        
        return jsonify({
            'status': 'success',
            'message': 'Technical Director reminder sent to n8n workflow successfully',
            'ticket_id': ticket_id
        })
        
    except requests.exceptions.RequestException as e:
        app.logger.error(f"Failed to send reminder webhook for ticket {ticket_id}: {e}")
        if hasattr(e, 'response') and e.response is not None:
            app.logger.error(f"Webhook response status: {e.response.status_code}, content: {e.response.text}")
        return jsonify({'status': 'error', 'message': f'Failed to schedule reminder: {str(e)}'}), 500
        
    except Exception as e:
        app.logger.error(f"Unexpected error scheduling reminder for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tech-director/cancel-reminder/<ticket_id>', methods=['POST'])
def cancel_tech_director_reminder(ticket_id):
    """Cancel Technical Director reminder when feedback is submitted"""
    try:
        db = get_db()
        
        # Check if ticket exists
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Prepare cancellation payload for n8n
        cancellation_payload = {
            'ticket_id': ticket_id,
            'action': 'cancel_reminder',
            'reason': 'technical_director_responded',
            'cancelled_at': datetime.now().isoformat()
        }
        
        # Send cancellation to n8n reminder webhook
        REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
        
        try:
            response = requests.post(REMINDER_WEBHOOK_URL, json=cancellation_payload, timeout=5)
            response.raise_for_status()
            app.logger.info(f"Reminder cancellation sent for ticket {ticket_id}")
        except Exception as e:
            app.logger.warning(f"Failed to send reminder cancellation for ticket {ticket_id}: {e}")
            # Don't fail the whole operation if cancellation fails
        
        # Update metadata to mark reminder as cancelled
        db.add_ticket_metadata(ticket_id, 'reminder_cancelled', datetime.now().isoformat())
        
        return jsonify({
            'status': 'success',
            'message': 'Reminder cancellation processed'
        })
        
    except Exception as e:
        app.logger.error(f"Error cancelling reminder for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# Add Technical Director feedback API endpoint
@app.route('/api/tech-director/feedback/<ticket_id>', methods=['POST'])
def submit_tech_director_feedback(ticket_id):
    """Submit Technical Director feedback and notify Support team"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check if user has Tech Director permission - only Technical Director (not Admin)
    member_role = session.get('member_role', '')
    if member_role != 'Technical Director':
        return jsonify({'status': 'error', 'message': 'Tech Director access required'}), 403
    
    try:
        data = request.json
        assessment_category = data.get('assessment_category', '')
        tech_director_notes = data.get('tech_director_notes', '')
        recommended_action = data.get('recommended_action', '')
        new_status = data.get('new_status', '')
        
        if not assessment_category or not tech_director_notes:
            return jsonify({'status': 'error', 'message': 'Assessment category and notes are required'}), 400
        
        db = get_db()
        
        # Get ticket data for notifications
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Update ticket with Tech Director assessment
        update_data = {
            'status': new_status if new_status else ticket.get('status'),
            'tech_director_assessment': assessment_category,
            'tech_director_notes': tech_director_notes,
            'tech_director_feedback_date': datetime.now(),
            'tech_director_reviewer': session.get('member_name', 'Technical Director')
        }
        
        if recommended_action:
            update_data['recommended_action'] = recommended_action
        
        db.update_ticket(ticket_id, update_data)
        
        # Store as metadata for better tracking
        metadata_updates = [
            ('tech_director_assessment', assessment_category),
            ('tech_director_notes', tech_director_notes),
            ('tech_director_feedback_date', datetime.now().isoformat()),
            ('tech_director_reviewer', session.get('member_name', 'Technical Director'))
        ]
        
        if recommended_action:
            metadata_updates.append(('recommended_action', recommended_action))
        
        for key, value in metadata_updates:
            # Remove existing entry first
            db.ticket_metadata.delete_many({'ticket_id': ticket_id, 'key': key})
            # Add new entry
            db.add_ticket_metadata(ticket_id, key, str(value))
        
        # Create a reply with the Tech Director's assessment
        reply_data = {
            'ticket_id': ticket_id,
            'thread_id': ticket.get('thread_id', ''),
            'message': """Technical Director Assessment Complete

Assessment Category: {assessment_category}

Technical Notes:
{tech_director_notes}

{f'Recommended Action: {recommended_action}' if recommended_action else ''}

This assessment has been completed by the Technical Director and the ticket has been returned to Support for follow-up action.""",
            'sender': 'tech_director'
        }
        db.create_reply(reply_data)
        
        # Send email notification to Support team about Tech Director feedback
        success = send_support_team_notification(ticket_id, ticket, {
            'assessment_category': assessment_category,
            'tech_director_notes': tech_director_notes,
            'recommended_action': recommended_action,
            'reviewer': session.get('member_name', 'Technical Director')
        })
        
        app.logger.info(f"Tech Director feedback submitted for ticket {ticket_id} by {session.get('member_name')}")
        
        # [NEW] NEW: Cancel any pending reminders since TD has responded
        try:
            cancellation_payload = {
                'ticket_id': ticket_id,
                'action': 'cancel_reminder',
                'reason': 'technical_director_responded',
                'cancelled_at': datetime.now().isoformat(),
                'responded_by': session.get('member_name', 'Technical Director')
            }
            
            REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
            
            response = requests.post(REMINDER_WEBHOOK_URL, json=cancellation_payload, timeout=5)
            response.raise_for_status()
            
            app.logger.info(f"Automatic reminder cancellation sent for ticket {ticket_id}")
            
            # Update metadata to mark reminder as cancelled
            db.add_ticket_metadata(ticket_id, 'auto_reminder_cancelled', datetime.now().isoformat())
            
        except Exception as e:
            app.logger.warning(f"Failed to cancel automatic reminder for ticket {ticket_id}: {e}")
            # Don't fail feedback submission if reminder cancellation fails
        
        return jsonify({
            'status': 'success',
            'message': 'Technical assessment submitted successfully. Support team has been notified.',
            'email_sent': success,
            'reminder_cancelled': True
        })
        
    except Exception as e:
        app.logger.error(f"Error submitting tech director feedback: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

 

 
 

  







@app.route('/api/tickets/<ticket_id>/assign', methods=['POST'])
def assign_ticket(ticket_id):
    """Assign ticket to member - Technical Director can FORWARD but not take over"""
    
    # Enhanced error handling and debugging
    try:
        app.logger.info(f"[TARGET] ASSIGN REQUEST - Ticket: {ticket_id}")
        
        # Check authentication first
        if 'member_id' not in session:
            app.logger.warning(f"[ERROR] UNAUTHORIZED - No session for ticket {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in'}), 401
        
        # Log request data
        request_data = request.get_json() if request.is_json else {}
        target_member_id = request_data.get('member_id', 'MISSING')
        is_forwarded_flag = request_data.get('is_forwarded', False)
        
        app.logger.info(f"[INFO] ASSIGN DATA - Target: {target_member_id}, Forwarded: {is_forwarded_flag}, Session User: {session.get('member_id')}")
        
    except Exception as debug_error:
        app.logger.error(f"[ALERT] ASSIGN INIT ERROR: {debug_error}")
        return jsonify({'status': 'error', 'message': 'Request processing error'}), 500
    
    # Technical Director can only forward tickets, not take them over
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    is_tech_director = current_member and current_member['role'] == 'Technical Director'
    
    if is_tech_director:
        # Technical Director can only forward, check if this is a forward operation
        data = request.json
        is_forwarded = data.get('is_forwarded', False)
        if not is_forwarded:
            return jsonify({'status': 'error', 'message': 'Technical Director can only forward tickets, not take them over.'}), 403
        
        # Ensure the ticket is referred to Technical Director
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket or ticket.get('status') != 'Referred to Tech Director':
            return jsonify({'status': 'error', 'message': 'You can only forward tickets that have been referred to you.'}), 403
    
    # Step 1: Authentication Check
    if 'member_id' not in session:
        app.logger.warning(f"Unauthorized assignment attempt for ticket {ticket_id}")
        return jsonify({
            'status': 'error', 
            'message': 'Unauthorized - Please log in first',
            'error_code': 'AUTH_REQUIRED'
        }), 401
    
    # Step 2: Basic Request Validation
    try:
        # Get request data
        data = request.get_json()
        app.logger.info(f"ASSIGN REQUEST - Ticket: {ticket_id}, Data: {data}, Session: {session.get('member_id')}")
        
        if not data:
            app.logger.error(f"Empty request body for ticket {ticket_id}")
            return jsonify({
                'status': 'error',
                'message': 'Request body is required',
                'error_code': 'EMPTY_BODY'
            }), 400
            
        if not data.get('member_id'):
            app.logger.error(f"Missing member_id in request for ticket {ticket_id}")
            app.logger.error(f"Request data received: {data}")
            return jsonify({
                'status': 'error',
                'message': 'Member ID is required. Please select a team member to assign the ticket to.',
                'error_code': 'MISSING_MEMBER_ID',
                'debug_info': {
                    'received_data': data,
                    'required_field': 'member_id'
                }
            }), 400
            
    except Exception as e:
        app.logger.error(f"Request parsing error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': 'Invalid JSON in request body',
            'error_code': 'INVALID_JSON'
        }), 400
    
    # Step 3: Database Connection
    try:
        db = get_db()
        app.logger.info(f"Database connection established for ticket {ticket_id}")
        
        # Check if ticket exists first
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        if not ticket:
            app.logger.error(f"Ticket not found: {ticket_id}")
            app.logger.info(f"Available tickets sample: {[t['ticket_id'] for t in db.tickets.find().limit(5)]}")
            return jsonify({
                'status': 'error',
                'message': f'Ticket {ticket_id} not found. Please verify the ticket ID.',
                'error_code': 'TICKET_NOT_FOUND'
            }), 404
    except Exception as e:
        app.logger.error(f"Database connection failed for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': 'Database connection failed',
            'error_code': 'DB_CONNECTION_FAILED'
        }), 500
    
    # Step 4: Validate and Process Member ID
    try:
        member_id_raw = data.get('member_id')
        app.logger.info(f"Processing member_id: '{member_id_raw}' (type: {type(member_id_raw)})")
        
        # Clean and validate member_id
        if not member_id_raw:
            return jsonify({
                'status': 'error',
                'message': 'member_id cannot be empty',
                'error_code': 'EMPTY_MEMBER_ID'
            }), 400
            
        member_id_str = str(member_id_raw).strip()
        if not member_id_str:
            return jsonify({
                'status': 'error',
                'message': 'member_id cannot be empty after trimming',
                'error_code': 'EMPTY_MEMBER_ID_TRIMMED'
            }), 400
            
        # Validate ObjectId format
        if not ObjectId.is_valid(member_id_str):
            app.logger.error(f"Invalid ObjectId format: '{member_id_str}'")
            return jsonify({
                'status': 'error',
                'message': f'Invalid member ID format: {member_id_str}',
                'error_code': 'INVALID_OBJECTID_FORMAT'
            }), 400
            
        member_id_obj = ObjectId(member_id_str)
        app.logger.info(f"Valid ObjectId created: {member_id_obj}")
        
    except Exception as e:
        app.logger.error(f"Member ID processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error processing member ID: {str(e)}',
            'error_code': 'MEMBER_ID_PROCESSING_ERROR'
        }), 400
    
    # Step 5: Validate Member Exists
    try:
        member = db.get_member_by_id(member_id_str)
        if not member:
            app.logger.error(f"Member not found: {member_id_str}")
            return jsonify({
                'status': 'error',
                'message': f'Member not found: {member_id_str}',
                'error_code': 'MEMBER_NOT_FOUND'
            }), 404
        # [ALERT] CRITICAL DEBUG: Member analysis
        member_role = member.get('role', 'NO_ROLE')
        member_name = member.get('name', 'NO_NAME')
        
        print("-" * 60)
        print(f"[ALERT] MEMBER FOUND: {member_name}")
        print(f"[ALERT] MEMBER ROLE: '{member_role}'")
        print(f"[ALERT] CURRENT USER is_tech_director: {is_tech_director}")
        print(f"[ALERT] ROLE CHECK: '{member_role}' == 'Technical Director' ? {member_role == 'Technical Director'}")
        print(f"[ALERT] USER CHECK: not is_tech_director ? {not is_tech_director}")
        print(f"[ALERT] WEBHOOK TRIGGER CONDITION: {member_role == 'Technical Director' and not is_tech_director}")
        print("-" * 60)
        
        app.logger.info(f"Member found: {member_name} (Role: {member_role}) - Webhook condition: {member_role == 'Technical Director' and not is_tech_director}")
        
        # Also check if Tech Director exists in database
        try:
            db_tech_directors = list(db.members.find({"role": "Technical Director"}))
            print(f"[ALERT] TECH DIRECTORS IN DB: {len(db_tech_directors)}")
            for td in db_tech_directors:
                print(f"[ALERT]   - {td.get('name', 'NO_NAME')} (ID: {str(td.get('_id', 'NO_ID'))}, Role: '{td.get('role', 'NO_ROLE')}')")
        except Exception as db_check_error:
            print(f"[ALERT] DB CHECK ERROR: {db_check_error}")
        
    except Exception as e:
        app.logger.error(f"Member lookup error for {member_id_str}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error finding member: {str(e)}',
            'error_code': 'MEMBER_LOOKUP_ERROR'
        }), 500
    
    # Step 7: Handle Existing Assignments - FIXED TRANSACTION LOGIC
    try:
        existing_assignment = db.get_assignment_by_ticket(ticket_id)
        app.logger.info(f"[DEBUG] EXISTING ASSIGNMENT CHECK - Ticket: {ticket_id}, Assignment: {existing_assignment}")
        
        if existing_assignment:
            existing_member_id = str(existing_assignment.get('member_id'))
            target_member_id_str = str(member_id_obj)
            
            app.logger.info(f"[INFO] ASSIGNMENT COMPARISON - Existing: {existing_member_id}, Target: {target_member_id_str}")
            
            # [FIX] Allow forwarding back to same user - only block if it's NOT a forward operation
            is_forwarding_to_same_user = (str(existing_assignment['member_id']) == member_id_str)
            is_forward_operation = data.get('is_forwarded', False)
            
            if is_forwarding_to_same_user and not is_forward_operation:
                # Only block if trying to assign to same user AND it's not a forward operation
                return jsonify({
                    'status': 'error',
                    'message': f'Ticket already assigned to {member["name"]}',
                    'error_code': 'ALREADY_ASSIGNED'
                }), 400
            elif is_forwarding_to_same_user and is_forward_operation:
                # Allow forwarding back to same user - this is valid
                app.logger.info(f"[FORWARD] Allowing forward back to same user: {member['name']}")
            
            # Remove existing assignment for reassignment (including forward to same user)
            result = db.ticket_assignments.delete_one({'ticket_id': ticket_id})
            app.logger.info(f"Removed existing assignment: {result.deleted_count} records")
        else:
            app.logger.info(f"No existing assignment for ticket {ticket_id}")
            
    except Exception as e:
        app.logger.error(f"Assignment check error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error checking existing assignments: {str(e)}',
            'error_code': 'ASSIGNMENT_CHECK_ERROR'
        }), 500
    
    # Step 8: Handle Forwarding Logic
    is_forwarded = data.get('is_forwarded', False)
    forwarded_from = None
    
    if is_forwarded:
        try:
            # Try to get forwarded_from from request
            forwarded_from_raw = data.get('forwarded_from')
            if forwarded_from_raw and ObjectId.is_valid(str(forwarded_from_raw)):
                forwarded_from = ObjectId(str(forwarded_from_raw))
                # Verify the forwarded_from member exists and log their role
                forwarded_member = db.get_member_by_id(forwarded_from)
                if forwarded_member:
                    app.logger.info(f"Using provided forwarded_from: {forwarded_from} ({forwarded_member.get('name')} - {forwarded_member.get('role')})")
                else:
                    app.logger.warning(f"Provided forwarded_from ID {forwarded_from} does not exist, using session user")
                    forwarded_from = ObjectId(session['member_id']) if session.get('member_id') else None
            
            # Fallback to current session user
            elif session.get('member_id') and ObjectId.is_valid(session['member_id']):
                forwarded_from = ObjectId(session['member_id'])
                # Log the session user's role for clarity
                session_member = db.get_member_by_id(forwarded_from)
                if session_member:
                    app.logger.info(f"Using session user as forwarded_from: {forwarded_from} ({session_member.get('name')} - {session_member.get('role')})")
                else:
                    app.logger.warning(f"Session member {forwarded_from} not found!")
            
            app.logger.info(f"Final forwarded_from value: {forwarded_from}")
            
        except Exception as e:
            app.logger.warning(f"Forwarding logic error (non-critical): {str(e)}")
            forwarded_from = None

    # Step 9: Create New Assignment
    try:
        assignment_data = {
            'ticket_id': ticket_id,
            'member_id': member_id_obj,  # Ensure this is ObjectId type
            'notes': data.get('notes', ''),
            'is_forwarded': is_forwarded,
            'forwarded_from': forwarded_from,
            'assigned_at': datetime.now(),
            'assigned_by': ObjectId(session['member_id']) if ObjectId.is_valid(session.get('member_id', '')) else None
        }
        
        app.logger.info(f"[ASSIGNMENT] Creating assignment with data: ticket_id={ticket_id}, member_id={member_id_obj} (type: {type(member_id_obj).__name__}), is_forwarded={is_forwarded}")
        app.logger.info(f"[ASSIGNMENT] Full assignment_data: {assignment_data}")
        
        # CRITICAL DEBUG: Check if the member actually exists
        test_member = db.get_member_by_id(str(member_id_obj))
        app.logger.info(f"[ASSIGNMENT] Member verification: member_id={member_id_obj}, exists={test_member is not None}, name={test_member.get('name') if test_member else 'NOT_FOUND'}")
        
        assignment_id = db.assign_ticket(assignment_data)
        app.logger.info(f"[SUCCESS] Assignment created with ID: {assignment_id}")
        
        # IMMEDIATE VERIFICATION: Check if assignment can be retrieved AND if member lookup works
        try:
            verification_check = db.get_assignment_by_ticket(ticket_id)
            if verification_check:
                app.logger.info(f"[VERIFY] Assignment immediately retrievable: {verification_check.get('_id')}")
                # Test the exact same lookup that dashboard uses
                stored_member_id = verification_check.get('member_id')
                app.logger.info(f"[VERIFY] Stored member_id: {stored_member_id} (type: {type(stored_member_id).__name__})")
                lookup_member = db.get_member_by_id(str(stored_member_id))
                app.logger.info(f"[VERIFY] Member lookup result: {lookup_member.get('name') if lookup_member else 'LOOKUP_FAILED'}")
            else:
                app.logger.error(f"[VERIFY] WARNING: Assignment not immediately retrievable after creation!")
        except Exception as verify_error:
            app.logger.error(f"[VERIFY] Error checking assignment: {verify_error}")
        
        # [NEW] COMPREHENSIVE DEBUG LOGGING BEFORE WEBHOOK LOGIC
        app.logger.info(f"[DEBUG] WEBHOOK TRIGGER ANALYSIS - Ticket: {ticket_id}")
        app.logger.info(f"  ?? Target Member: {member.get('name', 'Unknown')} (ID: {member_id_str})")
        app.logger.info(f"  ?? Target Member Role: '{member.get('role', 'No role')}'")
        app.logger.info(f"  ?? Current User: {session.get('member_name', 'Unknown')} (ID: {session.get('member_id')})")
        app.logger.info(f"  ?? Current User is_tech_director: {is_tech_director}")
        app.logger.info(f"  ?? Is Forwarded: {is_forwarded}")
        app.logger.info(f"  ?? Role Check: member.get('role') == 'Technical Director' ? {member.get('role') == 'Technical Director'}")
        app.logger.info(f"  ?? User Check: not is_tech_director ? {not is_tech_director}")
        app.logger.info(f"  ?? WEBHOOK CONDITION: {member.get('role') == 'Technical Director' and not is_tech_director}")
        
        if member.get('role') == 'Technical Director' and not is_tech_director:
            app.logger.info(f"[SUCCESS] WEBHOOK CONDITIONS MET - Proceeding with webhook")
        else:
            app.logger.info(f"[ERROR] WEBHOOK CONDITIONS NOT MET - Will skip webhook")
        
        # [ALERT] WEBHOOK TRIGGER: Check if ticket is being forwarded TO the tech director
        webhook_condition = member.get('role') == 'Technical Director' and not is_tech_director
        
        # Log webhook decision using app.logger.error to ensure visibility
        app.logger.error(f"[ALERT] WEBHOOK CHECK - Ticket: {ticket_id}, Member: {member.get('name')}, Role: '{member.get('role')}', Condition: {webhook_condition}")
        
        if webhook_condition:
            app.logger.error(f"[LAUNCH] WEBHOOK ACTIVATED - Triggering for ticket {ticket_id}")
            app.logger.info(f"[TARGET] FORWARDING TO TECH DIRECTOR - Triggering webhook for ticket {ticket_id}")
            
            # Update ticket status to "Referred to Tech Director" 
            db.update_ticket(ticket_id, {
                'status': 'Referred to Tech Director',
                'updated_at': datetime.now()
            })
            app.logger.info(f"[SUCCESS] Updated ticket {ticket_id} status to 'Referred to Tech Director'")
            
            # [LAUNCH] TRIGGER ASYNC WEBHOOK - Real-time behavior for assignments
            # Get ticket data for reminder
            ticket = db.get_ticket_by_id(ticket_id)
            
            # ðŸš¨ TEMPORARILY DISABLED: Tech Director webhook causing automatic replies
            # webhook_queued = trigger_tech_director_webhook_async(ticket_id, ticket, 'assignment', session.get('member_name', 'Support Team'))
            webhook_queued = False
            app.logger.warning(f"ðŸš¨ TECH DIRECTOR WEBHOOK DISABLED - Ticket {ticket_id} to prevent automatic replies")
            app.logger.info(f"[SUCCESS] ASSIGNMENT ASYNC WEBHOOK: Queued for ticket {ticket_id}")
        
        # [NEW] Handle when Technical Director forwards tickets to others
        elif is_tech_director and is_forwarded:
            # [FIX] FIX: Clear "Referred to Tech Director" status - ticket now belongs to new assignee
            app.logger.info(f"[RETRY] Tech Director forwarding ticket {ticket_id} to {member.get('name')} - Clearing TD status")
            
            # Determine appropriate status based on who is receiving the ticket
            target_role = member.get('role', 'Support')
            if target_role == 'Administrator':
                new_status = 'Open'  # Back to admin for review
            elif target_role in ['Support', 'Engineer', 'IT']:
                new_status = 'Under Review'  # With support team
            else:
                new_status = 'Open'  # Default fallback
            
            db.update_ticket(ticket_id, {
                'status': new_status,
                'updated_at': datetime.now(),
                'forwarded_from_tech_director': True,
                'forwarded_from_tech_director_at': datetime.now(),
                'forwarded_from_tech_director_to': member.get('name', 'Unknown')
            })
            
            app.logger.info(f"[SUCCESS] CLEARED TD STATUS - Ticket {ticket_id} status changed from 'Referred to Tech Director' to '{new_status}' (forwarded to {member.get('name')})")
            
            # Cancel reminder since Technical Director has completed their review by forwarding
            try:
                cancellation_payload = {
                    'ticket_id': ticket_id,
                    'action': 'cancel_reminder',
                    'reason': 'technical_director_forwarded',
                    'cancelled_at': datetime.now().isoformat(),
                    'forwarded_to': member["name"],
                    'new_status': new_status
                }
                
                REMINDER_WEBHOOK_URL = 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a'
                
                response = requests.post(REMINDER_WEBHOOK_URL, json=cancellation_payload, timeout=5)
                response.raise_for_status()
                
                app.logger.info(f"[SUCCESS] CANCELLED TD REMINDER - Ticket {ticket_id} forwarded to {member['name']} with status '{new_status}'")
                db.add_ticket_metadata(ticket_id, 'auto_reminder_cancelled_forwarded', datetime.now().isoformat())
                db.add_ticket_metadata(ticket_id, 'status_cleared_by_td_forward', f'Changed to {new_status}')
                
            except Exception as e:
                app.logger.warning(f"Failed to cancel reminder for forwarded ticket {ticket_id}: {e}")

        else:
            # Add debugging for when webhook doesn't trigger
            app.logger.error(f"[ERROR] NO WEBHOOK - Ticket: {ticket_id}, Role: '{member.get('role')}', is_tech_director: {is_tech_director}, forwarded: {data.get('is_forwarded', False)}")
            
            app.logger.info(f"[DEBUG] NO WEBHOOK TRIGGER - Ticket: {ticket_id}")
            app.logger.info(f"  ?? Member role: {member.get('role', 'No role')}")
            app.logger.info(f"  ?? Is tech director: {is_tech_director}")
            app.logger.info(f"  ?? Is forwarded: {data.get('is_forwarded', False)}")
            app.logger.info(f"[ERROR] SKIPPING STATUS UPDATE - Conditions not met for ticket {ticket_id}")
        
    except Exception as e:
        app.logger.error(f"Assignment creation error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Error creating assignment: {str(e)}',
            'error_code': 'ASSIGNMENT_CREATION_ERROR'
        }), 500
    
    # Step 9: Success Response
    try:
        action_type = "forwarded" if is_forwarded else "assigned"
        success_message = f'Ticket successfully {action_type} to {member["name"]}'
        
        app.logger.info(f"SUCCESS - {success_message} (Ticket: {ticket_id})")
        
        return jsonify({
            'status': 'success',
            'member_name': member['name'],
            'member_gender': member.get('gender', ''),
            'user_id': member.get('user_id', ''),

            'message': success_message,
            'assignment_id': str(assignment_id),
            'action': action_type
        }), 200
        
    except Exception as e:
        app.logger.error(f"Success response error for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Assignment created but response error: {str(e)}',
            'error_code': 'RESPONSE_ERROR'
        }), 500
    


    

@app.route('/api/tickets/<ticket_id>/assign/debug', methods=['POST', 'GET'])
def debug_assign_ticket(ticket_id):
    """Debug endpoint to test assignment functionality step by step"""
    debug_info = {
        'ticket_id': ticket_id,
        'timestamp': datetime.now().isoformat(),
        'session': {},
        'request_data': {},
        'validation_steps': {},
        'database_checks': {}
    }
    
    # Check session
    debug_info['session'] = {
        'has_member_id': 'member_id' in session,
        'member_id': session.get('member_id'),
        'member_name': session.get('member_name'),
        'member_role': session.get('member_role')
    }
    
    if request.method == 'POST':
        # Check request data
        try:
            data = request.get_json()
            debug_info['request_data'] = {
                'raw_data': data,
                'has_member_id': 'member_id' in data if data else False,
                'member_id_value': data.get('member_id') if data else None,
                'member_id_type': type(data.get('member_id')).__name__ if data and data.get('member_id') else None
            }
        except Exception as e:
            debug_info['request_data']['error'] = str(e)
        
        # Database checks
        try:
            db = get_db()
            
            # Check ticket exists
            ticket = db.tickets.find_one({'ticket_id': ticket_id})
            debug_info['database_checks']['ticket_exists'] = ticket is not None
            debug_info['database_checks']['ticket_data'] = str(ticket) if ticket else None
            
            # Check member exists (if member_id provided)
            if data and data.get('member_id'):
                member_id_str = str(data.get('member_id')).strip()
                debug_info['validation_steps']['member_id_cleaned'] = member_id_str
                debug_info['validation_steps']['is_valid_objectid'] = ObjectId.is_valid(member_id_str)
                
                if ObjectId.is_valid(member_id_str):
                    member = db.get_member_by_id(member_id_str)
                    debug_info['database_checks']['member_exists'] = member is not None
                    debug_info['database_checks']['member_data'] = {
                        'name': member.get('name') if member else None,
                        'user_id': member.get('user_id') if member else None
                    }
                
            # Check existing assignment
            existing = db.get_assignment_by_ticket(ticket_id)
            debug_info['database_checks']['existing_assignment'] = existing is not None
            debug_info['database_checks']['existing_assignment_data'] = str(existing) if existing else None
            
        except Exception as e:
            debug_info['database_checks']['error'] = str(e)
    
    return jsonify({
        'status': 'debug',
        'debug_info': debug_info
    })

@app.route('/api/tickets/<ticket_id>/assignment', methods=['DELETE'])
def unassign_ticket(ticket_id):
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    try:
        db.remove_assignment(ticket_id, session['member_id'])
        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/ticket/<ticket_id>')
def ticket_detail(ticket_id):
    """Show details for a specific ticket"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get current member role for access control
        current_member = db.get_member_by_id(session['member_id'])
        is_tech_director = current_member and current_member['role'] == 'Technical Director'
        
        # Technical Director can only view tickets referred to them
        if is_tech_director:
            ticket = db.get_ticket_by_id(ticket_id)
            if not ticket:
                return render_template('error.html', error="Ticket not found"), 404
            
            # Check if ticket is referred to Technical Director
            if ticket.get('status') != 'Referred to Tech Director':
                flash('You can only view tickets that have been referred to you for technical review.', 'warning')
                return redirect(url_for('tech_director_dashboard'))
            # If status IS "Referred to Tech Director", continue to show the ticket details
        
                # Only mark unread replies as read if there are actually new replies to be seen
        # This ensures the red dot stays visible until support actually sees the new replies
        if not is_tech_director:
            # Get latest reply to check if it's from customer
            replies = db.get_replies_by_ticket(ticket_id)
            if replies:
                # Sort by created_at descending to get latest first
                replies.sort(key=lambda x: x.get('created_at', datetime.min), reverse=True)
                latest_reply = replies[0]
                if latest_reply.get('sender') == 'customer':
                    # Mark as read only if viewing the ticket page (not just passing through)
                    db.update_ticket(ticket_id, {'has_unread_reply': False})
        
        # Get ticket with assignment info
        ticket = db.get_ticket_by_id(ticket_id)

        # Debug: Check for ticket ID consistency
        if ticket:
            actual_ticket_id = ticket.get('ticket_id', 'NO_TICKET_ID_FIELD')
            if str(ticket_id) != str(actual_ticket_id):
                app.logger.warning(f"âš ï¸ TICKET ID MISMATCH IN PORTAL - URL: {ticket_id}, Database: {actual_ticket_id}")
                app.logger.warning(f"âš ï¸ This could cause email template vs portal ticket ID mismatch!")

        # Mark forwarded assignment as seen when assignee opens the ticket
        try:
            if ticket and ticket.get('assignment'):
                assignment = ticket['assignment'][0]
                if assignment.get('is_forwarded'):
                    assignee_members = ticket.get('assigned_member') or []
                    if assignee_members:
                        assignee_id = assignee_members[0].get('_id')
                        if assignee_id and str(assignee_id) == str(session.get('member_id')):
                            db.mark_assignment_seen(ticket_id, assignee_id)
        except Exception as _:
            # Never block page render on seen-mark failure
            pass
        
        if not ticket:
            return render_template('error.html', error="Ticket not found"), 404
        
        # Get all replies for this ticket
        replies = db.get_replies_by_ticket(ticket_id)
        
        # Get all members for assignment dropdown
        members = db.get_all_members()
        
        # Get all technicians for technician assignment dropdown
        technicians = db.get_all_technicians()
        app.logger.info(f"ðŸ”§ Retrieved {len(technicians)} technicians for ticket {ticket_id}")
        for tech in technicians:
            app.logger.info(f"  - Technician: {tech.get('name')} (ID: {tech.get('_id')}, Role: {tech.get('role')})")
        
        # Debug: Check if technicians list is empty
        if not technicians:
            app.logger.warning(f" No technicians found for ticket {ticket_id} - this will cause dropdown to be empty!")
        else:
            app.logger.info(f" Successfully loaded {len(technicians)} technicians for dropdown")
        
        # Convert ObjectIds to strings for template and ensure consistency
        for member in members:
            member['_id'] = str(member['_id'])
            member['id'] = member['_id']  # Add 'id' field for admin.html compatibility
        
        # Convert technicians ObjectIds to strings for template
        for technician in technicians:
            technician['_id'] = str(technician['_id'])
            technician['id'] = technician['_id']
        
        # Debug: Log technician data after conversion
        app.logger.info(f"ðŸ”§ After ObjectId conversion - {len(technicians)} technicians:")
        for tech in technicians:
            app.logger.info(f"  - Converted: {tech.get('name')} (ID: {tech.get('id')}, _id: {tech.get('_id')})")
        
        # Convert ticket to dict and clean all ObjectIds and undefined values
        ticket = dict(ticket)
        
        def clean_data_for_template(obj):
            """Recursively clean data to make it JSON serializable"""
            if isinstance(obj, dict):
                cleaned = {}
                for k, v in obj.items():
                    if v is None:
                        cleaned[k] = None
                    elif hasattr(v, '__class__') and v.__class__.__name__ == 'ObjectId':
                        cleaned[k] = str(v)
                    elif isinstance(v, (dict, list)):
                        cleaned[k] = clean_data_for_template(v)
                    elif hasattr(v, '__class__') and v.__class__.__name__ == 'Undefined':
                        cleaned[k] = None  # Convert Undefined to None
                    else:
                        cleaned[k] = v
                return cleaned
            elif isinstance(obj, list):
                return [clean_data_for_template(item) for item in obj]
            elif hasattr(obj, '__class__') and obj.__class__.__name__ == 'ObjectId':
                return str(obj)
            elif hasattr(obj, '__class__') and obj.__class__.__name__ == 'Undefined':
                return None
            else:
                return obj
        
        # Initialize variables first (will clean them later)
        

        
        # Handle both datetime objects (from MongoDB) and string dates
        if ticket.get('created_at') and isinstance(ticket['created_at'], datetime):
            formatted_date = ticket['created_at'].strftime("%b %d, %Y %I:%M %p")
        else:
            try:
                created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                formatted_date = created_at.strftime("%b %d, %Y %I:%M %p")
            except:
                formatted_date = str(ticket['created_at'])
        
        formatted_replies = []
        for reply in replies:
            reply_dict = dict(reply)
            # Handle both datetime objects (from MongoDB) and string dates
            if isinstance(reply_dict['created_at'], datetime):
                reply_dict['formatted_date'] = reply_dict['created_at'].strftime("%b %d, %I:%M %p")
            else:
                try:
                    created_at = datetime.strptime(str(reply_dict['created_at']), "%Y-%m-%d %H:%M:%S")
                    reply_dict['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                except:
                    reply_dict['formatted_date'] = str(reply_dict['created_at'])
            reply_dict['is_customer'] = reply_dict.get('sender', 'support') == 'customer'
            
            # Get any attachments for this reply (stored in the reply document itself)
            reply_dict['attachments'] = reply_dict.get('attachments', [])
            
            # Format attachments for template compatibility
            formatted_attachments = []
            for attachment in reply_dict['attachments']:
                attachment_type = attachment.get('type', 'file')  # Default to 'file' if type missing
                
                if attachment_type == 'file':
                    # Get file path and calculate file size if missing
                    file_path = attachment.get('path', '')
                    file_size = attachment.get('size', 0)
                    
                    # Try to get file size from disk if not in database
                    if file_size == 0 and file_path:
                        try:
                            if os.path.exists(file_path):
                                file_size = os.path.getsize(file_path)
                            else:
                                # Try in uploads directory
                                uploads_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path))
                                if os.path.exists(uploads_path):
                                    file_size = os.path.getsize(uploads_path)
                        except Exception:
                            file_size = 0
                    
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', attachment.get('path', ''))),
                        'type': 'file',
                        'path': file_path,
                        'filename': attachment.get('filename', attachment.get('name', os.path.basename(file_path) if file_path else 'Unknown')),
                        'name': attachment.get('filename', attachment.get('name', os.path.basename(file_path) if file_path else 'Unknown')),
                        'url': attachment.get('url', f"/uploads/{os.path.basename(file_path)}" if file_path else ''),
                        'size': file_size,
                        'is_warranty': attachment.get('is_warranty', False)
                    })
                elif attachment_type == 'common-document':
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', attachment.get('ref', ''))),
                        'type': 'common-document',
                        'ref': attachment.get('ref', ''),
                        'name': attachment.get('name', 'Common Document')
                    })
                elif attachment_type == 'text_reference':
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', str(attachment))),
                        'type': 'text_reference',
                        'name': attachment.get('name', 'Document Reference'),
                        'description': attachment.get('description', '')
                    })
                else:
                    # Handle unknown attachment types gracefully
                    formatted_attachments.append({
                        'id': str(attachment.get('_id', str(attachment))),
                        'type': attachment_type,
                        'name': attachment.get('name', 'Unknown attachment'),
                        'path': attachment.get('path', ''),
                        'ref': attachment.get('ref', ''),
                        'size': attachment.get('size', 0)
                    })
            reply_dict['attachments'] = formatted_attachments
            
            formatted_replies.append(reply_dict)
        
        # Get ticket metadata with new fields
        vehicle_registration = None
        service_date = None
        claim_date = None
        engineer_id = None
        engineer_name = None
        attachments = []
        
        # New customer name fields
        customer_title = None
        customer_first_name = None
        customer_surname = None
        type_of_claim = None
        
        # New fields
        technician = None
        technician_id = None
        technician_info = None
        vhc_link = None
        days_between_service_claim = None
        
        # Checklist metadata fields
        advisories_followed = None
        within_warranty = None
        new_fault_codes = None
        dpf_light_on = None
        eml_light_on = None
        
        # Outcome fields
        outcome_category = None
        revisit_carried_out = None
        clean_under_warranty = None
        outcome_notes = None
        
        # Get metadata for this ticket
        metadata = db.get_ticket_metadata(ticket_id)
        
        # Process metadata attachments for manually created tickets
        metadata_attachments = []
        app.logger.info(f"DEBUG: Processing metadata for ticket {ticket_id} - Found {len(metadata)} metadata entries")
        
        for meta in metadata:
            app.logger.info(f"DEBUG: Processing metadata key: {meta.get('key')}")
            if meta.get('key', '').startswith('attachment_'):
                app.logger.info(f"DEBUG: Found attachment metadata: {meta.get('key')} = {meta.get('value')}")
                try:
                    attachment_data = json.loads(meta.get('value', '{}'))
                    app.logger.info(f"DEBUG: Parsed attachment data: {attachment_data}")
                    if attachment_data and isinstance(attachment_data, dict):
                        # FIXED: Convert metadata attachment to standard attachment format with base64 data
                        metadata_attachments.append({
                            'filename': attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File')),
                            'name': attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File')),
                            'size': attachment_data.get('size', 0),
                            'path': attachment_data.get('path', ''),
                            'data': attachment_data.get('data', ''),  # FIXED: Include base64 data
                            'is_warranty': attachment_data.get('is_warranty', False),
                            'source': 'metadata',
                            'type': 'file'
                        })
                        app.logger.info(f"SUCCESS: Added metadata attachment: {attachment_data.get('original_name', 'Unknown')} (base64: {len(attachment_data.get('data', ''))} chars)")
                    else:
                        app.logger.warning(f"WARNING: Attachment data is empty or not a dict: {attachment_data}")
                except (json.JSONDecodeError, TypeError) as e:
                    app.logger.warning(f"ERROR: Failed to parse attachment metadata for {meta.get('key')}: {e}")
                    continue
            else:
                app.logger.info(f"DEBUG: Non-attachment metadata: {meta.get('key')} = {meta.get('value')}")
        
        # Process main ticket document attachments (for manual tickets)
        ticket_attachments = []
        app.logger.info(f"DEBUG: Ticket {ticket_id} - has_attachments: {ticket.get('has_attachments', False)}")
        app.logger.info(f"DEBUG: Ticket {ticket_id} - attachments field: {ticket.get('attachments', 'NOT_FOUND')}")
        
        if ticket.get('has_attachments', False) and ticket.get('attachments'):
            app.logger.info(f"DEBUG: Processing {len(ticket['attachments'])} ticket document attachments")
            for i, att in enumerate(ticket['attachments']):
                app.logger.info(f"DEBUG: Processing attachment {i}: {att}")
                if isinstance(att, dict):
                    # FIXED: Include base64 data from ticket document attachments
                    ticket_attachments.append({
                        'filename': att.get('filename', att.get('original_name', 'Unknown File')),
                        'name': att.get('original_name', att.get('filename', 'Unknown File')),
                        'size': att.get('size', 0),
                        'path': att.get('path', ''),
                        'data': att.get('data', ''),  # FIXED: Include base64 data
                        'is_warranty': att.get('is_warranty', False),
                        'source': 'ticket_document',
                        'type': 'file',
                        'index': i  # For download URLs
                    })
                    app.logger.info(f"SUCCESS: Added ticket document attachment {i+1}: {att.get('filename', 'Unknown')} (base64: {len(att.get('data', ''))} chars)")
                else:
                    app.logger.warning(f"WARNING: Attachment {i} is not a dict: {type(att)} - {att}")
        else:
            app.logger.warning(f"WARNING: Ticket {ticket_id} has no attachments or has_attachments is False")
        
        # Combine all attachment sources - PRIORITIZE metadata attachments (manual tickets)
        app.logger.info(f"DEBUG: Before combining - metadata_attachments: {len(metadata_attachments)}, ticket_attachments: {len(ticket_attachments)}")
        
        # PRIORITY: Use metadata attachments for manually created tickets (source: 'metadata')
        if metadata_attachments:
            attachments.extend(metadata_attachments)
            app.logger.info(f"SUCCESS: Added {len(metadata_attachments)} metadata attachments to ticket {ticket_id}")
            # Skip ticket document attachments if we have metadata attachments (prevents duplicates)
            app.logger.info(f"INFO: Skipping ticket document attachments to prevent duplicates")
        elif ticket_attachments:
            # Only use ticket document attachments if no metadata attachments exist
            attachments.extend(ticket_attachments)
            app.logger.info(f"SUCCESS: Added {len(ticket_attachments)} ticket document attachments to ticket {ticket_id}")
        else:
            app.logger.info(f"INFO: No attachments found for ticket {ticket_id}")
        
        app.logger.info(f"FINAL RESULT: Total attachments for ticket {ticket_id}: {len(attachments)}")
        app.logger.info(f"DEBUG: Final attachments array: {attachments}")
        
        # ENHANCED DEBUGGING: Check what's in the ticket object itself
        app.logger.info(f"DEBUG: Ticket {ticket_id} has_attachments field: {ticket.get('has_attachments', 'NOT_FOUND')}")
        app.logger.info(f"DEBUG: Ticket {ticket_id} attachments field: {ticket.get('attachments', 'NOT_FOUND')}")
        if ticket.get('attachments'):
            app.logger.info(f"DEBUG: Ticket {ticket_id} attachments count: {len(ticket['attachments'])}")
            for i, att in enumerate(ticket['attachments']):
                app.logger.info(f"DEBUG: Ticket attachment {i}: {att}")
        
        # ENHANCED DEBUGGING: Check metadata attachments
        app.logger.info(f"DEBUG: Metadata attachments count: {len(metadata_attachments)}")
        for i, att in enumerate(metadata_attachments):
            app.logger.info(f"DEBUG: Metadata attachment {i}: {att}")
        
        # ENHANCED DEBUGGING: Check ticket document attachments
        app.logger.info(f"DEBUG: Ticket document attachments count: {len(ticket_attachments)}")
        for i, att in enumerate(ticket_attachments):
            app.logger.info(f"DEBUG: Ticket document attachment {i}: {att}")
            
        metadata_dict = {}
        for item in metadata:
            key = item['key']
            value = item['value']
            
            if key == 'vehicle_registration':
                vehicle_registration = value
            elif key == 'service_date':
                service_date = value
            elif key == 'claim_date':
                claim_date = value
            elif key == 'engineer':
                engineer_id = value
            elif key == 'customer_title':
                customer_title = value
            elif key == 'customer_first_name':
                customer_first_name = value
            elif key == 'customer_surname':
                customer_surname = value
            elif key == 'type_of_claim':
                type_of_claim = value
            elif key == 'technician_name':
                technician = value
            elif key == 'technician_id':
                technician_id = value
            elif key == 'vhc_link':
                vhc_link = value
            elif key == 'days_between_service_claim':
                days_between_service_claim = value
            elif key == 'advisories_followed':
                advisories_followed = value
            elif key == 'within_warranty':
                within_warranty = value
            elif key == 'new_fault_codes':
                new_fault_codes = value
            elif key == 'dpf_light_on':
                dpf_light_on = value
            elif key == 'eml_light_on':
                eml_light_on = value
            elif key == 'outcome_category':
                outcome_category = value
            elif key == 'revisit_carried_out':
                revisit_carried_out = value
            elif key == 'clean_under_warranty':
                clean_under_warranty = value
            elif key == 'outcome_notes':
                outcome_notes = value
            # ============================================================================
            # COMPLETELY REMOVED: Old metadata attachment processing
            # NO MORE warranty_form, dpf_report, or other_file_ metadata processing
            # All attachments must be real files in ticket.attachments or structured metadata
            # ============================================================================
            elif key in ['dpf_report', 'warranty_form'] or key.startswith('other_file_'):
                app.logger.info(f"ðŸš« IGNORED LEGACY METADATA: {key} = '{value}' (no longer processed for attachments)")
            else:
                metadata_dict[key] = value
        
        # If engineer ID is set, get engineer name (legacy support)
        if engineer_id:
            engineer = db.get_member_by_id(engineer_id)
            if engineer:
                engineer_name = engineer['name']
        
        # Get technician information if technician_id is set
        if technician_id and ObjectId.is_valid(technician_id):
            # Look in technicians collection first, then fallback to members collection
            technician_data = db.get_technician_by_id(technician_id)
            if technician_data:
                technician_info = {
                    'id': str(technician_data['_id']),
                    'name': technician_data['name'],
                    'user_id': technician_data.get('user_id', ''),
                    'gender': technician_data.get('gender', ''),
                    'role': technician_data.get('role', 'Technician')  # Default to 'Technician' if no role
                }
                # Set technician name for display (overrides legacy name if both exist)
                technician = technician_data['name']
                app.logger.info(f" Found technician in technicians collection: {technician} (ID: {technician_id})")
            else:
                # Fallback to members collection for backward compatibility
                technician_member = db.get_member_by_id(technician_id)
                if technician_member:
                    technician_info = {
                        'id': str(technician_member['_id']),
                        'name': technician_member['name'],
                        'user_id': technician_member.get('user_id', ''),
                        'gender': technician_member.get('gender', ''),
                        'role': technician_member.get('role', 'Technician')
                    }
                    technician = technician_member['name']
                    app.logger.info(f" Found technician in members collection (fallback): {technician} (ID: {technician_id})")
                else:
                    app.logger.warning(f" Technician with ID {technician_id} not found in either technicians or members collection")
        elif technician_id:
            app.logger.warning(f" Invalid technician_id format: {technician_id}")
        
        # Debug logging for technician data
        app.logger.info(f"Ticket {ticket_id} - Technician: {technician}, Technician ID: {technician_id}, Technician Info: {technician_info is not None}")
        
        # Handle assignment info for forwarded tickets
        if ticket.get('assignment') and len(ticket['assignment']) > 0:
            assignment = ticket['assignment'][0]
            ticket['is_forwarded'] = assignment.get('is_forwarded', False)
            
            # Handle forwarded from member info
            if ticket['is_forwarded'] and ticket.get('forwarded_from_member') and len(ticket['forwarded_from_member']) > 0:
                forwarded_member = ticket['forwarded_from_member'][0]
                ticket['forwarded_from_name'] = forwarded_member.get('name')
        
        # [FIX] NEW: Format attachments exactly like simple app with JSON cleaning
        simple_app_attachments = []
        
        # Process both ticket document attachments and metadata attachments (email attachments)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            for i, att in enumerate(ticket['attachments']):
                try:
                    # Clean any potential malformed JSON in attachment data
                    cleaned_att = {}
                    for k, v in att.items():
                        if isinstance(v, str):
                            # Clean potential JSON strings
                            try:
                                if v.strip() and v.strip() not in ['{}', '[]', 'null', 'undefined']:
                                    # Try to parse and re-serialize to ensure valid JSON
                                    if v.strip().startswith('{') or v.strip().startswith('['):
                                        clean_json = v.strip()
                                        if clean_json.endswith(',}'):
                                            clean_json = clean_json[:-2] + '}'
                                        elif clean_json.endswith(',]'):
                                            clean_json = clean_json[:-2] + ']'
                                        # Test parse to validate
                                        json.loads(clean_json)
                                        cleaned_att[k] = clean_json
                                    else:
                                        cleaned_att[k] = v
                                else:
                                    cleaned_att[k] = v
                            except (json.JSONDecodeError, TypeError):
                                # If JSON parsing fails, just use the string as-is
                                cleaned_att[k] = str(v) if v is not None else ''
                        else:
                            cleaned_att[k] = v
                    
                    simple_attachment = {
                        'id': f"{ticket_id}_{i}",  # Create unique ID for download URL
                        'fileName': cleaned_att.get('filename', 'unknown_file'),
                        'fileData': cleaned_att.get('data', ''),  # Keep for download
                        'size': cleaned_att.get('size', 0),
                        'is_warranty': cleaned_att.get('is_warranty', False)
                    }
                    simple_app_attachments.append(simple_attachment)
                except Exception as att_error:
                    app.logger.warning(f"Skipping malformed attachment {i} in ticket {ticket_id}: {att_error}")
                    continue
        
        # [FIX] NEW: Also process email attachments stored in metadata
        if metadata_attachments:
            for i, att in enumerate(metadata_attachments):
                try:
                    simple_attachment = {
                        'id': f"{ticket_id}_metadata_{i}",  # Create unique ID for download URL
                        'fileName': att.get('filename', 'unknown_file'),
                        'fileData': att.get('data', ''),  # Keep for download
                        'size': att.get('size', 0),
                        'is_warranty': att.get('is_warranty', False)
                    }
                    simple_app_attachments.append(simple_attachment)
                    app.logger.info(f"Added metadata attachment to simple_app_attachments: {att.get('filename', 'Unknown')}")
                except Exception as att_error:
                    app.logger.warning(f"Skipping malformed metadata attachment {i} in ticket {ticket_id}: {att_error}")
                    continue
        
        # Add simple app attachments to ticket for template (after cleaning)
        ticket['simple_attachments'] = simple_app_attachments
        ticket['attachments_count'] = len(simple_app_attachments)
        
        # DEBUGGING: Log attachments before template rendering
        app.logger.info(f" FINAL ATTACHMENTS FOR TEMPLATE: {len(attachments)} attachments")
        for i, att in enumerate(attachments):
            app.logger.info(f"  {i+1}. name: '{att.get('name', 'NO_NAME')}', file_path: '{att.get('file_path', 'NO_PATH')}', key: '{att.get('key', 'NO_KEY')}'")
        
        # Clean ALL data before template rendering (after all variables are initialized)
        try:
            app.logger.info(f"ðŸ§¹ Starting data cleaning for ticket {ticket_id}")
            
            # Special cleaning for attachments that might contain malformed JSON
            def clean_attachments_data(attachments_list):
                cleaned_list = []
                for item in attachments_list:
                    if isinstance(item, dict):
                        cleaned_item = {}
                        for k, v in item.items():
                            if isinstance(v, str):
                                # Clean any JSON strings that might be malformed
                                try:
                                    if v.strip() and v.strip() not in ['{}', '[]', 'null', 'undefined']:
                                        if v.strip().startswith('{') or v.strip().startswith('['):
                                            clean_json = v.strip()
                                            if clean_json.endswith(',}'):
                                                clean_json = clean_json[:-2] + '}'
                                            elif clean_json.endswith(',]'):
                                                clean_json = clean_json[:-2] + ']'
                                            # Test parse to validate
                                            json.loads(clean_json)
                                            cleaned_item[k] = clean_json
                                        else:
                                            cleaned_item[k] = v
                                    else:
                                        cleaned_item[k] = v
                                except (json.JSONDecodeError, TypeError):
                                    cleaned_item[k] = str(v) if v is not None else ''
                            else:
                                cleaned_item[k] = v
                        cleaned_list.append(cleaned_item)
                    else:
                        cleaned_list.append(item)
                return cleaned_list
            
            # Clean all variables
            ticket = clean_data_for_template(ticket)
            formatted_replies = clean_data_for_template(formatted_replies)
            attachments = clean_attachments_data(attachments)
            simple_app_attachments = clean_attachments_data(simple_app_attachments)
            members = clean_data_for_template(members)
            app.logger.info(f" Data cleaning completed for ticket {ticket_id}")
        except Exception as clean_error:
            app.logger.error(f" Error during data cleaning for ticket {ticket_id}: {clean_error}")
            # Ensure attachments is at least an empty list to prevent template errors
            attachments = []
            simple_app_attachments = []
            app.logger.info(f"ðŸ”„ Using empty attachments as fallback for ticket {ticket_id}")
        
        try:
            app.logger.info(f"ðŸŽ¨ Starting template render for ticket {ticket_id}")
            
            # Final safety check - test JSON serialization of attachments before template rendering
            try:
                json.dumps(attachments)
                app.logger.info(f" Attachments JSON serialization test passed for ticket {ticket_id}")
            except (TypeError, ValueError) as json_error:
                app.logger.warning(f" Attachments failed JSON serialization test: {json_error}, using empty list")
                attachments = []
            
            return render_template('ticket_detail.html', 
                                ticket=ticket,
                                formatted_date=formatted_date,
                                replies=formatted_replies,
                                members=members,
                                technicians=technicians,
                                vehicle_registration=vehicle_registration,
                                service_date=service_date,
                                claim_date=claim_date,
                                engineer_name=engineer_name,
                                customer_title=customer_title,
                                customer_first_name=customer_first_name,
                                customer_surname=customer_surname,
                                type_of_claim=type_of_claim,
                                technician=technician,
                                technician_name=technician,
                                technician_id=technician_id,
                                technician_info=technician_info,
                                vhc_link=vhc_link,
                                days_between_service_claim=days_between_service_claim,
                                advisories_followed=advisories_followed,
                                within_warranty=within_warranty,
                                new_fault_codes=new_fault_codes,
                                dpf_light_on=dpf_light_on,
                                eml_light_on=eml_light_on,
                                outcome_category=outcome_category,
                                revisit_carried_out=revisit_carried_out,
                                clean_under_warranty=clean_under_warranty,
                                outcome_notes=outcome_notes,
                                attachments=attachments,
                                current_user_id=session.get('member_id'),
                                current_user=session.get('member_name'),
                                current_user_role=current_member['role'] if current_member else 'Unknown',
                                is_tech_director=is_tech_director)
        except Exception as render_error:
            app.logger.error(f" Template render error for ticket {ticket_id}: {render_error}")
            return render_template('error.html', error=f"Error loading ticket details: {render_error}"), 500
    except Exception as e:
        app.logger.error(f" Error in ticket_detail for {ticket_id}: {e}")
        import traceback
        app.logger.error(f" Traceback: {traceback.format_exc()}")
        return render_template('error.html', error=f"Database error: {e}"), 500

# OLD ENDPOINT DISABLED - Using unified endpoint below
# @app.route('/api/tickets', methods=['POST'])
def create_ticket_api_DISABLED():
    """Create new ticket via API - Technical Director BLOCKED"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Block Technical Director from this route
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if current_member and current_member['role'] == 'Technical Director':
        return jsonify({'status': 'error', 'message': 'Access denied. Use Technical Director dashboard.'}), 403
    
    db = None
    try:
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'No data provided'}), 400

        thread_id = data.get('threadId')
        if not thread_id:
            return jsonify({'status': 'error', 'message': 'threadId is required'}), 400

        email = extract_email(data.get('form', ''))
        ticket_id = data.get('ticketId')
        
        db = get_db()
        
        # Check if ticket with this thread_id already exists
        existing_ticket = db.tickets.find_one({'thread_id': thread_id})

        if existing_ticket:
            # Update existing ticket - reopen if customer replied
            is_customer_reply = data.get('body') and data.get('body') != data.get('draft', '')
            
            update_data = {
                'draft_body': data.get('draft', ''),
                'classification': data.get('classification'),
                'priority': data.get('priority'),
                'updated_at': datetime.now()
            }
            
            if is_customer_reply:
                update_data['status'] = 'Open'
                update_data['has_unread_reply'] = True
            
            db.update_ticket(existing_ticket['ticket_id'], update_data)
            
            # Add reply if this is a response from customer
            if is_customer_reply:
                reply_data = {
                    'ticket_id': existing_ticket['ticket_id'],
                    'thread_id': thread_id,
                    'message': data.get('body'),
                    'sender': 'customer'
                }
                db.create_reply(reply_data)
            
            ticket_id = existing_ticket['ticket_id']
            action = 'updated'
        else:
            # Create new ticket with race condition protection
            if not ticket_id:
                # Use proper classification and priority codes to avoid conflicts
                class_code = get_classification_code(data.get('classification', 'General'))
                priority_code = get_priority_code(data.get('priority', 'Medium'))
                
                # Generate unique email ticket ID with race condition protection (same logic as n8n email system)
                max_attempts = 50
                for attempt in range(max_attempts):
                    # Use thread_id + email to generate 4-digit code (same as n8n email system)
                    thread_seed = str(thread_id) if thread_id else email
                    seed_string = f"{thread_seed}{email}{datetime.now().isoformat()}"
                    
                    # Calculate sum of character codes (matching n8n email system)
                    sum_chars = 0
                    for char in seed_string:
                        sum_chars += ord(char)
                    
                    # Generate 4-digit number (same as n8n: sum % 10000)
                    four_digit_code = sum_chars % 10000
                    four_digit_str = f"{four_digit_code:04d}"  # Ensure 4 digits with leading zeros
                    
                    potential_id = f"{class_code}{priority_code}{four_digit_str}"
                    app.logger.debug(f"? Email ticket calculation: thread_seed={thread_seed}, sum_chars={sum_chars}, 4-digit={four_digit_code}")
                    
                    try:
                        # Try to create ticket with this ID - will fail if duplicate
                        ticket_data = {
                            'ticket_id': potential_id,
                            'email': email,
                            'name': data.get('name'),
                            'phone': data.get('phone', ''),
                            'subject': data.get('subject'),
                            'body': data.get('body'),
                            'draft_body': data.get('draft', ''),
                            'classification': data.get('classification'),
                            'priority': data.get('priority'),
                            'status': 'Open',
                            'thread_id': thread_id,
                            'message_id': data.get('messageid'),
                            'creation_method': 'email'
                        }
                        
                        # ðŸš€ GENERATE DRAFT RESPONSE if none provided or empty
                        existing_draft = ticket_data.get('draft_body', '').strip()
                        if not existing_draft:
                            app.logger.info(f"ðŸ¤– GENERATING SMART DRAFT for email ticket {potential_id} (no existing draft)")
                            draft_response = generate_email_draft_response(ticket_data)
                            ticket_data['draft_body'] = draft_response
                            app.logger.info(f" SMART DRAFT GENERATED for ticket {potential_id} - Length: {len(draft_response)} chars")
                        else:
                            app.logger.info(f"ðŸ“ USING EXISTING DRAFT for ticket {potential_id} - Length: {len(existing_draft)} chars")
                        
                        # This will throw ValueError if ticket ID already exists (race condition safe)
                        db.create_ticket(ticket_data)
                        ticket_id = potential_id
                        app.logger.info(f"Successfully created email ticket with ID: {ticket_id} on attempt {attempt + 1}")
                        break
                        
                    except ValueError as e:
                        if "Ticket ID already exists" in str(e):
                            app.logger.debug(f"Email ticket ID {potential_id} collision detected, retrying (attempt {attempt + 1})")
                            continue  # Try next ID
                        else:
                            # Different error, re-raise
                            raise e
                
                if not ticket_id:
                    return jsonify({'status': 'error', 'message': 'Failed to generate unique ticket ID. Please try again.'}), 500
            action = 'created'
        return jsonify({
            'status': 'success', 
            'ticket_id': ticket_id,
            'customer_number': ticket_id,
            'action': action,
            'message': f'Ticket {action} successfully! Customer Number: {ticket_id}',
            'reference_message': f'Your Customer Number is {ticket_id}. Please reference this number for all inquiries.'
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

# [Rest of the code remains exactly the same until the send_reply function]

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.route('/api/tickets/<ticket_id>/reply', methods=['POST'])
def send_reply(ticket_id):
    """Send a reply to a ticket - All team members can participate in conversations"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # All team members (including Technical Director) can reply to tickets
    
    try:
        # Input validation
        if not ticket_id or len(ticket_id) > 20:
            return jsonify({'status': 'error', 'message': 'Invalid ticket ID'}), 400
            
        # Get the response text from form data
        response_text = request.form.get('response', '').strip()
        if not response_text:
            return jsonify({'status': 'error', 'message': 'Response text is required'}), 400
        
        if len(response_text) > 10000:  # Reasonable limit
            return jsonify({'status': 'error', 'message': 'Response text too long'}), 400

        # ANTI-SPAM: Check for duplicate submissions within last 5 seconds
        member_id = session['member_id']
        current_time = datetime.now()
        cache_key = f"reply_spam_{ticket_id}_{member_id}_{response_text[:50]}"
        
        # Simple in-memory cache for spam prevention
        if not hasattr(app, '_reply_cache'):
            app._reply_cache = {}
        
        # Clean old entries (older than 5 seconds)
        app._reply_cache = {k: v for k, v in app._reply_cache.items() 
                           if (current_time - v).total_seconds() < 5}
        
        if cache_key in app._reply_cache:
            app.logger.warning(f"ðŸš« SPAM BLOCKED - Duplicate reply attempt for ticket {ticket_id} by member {member_id}")
            return jsonify({'status': 'error', 'message': 'Duplicate submission detected. Please wait before sending again.'}), 429
        
        # Record this submission to prevent duplicates
        app._reply_cache[cache_key] = current_time
        
        app.logger.info(f" PROCESSING REPLY - Ticket: {ticket_id}, Member: {member_id}, Text: {response_text[:30]}...")

        db = get_db()
        
        # Get ticket details
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        
        if not ticket:
            app.logger.warning(f"Reply attempt for non-existent ticket: {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404

        # Save reply to database
        reply_data = {
            'ticket_id': ticket_id,
            'thread_id': ticket['thread_id'],
            'message': response_text,
            'sender': 'support'
        }
        
        reply_id = db.create_reply(reply_data)
        
        # Process file attachments - handle both attachment_ and response_attachments
        attachment_files = []
        
        # Handle multiple files from response_attachments field (from ticket detail page)
        app.logger.info(f"ðŸ“Ž PROCESSING REPLY ATTACHMENTS for ticket {ticket_id}")
        app.logger.info(f"ðŸ“Ž Files in request: {list(request.files.keys())}")
        
        if 'response_attachments' in request.files:
            files = request.files.getlist('response_attachments')
            app.logger.info(f"ðŸ“Ž Found {len(files)} files in response_attachments")
            
            for i, file in enumerate(files):
                app.logger.info(f"ðŸ“Ž Processing file {i+1}: {file.filename if file else 'No file'}")
                
                if file and file.filename and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_uuid = str(uuid.uuid4())
                    safe_filename = f"{file_uuid}_{filename}"
                    file_path = os.path.join(UPLOAD_FOLDER, safe_filename)
                    
                    try:
                        file.save(file_path)
                        file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                        
                        attachment_files.append({
                            'path': file_path,
                            'original_name': filename,
                            'size': file_size
                        })
                        app.logger.info(f" SAVED ATTACHMENT: {filename} as {safe_filename} ({file_size} bytes)")
                    except Exception as e:
                        app.logger.error(f" ERROR saving attachment {filename}: {e}")
                else:
                    app.logger.warning(f" SKIPPED invalid file: {file.filename if file else 'None'}")
        else:
            app.logger.info("ðŸ“Ž No response_attachments field found in request")
        
        # Handle individual attachment_ fields (backward compatibility)
        for key in request.files:
            if key.startswith('attachment_'):
                file = request.files[key]
                if file and file.filename and allowed_file(file.filename):
                    filename = secure_filename(file.filename)
                    file_uuid = str(uuid.uuid4())
                    safe_filename = f"{file_uuid}_{filename}"
                    file_path = os.path.join(UPLOAD_FOLDER, safe_filename)
                    file.save(file_path)
                    attachment_files.append({
                        'path': file_path,
                        'original_name': filename,
                        'size': os.path.getsize(file_path) if os.path.exists(file_path) else 0
                    })
                    app.logger.info(f"Saved attachment: {filename} as {safe_filename}")
        
        # Process common document references
        common_document_refs = []
        common_document_names = []
        
        # Debug: Log all form fields to understand what's being sent
        app.logger.info(f"ðŸ” DEBUG: All form fields received: {list(request.form.keys())}")
        
        for key in request.form:
            # Only process fields that are exactly in the format common_document_<number> (the document ID fields)
            # This regex matches: common_document_0, common_document_1, common_document_2, etc.
            if re.match(r'^common_document_\d+$', key):
                doc_id = request.form[key]
                doc_name_key = f"{key}_name"
                doc_name = request.form.get(doc_name_key, 'Unknown Document')
                
                app.logger.info(f"ðŸ” DEBUG: Processing document field: {key} = {doc_id}, name_key = {doc_name_key}, name = {doc_name}")
                
                # Additional validation: ensure doc_id is not empty and looks like a valid ID
                if doc_id and doc_id.strip() and doc_id != 'undefined' and doc_id != 'null':
                    common_document_refs.append(doc_id)
                    common_document_names.append(doc_name)
                    app.logger.info(f"ðŸ“„ Found common document reference: {doc_name} (ID: {doc_id})")
                    
                    # Debug: Check if the name field actually exists and has a value
                    if doc_name_key in request.form:
                        app.logger.info(f"âœ… Name field {doc_name_key} exists with value: {request.form[doc_name_key]}")
                    else:
                        app.logger.warning(f"âš ï¸ Name field {doc_name_key} NOT FOUND in form data!")
                        app.logger.warning(f"âš ï¸ Available form fields: {[k for k in request.form.keys() if k.startswith('common_document_')]}")
                else:
                    app.logger.warning(f"âš ï¸ Skipping invalid document ID: {doc_id} for key: {key}")
            elif key.startswith('common_document_'):
                # Log metadata fields for debugging
                app.logger.info(f"ðŸ” DEBUG: Skipping metadata field: {key} = {request.form[key]}")
        
        app.logger.info(f"ðŸ“„ Total common documents processed: {len(common_document_refs)}")
        
        # Additional safety check: ensure we don't have duplicate document IDs
        unique_doc_refs = list(dict.fromkeys(common_document_refs))
        if len(unique_doc_refs) != len(common_document_refs):
            app.logger.warning(f"âš ï¸ Duplicate document IDs detected! Original: {len(common_document_refs)}, Unique: {len(unique_doc_refs)}")
            app.logger.warning(f"âš ï¸ Original IDs: {common_document_refs}")
            app.logger.warning(f"âš ï¸ Unique IDs: {unique_doc_refs}")
            app.logger.warning(f"âš ï¸ Original Names: {common_document_names}")
            # Use unique IDs to prevent duplicates
            common_document_refs = unique_doc_refs
            # Also deduplicate names to match
            common_document_names = [common_document_names[common_document_refs.index(doc_id)] for doc_id in unique_doc_refs]
            app.logger.info(f"ðŸ“„ After deduplication: {len(common_document_refs)} documents")
            app.logger.info(f"ðŸ“„ After deduplication names: {common_document_names}")
        else:
            app.logger.info(f"ðŸ“„ No duplicates found - keeping original names: {common_document_names}")
        
        # Save file attachments - handle both old and new attachment format
        attachments = []
        for attachment_info in attachment_files:
            if isinstance(attachment_info, dict):
                # New format with detailed info
                file_path = attachment_info['path']
                filename = attachment_info['original_name']
                file_size = attachment_info['size']
            else:
                # Old format (backward compatibility)
                file_path = attachment_info
            filename = os.path.basename(file_path)
            file_size = 0
            try:
                file_size = os.path.getsize(file_path)
            except OSError:
                file_size = 0
            
            # Create URL for n8n to download the file
            file_url = f"{request.host_url.rstrip('/')}/uploads/{os.path.basename(file_path)}"
            # Automatic warranty detection for reply attachments
            is_warranty = detect_warranty_form(filename)
            file_type_info = get_enhanced_file_type_info(filename, file_size)
            
            attachments.append({
                'type': 'file',
                'path': file_path,
                'filename': filename,
                'url': file_url,
                'size': file_size,
                'name': filename,  # Add name field for template compatibility
                'is_warranty': is_warranty,
                'file_type_info': file_type_info,
                'original_name': filename  # Ensure original filename is preserved
            })
        
        # Save common document references with detailed info
        for i, doc_ref in enumerate(common_document_refs):
            doc_name = common_document_names[i] if i < len(common_document_names) else 'Unknown Document'
            app.logger.info(f"ðŸ” DEBUG: Creating attachment {i+1}: ref={doc_ref}, name={doc_name}, available_names={common_document_names}")
            
            attachments.append({
                'type': 'common-document',
                'ref': doc_ref,
                'name': doc_name,
                'filename': doc_name,
                'original_name': doc_name,
                'is_warranty': False,  # Common documents are not warranty forms
                'file_type_info': {'type': 'common_document', 'icon': 'ðŸ“„'}
            })
            app.logger.info(f"ðŸ“„ Added common document attachment: {doc_name} (ID: {doc_ref})")
        
        # If there are attachments, update the reply with them
        if attachments:
            app.logger.info(f"ðŸ“Ž SAVING {len(attachments)} attachments to reply {reply_id}")
            for i, att in enumerate(attachments):
                app.logger.info(f"ðŸ“Ž Attachment {i+1}: {att.get('name', 'Unknown')} - Type: {att.get('type', 'file')}")
            
            result = db.replies.update_one(
                {'_id': reply_id},
                {'$set': {'attachments': attachments}}
            )
            app.logger.info(f"ðŸ“Ž Database update result: {result.modified_count} modified")
        else:
            app.logger.info("ðŸ“Ž No attachments to save to reply")
        
        # Update ticket status - preserve TD status when Tech Director replies
        current_member = db.get_member_by_id(session['member_id'])
        is_tech_director = current_member and current_member['role'] == 'Technical Director'
        
        # If Tech Director replies to a ticket referred to them, keep the status so it stays in their dashboard
        if is_tech_director and ticket.get('status') == 'Referred to Tech Director':
            # Keep the "Referred to Tech Director" status so TD can continue working on it
            new_status = 'Referred to Tech Director'
            app.logger.info(f"[TARGET] TD REPLY - Preserving 'Referred to Tech Director' status for ticket {ticket_id}")
        else:
            # Normal behavior for other users
            new_status = 'Waiting for Response'
        
        update_data = {
            'status': new_status,
            'draft_body': '',
            'updated_at': datetime.now(),
            'has_unread_reply': False
        }
        db.update_ticket(ticket_id, update_data)
        
        # Prepare webhook payload in the required format (as array with specific structure)
        current_timestamp = datetime.now().isoformat()
        
        # Format attachments to match required structure with proper base64 encoding
        formatted_attachments = []
        app.logger.info(f"ðŸ” Processing {len(attachments)} attachments for webhook payload")
        
        for i, attachment in enumerate(attachments):
            app.logger.info(f"ðŸ” Processing attachment {i}: type={attachment.get('type')}, name={attachment.get('filename', attachment.get('name', 'unknown'))}")
            
            if attachment.get('type') == 'file':
                # Read file data and convert to base64 if it's a file attachment
                try:
                    file_path = attachment.get('path', '')
                    filename = attachment.get('filename', attachment.get('name', 'unknown_file'))
                    
                    if file_path and os.path.exists(file_path):
                        with open(file_path, 'rb') as f:
                            file_data = base64.b64encode(f.read()).decode('utf-8')
                        app.logger.info(f"âœ… Successfully encoded file attachment {filename} ({len(file_data)} base64 chars)")
                    else:
                        file_data = ""
                        app.logger.warning(f"âš ï¸ Attachment file not found: {file_path}")
                    
                    formatted_attachments.append({
                        "fileName": filename,
                        "fileData": file_data,
                        "id": str(attachment.get('id', uuid.uuid4().hex[:8])),
                        "size": attachment.get('size', 0),
                        "isWarranty": attachment.get('is_warranty', False)
                    })
                except Exception as e:
                    app.logger.error(f"âŒ Could not process file attachment {filename}: {e}")
                    
            elif attachment.get('type') in ['common-document', 'common_document']:
                # ðŸš€ FIXED: Handle both hyphen and underscore versions
                app.logger.info(f"ðŸ“„ Processing common document attachment: {attachment.get('filename', attachment.get('name', 'unknown'))}")
                
                # Use helper function to ensure common documents include file data
                enhanced_attachment = ensure_common_document_file_data(attachment)
                formatted_attachments.append(enhanced_attachment)
                
                app.logger.info(f"âœ… Enhanced common document attachment: {enhanced_attachment.get('fileName')} (fileData length: {len(enhanced_attachment.get('fileData', ''))})")
                
            else:
                app.logger.warning(f"âš ï¸ Unknown attachment type: {attachment.get('type')} for {attachment.get('filename', attachment.get('name', 'unknown'))}")
                # Include as basic attachment
                formatted_attachments.append({
                    "fileName": attachment.get('filename', attachment.get('name', 'unknown_file')),
                    "fileData": "",
                    "id": str(attachment.get('id', uuid.uuid4().hex[:8])),
                    "size": attachment.get('size', 0),
                    "isWarranty": False
                })
                
        app.logger.info(f"ðŸ“Š Formatted {len(formatted_attachments)} attachments for webhook payload")
        
        # Use original email message ID if this ticket came from an email, otherwise generate a custom one
        original_message_id = ticket.get('message_id', '')
        is_email_originated = bool(original_message_id and original_message_id.strip() and not original_message_id.startswith('msg-'))
        
        if is_email_originated:
            # Use the original email's message ID for Microsoft Outlook to reply properly
            message_id = original_message_id.strip()
            app.logger.info(f"Using original email message ID for Outlook reply: {message_id[:50]}...")
        else:
            # Generate custom ID for manually created tickets
            message_id = f"msg-{ticket_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}-{uuid.uuid4().hex[:8]}"
            app.logger.info(f"Generated custom message ID for manual ticket: {message_id}")
            
        # Determine if this ticket supports reply operation
        can_reply_to_email = is_email_originated
        
        # ðŸš€ SINGLE WEBHOOK PAYLOAD: Create one unified payload for n8n compatibility
        webhook_payload = {
            'ticket_id': ticket_id,
            'response_text': response_text,
            'replyMessage': response_text,
            'timestamp': current_timestamp,
            'user_id': session.get('member_id', 'unknown'),
            'ticket_subject': ticket.get('subject', ''),
            'subject': ticket.get('subject', ''),
            'ticket_status': new_status,
            'customer_email': ticket.get('email', ''),
            'customer_name': ticket.get('name', ''),
            'priority': ticket.get('priority', 'Medium'),
            'has_attachments': len(formatted_attachments) > 0,
            'attachments': formatted_attachments,
            'attachment_count': len(formatted_attachments),
            'message_id': message_id,
            'is_email_ticket': is_email_originated,
            'ticketSource': 'email' if is_email_originated else 'manual',
            # Additional n8n compatibility fields
            'id': ticket_id,
            'threadId': ticket.get('thread_id', ''),
            'email': ticket.get('email', ''),
            'body': ticket.get('body', ''),
            'draft': response_text,
            'message': response_text,
            'content': response_text,
            'classification': ticket.get('classification', 'General'),
            'date': current_timestamp,
            'created_at': current_timestamp,
            'canReplyToEmail': can_reply_to_email,
            'isEmailOriginated': is_email_originated,
            'recommendedOperation': 'reply' if can_reply_to_email else 'send'
        }
            
                    # ðŸš€ RE-ENABLED: Send webhook request to n8n for conversation module
        # This ensures webhooks trigger for all ticket replies
        try:
            app.logger.info(f"ðŸš€ SENDING BACKEND WEBHOOK for ticket: {ticket_id}")
            
            # Send to n8n webhook
            webhook_url = os.environ.get('WEBHOOK_URL', 'https://ffxtrading.app.n8n.cloud/webhook/fb4af014-26e6-4477-821f-917fc9b3ee96')
            response = requests.post(webhook_url, json=webhook_payload, timeout=10)
            
            if response.ok:
                app.logger.info(f"âœ… BACKEND WEBHOOK SUCCESS: {response.status_code}")
            else:
                app.logger.warning(f"âš ï¸ BACKEND WEBHOOK WARNING: {response.status_code} - {response.text}")
                
        except Exception as webhook_error:
            app.logger.error(f"âŒ BACKEND WEBHOOK ERROR: {webhook_error}")
            # Don't fail the main process if webhook fails
        
        app.logger.info(f"ðŸ“ Reply saved to database, backend webhook sent")
        
        app.logger.info(f"ðŸŽ‰ REPLY COMPLETED - Ticket: {ticket_id}, Member: {member_id}")
        
        # Return JSON response that the frontend expects
        return jsonify({
            'status': 'success',
            'message': 'Reply sent successfully',
            'redirect': url_for('ticket_detail', ticket_id=ticket_id)
        })
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/important', methods=['POST'])
def mark_as_important(ticket_id):
    """Toggle important status for a ticket"""
    try:
        db = get_db()
        # Get current status
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        if ticket:
            new_status = not ticket.get('is_important', False)
            db.update_ticket(ticket_id, {
                'is_important': new_status,
                'updated_at': datetime.now()
            })
        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/priority', methods=['POST'])
def update_ticket_priority(ticket_id):
    """Update ticket priority"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        new_priority = data.get('priority')
        
        if not new_priority:
            return jsonify({'status': 'error', 'message': 'Priority is required'}), 400
        
        # Validate priority value
        valid_priorities = ['Urgent', 'High', 'Medium', 'Low']
        if new_priority not in valid_priorities:
            return jsonify({'status': 'error', 'message': 'Invalid priority value'}), 400
        
        db = get_db()
        
        # Update the ticket priority
        update_result = db.update_ticket(ticket_id, {
            'priority': new_priority,
            'updated_at': datetime.now()
        })
        
        # Log priority change
        app.logger.info(f"Ticket {ticket_id} priority updated to: {new_priority} by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket priority updated to: {new_priority}'
        })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket priority: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/technician', methods=['POST'])
def update_ticket_technician(ticket_id):
    """Update ticket technician assignment"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        technician_id = data.get('technician_id')
        
        try:
            db = get_db()
        except Exception as db_error:
            app.logger.error(f"Database connection failed: {db_error}")
            return jsonify({'status': 'error', 'message': 'Database connection failed. Please check your MongoDB configuration.'}), 500
        
        if technician_id:
            # Get technician details
            try:
                app.logger.info(f" Looking for technician with ID: {technician_id}")
                technician = db.get_technician_by_id(technician_id)
                app.logger.info(f" Retrieved technician: {technician}")
            except Exception as e:
                app.logger.error(f" Error getting technician by ID {technician_id}: {e}")
                return jsonify({'status': 'error', 'message': f'Error retrieving technician: {str(e)}'}), 500
                
            if not technician:
                app.logger.warning(f"Technician not found for ID: {technician_id}")
                return jsonify({'status': 'error', 'message': 'Technician not found'}), 404
            
            # Update ticket metadata with technician information
            try:
                app.logger.info(f"ðŸ’¾ Setting metadata for ticket {ticket_id}: technician_id={technician_id}, technician_name={technician['name']}")
                result1 = db.set_ticket_metadata(ticket_id, 'technician_id', technician_id)
                result2 = db.set_ticket_metadata(ticket_id, 'technician_name', technician['name'])
                app.logger.info(f" Metadata set results: technician_id={result1}, technician={result2}")
                
                # Verify the metadata was saved by retrieving it
                verification_metadata = db.get_ticket_metadata(ticket_id)
                app.logger.info(f" Verification: Retrieved metadata after save: {verification_metadata}")
                
                # Check if technician data is properly saved
                technician_saved = False
                for meta in verification_metadata:
                    if meta.get('key') == 'technician_name' and meta.get('value') == technician['name']:
                        technician_saved = True
                        break
                
                if not technician_saved:
                    app.logger.warning(f" Technician assignment may not have been saved properly for ticket {ticket_id}")
                    return jsonify({'status': 'error', 'message': 'Technician assignment was not saved properly. Please try again.'}), 500
                    
            except Exception as e:
                app.logger.error(f" Error setting metadata for ticket {ticket_id}: {e}")
                return jsonify({'status': 'error', 'message': f'Error saving technician assignment: {str(e)}'}), 500
            
            app.logger.info(f"Ticket {ticket_id} assigned to technician: {technician['name']} (ID: {technician_id}) by user {session.get('member_name')}")
            
            return jsonify({
                'status': 'success',
                'message': f'Ticket assigned to technician: {technician["name"]}',
                'technician_name': technician['name']
            })
        else:
            # Remove technician assignment
            try:
                app.logger.info(f"ðŸ—‘ Removing technician assignment for ticket {ticket_id}")
                result1 = db.delete_ticket_metadata(ticket_id, 'technician_id')
                result2 = db.delete_ticket_metadata(ticket_id, 'technician_name')
                app.logger.info(f" Metadata deletion results: technician_id={result1}, technician={result2}")
                
                # Verify deletion by checking metadata
                remaining_metadata = db.get_ticket_metadata(ticket_id)
                app.logger.info(f" Remaining metadata after deletion: {remaining_metadata}")
                
            except Exception as e:
                app.logger.error(f" Error removing technician assignment for ticket {ticket_id}: {e}")
                return jsonify({'status': 'error', 'message': f'Error removing technician assignment: {str(e)}'}), 500
            
            app.logger.info(f"Ticket {ticket_id} technician assignment removed by user {session.get('member_name')}")
            
            return jsonify({
                'status': 'success',
                'message': 'Technician assignment removed',
                'technician_name': None
            })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket technician assignment: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/technician-assignments', methods=['GET'])
def get_all_technician_assignments():
    """Get all technician assignments for debugging"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get all technician metadata from database
        all_metadata = list(db.ticket_metadata.find({"key": {"$in": ["technician_id", "technician_name"]}}))
        
        # Group by ticket_id
        assignments = {}
        for meta in all_metadata:
            ticket_id = meta.get('ticket_id')
            if ticket_id not in assignments:
                assignments[ticket_id] = {}
            assignments[ticket_id][meta.get('key')] = meta.get('value')
        
        # Get ticket details for each assignment
        result = []
        for ticket_id, tech_data in assignments.items():
            try:
                ticket = db.get_ticket(ticket_id)
                if ticket:
                    result.append({
                        'ticket_id': ticket_id,
                        'subject': ticket.get('subject', 'No Subject'),
                        'technician_id': tech_data.get('technician_id'),
                        'technician_name': tech_data.get('technician_name'),
                        'status': ticket.get('status', 'Unknown'),
                        'created_at': ticket.get('created_at')
                    })
            except Exception as e:
                app.logger.error(f"Error getting ticket {ticket_id}: {e}")
                result.append({
                    'ticket_id': ticket_id,
                    'subject': 'Error retrieving ticket',
                    'technician_id': tech_data.get('technician_id'),
                    'technician_name': tech_data.get('technician_name'),
                    'status': 'Error',
                    'created_at': None
                })
        
        return jsonify({
            'status': 'success',
            'assignments': result,
            'total_assignments': len(result)
        })
        
    except Exception as e:
        app.logger.error(f"Error getting technician assignments: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# ============ COMMON DOCUMENTS API ENDPOINTS ============

def ensure_common_document_file_data(attachment):
    """
    Helper function to ensure common document attachments include their actual file data
    This function can be used across all webhook payload constructions
    """
    # ðŸš€ FIXED: Handle both hyphen and underscore versions
    if attachment.get('type') in ['common-document', 'common_document']:
        try:
            doc_ref = attachment.get('ref', '')
            if doc_ref:
                # Fetch the actual document file content from database
                db = get_db()
                file_data = db.get_document_file_content(doc_ref)
                
                if file_data and file_data.get('content'):
                    # â­ file_data['content'] IS NOW ALREADY BASE64 STRING
                    file_content_base64 = file_data['content']  # No need to encode again
                    file_size = file_data.get('file_size', len(file_content_base64))
                    filename = file_data.get('file_name', f"common_doc_{doc_ref}")
                    
                    app.logger.info(f"Successfully retrieved common document {filename} ({len(file_content_base64)} base64 chars)")
                    
                    # Return enhanced attachment with file data
                    return {
                        "fileName": filename,
                        "fileData": file_content_base64,  # â­ BASE64 DATA READY TO USE
                        "id": str(doc_ref),
                        "size": file_size,
                        "isWarranty": False,
                        "type": "common_document",
                        "original_attachment": attachment
                    }
                else:
                    app.logger.warning(f"Common document {doc_ref} file content not found")
                    return {
                        "fileName": f"common_doc_{doc_ref}",
                        "fileData": "",  # Fallback to empty if no content
                        "id": str(doc_ref),
                        "size": 0,
                        "isWarranty": False,
                        "type": "common_document",
                        "original_attachment": attachment
                    }
            else:
                app.logger.warning(f"Common document attachment missing ref: {attachment}")
                return {
                    "fileName": "unknown_common_doc",
                    "fileData": "",
                    "id": str(uuid.uuid4().hex[:8]),
                    "size": 0,
                    "isWarranty": False,
                    "type": "common_document",
                    "original_attachment": attachment
                }
        except Exception as e:
            app.logger.error(f"Error processing common document attachment: {e}")
            # Fallback to basic structure if processing fails
            return {
                "fileName": f"common_doc_{attachment.get('ref', 'unknown')}",
                "fileData": "",
                "id": str(attachment.get('ref', uuid.uuid4().hex[:8])),
                "size": 0,
                "isWarranty": False,
                "type": "common_document",
                "original_attachment": attachment
            }
    
    # Return original attachment if not a common document
    return attachment

@app.route('/api/common-documents', methods=['GET'])
def get_common_documents():
    """Get all common documents"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common documents access without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        db = get_db()
        documents = db.get_all_common_documents()
        
        return jsonify({
            'status': 'success',
            'documents': documents,
            'total': len(documents)
        })
    except Exception as e:
        app.logger.error(f"Error getting common documents: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500
    
    try:
        db = get_db()
        documents = db.get_all_common_documents()
        
        return jsonify({
            'status': 'success',
            'documents': documents,
            'total': len(documents)
        })
    except Exception as e:
        app.logger.error(f"Error getting common documents: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents', methods=['POST'])
def create_common_document():
    """Create a new common document with file upload and webhook trigger"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document creation without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        # Check if this is a multipart form data request (file upload)
        if request.content_type and 'multipart/form-data' in request.content_type:
            # Handle file upload
            name = request.form.get('name', '').strip()
            doc_type = request.form.get('type', 'form')
            description = request.form.get('description', '').strip()
            
            if not name:
                return jsonify({'status': 'error', 'message': 'Document name is required'}), 400
            
            # Get the uploaded file
            if 'file' not in request.files:
                return jsonify({'status': 'error', 'message': 'No file uploaded'}), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({'status': 'error', 'message': 'No file selected'}), 400
            
            # ENHANCED: Process file upload with same logic as manual tickets
            app.logger.info(f"ðŸ“„ Processing common document upload: {file.filename}")
            
            # Generate safe filename and save to disk
            filename = secure_filename(file.filename)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            safe_filename = f"{timestamp}_{filename}"
            
            # Create uploads directory for common documents
            upload_dir = os.path.join(UPLOAD_FOLDER, 'common_documents')
            os.makedirs(upload_dir, exist_ok=True)
            
            file_path = os.path.join(upload_dir, safe_filename)
            
            # Save file to disk (for backup and compatibility)
            file.save(file_path)
            app.logger.info(f"ðŸ“„ File saved to disk: {file_path}")
            
            # Get file size
            file_size = os.path.getsize(file_path)
            
            # ðŸš€ ENHANCED: Read file content with comprehensive validation
            try:
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                    
                # ðŸš¨ CRITICAL VALIDATION: Ensure file content is not empty
                if not file_content:
                    raise ValueError(f"File {filename} is empty (0 bytes)")
                
                # ðŸš¨ CRITICAL VALIDATION: Check file size limits (100MB max)
                if len(file_content) > 100 * 1024 * 1024:
                    raise ValueError(f"File {filename} too large: {len(file_content)} bytes (max 100MB)")
                
                # ðŸš€ ENHANCED: Convert to base64 with validation
                file_data_base64 = base64.b64encode(file_content).decode('utf-8')
                
                # ðŸš¨ CRITICAL VALIDATION: Verify base64 conversion integrity
                if not file_data_base64:
                    raise ValueError(f"Base64 conversion failed for {filename}")
                
                # ðŸš€ ENHANCED: Test base64 decode to ensure integrity
                test_decode = base64.b64decode(file_data_base64)
                if test_decode != file_content:
                    raise ValueError(f"Base64 integrity check failed for {filename}")
                
                app.logger.info(f"ðŸ“„ SUCCESS: File validated and converted to base64: {filename} ({len(file_content)} bytes -> {len(file_data_base64)} chars)")
                
            except Exception as e:
                app.logger.error(f"ðŸ“„ CRITICAL ERROR: File processing failed for {filename}: {e}")
                # Clean up the corrupted file
                try:
                    os.remove(file_path)
                    app.logger.info(f"ðŸ“„ Cleaned up corrupted file: {file_path}")
                except:
                    pass
                return jsonify({'status': 'error', 'message': f'File processing failed: {str(e)}'}), 500
            
            # ðŸš€ ENHANCED: Determine file type with comprehensive validation
            import mimetypes
            file_type, encoding = mimetypes.guess_type(filename)
            
            # ðŸš¨ CRITICAL VALIDATION: Ensure proper MIME type detection
            if not file_type:
                # Fallback MIME type detection based on file extension
                file_extension = filename.lower().split('.')[-1] if '.' in filename else ''
                mime_type_map = {
                    'pdf': 'application/pdf',
                    'doc': 'application/msword',
                    'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    'xls': 'application/vnd.ms-excel',
                    'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    'txt': 'text/plain',
                    'jpg': 'image/jpeg',
                    'jpeg': 'image/jpeg',
                    'png': 'image/png',
                    'gif': 'image/gif',
                    'bmp': 'image/bmp',
                    'tiff': 'image/tiff',
                    'zip': 'application/zip',
                    'rar': 'application/x-rar-compressed',
                    '7z': 'application/x-7z-compressed'
                }
                file_type = mime_type_map.get(file_extension, 'application/octet-stream')
                app.logger.info(f"ðŸ“„ MIME type fallback for {filename}: {file_type}")
            
            # ðŸš¨ CRITICAL VALIDATION: Log file type for debugging
            app.logger.info(f"ðŸ“„ Final MIME type for {filename}: {file_type}")
            
            db = get_db()
            
            # ðŸš€ ENHANCED: Create document data using proven ticket attachment logic
            document_data = {
                'name': name,
                'type': doc_type,
                'description': description,
                'file_name': filename,
                'original_filename': file.filename,
                'safe_filename': safe_filename,
                'file_path': file_path,  # Full path for file operations (backup storage)
                'file_size': file_size,
                'file_type': file_type,
                'created_by': session.get('member_name', 'Unknown'),
                'upload_method': 'web_upload',
                
                # ðŸš€ CRITICAL: Dual storage system (like tickets)
                'has_file_data': True,
                'file_data': file_data_base64,      # Primary storage (base64)
                'file_content': file_data_base64,   # Legacy compatibility
                
                # ðŸš€ ENHANCED: Additional fields for consistency
                'source': 'common_document_upload',
                'is_common_document': True,
                'status': 'active',
                'uploaded_at': datetime.now().isoformat(),
                'file_extension': os.path.splitext(filename)[1] if '.' in filename else '',
                
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            }
            
            # Create common document in database
            document_id = db.create_common_document(document_data)
            app.logger.info(f"ðŸ“„ SUCCESS: Created enhanced common document with ID: {document_id}")
            
            # ðŸš€ ENHANCED: Store additional metadata (like ticket system)
            try:
                metadata_entries = [
                    {'document_id': document_id, 'key': 'upload_method', 'value': 'web_upload'},
                    {'document_id': document_id, 'key': 'file_category', 'value': 'common_document'},
                    {'document_id': document_id, 'key': 'access_count', 'value': '0'},
                    {'document_id': document_id, 'key': 'last_accessed', 'value': datetime.now().isoformat()},
                    {'document_id': document_id, 'key': 'file_extension', 'value': os.path.splitext(filename)[1] if '.' in filename else ''},
                    {'document_id': document_id, 'key': 'storage_type', 'value': 'dual_storage'},
                    {'document_id': document_id, 'key': 'base64_length', 'value': str(len(file_data_base64))},
                    {'document_id': document_id, 'key': 'disk_backup', 'value': 'true'},
                    {'document_id': document_id, 'key': 'mime_type', 'value': file_type}
                ]
                
                for metadata in metadata_entries:
                    db.add_common_document_metadata(document_id, metadata['key'], metadata['value'])
                
                app.logger.info(f"ðŸ“„ SUCCESS: Enhanced metadata stored for document: {document_id}")
            except Exception as metadata_error:
                app.logger.warning(f"ðŸ“„ WARNING: Metadata storage failed: {metadata_error}")
            
            # ðŸš€ FIXED: Removed webhook trigger for common documents
            # Common documents should NOT trigger the main ticket webhook
            # They are just document storage, not ticket-related actions
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: Common documents don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Enhanced common document uploaded successfully',
                'document_id': document_id,
                'filename': filename,
                'file_size': file_size,
                'storage_method': 'dual_storage',
                'base64_available': True,
                'disk_backup': True,
                'file_type': file_type
            })
            
        else:
            # Handle JSON request (for backward compatibility)
            data = request.json
            required_fields = ['name', 'type', 'description']
            
            for field in required_fields:
                if not data.get(field):
                    return jsonify({'status': 'error', 'message': f'Missing required field: {field}'}), 400
            
            db = get_db()
            
            document_data = {
                'name': data['name'],
                'type': data['type'],
                'description': data['description'],
                'file_name': data.get('file_name', ''),
                'created_by': session.get('member_name', 'Unknown'),
                'upload_method': 'json_api',
                'has_file_data': False,
                'created_at': datetime.now(),
                'updated_at': datetime.now()
            }
            
            document_id = db.create_common_document(document_data)
            
            # ðŸš€ FIXED: Removed webhook trigger for JSON common documents
            # Common documents should NOT trigger the main ticket webhook
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: JSON common documents don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Document created successfully',
                'document_id': document_id
            })
            
    except Exception as e:
        app.logger.error(f"ðŸ“„ ERROR: Error creating common document: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ Full traceback: {traceback.format_exc()}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>', methods=['PUT'])
def update_common_document(document_id):
    """Update a common document"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document update without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        data = request.json
        db = get_db()
        
        update_data = {}
        if 'name' in data:
            update_data['name'] = data['name']
        if 'type' in data:
            update_data['type'] = data['type']
        if 'description' in data:
            update_data['description'] = data['description']
        if 'file_name' in data:
            update_data['file_name'] = data['file_name']
        if 'file_url' in data:
            update_data['file_url'] = data['file_url']
        
        if not update_data:
            return jsonify({'status': 'error', 'message': 'No fields to update'}), 400
        
        success = db.update_common_document(document_id, update_data)
        
        if success:
            # ðŸš€ FIXED: Removed webhook trigger for common document updates
            # Common documents should NOT trigger the main ticket webhook
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: Common document updates don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Document updated successfully'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'Document not found or no changes made'
            }), 404
    except Exception as e:
        app.logger.error(f"Error updating common document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>', methods=['DELETE'])
def delete_common_document(document_id):
    """Delete a common document"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document deletion without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        db = get_db()
        success = db.delete_common_document(document_id)
        
        if success:
            # ðŸš€ FIXED: Removed webhook trigger for common document deletions
            # Common documents should NOT trigger the main ticket webhook
            app.logger.info(f"ðŸ“„ SKIPPING WEBHOOK: Common document deletions don't trigger ticket webhooks")
            
            return jsonify({
                'status': 'success',
                'message': 'Document deleted successfully'
            })
        else:
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
    except Exception as e:
        app.logger.error(f"Error deleting common document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/download', methods=['GET'])
def download_common_document(document_id):
    """Download a document file"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document download without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"Download request for document ID: {document_id}")
        db = get_db()
        
        # First, let's check if the document exists at all
        document_exists = db.get_common_document_by_id(document_id)
        if not document_exists:
            app.logger.error(f"Document {document_id} not found in database")
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
        
        app.logger.info(f"Document found: {document_exists.get('name', 'Unknown')}")
        
        # ðŸš€ ENHANCED: Get file content using priority-based retrieval (like tickets)
        file_data = db.get_document_file_content(document_id)
        
        if not file_data:
            app.logger.warning(f"âš ï¸ File content not found for document {document_id} - attempting enhanced retrieval...")
            
            # ðŸš€ ENHANCED: Try multiple retrieval methods (like ticket system)
            try:
                # METHOD 1: Try repair first
                repair_success, repair_message = db.repair_document_file_content(document_id)
                if repair_success:
                    app.logger.info(f"âœ… Document repaired successfully: {repair_message}")
                    file_data = db.get_document_file_content(document_id)
                    if file_data:
                        app.logger.info(f"âœ… File content retrieved after repair")
                    else:
                        app.logger.error(f"âŒ File content still not found after repair")
                
                # METHOD 2: If repair failed, try direct file access
                if not file_data:
                    app.logger.info(f"ðŸ”„ Attempting direct file access for document {document_id}")
                    document = db.get_common_document_by_id(document_id)
                    if document and document.get('file_path'):
                        file_path = document['file_path']
                        if os.path.exists(file_path):
                            app.logger.info(f"ðŸ”„ Found file on disk: {file_path}")
                            try:
                                with open(file_path, 'rb') as f:
                                    file_content = f.read()
                                    file_data_base64 = base64.b64encode(file_content).decode('utf-8')
                                
                                # Auto-repair: Update database with base64 data
                                db.update_common_document(document_id, {
                                    'file_data': file_data_base64,
                                    'file_content': file_data_base64,
                                    'has_file_data': True
                                })
                                
                                file_data = {'content': file_data_base64}
                                app.logger.info(f"âœ… Auto-repaired document with disk data: {len(file_content)} bytes")
                            except Exception as file_error:
                                app.logger.error(f"âŒ Error reading file from disk: {file_error}")
                
                # METHOD 3: Final check
                if not file_data:
                    app.logger.error(f"âŒ All retrieval methods failed for document {document_id}")
                    return jsonify({'status': 'error', 'message': 'File content not found and all recovery methods failed'}), 404
                    
            except Exception as retrieval_error:
                app.logger.error(f"âŒ Error during enhanced retrieval: {retrieval_error}")
                return jsonify({'status': 'error', 'message': f'File content not found. Retrieval error: {str(retrieval_error)}'}), 404
        
        app.logger.info(f"File data retrieved: {file_data.get('file_name', 'Unknown')} ({len(file_data.get('content', ''))} base64 chars)")
        
        # Increment download count
        db.increment_document_download_count(document_id)
        
        # Return the file as a download
        from flask import send_file
        import io
        import base64
        
        # ðŸš€ ENHANCED: CONVERT BASE64 BACK TO BINARY FOR DOWNLOAD WITH VALIDATION
        try:
            # ðŸš¨ CRITICAL VALIDATION: Ensure we have base64 content
            if not file_data.get('content'):
                raise ValueError("No file content found in database")
            
            # ðŸš€ ENHANCED: Decode base64 with comprehensive error handling
            try:
                file_binary = base64.b64decode(file_data['content'])
            except Exception as base64_error:
                app.logger.error(f"ðŸš¨ CRITICAL: Base64 decode failed for {file_data.get('file_name', 'Unknown')}: {base64_error}")
                raise ValueError(f"File content is corrupted or invalid base64 format")
            
            # ðŸš¨ CRITICAL VALIDATION: Verify decoded content integrity
            if not file_binary:
                raise ValueError("Decoded file content is empty")
            
            # ðŸš€ ENHANCED: Create file stream with proper positioning
            file_stream = io.BytesIO(file_binary)
            file_stream.seek(0)
            
            # ðŸš¨ CRITICAL VALIDATION: Verify file stream integrity
            if file_stream.getvalue() != file_binary:
                raise ValueError("File stream creation failed")
            
            # ðŸš€ ENHANCED: Get proper filename and MIME type
            download_filename = file_data.get('file_name', 'document')
            mime_type = file_data.get('file_type', 'application/octet-stream')
            
            # ðŸš¨ CRITICAL VALIDATION: Ensure MIME type is valid
            if not mime_type or mime_type == 'application/octet-stream':
                # Try to detect MIME type from filename
                import mimetypes
                detected_type, _ = mimetypes.guess_type(download_filename)
                if detected_type:
                    mime_type = detected_type
                    app.logger.info(f"ðŸ“„ MIME type corrected for {download_filename}: {mime_type}")
            
            app.logger.info(f"ðŸ“„ DOWNLOAD: Sending file {download_filename} ({len(file_binary)} bytes, MIME: {mime_type})")
            
            return send_file(
                file_stream,
                as_attachment=True,
                download_name=download_filename,
                mimetype=mime_type
            )
            
        except Exception as decode_error:
            app.logger.error(f"ðŸš¨ CRITICAL ERROR: File download failed for {file_data.get('file_name', 'Unknown')}: {decode_error}")
            return jsonify({'status': 'error', 'message': f'File download failed: {str(decode_error)}'}), 500
        
    except Exception as e:
        app.logger.error(f"Error downloading document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/increment-download', methods=['POST'])
def increment_document_download_count(document_id):
    """Increment download count for a document"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        success = db.increment_document_download_count(document_id)
        
        if success:
            return jsonify({
                'status': 'success',
                'message': 'Download count updated'
            })
        else:
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
    except Exception as e:
        app.logger.error(f"Error updating download count: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/validate', methods=['GET'])
def validate_common_document(document_id):
    """ðŸš€ ENHANCED: Validate common document integrity and fix issues if possible"""
    # Allow access if user has any valid session
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        app.logger.warning(f"Common document validation without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"ðŸ” Validating document integrity for ID: {document_id}")
        db = get_db()
        
        # Validate document integrity
        is_valid, message = db.validate_document_integrity(document_id)
        
        if is_valid:
            app.logger.info(f"âœ… Document {document_id} validation successful: {message}")
            return jsonify({
                'status': 'success',
                'message': 'Document integrity validated successfully',
                'details': message,
                'document_id': document_id
            })
        else:
            app.logger.warning(f"âš ï¸ Document {document_id} validation failed: {message}")
            return jsonify({
                'status': 'warning',
                'message': 'Document validation issues detected',
                'details': message,
                'document_id': document_id
            }), 200  # Return 200 with warning status
            
    except Exception as e:
        app.logger.error(f"âŒ Error validating document {document_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Validation error: {str(e)}'}), 500

@app.route('/api/common-documents/<document_id>/repair', methods=['POST'])
def repair_common_document(document_id):
    """ðŸš€ NEW: Repair common document file content by restoring from disk"""
    # Allow access if user has any valid session
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        app.logger.warning(f"Common document repair without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"ðŸ”§ Repairing document file content for ID: {document_id}")
        db = get_db()
        
        # Attempt to repair document
        repair_success, repair_message = db.repair_document_file_content(document_id)
        
        if repair_success:
            app.logger.info(f"âœ… Document {document_id} repair successful: {repair_message}")
            return jsonify({
                'status': 'success',
                'message': 'Document repaired successfully',
                'details': repair_message,
                'document_id': document_id
            })
        else:
            app.logger.error(f"âŒ Document {document_id} repair failed: {repair_message}")
            return jsonify({
                'status': 'error',
                'message': 'Document repair failed',
                'details': repair_message,
                'document_id': document_id
            }), 400
            
    except Exception as e:
        app.logger.error(f"âŒ Error repairing document {document_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Repair error: {str(e)}'}), 500

@app.route('/api/common-documents/repair-all', methods=['POST'])
def repair_all_common_documents():
    """ðŸš€ NEW: Repair all common documents that have missing file content"""
    # Allow access if user has any valid session
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        app.logger.warning(f"Bulk common document repair without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"ðŸ”§ Starting bulk repair of all common documents")
        db = get_db()
        
        # Get all documents
        all_documents = db.get_all_common_documents()
        repair_results = []
        
        for doc in all_documents:
            doc_id = doc.get('_id')
            doc_name = doc.get('name', 'Unknown')
            
            app.logger.info(f"ðŸ”§ Checking document: {doc_name} (ID: {doc_id})")
            
            # Check if document needs repair
            is_valid, message = db.validate_document_integrity(doc_id)
            
            if not is_valid:
                app.logger.info(f"ðŸ”§ Document {doc_name} needs repair: {message}")
                
                # Attempt repair
                repair_success, repair_message = db.repair_document_file_content(doc_id)
                
                repair_results.append({
                    'document_id': doc_id,
                    'name': doc_name,
                    'needed_repair': True,
                    'repair_success': repair_success,
                    'repair_message': repair_message
                })
                
                if repair_success:
                    app.logger.info(f"âœ… Document {doc_name} repaired successfully")
                else:
                    app.logger.error(f"âŒ Document {doc_name} repair failed: {repair_message}")
            else:
                repair_results.append({
                    'document_id': doc_id,
                    'name': doc_name,
                    'needed_repair': False,
                    'repair_success': True,
                    'repair_message': 'Document was already valid'
                })
        
        # Count results
        total_docs = len(repair_results)
        docs_needing_repair = len([r for r in repair_results if r['needed_repair']])
        successful_repairs = len([r for r in repair_results if r['needed_repair'] and r['repair_success']])
        failed_repairs = len([r for r in repair_results if r['needed_repair'] and not r['repair_success']])
        
        app.logger.info(f"ðŸ”§ Bulk repair completed: {total_docs} total, {docs_needing_repair} needed repair, {successful_repairs} successful, {failed_repairs} failed")
        
        return jsonify({
            'status': 'success',
            'message': f'Bulk repair completed: {successful_repairs}/{docs_needing_repair} documents repaired successfully',
            'summary': {
                'total_documents': total_docs,
                'documents_needing_repair': docs_needing_repair,
                'successful_repairs': successful_repairs,
                'failed_repairs': failed_repairs
            },
            'results': repair_results
        })
        
    except Exception as e:
        app.logger.error(f"âŒ Error during bulk repair: {e}")
        return jsonify({'status': 'error', 'message': f'Bulk repair error: {str(e)}'}), 500

@app.route('/api/common-documents/<document_id>', methods=['GET'])
def get_common_document(document_id):
    """Get a specific common document"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        document = db.get_common_document_by_id(document_id)
        
        if document:
            return jsonify({
                'status': 'success',
                'document': document
            })
        else:
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
    except Exception as e:
        app.logger.error(f"Error getting common document: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/<document_id>/send-data', methods=['GET'])
def get_common_document_send_data(document_id):
    """Get common document data formatted for external transmission with fileData key"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Common document send data access without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        app.logger.info(f"Send data request for document ID: {document_id}")
        db = get_db()
        
        # Get the document metadata
        document = db.get_common_document_by_id(document_id)
        if not document:
            app.logger.error(f"Document {document_id} not found in database")
            return jsonify({'status': 'error', 'message': 'Document not found'}), 404
        
        # Get the file content
        file_data = db.get_document_file_content(document_id)
        if not file_data:
            app.logger.error(f"File content not found for document {document_id}")
            return jsonify({'status': 'error', 'message': 'File content not found'}), 404
        
        # Convert binary file content to base64 for transmission
        import base64
        file_content_base64 = base64.b64encode(file_data['content']).decode('utf-8')
        
        # Format document data with fileData key for external transmission
        send_data = {
            'document_id': document_id,
            'name': document.get('name', ''),
            'fileName': file_data.get('file_name', document.get('file_name', '')),
            'fileData': file_content_base64,  # Key requested by user
            'file_type': file_data.get('file_type', 'application/octet-stream'),
            'file_size': file_data.get('file_size', len(file_data['content']) if file_data.get('content') else 0),
            'description': document.get('description', ''),
            'type': document.get('type', 'form'),
            'created_at': document.get('created_at', ''),
            'created_by': document.get('created_by', ''),
            'download_count': document.get('download_count', 0),
            'timestamp': datetime.now().isoformat(),
            'status': 'ready_for_transmission'
        }
        
        # Increment download count since this is a data access
        db.increment_document_download_count(document_id)
        
        app.logger.info(f"Document send data prepared: {document.get('name', 'Unknown')} ({len(file_content_base64)} chars base64)")
        
        return jsonify({
            'status': 'success',
            'message': 'Document data ready for transmission',
            'data': send_data
        })
        
    except Exception as e:
        app.logger.error(f"Error preparing document send data: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/common-documents/send-data', methods=['POST'])
def get_multiple_common_documents_send_data():
    """Get multiple common documents data formatted for external transmission with fileData key"""
    # Allow access if user has any valid session (member_id, user_id, or is authenticated)
    if not session or (not session.get('member_id') and not session.get('user_id') and not session.get('authenticated')):
        # For development/testing, allow access without strict authentication
        app.logger.warning(f"Multiple common documents send data access without full authentication - session: {dict(session) if session else 'None'}")
    
    try:
        data = request.json
        document_ids = data.get('document_ids', [])
        
        if not document_ids:
            return jsonify({'status': 'error', 'message': 'Document IDs are required'}), 400
        
        app.logger.info(f"Send data request for {len(document_ids)} documents: {document_ids}")
        db = get_db()
        
        documents_data = []
        
        for document_id in document_ids:
            try:
                # Get the document metadata
                document = db.get_common_document_by_id(document_id)
                if not document:
                    app.logger.warning(f"Document {document_id} not found, skipping")
                    continue
                
                # Get the file content
                file_data = db.get_document_file_content(document_id)
                if not file_data:
                    app.logger.warning(f"File content not found for document {document_id}, skipping")
                    continue
                
                # Convert binary file content to base64 for transmission
                import base64
                file_content_base64 = base64.b64encode(file_data['content']).decode('utf-8')
                
                # Format document data with fileData key for external transmission
                send_data = {
                    'document_id': document_id,
                    'name': document.get('name', ''),
                    'fileName': file_data.get('file_name', document.get('file_name', '')),
                    'fileData': file_content_base64,  # Key requested by user
                    'file_type': file_data.get('file_type', 'application/octet-stream'),
                    'file_size': file_data.get('file_size', len(file_data['content']) if file_data.get('content') else 0),
                    'description': document.get('description', ''),
                    'type': document.get('type', 'form'),
                    'created_at': document.get('created_at', ''),
                    'created_by': document.get('created_by', ''),
                    'download_count': document.get('download_count', 0),
                    'timestamp': datetime.now().isoformat(),
                    'status': 'ready_for_transmission'
                }
                
                documents_data.append(send_data)
                
                # Increment download count since this is a data access
                db.increment_document_download_count(document_id)
                
                app.logger.info(f"Document prepared: {document.get('name', 'Unknown')} ({len(file_content_base64)} chars base64)")
                
            except Exception as doc_error:
                app.logger.error(f"Error processing document {document_id}: {doc_error}")
                continue
        
        if not documents_data:
            return jsonify({'status': 'error', 'message': 'No valid documents found'}), 404
        
        app.logger.info(f"Prepared {len(documents_data)} documents for transmission")
        
        return jsonify({
            'status': 'success',
            'message': f'{len(documents_data)} documents ready for transmission',
            'count': len(documents_data),
            'data': documents_data
        })
        
    except Exception as e:
        app.logger.error(f"Error preparing multiple documents send data: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500


# ============ COMMON DOCUMENT WEBHOOK TRIGGER ============
def trigger_common_document_webhook(document_id, document_data):
    """
    Trigger webhook for common document creation/update
    Uses the same webhook infrastructure as tickets
    """
    try:
        app.logger.info(f"ðŸ“„ TRIGGERING COMMON DOCUMENT WEBHOOK - Document: {document_id}")
        
        # Prepare webhook payload with enhanced document data
        webhook_payload = {
            "json": [{
                "document_id": document_id,
                "name": document_data.get('name', 'Unknown'),
                "type": document_data.get('type', 'form'),
                "description": document_data.get('description', ''),
                "file_name": document_data.get('file_name', ''),
                "original_filename": document_data.get('original_filename', ''),
                "safe_filename": document_data.get('safe_filename', ''),
                "file_path": document_data.get('file_path', ''),
                "file_size": document_data.get('file_size', 0),
                "file_type": document_data.get('file_type', 'application/octet-stream'),
                "created_by": document_data.get('created_by', 'Unknown'),
                "upload_method": document_data.get('upload_method', 'unknown'),
                "has_file_data": document_data.get('has_file_data', False),
                "file_data": document_data.get('file_data', ''),  # Base64 encoded file content
                "created_at": document_data.get('created_at', datetime.now()).isoformat() if hasattr(document_data.get('created_at'), 'isoformat') else str(document_data.get('created_at', datetime.now())),
                "updated_at": document_data.get('updated_at', datetime.now()).isoformat() if hasattr(document_data.get('updated_at'), 'isoformat') else str(document_data.get('updated_at', datetime.now())),
                "webhook_type": "common_document_created",
                "webhook_timestamp": datetime.now().isoformat(),
                "system": "AutoAssistGroup",
                "version": "2.0"
            }],
            "binary": {
                "has_attachments": document_data.get('has_file_data', False),
                "total_attachments": 1 if document_data.get('has_file_data') else 0,
                "attachments": [{
                    "filename": document_data.get('file_name', ''),
                    "original_name": document_data.get('original_filename', ''),
                    "name": document_data.get('file_name', ''),
                    "size": document_data.get('file_size', 0),
                    "is_warranty": False,  # Common documents are not warranty forms
                    "file_type": document_data.get('file_type', 'application/octet-stream'),
                    "uploaded_at": document_data.get('created_at', datetime.now()).isoformat() if hasattr(document_data.get('created_at'), 'isoformat') else str(document_data.get('created_at', datetime.now())),
                    "source": "common_document_upload",
                    "path": document_data.get('file_path', ''),
                    "type": "file",
                    "data": document_data.get('file_data', ''),  # Base64 data for webhook
                    "is_common_document": True,
                    "document_id": document_id
                }] if document_data.get('has_file_data') else []
            }
        }
        
        # Use the main webhook URL for common documents
        webhook_url = os.environ.get('WEBHOOK_URL', 'https://ffxtrading.app.n8n.cloud/webhook/7514d383-c720-4dd3-9251-061d66a86a6a')
        
        app.logger.info(f"ðŸ“„ SENDING COMMON DOCUMENT WEBHOOK - URL: {webhook_url}")
        app.logger.info(f"ðŸ“„ PAYLOAD: Document {document_id} - {document_data.get('name', 'Unknown')} ({document_data.get('file_size', 0)} bytes)")
        
        # Send webhook request with retry logic
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    webhook_url,
                    json=webhook_payload,
                    timeout=15,
                    headers={'Content-Type': 'application/json'}
                )
                response.raise_for_status()
                
                app.logger.info(f"ðŸ“„ SUCCESS: Common document webhook sent successfully - Document: {document_id}, Status: {response.status_code}")
                
                # Store webhook metadata
                try:
                    db = get_db()
                    db.add_ticket_metadata(document_id, 'webhook_triggered', datetime.now().isoformat())
                    db.add_ticket_metadata(document_id, 'webhook_url', webhook_url)
                    db.add_ticket_metadata(document_id, 'webhook_status', 'success')
                    db.add_ticket_metadata(document_id, 'webhook_response_code', str(response.status_code))
                except Exception as metadata_error:
                    app.logger.warning(f"ðŸ“„ WARNING: Failed to store webhook metadata: {metadata_error}")
                
                return True
                
            except requests.exceptions.RequestException as e:
                app.logger.warning(f"ðŸ“„ WARNING: Common document webhook attempt {attempt + 1} failed - Document: {document_id}: {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(1)  # Brief pause before retry
                    continue
                else:
                    app.logger.error(f"ðŸ“„ ERROR: Common document webhook final failure - Document: {document_id} after {max_retries} attempts")
                    
                    # Store failure metadata
                    try:
                        db = get_db()
                        db.add_ticket_metadata(document_id, 'webhook_failed', datetime.now().isoformat())
                        db.add_ticket_metadata(document_id, 'webhook_error', str(e))
                    except Exception as metadata_error:
                        app.logger.warning(f"ðŸ“„ WARNING: Failed to store webhook failure metadata: {metadata_error}")
                    
                    return False
                    
            except Exception as e:
                app.logger.error(f"ðŸ“„ ERROR: Common document webhook unexpected error - Document: {document_id}: {e}")
                return False
        
        return False
        
    except Exception as e:
        app.logger.error(f"ðŸ“„ ERROR: Failed to trigger common document webhook - Document: {document_id}: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ Full traceback: {traceback.format_exc()}")
        return False


# ============ COMMON DOCUMENT WEBHOOK TEST ENDPOINT ============
@app.route('/debug/common-document-webhook-test')
def debug_common_document_webhook_test():
    """Debug endpoint to test common document webhook functionality"""
    try:
        app.logger.info(f"ðŸ“„ TESTING COMMON DOCUMENT WEBHOOK FUNCTIONALITY")
        
        # Create test document data
        test_document_data = {
            'name': 'Test Common Document',
            'type': 'test',
            'description': 'This is a test document for webhook testing',
            'file_name': 'test_document.txt',
            'original_filename': 'test_document.txt',
            'safe_filename': '20250126_120000_test_document.txt',
            'file_path': '/tmp/test_path.txt',
            'file_size': 1024,
            'file_type': 'text/plain',
            'created_by': 'Test User',
            'upload_method': 'test',
            'has_file_data': True,
            'file_data': 'VGhpcyBpcyBhIHRlc3QgZmlsZSBjb250ZW50IGZvciB3ZWJob29rIHRlc3Rpbmc=',  # Base64 encoded test content
            'created_at': datetime.now(),
            'updated_at': datetime.now()
        }
        
        # Test webhook trigger
        webhook_result = trigger_common_document_webhook('test_document_id', test_document_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Common document webhook test completed',
            'webhook_triggered': webhook_result,
            'test_data': {
                'document_name': test_document_data['name'],
                'file_size': test_document_data['file_size'],
                'has_file_data': test_document_data['has_file_data'],
                'base64_length': len(test_document_data['file_data'])
            }
        })
        
    except Exception as e:
        app.logger.error(f"ðŸ“„ ERROR: Common document webhook test failed: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ Full traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Common document webhook test failed: {str(e)}',
            'error_type': type(e).__name__
        }), 500


# ============ ENHANCED COMMON DOCUMENT FILE DATA HELPER ============
def ensure_common_document_file_data_enhanced(attachment):
    """
    Enhanced helper function to ensure common document attachments include their actual file data
    Works with both new and legacy data structures
    """
    try:
        if attachment.get('type') == 'common-document':
            doc_ref = attachment.get('ref')
            if doc_ref:
                app.logger.info(f"ðŸ“„ ENHANCED: Processing common document attachment: {doc_ref}")
                
                db = get_db()
                document = db.get_common_document_by_id(doc_ref)
                
                if document:
                    filename = document.get('file_name', 'Unknown')
                    
                    # ENHANCED: Check for file_data first (new structure), then file_content (legacy)
                    file_content_base64 = None
                    if document.get('file_data'):
                        file_content_base64 = document.get('file_data')
                        app.logger.info(f"ðŸ“„ ENHANCED: Using new file_data structure: {filename} ({len(file_content_base64)} base64 chars)")
                    elif document.get('file_content'):
                        file_content_base64 = document.get('file_content')
                        app.logger.info(f"ðŸ“„ ENHANCED: Using legacy file_content structure: {filename} ({len(file_content_base64)} base64 chars)")
                    
                    if file_content_base64:
                        app.logger.info(f"ðŸ“„ ENHANCED: SUCCESS: Retrieved common document {filename} ({len(file_content_base64)} base64 chars)")
                        
                        return {
                            "type": "common_document",
                            "name": filename,
                            "data": file_content_base64,
                            "size": document.get('file_size', 0),
                            "is_warranty": False,
                            "file_type_info": {'type': 'common_document', 'icon': 'ðŸ“„'},
                            "document_id": doc_ref,
                            "original_filename": document.get('original_filename', filename),
                            "safe_filename": document.get('safe_filename', filename),
                            "file_path": document.get('file_path', ''),
                            "file_type": document.get('file_type', 'application/octet-stream'),
                            "upload_method": document.get('upload_method', 'unknown'),
                            "has_file_data": True,
                            "is_common_document": True
                        }
                    else:
                        app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Common document {doc_ref} has no file content (neither file_data nor file_content)")
                        return attachment
                else:
                    app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Common document {doc_ref} not found in database")
                    return attachment
            else:
                app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Common document attachment missing ref: {attachment}")
                return attachment
        else:
            app.logger.warning(f"ðŸ“„ ENHANCED: WARNING: Not a common document attachment: {attachment}")
            return attachment
            
    except Exception as e:
        app.logger.error(f"ðŸ“„ ENHANCED: ERROR: Error processing common document attachment: {e}")
        import traceback
        app.logger.error(f"ðŸ“„ ENHANCED: Full traceback: {traceback.format_exc()}")
        return {
            "type": "common_document",
            "name": "Error",
            "data": "",
            "size": 0,
            "is_warranty": False,
            "file_type_info": {'type': 'common_document', 'icon': 'ðŸ“„'},
            "is_common_document": True,
            "has_file_data": False
        }
    
    # Return original attachment if not a common document
    return attachment


@app.route('/api/tickets/<ticket_id>/classification', methods=['POST'])
def update_ticket_classification(ticket_id):
    """Update ticket classification"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        new_classification = data.get('classification')
        
        if not new_classification:
            return jsonify({'status': 'error', 'message': 'Classification is required'}), 400
        
        # Validate classification value
        valid_classifications = ['General', 'Technical', 'Payment', 'Account', 'Warranty Claim', 'Support', 'Others']
        if new_classification not in valid_classifications:
            return jsonify({'status': 'error', 'message': 'Invalid classification value'}), 400
        
        db = get_db()
        
        # Update the ticket classification
        update_result = db.update_ticket(ticket_id, {
            'classification': new_classification,
            'updated_at': datetime.now()
        })
        
        # Log classification change
        app.logger.info(f"Ticket {ticket_id} classification updated to: {new_classification} by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket classification updated to: {new_classification}'
        })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket classification: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/outcome', methods=['POST'])
def update_ticket_outcome(ticket_id):
    """Update ticket outcome information"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        outcome_category = data.get('outcome_category', '')
        revisit_carried_out = '1' if data.get('revisit_carried_out') else '0'
        clean_under_warranty = '1' if data.get('clean_under_warranty') else '0'
        outcome_notes = data.get('outcome_notes', '')
        
        db = get_db()
        
        # Update or create outcome metadata entries
        outcome_metadata = [
            {'key': 'outcome_category', 'value': outcome_category},
            {'key': 'revisit_carried_out', 'value': revisit_carried_out},
            {'key': 'clean_under_warranty', 'value': clean_under_warranty},
            {'key': 'outcome_notes', 'value': outcome_notes}
        ]
        
        for metadata in outcome_metadata:
            # Remove existing entry
            db.ticket_metadata.delete_many({
                'ticket_id': ticket_id,
                'key': metadata['key']
            })
            # Add updated entry if value is not empty
            if metadata['value']:
                db.add_ticket_metadata(ticket_id, metadata['key'], metadata['value'])
        
        # Update ticket timestamp
        db.update_ticket(ticket_id, {'updated_at': datetime.now()})
        
        # Log outcome update
        app.logger.info(f"Ticket {ticket_id} outcome updated by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': 'Outcome information updated successfully'
        })
        
    except Exception as e:
        app.logger.error(f"Error updating ticket outcome: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/warranty-check')
def check_ticket_warranty_status(ticket_id):
    """ Check if a specific ticket has warranty claim classification"""
    try:
        db = get_db()
        
        # Get ticket details
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({
                'status': 'error',
                'message': f'Ticket #{ticket_id} not found',
                'ticket_id': ticket_id
            }), 404
        
        # Extract warranty-related information
        classification = ticket.get('classification', 'Unknown')
        has_warranty = ticket.get('has_warranty', False)
        priority = ticket.get('priority', 'Unknown')
        name = ticket.get('name', 'Unknown')
        email = ticket.get('email', 'Unknown')
        subject = ticket.get('subject', 'Unknown')
        creation_method = ticket.get('creation_method', 'Unknown')
        
        # Get attachments metadata
        metadata = db.get_ticket_metadata(ticket_id)
        warranty_attachments = []
        
        if metadata:
            for meta in metadata:
                key = meta.get('key', 'unknown')
                filename = meta.get('filename', 'unknown')
                
                # Check if this is a warranty-related attachment
                is_warranty_related = (
                    'warranty' in key.lower() or 
                    'warranty' in filename.lower() or
                    'claim' in key.lower() or
                    'dpf' in key.lower()
                )
                
                if is_warranty_related:
                    warranty_attachments.append({
                        'key': key,
                        'filename': filename,
                        'is_warranty_related': is_warranty_related
                    })
        
        # Check content for warranty keywords
        body = ticket.get('body', '').lower()
        warranty_keywords = ['warranty', 'claim', 'dpf', 'filter', 'defect', 'fault', 'repair']
        found_keywords = [kw for kw in warranty_keywords if kw in body or kw in subject.lower()]
        
        # Determine if should be warranty claim
        should_be_warranty = (
            classification == 'Warranty Claim' or
            has_warranty or
            len(warranty_attachments) > 0 or
            len(found_keywords) > 0
        )
        
        is_warranty_claim = classification == 'Warranty Claim'
        
        app.logger.info(f" WARRANTY CHECK: Ticket {ticket_id} - Classification: {classification}, Has Warranty: {has_warranty}, Warranty Attachments: {len(warranty_attachments)}, Keywords: {found_keywords}")
        
        return jsonify({
            'status': 'success',
            'ticket_id': ticket_id,
            'warranty_analysis': {
                'is_warranty_claim': is_warranty_claim,
                'should_be_warranty_claim': should_be_warranty,
                'classification_correct': is_warranty_claim == should_be_warranty
            },
            'ticket_details': {
                'classification': classification,
                'has_warranty_flag': has_warranty,
                'priority': priority,
                'customer': f"{name} ({email})",
                'subject': subject,
                'creation_method': creation_method
            },
            'warranty_evidence': {
                'warranty_attachments': warranty_attachments,
                'warranty_keywords_found': found_keywords,
                'total_warranty_attachments': len(warranty_attachments),
                'total_warranty_keywords': len(found_keywords)
            },
            'verdict': {
                'status': ' WARRANTY CLAIM' if is_warranty_claim else ' NOT WARRANTY CLAIM',
                'recommendation': ' CORRECT' if is_warranty_claim == should_be_warranty else (' SHOULD BE WARRANTY CLAIM' if should_be_warranty else ' SHOULD NOT BE WARRANTY CLAIM'),
                'confidence': 'HIGH' if (len(warranty_attachments) > 0 or len(found_keywords) >= 2) else 'MEDIUM'
            }
        })
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ Error checking warranty status for ticket {ticket_id}: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Failed to check warranty status: {str(e)}',
            'ticket_id': ticket_id
        }), 500

@app.route('/api/tickets/search', methods=['GET'])
def search_tickets():
    """Search tickets with filters"""
    try:
        query = request.args.get('q', '')
        priority = request.args.get('priority', '')
        classification = request.args.get('type', '')
        status = request.args.get('status', '')
        advisor = request.args.get('advisor', '')
        age = request.args.get('age', '')
        
        db = get_db()
        
        # Use MongoDB search functionality
        tickets = db.search_tickets(
            query=query if query else None,
            priority=priority if priority and priority != 'All' else None,
            classification=classification if classification and classification != 'All' else None,
            status=status if status and status != 'All' else None
        )
        
        # Additional client-side filtering for dashboard-specific filters
        if advisor or age:
            filtered_tickets = []
            for ticket in tickets:
                include_ticket = True
                
                # Filter by advisor (assigned member)
                if advisor:
                    # Check if ticket has assignment
                    assignment = db.get_assignment_by_ticket(ticket.get('ticket_id'))
                    if assignment:
                        assigned_member = db.get_member_by_id(assignment.get('member_id'))
                        if not assigned_member or assigned_member.get('name') != advisor:
                            include_ticket = False
                    else:
                        include_ticket = False
                
                # Filter by age
                if age and include_ticket:
                    from datetime import datetime, timedelta
                    now = datetime.now()
                    created_at = ticket.get('created_at')
                    
                    if isinstance(created_at, datetime):
                        ticket_age = now - created_at
                        
                        if age == 'today' and ticket_age.days > 0:
                            include_ticket = False
                        elif age == '1-3days' and (ticket_age.days < 1 or ticket_age.days > 3):
                            include_ticket = False
                        elif age == 'overdue' and ticket_age.days <= 3:
                            include_ticket = False
                
                if include_ticket:
                    filtered_tickets.append(ticket)
            
            tickets = filtered_tickets
        
        formatted_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Format date
            if 'created_at' in ticket_dict and ticket_dict['created_at']:
                if isinstance(ticket_dict['created_at'], datetime):
                    ticket_dict['formatted_date'] = ticket_dict['created_at'].strftime("%b %d, %I:%M %p")
                else:
                    try:
                        created_at = datetime.strptime(str(ticket_dict['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket_dict['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                    except:
                        ticket_dict['formatted_date'] = str(ticket_dict['created_at'])
            
            formatted_tickets.append(ticket_dict)
            
        return jsonify({
            'status': 'success',
            'tickets': formatted_tickets
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/close', methods=['POST'])
def close_ticket(ticket_id):
    """Close ticket - Available for ALL users including Technical Director (with takeover check)"""
    
    # Enhanced error handling and debugging
    app.logger.info(f"[TARGET] CLOSE TICKET REQUEST - Ticket: {ticket_id}")
    
    if 'member_id' not in session:
        app.logger.warning(f"[ERROR] UNAUTHORIZED - No session for close ticket {ticket_id}")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in'}), 401
    
    try:
        db = get_db()

        app.logger.info(f"[INFO] CLOSE TICKET - User: {session.get('member_name')} closing ticket {ticket_id}")
        
        # Validate ticket exists
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            app.logger.warning(f"[ERROR] TICKET NOT FOUND - {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # CHECK TAKEOVER STATUS: Ticket must be taken over before closing
        assignment = db.ticket_assignments.find_one({'ticket_id': ticket_id})
        
        if not assignment:
            app.logger.warning(f"[ERROR] TICKET NOT TAKEN OVER - {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Please take over the ticket first before closing it'}), 400
        
        # Verify the assignment is not just a forward (must be taken over)
        if assignment.get('is_forwarded', False):
            app.logger.warning(f"[ERROR] TICKET ONLY FORWARDED - {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket is only forwarded. Please take over the ticket first before closing it'}), 400
        
        app.logger.info(f"[SUCCESS] TAKEOVER VALIDATED - Ticket {ticket_id} taken over by member {assignment.get('member_id')}")
        
        # Update ticket status to closed
        db.update_ticket(ticket_id, {
            'status': 'Resolved',
            'updated_at': datetime.now(),
            'closed_by': session.get('member_name'),
            'closed_at': datetime.now()
        })
        
        app.logger.info(f"[SUCCESS] TICKET CLOSED - {ticket_id} by {session.get('member_name')}")
        return jsonify({'status': 'success', 'message': 'Ticket closed successfully'})
        
    except Exception as e:
        app.logger.error(f"[ERROR] ERROR CLOSING TICKET {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Failed to close ticket: {str(e)}'}), 500

@app.route('/api/admin/update-creation-methods', methods=['POST', 'GET'])
def update_creation_methods():
    """Admin endpoint to retroactively add creation_method to existing tickets"""
    # Allow GET for easy testing - in production you might want to remove this
    # if 'member_id' not in session:
    #     return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get all tickets without creation_method
        tickets_to_update = list(db.tickets.find({
            "$or": [
                {"creation_method": {"$exists": False}},
                {"creation_method": None}
            ]
        }))
        
        updated_count = 0
        manual_count = 0
        email_count = 0
        
        for ticket in tickets_to_update:
            ticket_id = ticket.get('ticket_id', '')
            creation_method = None
            
            # Determine creation method based on ticket ID patterns
            if ticket_id.startswith('M') or ticket_id.startswith('WM'):
                # Manual tickets: M{type_code}{4_digits} or legacy WM prefixes
                creation_method = 'manual'
                manual_count += 1
            elif ticket_id.startswith('W') and not ticket_id.startswith('WM'):
                # Warranty tickets: W{5_digits} - treat as email since they come from forms
                creation_method = 'email'
                email_count += 1
            elif ticket_id.startswith(('E', 'G', 'S', 'T', 'O')):
                # Email tickets with classification codes: {class_code}{priority_code}{4_digits}
                creation_method = 'email'
                email_count += 1
            else:
                # Better fallback: analyze ticket content for better detection
                thread_id = ticket.get('thread_id', '')
                body = ticket.get('body', '').lower()
                
                # Check for email indicators
                if thread_id or '@' in ticket.get('email', '') or 'email' in body:
                    creation_method = 'email'
                    email_count += 1
                elif ticket.get('name') == 'System' or 'manual' in body:
                    creation_method = 'manual'
                    manual_count += 1
                else:
                    # Default to email as most tickets come from email/forms
                    creation_method = 'email'
                    email_count += 1
            
            # Update the ticket
            if creation_method:
                result = db.tickets.update_one(
                    {"ticket_id": ticket_id},
                    {"$set": {
                        "creation_method": creation_method,
                        "updated_at": datetime.now()
                    }}
                )
                
                if result.modified_count > 0:
                    updated_count += 1
        
        return jsonify({
            'status': 'success',
            'message': f'Updated {updated_count} tickets',
            'details': {
                'total_updated': updated_count,
                'manual_tickets': manual_count,
                'email_tickets': email_count
            }
        })
        
    except Exception as e:
        app.logger.error(f"Error updating creation methods: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/reset-creation-methods', methods=['POST'])
def reset_creation_methods():
    """Reset all tickets back to unknown creation method"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Remove creation_method field from all tickets
        result = db.tickets.update_many(
            {},
            {"$unset": {"creation_method": ""}}
        )
        
        return jsonify({
            'status': 'success',
            'message': f'Reset {result.modified_count} tickets to unknown',
            'modified_count': result.modified_count
        })
        
    except Exception as e:
        app.logger.error(f"Error resetting creation methods: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/status')
def status_dashboard():
    """Dedicated status dashboard page"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get pagination parameters
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status_filter = request.args.get('status', 'All')
        priority_filter = request.args.get('priority', 'All')
        search_query = request.args.get('search', '')
        
        # Get paginated tickets with assignment info
        tickets = db.get_tickets_with_assignments(
            page=page, 
            per_page=per_page, 
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # Get total count for pagination
        total_tickets = db.get_tickets_count(
            status_filter=status_filter,
            priority_filter=priority_filter,
            search_query=search_query
        )
        
        # Convert to dict format and format dates
        formatted_tickets = []
        for ticket in tickets:
            ticket['_id'] = str(ticket['_id'])
            
            # Handle assignment info
            if ticket.get('assignment') and len(ticket['assignment']) > 0:
                if ticket.get('assigned_member') and len(ticket['assigned_member']) > 0:
                    member = ticket['assigned_member'][0]
                    ticket['assigned_to'] = member.get('name')
                else:
                    ticket['assigned_to'] = None
            else:
                ticket['assigned_to'] = None
            
            # Format created_at date
            if 'created_at' in ticket and ticket['created_at']:
                if isinstance(ticket['created_at'], datetime):
                    ticket['formatted_date'] = ticket['created_at'].strftime("%b %d, %I:%M %p")
                else:
                    try:
                        created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                    except:
                        ticket['formatted_date'] = str(ticket['created_at'])
            else:
                ticket['formatted_date'] = 'Unknown'
            
            formatted_tickets.append(ticket)
        
        # Calculate stats - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(formatted_tickets)
        
        # Status counts
        status_counts = {}
        for ticket in formatted_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # Priority counts
        priority_counts = {}
        for ticket in formatted_tickets:
            priority = ticket.get('priority', 'Unknown')
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
        
        # Creation method counts
        creation_methods = {}
        for ticket in formatted_tickets:
            method = ticket.get('creation_method', 'unknown')
            creation_methods[method] = creation_methods.get(method, 0) + 1
        
        # Calculate specific metrics
        open_tickets = len([t for t in formatted_tickets if t.get('status') == 'Open'])
        waiting_tickets = len([t for t in formatted_tickets if t.get('status') == 'Waiting for Response'])
        active_tickets = open_tickets + waiting_tickets
        
        # Resolved today
        today = datetime.now().date()
        resolved_today = 0
        for ticket in formatted_tickets:
            if ticket.get('status') in ['Resolved', 'Closed']:
                if 'created_at' in ticket and ticket['created_at']:
                    try:
                        if isinstance(ticket['created_at'], datetime):
                            ticket_date = ticket['created_at'].date()
                        else:
                            ticket_date = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S").date()
                        
                        if ticket_date == today:
                            resolved_today += 1
                    except:
                        pass
        
        # Get recent tickets (last 50)
        recent_tickets = sorted(formatted_tickets, 
                              key=lambda x: x.get('created_at', datetime.min), 
                              reverse=True)[:50]
        
        # Get current user info for navbar
        current_member = db.get_member_by_id(session['member_id'])
        current_user_role = current_member['role'] if current_member else 'Unknown'
        
        # Calculate pagination info
        total_pages = (total_tickets + per_page - 1) // per_page
        has_prev = page > 1
        has_next = page < total_pages
        prev_page = page - 1 if has_prev else None
        next_page = page + 1 if has_next else None
        
        pagination_info = {
            'current_page': page,
            'per_page': per_page,
            'total_tickets': total_tickets,
            'total_pages': total_pages,
            'has_prev': has_prev,
            'has_next': has_next,
            'prev_page': prev_page,
            'next_page': next_page,
            'status_filter': status_filter,
            'priority_filter': priority_filter,
            'search_query': search_query
        }
        
        return render_template('status.html',
                             total_tickets=total_tickets,
                             active_tickets=active_tickets,
                             waiting_tickets=waiting_tickets,
                             resolved_today=resolved_today,
                             status_counts=status_counts,
                             priority_counts=priority_counts,
                             creation_methods=creation_methods,
                             recent_tickets=recent_tickets,
                             current_user=session.get('member_name'),
                             current_user_role=current_user_role,
                             pagination=pagination_info)
                             
    except Exception as e:
        app.logger.error(f"Error loading status dashboard: {e}")
        return render_template('error.html', error="Failed to load status dashboard"), 500

# Add custom Jinja2 filters
@app.template_filter('basename')
def get_basename(path):
    """Jinja2 filter to get basename of a path"""
    return os.path.basename(path)

@app.template_filter('format_datetime')
def format_datetime(value):
    """Jinja2 filter to format datetime"""
    return safe_date_format(value)


@app.route('/create-first-user')
def create_first_user():
    db = get_db()
    try:
        # Check if admin user already exists
        existing_admin = db.get_member_by_user_id('admin')
        if existing_admin:
            return 'User already exists'
        
        member_data = {
            'name': 'Admin User',
            'role': 'Administrator',
            'gender': 'male',
            'user_id': 'admin',
            'password_hash': generate_password_hash('admin123')
        }
        
        db.create_member(member_data)
        return 'Created first user: admin/admin123'
    except Exception as e:
        return f'Error creating user: {str(e)}'

@app.route('/debug-members')
def debug_members():
    """Debug endpoint to check all members and find tech director"""
    try:
        db = get_db()
        
        # Get all members
        all_members = list(db.members.find({}))
        
        # Find tech directors
        tech_directors = [m for m in all_members if m.get('role') == 'Technical Director']
        
        debug_info = {
            'total_members': len(all_members),
            'tech_directors_count': len(tech_directors),
            'all_members': [
                {
                    'name': m.get('name'),
                    'role': m.get('role'),
                    'user_id': m.get('user_id'),
                    'id': str(m.get('_id')),
                    'email': m.get('email')
                } for m in all_members
            ],
            'tech_directors': [
                {
                    'name': m.get('name'),
                    'role': m.get('role'),
                    'user_id': m.get('user_id'),
                    'id': str(m.get('_id')),
                    'email': m.get('email')
                } for m in tech_directors
            ]
        }
        
        return f'''
        <h2>[DEBUG] Member Debug Info</h2>
        <h3>Total Members: {len(all_members)}</h3>
        <h3>Tech Directors Found: {len(tech_directors)}</h3>
        
        <h4>All Members:</h4>
        <table border="1">
            <tr><th>Name</th><th>Role</th><th>User ID</th><th>Object ID</th><th>Email</th></tr>
            {"".join([f"<tr><td>{m.get('name', 'N/A')}</td><td>{m.get('role', 'N/A')}</td><td>{m.get('user_id', 'N/A')}</td><td>{str(m.get('_id', 'N/A'))}</td><td>{m.get('email', 'N/A')}</td></tr>" for m in all_members])}
        </table>
        
        <h4>Tech Directors:</h4>
        <table border="1">
            <tr><th>Name</th><th>Role</th><th>User ID</th><th>Object ID</th><th>Email</th></tr>
            {"".join([f"<tr><td>{m.get('name', 'N/A')}</td><td>{m.get('role', 'N/A')}</td><td>{m.get('user_id', 'N/A')}</td><td>{str(m.get('_id', 'N/A'))}</td><td>{m.get('email', 'N/A')}</td></tr>" for m in tech_directors])}
        </table>
        
        <p><a href="/test-webhook">Test Webhook</a> | <a href="/create-tech-director">Create Tech Director</a></p>
        '''
        
    except Exception as e:
        return f'<h2>[ERROR] Debug Error:</h2><p>{str(e)}</p>'


@app.route('/debug-tech-director')
def debug_tech_director():
    """Debug endpoint to check Technical Director details"""
    db = get_db()
    try:
        # Check all members with Technical Director role
        all_members = list(db.members.find({"role": "Technical Director"}))
        
        # Also check by user_id
        marc_user = db.get_member_by_user_id('marc001')
        
        debug_info = {
            'total_tech_directors': len(all_members),
            'tech_directors_found': [
                {
                    'name': member.get('name'),
                    'role': member.get('role'), 
                    'user_id': member.get('user_id'),
                    'id': str(member.get('_id')),
                    'email': member.get('email')
                } for member in all_members
            ],
            'marc_user_lookup': {
                'found': marc_user is not None,
                'details': {
                    'name': marc_user.get('name') if marc_user else None,
                    'role': marc_user.get('role') if marc_user else None,
                    'id': str(marc_user.get('_id')) if marc_user else None
                } if marc_user else None
            }
        }
        
        return f'''
        <h2>[DEBUG] Technical Director Debug Info</h2>
        <pre>{str(debug_info)}</pre>
        <hr>
        <p><a href="/create-tech-director">Create/Check Tech Director</a></p>
        '''
        
    except Exception as e:
        return f'<h2>[ERROR] Debug Error:</h2><p>{str(e)}</p>'

@app.route('/create-tech-director')
def create_tech_director():
    """Create or verify Technical Director account exists"""
    db = get_db()
    try:
        # Check if tech director user already exists
        existing_tech_director = db.get_member_by_user_id('marc001')
        if existing_tech_director:
            return f'''
            <h2>[SUCCESS] Technical Director Account Status</h2>
            <p><strong>Account exists:</strong> marc001</p>
            <p><strong>Name:</strong> {existing_tech_director.get('name', 'Unknown')}</p>
            <p><strong>Role:</strong> {existing_tech_director.get('role', 'Unknown')}</p>
            <p><strong>Email:</strong> {existing_tech_director.get('email', 'Not set')}</p>
            <p><strong>Status:</strong> Active and ready to use</p>
            <hr>
            <p><a href="/login">Login to System</a> | <a href="/tech-director">Tech Director Portal</a></p>
            '''
        
        # Create Technical Director account
        member_data = {
            'name': 'Marc (Technical Director)',
            'role': 'Technical Director',
            'gender': 'male',
            'user_id': 'marc001',
            'password_hash': generate_password_hash('tech@123'),
            'email': 'marc@autoassistgroup.com',
            'department': 'Technical',
            'is_active': True,
            'created_at': datetime.now()
        }
        
        db.create_member(member_data)
        return '''
        <h2>[SUCCESS] Technical Director Account Created Successfully!</h2>
        <p><strong>Username:</strong> marc001</p>
        <p><strong>Password:</strong> tech@123</p>
        <p><strong>Role:</strong> Technical Director</p>
        <p><strong>Email:</strong> marc@autoassistgroup.com</p>
        <hr>
        <p><strong>[WARNING] Important:</strong> Change the password after first login!</p>
        <p><a href="/login">Login Now</a> | <a href="/tech-director">Tech Director Portal</a></p>
        '''
    except Exception as e:
        return f'<h2>[ERROR] Error creating Technical Director account:</h2><p>{str(e)}</p>'

@app.route('/debug/ticket-creation', methods=['GET'])
def debug_ticket_creation():
    """Debug endpoint to test ticket creation without full form"""
    try:
        db = get_db()
        
        # Test database connection
        db.client.admin.command('ping')
        
        # Generate a simple test ticket
        test_ticket_id = f"TEST{str(uuid.uuid4())[:2].upper()}"
        
        ticket_data = {
            'ticket_id': test_ticket_id,
            'email': 'test@example.com',
            'name': 'Test User',
            'subject': 'Debug Test Ticket',
            'body': 'This is a debug test ticket',
            'status': 'Open',
            'priority': 'Medium',
            'creation_method': 'debug'
        }
        
        # Try to create the ticket
        result = db.create_ticket(ticket_data)
        
        return jsonify({
            'status': 'success',
            'message': 'Debug ticket created successfully',
            'ticket_id': test_ticket_id,
            'mongodb_result': str(result),
            'db_connection': 'OK'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'status': 'error',
            'message': str(e),
            'error_type': type(e).__name__,
            'traceback': traceback.format_exc()
        }), 500

# Add route to serve uploaded files with enhanced error handling for Vercel
@app.route('/uploads/<filename>')
def uploaded_file(filename):
    """Serve uploaded files with Vercel compatibility"""
    try:
        # Check authentication
        if 'member_id' not in session:
            app.logger.warning(f"Unauthorized access attempt to file: {filename}")
            return redirect(url_for('portal'))
        
        # Log the request
        app.logger.info(f"FOLDER FILE REQUEST: {filename}")
        app.logger.info(f"FOLDER UPLOAD_FOLDER: {UPLOAD_FOLDER}")
        
        # Check if upload folder exists
        if not os.path.exists(UPLOAD_FOLDER):
            app.logger.error(f" UPLOAD_FOLDER does not exist: {UPLOAD_FOLDER}")
            return jsonify({'error': 'Upload directory not found'}), 404
        
        # Get full file path
        file_path = os.path.join(UPLOAD_FOLDER, filename)
        app.logger.info(f"FOLDER FULL PATH: {file_path}")
        
        # Check if file exists
        if not os.path.exists(file_path):
            app.logger.error(f" FILE NOT FOUND: {file_path}")
            # List available files for debugging
            try:
                available_files = os.listdir(UPLOAD_FOLDER)
                app.logger.info(f"FOLDER AVAILABLE FILES: {available_files}")
            except Exception as e:
                app.logger.error(f" Cannot list directory: {e}")
            return jsonify({'error': 'File not found'}), 404
        
        # Serve the file
        app.logger.info(f" SERVING FILE: {filename}")
        return send_from_directory(UPLOAD_FOLDER, filename)

    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR SERVING FILE {filename}: {e}")
        return jsonify({'error': f'Server error: {str(e)}'}), 500

# Debug endpoint for uploads directory
@app.route('/debug/uploads')
def debug_uploads():
    """Debug endpoint to check uploads directory status on Vercel"""
    try:
        debug_info = {
            'upload_folder': UPLOAD_FOLDER,
            'upload_folder_exists': os.path.exists(UPLOAD_FOLDER) if UPLOAD_FOLDER else False,
            'is_production': is_production,
            'environment': os.environ.get('FLASK_ENV', 'development'),
            'current_directory': os.getcwd(),
            'temp_directory': '/tmp',
            'temp_exists': os.path.exists('/tmp'),
            'files_in_upload_folder': [],
            'files_in_tmp': [],
            'error': None
        }
        
        # List files in upload folder if it exists
        if debug_info['upload_folder_exists']:
            try:
                debug_info['files_in_upload_folder'] = os.listdir(UPLOAD_FOLDER)
            except Exception as e:
                debug_info['error'] = f"Cannot list upload folder: {e}"
        
        # List files in /tmp
        try:
            debug_info['files_in_tmp'] = os.listdir('/tmp')[:20]  # Limit to first 20 files
        except Exception as e:
            debug_info['files_in_tmp'] = f"Cannot list /tmp: {e}"
        
        return jsonify(debug_info)
        
    except Exception as e:
        return jsonify({
            'error': f'Debug endpoint error: {str(e)}',
            'upload_folder': UPLOAD_FOLDER,
            'is_production': is_production
        }), 500

@app.route('/dashboard')
def live_dashboard():
    """Display the live ticket dashboard with detailed statistics"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get current user's role
        current_member = db.get_member_by_id(session['member_id'])
        if not current_member:
            return redirect(url_for('portal'))
        current_user_role = current_member['role']
        
        # Redirect Technical Director to their specific dashboard
        if current_user_role == 'Technical Director':
            return redirect(url_for('tech_director_dashboard'))
        
        # Get pagination parameters
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        status_filter = request.args.get('status', 'All')
        priority_filter = request.args.get('priority', 'All')
        search_query = request.args.get('search', '')
        
        # Get paginated tickets with assignment info
        try:
            tickets = db.get_tickets_with_assignments(
                page=page, 
                per_page=per_page, 
                status_filter=status_filter,
                priority_filter=priority_filter,
                search_query=search_query
            )
            if not tickets:
                app.logger.warning("No tickets found in database")
                tickets = []
        except Exception as e:
            app.logger.error(f"Error getting tickets: {e}")
            tickets = []
        
        # Get total count for pagination
        try:
            total_tickets = db.get_tickets_count(
                status_filter=status_filter,
                priority_filter=priority_filter,
                search_query=search_query
            )
        except Exception as e:
            app.logger.error(f"Error getting tickets count: {e}")
            total_tickets = 0
        
        # Convert to dict format for easier manipulation
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
                ticket_dict['is_forwarded'] = assignment.get('is_forwarded', False)
                
                # Handle forwarded from member info
                if ticket_dict['is_forwarded'] and ticket_dict.get('forwarded_from_member') and len(ticket_dict['forwarded_from_member']) > 0:
                    forwarded_member = ticket_dict['forwarded_from_member'][0]
                    ticket_dict['forwarded_from_name'] = forwarded_member.get('name')
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
                ticket_dict['is_forwarded'] = False
            
            # Get vehicle registration from metadata
            try:
                metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
                for meta in metadata:
                    if meta['key'] == 'vehicle_registration':
                        ticket_dict['vehicle_registration'] = meta['value']
                        break
            except Exception as e:
                app.logger.warning(f"Error getting metadata for ticket {ticket_dict.get('ticket_id')}: {e}")
                ticket_dict['vehicle_registration'] = ''
            
            # Set default values for missing fields that template expects
            ticket_dict.setdefault('has_warranty', False)
            ticket_dict.setdefault('has_attachments', False)
            ticket_dict.setdefault('attachments', [])
            ticket_dict.setdefault('priority', 'Medium')
            ticket_dict.setdefault('classification', 'General')
            ticket_dict.setdefault('subject', ticket_dict.get('body', '')[:100] if ticket_dict.get('body') else 'No Subject')
            ticket_dict.setdefault('body', 'No description available')
            ticket_dict.setdefault('warranty_forms_count', 0)
            ticket_dict.setdefault('creation_method', 'auto-detect')
            ticket_dict.setdefault('thread_id', None)
            ticket_dict.setdefault('email', None)
            
            # Check if ticket has attachments
            if ticket_dict.get('attachments') and len(ticket_dict['attachments']) > 0:
                ticket_dict['has_attachments'] = True
            
            # Check if ticket has warranty (basic check)
            if ticket_dict.get('classification') == 'Warranty Claim':
                ticket_dict['has_warranty'] = True
            
            all_tickets.append(ticket_dict)
        
        # 1. Ticket Status Breakdown (Live Count)
        status_counts = {}
        for ticket in all_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # 2. Outstanding Claims (Aged Tickets)
        now = datetime.now()
        overdue_tickets = []
        open_1_3_days = []
        open_today = []
        
        for ticket in all_tickets:
            # Handle both datetime objects (from MongoDB) and string dates
            if isinstance(ticket['created_at'], datetime):
                created_at = ticket['created_at']
            else:
                try:
                    created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                except:
                    continue  # Skip tickets with invalid dates
            
            days_open = (now - created_at).days
            
            if days_open > 3:
                overdue_tickets.append(ticket)
            elif 1 <= days_open <= 3:
                open_1_3_days.append(ticket)
            elif days_open == 0:
                open_today.append(ticket)
        
        # 3. Average Resolution Time
        resolved_tickets = [t for t in all_tickets if t['status'] == 'Resolved' or t['status'] == 'Closed']
        total_resolution_time = 0
        for ticket in resolved_tickets:
            try:
                # Handle both datetime objects (from MongoDB) and string dates
                if isinstance(ticket['created_at'], datetime):
                    created_at = ticket['created_at']
                else:
                    created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                
                if isinstance(ticket['updated_at'], datetime):
                    updated_at = ticket['updated_at']
                else:
                    updated_at = datetime.strptime(str(ticket['updated_at']), "%Y-%m-%d %H:%M:%S")
                
                resolution_time = (updated_at - created_at).total_seconds() / 3600  # in hours
                total_resolution_time += resolution_time
            except:
                continue  # Skip tickets with invalid dates
        
        avg_resolution_time = 0
        if resolved_tickets:
            avg_resolution_time = total_resolution_time / len(resolved_tickets)
        
        # 4. Claim Outcomes Summary
        total_claims = len(all_tickets)
        approved_claims = len([t for t in all_tickets if t['status'] == 'Approved - Revisit Booked'])
        declined_claims = len([t for t in all_tickets if t['status'] == 'Declined - Not Covered'])
        referred_claims = len([t for t in all_tickets if t['status'] == 'Referred to Tech Director'])
        
        approved_percent = (approved_claims / total_claims * 100) if total_claims > 0 else 0
        declined_percent = (declined_claims / total_claims * 100) if total_claims > 0 else 0
        referred_percent = (referred_claims / total_claims * 100) if total_claims > 0 else 0
        
        # 5. Advisory-Related Rejections
        # Get rejection reasons from metadata
        rejection_reasons = {
            'uncompleted_advisories': 0,
            'no_fault_code': 0,
            'warranty_expired': 0
        }
        
        for ticket in all_tickets:
            if ticket.get('status') == 'Declined - Not Covered':
                # Check metadata for rejection reasons
                metadata = db.get_ticket_metadata(ticket['ticket_id'])
                
                for meta in metadata:
                    if meta['key'] == 'advisories_followed' and meta['value'] == '0':
                        rejection_reasons['uncompleted_advisories'] += 1
                    elif meta['key'] == 'new_fault_codes' and meta['value'] == '0':
                        rejection_reasons['no_fault_code'] += 1
                    elif meta['key'] == 'within_warranty' and meta['value'] == '0':
                        rejection_reasons['warranty_expired'] += 1
        
        # 6. Team Performance
        team_performance = {}
        
        # Get all team members first
        all_members = db.get_all_members()
        
        # Initialize all members with 0 tickets
        for member in all_members:
            if member.get('role', '').lower() != 'administrator':  # Exclude admin users
                team_performance[member['name']] = 0
        
        # Use MongoDB aggregation to get team performance
        pipeline = [
            {
                "$lookup": {
                    "from": "members",
                    "localField": "member_id",
                    "foreignField": "_id",
                    "as": "member"
                }
            },
            {
                "$unwind": "$member"
            },
            {
                "$group": {
                    "_id": "$member.name",
                    "tickets_count": {"$sum": 1}
                }
            }
        ]
        
        try:
            assignments = list(db.ticket_assignments.aggregate(pipeline))
            # Update counts for members who have assignments
            for assignment in assignments:
                team_performance[assignment['_id']] = assignment['tickets_count']
        except Exception as e:
            # Fallback: count assignments manually
            try:
                assignments = list(db.ticket_assignments.find())
                for assignment in assignments:
                    member = db.get_member_by_id(str(assignment['member_id']))
                    if member and member.get('role', '').lower() != 'administrator':
                        name = member['name']
                        team_performance[name] = team_performance.get(name, 0) + 1
            except Exception as fallback_error:
                # Log error in production: Team performance calculation failed
                # If everything fails, at least show team members with 0 tickets
                pass
        
        # Calculate pagination info
        total_pages = (total_tickets + per_page - 1) // per_page
        has_prev = page > 1
        has_next = page < total_pages
        prev_page = page - 1 if has_prev else None
        next_page = page + 1 if has_next else None
        
        pagination_info = {
            'current_page': page,
            'per_page': per_page,
            'total_tickets': total_tickets,
            'total_pages': total_pages,
            'has_prev': has_prev,
            'has_next': has_next,
            'prev_page': prev_page,
            'next_page': next_page,
            'status_filter': status_filter,
            'priority_filter': priority_filter,
            'search_query': search_query
        }
        
        return render_template('dashboard.html',
                            status_counts=status_counts,
                            overdue_tickets=overdue_tickets,
                            open_1_3_days=open_1_3_days,
                            open_today=open_today,
                            avg_resolution_time=avg_resolution_time,
                            total_claims=total_claims,
                            approved_claims=approved_claims,
                            declined_claims=declined_claims,
                            referred_claims=referred_claims,
                            approved_percent=approved_percent,
                            declined_percent=declined_percent,
                            referred_percent=referred_percent,
                            rejection_reasons=rejection_reasons,
                            team_performance=team_performance,
                            all_tickets=all_tickets,
                            current_user=session.get('member_name'),
                            current_user_role=current_user_role,
                            pagination=pagination_info)
    except Exception as e:
        return render_template('error.html', error=f"Database error: {e}"), 500

@app.route('/export/csv')
def export_csv():
    """Export dashboard data as CSV file"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get all tickets with assignment info (reuse the same logic as dashboard)
        tickets = db.get_tickets_with_assignments()
        
        # Convert to dict format for easier manipulation
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
                ticket_dict['is_forwarded'] = assignment.get('is_forwarded', False)
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
                ticket_dict['is_forwarded'] = False
            
            # Get vehicle registration from metadata
            ticket_dict['vehicle_registration'] = ''
            metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
            for meta in metadata:
                if meta['key'] == 'vehicle_registration':
                    ticket_dict['vehicle_registration'] = meta['value']
                    break
            
            all_tickets.append(ticket_dict)
        
        # Create CSV content
        output = io.StringIO()
        fieldnames = [
            'ticket_id', 'status', 'priority', 'created_at', 'updated_at',
            'customer_name', 'customer_email', 'customer_phone',
                            'vehicle_registration', 'assigned_to', 'assigned_at', 'is_forwarded',
            'description', 'notes'
        ]
        
        writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction='ignore')
        writer.writeheader()
        
        for ticket in all_tickets:
            # Format datetime objects for CSV
            row = ticket.copy()
            if isinstance(row.get('created_at'), datetime):
                row['created_at'] = row['created_at'].strftime('%Y-%m-%d %H:%M:%S')
            if isinstance(row.get('updated_at'), datetime):
                row['updated_at'] = row['updated_at'].strftime('%Y-%m-%d %H:%M:%S')
            if isinstance(row.get('assigned_at'), datetime):
                row['assigned_at'] = row['assigned_at'].strftime('%Y-%m-%d %H:%M:%S')
                
            writer.writerow(row)
        
        # Create response
        csv_content = output.getvalue()
        output.close()
        
        # Generate filename with current timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'warranty_dashboard_export_{timestamp}.csv'
        
        response = Response(
            csv_content,
            mimetype='text/csv',
            headers={
                'Content-Disposition': f'attachment; filename={filename}'
            }
        )
        
        return response
        
    except Exception as e:
        return render_template('error.html', error=f"Export error: {e}"), 500

@app.route('/export/pdf')
def export_pdf():
    """Export dashboard data as PDF file"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        
        # Get all tickets with assignment info (reuse the same logic as dashboard)
        tickets = db.get_tickets_with_assignments()
        
        # Convert to dict format for easier manipulation
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
            
            # Get vehicle registration from metadata
            ticket_dict['vehicle_registration'] = ''
            metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
            for meta in metadata:
                if meta['key'] == 'vehicle_registration':
                    ticket_dict['vehicle_registration'] = meta['value']
                    break
            
            all_tickets.append(ticket_dict)
        
        # Calculate dashboard statistics
        status_counts = {}
        for ticket in all_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        total_claims = len(all_tickets)
        approved_claims = len([t for t in all_tickets if t['status'] == 'Approved - Revisit Booked'])
        declined_claims = len([t for t in all_tickets if t['status'] == 'Declined - Not Covered'])
        referred_claims = len([t for t in all_tickets if t['status'] == 'Referred to Tech Director'])
        
        # Create PDF content
        output = io.BytesIO()
        doc = SimpleDocTemplate(output, pagesize=A4, rightMargin=72, leftMargin=72,
                               topMargin=72, bottomMargin=18)
        
        # Container for the 'Flowable' objects
        elements = []
        
        # Get styles
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=18,
            spaceAfter=30,
            alignment=1  # Center alignment
        )
        
        # Add title
        elements.append(Paragraph("Warranty Dashboard Report", title_style))
        elements.append(Spacer(1, 12))
        
        # Add generation timestamp
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        elements.append(Paragraph(f"Generated on: {timestamp}", styles['Normal']))
        elements.append(Spacer(1, 20))
        
        # Add summary statistics
        elements.append(Paragraph("Summary Statistics", styles['Heading2']))
        
        summary_data = [
            ['Total Claims', str(total_claims)],
            ['Approved Claims', f"{approved_claims} ({(approved_claims / total_claims * 100) if total_claims > 0 else 0:.1f}%)"],
            ['Declined Claims', f"{declined_claims} ({(declined_claims / total_claims * 100) if total_claims > 0 else 0:.1f}%)"],
            ['Referred Claims', f"{referred_claims} ({(referred_claims / total_claims * 100) if total_claims > 0 else 0:.1f}%)"]
        ]
        
        summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
        summary_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        elements.append(summary_table)
        elements.append(Spacer(1, 20))
        
        # Add status breakdown
        elements.append(Paragraph("Status Breakdown", styles['Heading2']))
        
        status_data = [['Status', 'Count']]
        for status, count in status_counts.items():
            status_data.append([status, str(count)])
        
        status_table = Table(status_data, colWidths=[4*inch, 1*inch])
        status_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        elements.append(status_table)
        elements.append(Spacer(1, 20))
        
        # Add detailed ticket list (first 20 tickets to avoid huge PDFs)
        elements.append(Paragraph("Recent Tickets (Latest 20)", styles['Heading2']))
        
        ticket_data = [['Ticket ID', 'Status', 'Customer', 'Created', 'Assigned To']]
        
        # Sort tickets by creation date (newest first) and take first 20
        sorted_tickets = sorted(all_tickets, 
                               key=lambda x: x.get('created_at', datetime.min) if isinstance(x.get('created_at'), datetime) else datetime.min, 
                               reverse=True)[:20]
        
        for ticket in sorted_tickets:
            created_date = ""
            if isinstance(ticket.get('created_at'), datetime):
                created_date = ticket['created_at'].strftime('%Y-%m-%d')
            elif ticket.get('created_at'):
                try:
                    created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                    created_date = created_at.strftime('%Y-%m-%d')
                except:
                    created_date = str(ticket.get('created_at', ''))[:10]
            
            ticket_data.append([
                ticket.get('ticket_id', '')[:10],  # Truncate long IDs
                ticket.get('status', '')[:20],     # Truncate long status
                ticket.get('customer_name', '')[:15],  # Truncate long names
                created_date,
                ticket.get('assigned_to', 'Unassigned')[:15]  # Truncate long names
            ])
        
        ticket_table = Table(ticket_data, colWidths=[1.2*inch, 1.5*inch, 1.2*inch, 1*inch, 1.1*inch])
        ticket_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('FONTSIZE', (0, 1), (-1, -1), 8),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('VALIGN', (0, 0), (-1, -1), 'TOP'),
        ]))
        elements.append(ticket_table)
        
        # Build PDF
        doc.build(elements)
        
        # Get PDF content
        pdf_content = output.getvalue()
        output.close()
        
        # Generate filename with current timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'warranty_dashboard_report_{timestamp}.pdf'
        
        response = Response(
            pdf_content,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'attachment; filename={filename}'
            }
        )
        
        return response
        
    except Exception as e:
        return render_template('error.html', error=f"PDF Export error: {e}"), 500

# Enhanced API endpoint for getting dashboard data with date filtering
@app.route('/api/ticket/analysis/<ticket_id>')
def ticket_analysis(ticket_id):
    """Get detailed analysis of ticket origin and structure"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Get ticket origin analysis
        origin_info = identify_ticket_origin(ticket)
        
        return jsonify({
            'status': 'success',
            'ticket_id': ticket_id,
            'origin_analysis': origin_info,
            'creation_method': ticket.get('creation_method', 'unknown'),
            'created_at': str(ticket.get('created_at', '')),
            'thread_id': ticket.get('thread_id', ''),
        })
    except Exception as e:
        app.logger.error(f"Error analyzing ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/dashboard/data', methods=['GET'])
def dashboard_data():
    """API endpoint to get dashboard data for AJAX updates with date filtering"""
    app.logger.info(" API: Dashboard data request received")
    
    # Enhanced session validation
    if 'member_id' not in session:
        app.logger.warning("API: Unauthorized access attempt - no member_id in session")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Please log in again'}), 401
    
    if not session.get('member_id'):
        app.logger.warning("API: Unauthorized access attempt - empty member_id in session")
        return jsonify({'status': 'error', 'message': 'Unauthorized - Invalid session'}), 401
    
    try:
        app.logger.info("API: Getting database connection")
        db = get_db()
        app.logger.info("API: Database connection successful")
        
        # Get date range parameters
        start_date_str = request.args.get('start_date')
        end_date_str = request.args.get('end_date')
        
        # Parse dates if provided
        start_date = None
        end_date = None
        try:
            if start_date_str:
                start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
            if end_date_str:
                end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
                end_date = end_date.replace(hour=23, minute=59, second=59)  # End of day
        except ValueError as e:
            app.logger.warning(f"Invalid date format provided: {e}")
            # Continue without date filtering
            start_date = None
            end_date = None
        
        # Get all tickets with assignment info with error handling
        try:
            app.logger.info("API: Attempting to get tickets with assignments")
            tickets = db.get_tickets_with_assignments()
            if not tickets:
                app.logger.warning("API: No tickets found in database")
                tickets = []
            else:
                app.logger.info(f"API: Successfully retrieved {len(tickets)} tickets with assignments")
        except Exception as e:
            app.logger.error(f"API: Failed to get tickets with assignments: {e}")
            # Fallback to simple ticket fetch
            try:
                app.logger.info("API: Attempting fallback ticket fetch")
                tickets = list(db.tickets.find().sort([("created_at", -1)]))
                app.logger.info(f"API: Fallback ticket fetch returned {len(tickets)} tickets")
            except Exception as fallback_error:
                app.logger.error(f"API: Fallback ticket fetch also failed: {fallback_error}")
                # Return empty response instead of crashing
                return jsonify({
                    'status': 'error',
                    'message': 'Database temporarily unavailable. Please try again later.',
                    'data': {
                        'total_tickets': 0,
                        'status_counts': {},
                        'priority_counts': {},
                        'classification_counts': {},
                        'outstanding_claims': {'overdue': 0, 'open_1_3_days': 0, 'open_today': 0, 'overdue_tickets': []},
                        'resolution_metrics': {'avg_resolution_time': 0, 'resolved_count': 0},
                        'claim_outcomes': {'approved': 0, 'declined': 0, 'referred': 0, 'warranty_received': 0, 'approved_percent': 0, 'declined_percent': 0, 'referred_percent': 0},
                        'date_range': {'start_date': start_date_str, 'end_date': end_date_str, 'filtered': False}
                    }
                }), 503
        
        # Convert to dict format and apply date filtering
        app.logger.info(f"API: Processing {len(tickets)} tickets")
        all_tickets = []
        for ticket in tickets:
            ticket_dict = dict(ticket)
            
            # Convert ObjectId to string
            ticket_dict['_id'] = str(ticket_dict['_id'])
            
            # Convert any other ObjectId fields that might cause JSON serialization issues
            if 'member_id' in ticket_dict and hasattr(ticket_dict['member_id'], '__class__') and ticket_dict['member_id'].__class__.__name__ == 'ObjectId':
                ticket_dict['member_id'] = str(ticket_dict['member_id'])
            
            # Handle assignment ObjectIds
            if 'assignment' in ticket_dict and isinstance(ticket_dict['assignment'], list):
                for assignment in ticket_dict['assignment']:
                    if isinstance(assignment, dict):
                        if 'member_id' in assignment and hasattr(assignment['member_id'], '__class__') and assignment['member_id'].__class__.__name__ == 'ObjectId':
                            assignment['member_id'] = str(assignment['member_id'])
                        if 'forwarded_from' in assignment and hasattr(assignment['forwarded_from'], '__class__') and assignment['forwarded_from'].__class__.__name__ == 'ObjectId':
                            assignment['forwarded_from'] = str(assignment['forwarded_from'])
            
            # Handle assigned_member ObjectIds
            if 'assigned_member' in ticket_dict and isinstance(ticket_dict['assigned_member'], list):
                for member in ticket_dict['assigned_member']:
                    if isinstance(member, dict) and '_id' in member and hasattr(member['_id'], '__class__') and member['_id'].__class__.__name__ == 'ObjectId':
                        member['_id'] = str(member['_id'])
            
            # Handle forwarded_from_member ObjectIds
            if 'forwarded_from_member' in ticket_dict and isinstance(ticket_dict['forwarded_from_member'], list):
                for member in ticket_dict['forwarded_from_member']:
                    if isinstance(member, dict) and '_id' in member and hasattr(member['_id'], '__class__') and member['_id'].__class__.__name__ == 'ObjectId':
                        member['_id'] = str(member['_id'])
            
            # Handle assignment info
            if ticket_dict.get('assignment') and len(ticket_dict['assignment']) > 0:
                assignment = ticket_dict['assignment'][0]
                if ticket_dict.get('assigned_member') and len(ticket_dict['assigned_member']) > 0:
                    member = ticket_dict['assigned_member'][0]
                    ticket_dict['assigned_to'] = member.get('name', 'Unassigned')
                    ticket_dict['assigned_to_gender'] = member.get('gender', '')
                else:
                    ticket_dict['assigned_to'] = 'Unassigned'
                    ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = assignment.get('assigned_at', '')
                ticket_dict['is_forwarded'] = assignment.get('is_forwarded', False)
                
                # Handle forwarded from member info
                if ticket_dict['is_forwarded'] and ticket_dict.get('forwarded_from_member') and len(ticket_dict['forwarded_from_member']) > 0:
                    forwarded_member = ticket_dict['forwarded_from_member'][0]
                    ticket_dict['forwarded_from_name'] = forwarded_member.get('name')
            else:
                ticket_dict['assigned_to'] = 'Unassigned'
                ticket_dict['assigned_to_gender'] = ''
                ticket_dict['assigned_at'] = ''
                ticket_dict['is_forwarded'] = False
            
            # Get vehicle registration from metadata
            try:
                metadata = db.get_ticket_metadata(ticket_dict['ticket_id'])
                for meta in metadata:
                    if meta['key'] == 'vehicle_registration':
                        ticket_dict['vehicle_registration'] = meta['value']
                        break
            except Exception as e:
                app.logger.warning(f"Error getting metadata for API ticket {ticket_dict.get('ticket_id')}: {e}")
                ticket_dict['vehicle_registration'] = ''
            
            # Set default values for missing fields that template expects
            ticket_dict.setdefault('has_warranty', False)
            ticket_dict.setdefault('has_attachments', False)
            ticket_dict.setdefault('attachments', [])
            ticket_dict.setdefault('priority', 'Medium')
            ticket_dict.setdefault('classification', 'General')
            ticket_dict.setdefault('subject', ticket_dict.get('body', '')[:100] if ticket_dict.get('body') else 'No Subject')
            ticket_dict.setdefault('body', 'No description available')
            ticket_dict.setdefault('warranty_forms_count', 0)
            ticket_dict.setdefault('creation_method', 'auto-detect')
            ticket_dict.setdefault('thread_id', None)
            ticket_dict.setdefault('email', None)
            
            # Check if ticket has attachments
            if ticket_dict.get('attachments') and len(ticket_dict['attachments']) > 0:
                ticket_dict['has_attachments'] = True
            
            # Check if ticket has warranty (basic check)
            if ticket_dict.get('classification') == 'Warranty Claim':
                ticket_dict['has_warranty'] = True
            
            # Parse created_at for filtering
            if 'created_at' in ticket_dict and ticket_dict['created_at']:
                if isinstance(ticket_dict['created_at'], datetime):
                    created_at = ticket_dict['created_at']
                else:
                    try:
                        created_at = datetime.strptime(str(ticket_dict['created_at']), "%Y-%m-%d %H:%M:%S")
                    except:
                        continue  # Skip tickets with invalid dates
                
                # Apply date filtering
                if start_date and created_at < start_date:
                    continue
                if end_date and created_at > end_date:
                    continue
                
                ticket_dict['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                ticket_dict['created_at_dt'] = created_at
            
            all_tickets.append(ticket_dict)
        
        #  DYNAMIC WARRANTY CLASSIFICATION: Update classification for tickets with warranty attachments
        for ticket_dict in all_tickets:
            ticket_id = ticket_dict.get('ticket_id')
            if ticket_id:
                try:
                    # Check if ticket has warranty attachments
                    metadata = db.get_ticket_metadata(ticket_id)
                    has_warranty_attachment = False
                    
                    if metadata:
                        for meta in metadata:
                            try:
                                # Ensure meta is a dictionary
                                if not isinstance(meta, dict):
                                    continue
                                
                                meta_value = meta.get('value')
                                if isinstance(meta_value, str):
                                    # Handle potential malformed JSON
                                    if meta_value.strip() and meta_value.strip() not in ['{}', '']:
                                        try:
                                            # Clean JSON before parsing
                                            clean_json = meta_value.strip()
                                            # Remove trailing commas and fix common JSON issues
                                            if clean_json.endswith(',}'):
                                                clean_json = clean_json[:-2] + '}'
                                            elif clean_json.endswith(',]'):
                                                clean_json = clean_json[:-2] + ']'
                                            # Remove any leading/trailing whitespace and quotes
                                            clean_json = clean_json.strip().strip('"\'')
                                            # Skip if still empty after cleaning
                                            if not clean_json or clean_json in ['{}', '[]', 'null', 'undefined']:
                                                meta_data = {}
                                            else:
                                                meta_data = json.loads(clean_json)
                                        except json.JSONDecodeError as json_err:
                                            # Only log if it's actually malformed, not just empty
                                            if meta_value.strip() and meta_value.strip() not in ['{}', '[]', 'null', 'undefined', '']:
                                                app.logger.debug(f"Skipping malformed JSON in API metadata: {json_err} - Value: {meta_value[:50]}")
                                            meta_data = {}
                                    else:
                                        meta_data = {}
                                elif isinstance(meta_value, dict):
                                    meta_data = meta_value
                                else:
                                    meta_data = {}
                                
                                # Check if this attachment is warranty-related
                                if isinstance(meta_data, dict):
                                    is_warranty = meta_data.get('is_warranty', False)
                                    if is_warranty:
                                        has_warranty_attachment = True
                                        break
                            except (json.JSONDecodeError, TypeError, AttributeError) as e:
                                app.logger.warning(f"Error processing API metadata for ticket {ticket_id}: {e}")
                                continue
                    
                    # Also check direct has_warranty flag on ticket
                    has_warranty_flag = ticket_dict.get('has_warranty', False)
                    
                    # If ticket has warranty attachments or warranty flag, ensure classification is "Warranty Claim"
                    if has_warranty_attachment or has_warranty_flag:
                        original_classification = ticket_dict.get('classification')
                        ticket_dict['classification'] = 'Warranty Claim'
                        
                        if original_classification != 'Warranty Claim':
                            app.logger.info(f" API DASHBOARD WARRANTY CLASSIFICATION: Ticket {ticket_id} updated from '{original_classification}' to 'Warranty Claim'")
                
                except Exception as e:
                    app.logger.error(f"Error checking warranty status for API ticket {ticket_id}: {e}")
        
        # Calculate comprehensive statistics - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(all_tickets)
        
        # 1. Ticket Status Breakdown
        status_counts = {}
        for ticket in all_tickets:
            status = ticket.get('status', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        # 2. Priority Breakdown
        priority_counts = {}
        for ticket in all_tickets:
            priority = ticket.get('priority', 'Medium')
            priority_counts[priority] = priority_counts.get(priority, 0) + 1
        
        # 3. Classification Breakdown
        classification_counts = {}
        for ticket in all_tickets:
            classification = ticket.get('classification', 'General')
            classification_counts[classification] = classification_counts.get(classification, 0) + 1
        
        # 4. Outstanding Claims Analysis
        now = datetime.now()
        overdue_tickets = []
        open_1_3_days = []
        open_today = []
        
        for ticket in all_tickets:
            if 'created_at_dt' in ticket:
                days_open = (now - ticket['created_at_dt']).days
                
                if days_open > 3:
                    overdue_tickets.append(ticket)
                elif 1 <= days_open <= 3:
                    open_1_3_days.append(ticket)
                elif days_open == 0:
                    open_today.append(ticket)
        
        # 5. Average Resolution Time
        resolved_tickets = [t for t in all_tickets if t.get('status') in ['Resolved', 'Closed']]
        avg_resolution_time = 0
        total_resolution_time = 0
        
        for ticket in resolved_tickets:
            try:
                if 'created_at_dt' in ticket and 'updated_at' in ticket:
                    created_at = ticket['created_at_dt']
                    
                    if isinstance(ticket['updated_at'], datetime):
                        updated_at = ticket['updated_at']
                    else:
                        updated_at = datetime.strptime(str(ticket['updated_at']), "%Y-%m-%d %H:%M:%S")
                    
                    resolution_time = (updated_at - created_at).total_seconds() / 3600  # in hours
                    total_resolution_time += resolution_time
            except:
                continue
        
        if resolved_tickets:
            avg_resolution_time = total_resolution_time / len(resolved_tickets)
        
        # 6. Claim Outcomes
        approved_claims = len([t for t in all_tickets if t.get('status') == 'Approved - Revisit Booked'])
        declined_claims = len([t for t in all_tickets if t.get('status') == 'Declined - Not Covered'])
        referred_claims = len([t for t in all_tickets if t.get('status') == 'Referred to Tech Director'])
        warranty_received = len([t for t in all_tickets if t.get('status') == 'Warranty Form Received'])
        
        # Calculate percentages
        approved_percent = (approved_claims / total_tickets * 100) if total_tickets > 0 else 0
        declined_percent = (declined_claims / total_tickets * 100) if total_tickets > 0 else 0
        referred_percent = (referred_claims / total_tickets * 100) if total_tickets > 0 else 0
        
        app.logger.info(f"API: Successfully processed dashboard data - {total_tickets} tickets")
        
        # Final safety check: ensure no ObjectIds remain in the response data
        try:
            response_data = {
                'status': 'success',
                'data': {
                    'total_tickets': total_tickets,
                    'status_counts': status_counts,
                    'priority_counts': priority_counts,
                    'classification_counts': classification_counts,
                    'outstanding_claims': {
                        'overdue': len(overdue_tickets),
                        'open_1_3_days': len(open_1_3_days),
                        'open_today': len(open_today),
                        'overdue_tickets': overdue_tickets[:5]  # Top 5 most urgent
                    },
                    'resolution_metrics': {
                        'avg_resolution_time': avg_resolution_time,
                        'resolved_count': len(resolved_tickets)
                    },
                    'claim_outcomes': {
                        'approved': approved_claims,
                        'declined': declined_claims,
                        'referred': referred_claims,
                        'warranty_received': warranty_received,
                        'approved_percent': approved_percent,
                        'declined_percent': declined_percent,
                        'referred_percent': referred_percent
                    },
                    'date_range': {
                        'start_date': start_date_str,
                        'end_date': end_date_str,
                        'filtered': bool(start_date_str or end_date_str)
                    }
                }
            }
            
            # Test JSON serialization to catch any remaining ObjectIds
            json.dumps(response_data)
            app.logger.info("API: JSON serialization test passed")
            
            return jsonify(response_data)
            
        except TypeError as e:
            app.logger.error(f"API: JSON serialization failed due to ObjectId: {e}")
            # Return a simplified response without problematic data
            return jsonify({
                'status': 'success',
                'data': {
                    'total_tickets': total_tickets,
                    'status_counts': status_counts,
                    'priority_counts': priority_counts,
                    'classification_counts': classification_counts,
                    'outstanding_claims': {
                        'overdue': len(overdue_tickets),
                        'open_1_3_days': len(open_1_3_days),
                        'open_today': len(open_today),
                        'overdue_tickets': []  # Skip detailed ticket data to avoid ObjectId issues
                    },
                    'resolution_metrics': {
                        'avg_resolution_time': avg_resolution_time,
                        'resolved_count': len(resolved_tickets)
                    },
                    'claim_outcomes': {
                        'approved': approved_claims,
                        'declined': declined_claims,
                        'referred': referred_claims,
                        'warranty_received': warranty_received,
                        'approved_percent': approved_percent,
                        'declined_percent': declined_percent,
                        'referred_percent': referred_percent
                    },
                    'date_range': {
                        'start_date': start_date_str,
                        'end_date': end_date_str,
                        'filtered': bool(start_date_str or end_date_str)
                    }
                }
            })
    except Exception as e:
        app.logger.error(f"Error getting dashboard data: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# AI-based warranty form detection (placeholder for future AI integration)
def analyze_warranty_form(file_path, filename):
    """
    Analyze uploaded file to determine if it's a warranty form
    This is a placeholder for future AI integration
    """
    try:
        # For now, simple heuristic based on filename and extension
        filename_lower = filename.lower()
        
        # Check for warranty-related keywords in filename
        warranty_keywords = ['warranty', 'claim', 'form', 'dpf', 'service', 'guarantee']
        has_warranty_keyword = any(keyword in filename_lower for keyword in warranty_keywords)
        
        # Check file extension
        valid_extensions = ['.pdf', '.doc', '.docx', '.jpg', '.jpeg', '.png']
        has_valid_extension = any(filename_lower.endswith(ext) for ext in valid_extensions)
        
        # Simple confidence calculation
        confidence = 0
        if has_warranty_keyword:
            confidence += 70
        if has_valid_extension:
            confidence += 30
        
        # Return analysis result
        return {
            'is_warranty_form': confidence >= 70,
            'confidence': confidence,
            'analysis': {
                'has_warranty_keywords': has_warranty_keyword,
                'valid_file_type': has_valid_extension,
                'detected_keywords': [kw for kw in warranty_keywords if kw in filename_lower]
            }
        }
    except Exception as e:
        app.logger.error(f"Error analyzing warranty form: {e}")
        return {
            'is_warranty_form': False,
            'confidence': 0,
            'analysis': {'error': str(e)}
        }

# API endpoint for warranty form analysis
@app.route('/api/tickets/<ticket_id>/analyze-warranty-form', methods=['POST'])
def analyze_ticket_warranty_form(ticket_id):
    """Analyze warranty form and suggest status update"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get ticket metadata to check for warranty form
        metadata = db.get_ticket_metadata(ticket_id)
        
        warranty_form_path = None
        for item in metadata:
            if item['key'] == 'warranty_form':
                warranty_form_path = item['value']
                break
        
        if not warranty_form_path:
            return jsonify({
                'status': 'error', 
                'message': 'No warranty form found for this ticket'
            }), 404
        
        # Extract filename from path
        filename = os.path.basename(warranty_form_path)
        
        # Analyze the warranty form
        analysis_result = analyze_warranty_form(warranty_form_path, filename)
        
        # Add suggested actions
        suggestions = []
        if analysis_result['is_warranty_form']:
            suggestions.append({
                'action': 'update_status',
                'status': 'Warranty Form Received',
                'reason': f"AI detected warranty form with {analysis_result['confidence']}% confidence"
            })
            suggestions.append({
                'action': 'notify_team',
                'message': 'Warranty form detected and ready for manual verification'
            })
        else:
            suggestions.append({
                'action': 'manual_review',
                'reason': f"Low confidence ({analysis_result['confidence']}%) - manual review recommended"
            })
        
        return jsonify({
            'status': 'success',
            'analysis': analysis_result,
            'suggestions': suggestions,
            'requires_manual_confirmation': True
        })
        
    except Exception as e:
        app.logger.error(f"Error analyzing warranty form for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Analysis failed'}), 500

# API endpoint to confirm AI warranty form detection
@app.route('/api/tickets/<ticket_id>/confirm-warranty-form', methods=['POST'])
def confirm_warranty_form(ticket_id):
    """Confirm AI warranty form detection and update status"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        is_correct = data.get('is_correct', False)
        user_feedback = data.get('feedback', '')
        
        db = get_db()
        
        if is_correct:
            # Update ticket status to "Warranty Form Received"
            db.update_ticket(ticket_id, {'status': 'Warranty Form Received'})
            
            # Log successful AI detection
            app.logger.info(f"AI warranty form detection confirmed for ticket {ticket_id} by {session.get('member_name')}")
            
            return jsonify({
                'status': 'success',
                'message': 'Warranty form confirmed and ticket status updated',
                'new_status': 'Warranty Form Received'
            })
        else:
            # Log incorrect AI detection for improvement
            app.logger.warning(f"AI warranty form detection incorrect for ticket {ticket_id}. Feedback: {user_feedback}")
            
            return jsonify({
                'status': 'success',
                'message': 'Feedback recorded. Please upload the correct warranty form.',
                'action_required': 'request_correct_form'
            })
        
    except Exception as e:
        app.logger.error(f"Error confirming warranty form for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Confirmation failed'}), 500

# Add route for the create ticket page
@app.route('/technicians')
def technicians_management():
    """Technicians management page"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if current user is admin
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return render_template('error.html', error="Access denied. Administrator access required."), 403
    
    try:
        db = get_db()
        technicians = db.get_all_technicians()
        for tech in technicians:
            tech['_id'] = str(tech['_id'])
        
        return render_template('technicians.html', 
                         technicians=technicians,
                         current_user=session.get('member_name'),
                         current_user_role=session.get('member_role'))
    except Exception as e:
        app.logger.error(f"Error loading technicians page: {e}")
        return render_template('error.html', error="Failed to load technicians page"), 500

@app.route('/create-ticket')
def create_ticket_form():
    """Display form for creating a new ticket"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    try:
        db = get_db()
        # Get all technicians for the dropdown
        technicians = db.get_all_technicians()
        for tech in technicians:
            tech['_id'] = str(tech['_id'])
        
        # Get current user info for navbar
        current_member = db.get_member_by_id(session['member_id'])
        current_user_role = current_member['role'] if current_member else 'Unknown'
        
        return render_template('create_ticket.html', 
                         technicians=technicians,
                         current_user=session.get('member_name'),
                         current_user_role=current_user_role)
    except Exception as e:
        app.logger.error(f"Error loading create ticket form: {e}")
        return render_template('create_ticket.html', 
                         technicians=[],
                         current_user=session.get('member_name'),
                         current_user_role=session.get('member_role', 'Unknown'))

# Add API endpoint for ticket creation with new structured fields
@app.route('/api/dashboard/updates', methods=['POST'])
def dashboard_updates():
    """
    API endpoint to provide real-time dashboard updates
    Returns only changed data to minimize bandwidth and improve performance
    """
    try:
        # Enhanced session validation with automatic restoration
        if 'member_id' not in session:
            app.logger.warning(f"Dashboard updates API called without valid session from {request.remote_addr}")
            
            # Try to restore the session before giving up
            if check_and_restore_session():
                app.logger.info(f"Session restored successfully for dashboard updates API")
            else:
                app.logger.warning(f"Failed to restore session for dashboard updates API")
                return jsonify({'status': 'error', 'message': 'Session expired - Please select your portal again'}), 401
        
        # Sessions are permanent - no timeout checks needed
        # Users stay logged in forever
        
        data = request.json
        if not data:
            return jsonify({'status': 'error', 'message': 'Invalid request data'}), 400
            
        last_update = data.get('last_update', 0)
        current_tickets = data.get('current_tickets', [])
        
        # Convert timestamp to datetime
        last_update_dt = datetime.fromtimestamp(last_update / 1000) if last_update > 0 else datetime.min
        
        db = get_db()
        
        # Get all tickets with assignments
        all_tickets = db.get_tickets_with_assignments()
        
        # Check for new tickets
        new_tickets = []
        updated_tickets = []
        removed_tickets = []
        
        # Process tickets to find changes
        for ticket in all_tickets:
            ticket_id = ticket.get('ticket_id')
            created_at = ticket.get('created_at')
            
            if created_at and created_at > last_update_dt:
                # New ticket
                new_tickets.append({
                    'ticket_id': ticket_id,
                    'name': ticket.get('name', 'Unknown'),
                    'subject': ticket.get('subject', 'No Subject'),
                    'body': ticket.get('body', ''),
                    'priority': ticket.get('priority', 'Medium'),
                    'classification': ticket.get('classification', 'General'),
                    'status': ticket.get('status', 'New'),
                    'has_attachments': ticket.get('has_attachments', False),
                    'has_warranty': ticket.get('has_warranty', False),
                    'has_unread_reply': ticket.get('has_unread_reply', False),
                    'created_at': created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at),
                    'date': created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at)
                })
            elif ticket_id in current_tickets:
                # Check if existing ticket has updates
                # For now, we'll consider all existing tickets as potentially updated
                # In a more sophisticated implementation, you could track modification times
                pass
        
        # Calculate current stats - FIXED: Use database total count
        # total_tickets should come from database.get_tickets_count() not len(all_tickets)
        open_tickets = len([t for t in all_tickets if t.get('status') == 'Open'])
        resolved_tickets = len([t for t in all_tickets if t.get('status') == 'Resolved'])
        waiting_tickets = len([t for t in all_tickets if t.get('status') == 'Waiting for Response'])
        
        # Calculate breakdowns
        priorities = {}
        classifications = {}
        for ticket in all_tickets:
            priority = ticket.get('priority', 'Medium')
            classification = ticket.get('classification', 'General')
            
            priorities[priority] = priorities.get(priority, 0) + 1
            classifications[classification] = classifications.get(classification, 0) + 1
        
        has_updates = len(new_tickets) > 0 or len(updated_tickets) > 0 or len(removed_tickets) > 0
        
        app.logger.debug(f"Dashboard updates API: {len(new_tickets)} new, {len(updated_tickets)} updated tickets for user {session.get('member_name', 'Unknown')}")
        
        return jsonify({
            'status': 'success',
            'has_updates': has_updates,
            'stats': {
                'total_tickets': total_tickets,
                'open_tickets': open_tickets,
                'resolved_tickets': resolved_tickets,
                'waiting_tickets': waiting_tickets
            },
            'tickets': {
                'new_tickets': new_tickets,
                'updated_tickets': updated_tickets,
                'removed_tickets': removed_tickets
            },
            'breakdowns': {
                'priorities': priorities,
                'classifications': classifications
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error in dashboard updates: {e}")
        return jsonify({'status': 'error', 'message': 'Internal server error'}), 500

@app.route('/api/tickets', methods=['POST'])
def n8n_tickets_api():
    """
    [FIXED] N8N TICKETS CREATION ENDPOINT - Creates actual tickets in database
    
    Designed specifically for n8n workflows:
    - No authentication required (perfect for n8n)
    - ACCEPTS any ticket ID format from N8N (GS5160, EO5267, TO3356, etc.)
    - CREATES tickets in database for frontend display
    - Handles attachments and saves them to disk
    - Full ticket processing with database storage
    - Always returns proper success/error responses
    - Perfect for N8N workflows that need to create real tickets
    """
    try:
        # Get request data (same as working simple app)
        raw_data = request.get_data()
        app.logger.info(f"[FIX] N8N /api/tickets received request: Content-Type={request.content_type}, Size={len(raw_data)}")
        
        # Parse JSON data (same as working simple app)
        try:
            if request.is_json:
                data = request.get_json()
            else:
                # Try to parse as JSON anyway
                data = json.loads(raw_data.decode('utf-8'))
        except Exception as json_error:
                app.logger.error(f"[ERROR] JSON parsing error: {json_error}")
                return jsonify({
                'success': False,
                'message': f'Invalid JSON format: {str(json_error)}'
                }), 400
            
        app.logger.info(f"? Parsed data type: {type(data)}")
        
        # [CRITICAL DEBUG] Log the exact data received to identify ticket ID issue
        app.logger.info(f"[DEBUG] RECEIVED DATA ANALYSIS:")
        app.logger.info(f"  - Raw data length: {len(raw_data)} bytes")
        app.logger.info(f"  - Content-Type: {request.content_type}")
        app.logger.info(f"  - Parsed data type: {type(data)}")
        if isinstance(data, dict):
            app.logger.info(f"  - Top-level keys: {list(data.keys())}")
            if 'ticket_id' in data:
                app.logger.info(f"  - ticket_id field: '{data['ticket_id']}' (type: {type(data['ticket_id'])})")
            else:
                app.logger.info(f"  - âŒ NO ticket_id field found in top-level data!")
        elif isinstance(data, list):
            app.logger.info(f"  - Array length: {len(data)}")
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    app.logger.info(f"  - Item {i} keys: {list(item.keys())}")
                    if 'ticket_id' in item:
                        app.logger.info(f"  - Item {i} ticket_id: '{item['ticket_id']}'")
                    elif 'complete' in item:
                        app.logger.info(f"  - Item {i} has 'complete' field (length: {len(str(item['complete']))})")
                else:
                    app.logger.info(f"  - Item {i} type: {type(item)}")
        else:
            app.logger.info(f"  - Unexpected data structure: {data}")
        
        # [CRITICAL FIX] Extract and preserve N8N ticket ID from ANY location in the data
        preserved_n8n_ticket_id = None
        
        # Search for ticket_id in the data structure
        if isinstance(data, dict) and 'ticket_id' in data:
            preserved_n8n_ticket_id = data['ticket_id']
            app.logger.info(f"[CRITICAL] Found N8N ticket ID at top level: {preserved_n8n_ticket_id}")
        elif isinstance(data, list):
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    # Check direct ticket_id
                    if 'ticket_id' in item:
                        preserved_n8n_ticket_id = item['ticket_id']
                        app.logger.info(f"[CRITICAL] Found N8N ticket ID in array item {i}: {preserved_n8n_ticket_id}")
                        break
                    
                    # Check in 'complete' field
                    elif 'complete' in item:
                        try:
                            clean_json = item['complete'].strip()
                            if clean_json.endswith(',}'):
                                clean_json = clean_json[:-2] + '}'
                            elif clean_json.endswith(',]'):
                                clean_json = clean_json[:-2] + ']'
                            
                            parsed_complete = json.loads(clean_json)
                            if isinstance(parsed_complete, dict) and 'ticket_id' in parsed_complete:
                                preserved_n8n_ticket_id = parsed_complete['ticket_id']
                                app.logger.info(f"[CRITICAL] Found N8N ticket ID in complete field of item {i}: {preserved_n8n_ticket_id}")
                                break
                        except Exception as parse_error:
                            app.logger.warning(f"[CRITICAL] Failed to parse complete field for item {i}: {parse_error}")
        
        if preserved_n8n_ticket_id:
            app.logger.info(f"[CRITICAL] ðŸŽ¯ N8N TICKET ID PRESERVED: {preserved_n8n_ticket_id}")
        else:
            app.logger.warning(f"[CRITICAL] âš ï¸ NO N8N TICKET ID FOUND in the data structure!")
        
        # Process data and create tickets in database (FIXED - now creates real tickets)
        processed_tickets = []
        
        # Case 1: Direct ticket data structure
        if isinstance(data, dict) and any(key in data for key in ['threadId', 'ticket_id', 'name', 'body', 'from']):
            app.logger.info("[DEBUG] Processing direct ticket data structure")
            # Pass preserved ticket ID if available
            if preserved_n8n_ticket_id:
                data['_preserved_n8n_ticket_id'] = preserved_n8n_ticket_id
            ticket = process_n8n_ticket_data(data)
            if ticket:
                processed_tickets.append(ticket)
                
        # Case 2: Array of data items
        elif isinstance(data, list):
            app.logger.info(f"[DEBUG] Processing array with {len(data)} items")
            
            # Special handling for your n8n format with "complete" fields
            complete_items = []
            attachments_data = []
            ticket_data_item = None
            
            # [ENHANCED DEBUG] Log the complete field parsing process
            app.logger.info(f"[DEBUG] Processing N8N 'complete' field format:")
            
            # First pass: collect and parse all "complete" items
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    # Check if item has ticket fields directly
                    if any(key in item for key in ['threadId', 'ticket_id', 'name', 'body', 'from']):
                        app.logger.info(f"[DEBUG] Item {i} has direct ticket fields: {list(item.keys())}")
                        ticket = process_n8n_ticket_data(item)
                        if ticket:
                            processed_tickets.append(ticket)
                    # Check if item has 'complete' field with JSON data (your real n8n format)
                    elif 'complete' in item:
                        app.logger.info(f"[DEBUG] Item {i} has 'complete' field, length: {len(str(item['complete']))}")
                        try:
                            # Clean JSON before parsing
                            clean_json = item['complete'].strip()
                            if clean_json.endswith(',}'):
                                clean_json = clean_json[:-2] + '}'
                            elif clean_json.endswith(',]'):
                                clean_json = clean_json[:-2] + ']'
                            
                            app.logger.info(f"[DEBUG] Cleaned JSON for item {i}: {clean_json[:100]}...")
                            parsed_data = json.loads(clean_json)
                            
                            if isinstance(parsed_data, dict):
                                complete_items.append(parsed_data)
                                app.logger.info(f"[DEBUG] Parsed complete item {i}: {list(parsed_data.keys())}")
                                
                                # [CRITICAL] Check if this contains the ticket_id we're looking for
                                if 'ticket_id' in parsed_data:
                                    app.logger.info(f"[DEBUG] âœ… FOUND ticket_id in complete item {i}: '{parsed_data['ticket_id']}'")
                                else:
                                    app.logger.info(f"[DEBUG] âŒ NO ticket_id in complete item {i}")
                            else:
                                app.logger.warning(f"[DEBUG] Complete item {i} is not a dict: {type(parsed_data)}")
                                
                        except Exception as parse_error:
                            app.logger.warning(f"[DEBUG] Failed to parse 'complete' field for item {i}: {parse_error}")
                            app.logger.warning(f"[DEBUG] Raw complete content: {item['complete'][:200]}...")
            
            # Second pass: separate attachments from ticket data
            if complete_items:
                app.logger.info(f"[DEBUG] Processing {len(complete_items)} parsed complete items")
                for parsed_item in complete_items:
                    # Check if it's attachment data (has fileName and fileData)
                    if 'fileName' in parsed_item and 'fileData' in parsed_item:
                        attachments_data.append({
                            'fileName': parsed_item['fileName'],
                            'fileData': parsed_item['fileData']
                        })
                        app.logger.info(f"[DEBUG] Found attachment: {parsed_item['fileName']}")
                    # Check if it's ticket data (has ticket_id)
                    elif 'ticket_id' in parsed_item:
                        ticket_data_item = parsed_item
                        app.logger.info(f"[DEBUG] âœ… Found ticket data with ID: {parsed_item['ticket_id']}")
                        app.logger.info(f"[DEBUG] Ticket data keys: {list(parsed_item.keys())}")
                    else:
                        app.logger.info(f"[DEBUG] Complete item has neither attachment nor ticket data: {list(parsed_item.keys())}")
                
                # Third pass: combine ticket data with attachments
                if ticket_data_item:
                    app.logger.info(f"[DEBUG] Processing ticket data item with ID: {ticket_data_item['ticket_id']}")
                    # Add attachments to ticket data
                    if attachments_data:
                        ticket_data_item['attachments'] = attachments_data
                        app.logger.info(f"[DEBUG] Combined ticket {ticket_data_item['ticket_id']} with {len(attachments_data)} attachments")
                    
                    # Pass preserved ticket ID if available
                    if preserved_n8n_ticket_id:
                        ticket_data_item['_preserved_n8n_ticket_id'] = preserved_n8n_ticket_id
                    
                    ticket = process_n8n_ticket_data(ticket_data_item)
                    if ticket:
                        processed_tickets.append(ticket)
                elif attachments_data:
                    app.logger.info(f"[DEBUG] Only attachments found, no ticket data")
                    # If we only have attachments without ticket data, create file upload tickets
                    for attachment in attachments_data:
                        ticket = create_file_upload_ticket(attachment)
                        if ticket:
                            processed_tickets.append(ticket)
                            
        # Case 3: File upload only
        elif isinstance(data, dict) and 'fileName' in data and 'fileData' in data:
            app.logger.info("[DEBUG] Processing file upload only")
            ticket = create_file_upload_ticket(data)
            if ticket:
                processed_tickets.append(ticket)
        else:
            app.logger.warning(f"[ERROR] No valid ticket structure found in data: {list(data.keys()) if isinstance(data, dict) else type(data)}")
        
        # [DUPLICATE PREVENTION] Add deduplication logic to prevent duplicate tickets
        if processed_tickets:
            app.logger.info(f"[DEDUP] Processing {len(processed_tickets)} tickets before deduplication")
            
            # Deduplication based on ticket_id
            seen_ticket_ids = set()
            unique_processed_tickets = []
            duplicate_count = 0
            
            for ticket_data in processed_tickets:
                ticket_id = ticket_data.get('ticket_id')
                if ticket_id and ticket_id not in seen_ticket_ids:
                    seen_ticket_ids.add(ticket_id)
                    unique_processed_tickets.append(ticket_data)
                    app.logger.info(f"[DEDUP] âœ… Keeping unique ticket: {ticket_id}")
                else:
                    duplicate_count += 1
                    app.logger.warning(f"[DEDUP] ðŸš« Duplicate ticket ID {ticket_id} detected, skipping")
            
            # Update processed_tickets with deduplicated list
            processed_tickets = unique_processed_tickets
            app.logger.info(f"[DEDUP] Deduplication complete: {len(processed_tickets)} unique tickets, {duplicate_count} duplicates removed")
        
        # [FIXED] Create actual tickets in database instead of just accepting them
        if processed_tickets:
            db = get_db()
            created_tickets = []
            received_ticket_ids = []
            
            for ticket_data in processed_tickets:
                try:
                    ticket_id = ticket_data.get('ticket_id', 'unknown')
                    app.logger.info(f"[DATABASE] Creating ticket {ticket_id} in database...")
                    
                    # Prepare ticket data for database creation
                    db_ticket_data = {
                        'ticket_id': ticket_id,
                        'name': ticket_data.get('name', 'Unknown'),
                        'email': ticket_data.get('email', ''),
                        'subject': ticket_data.get('subject', 'No Subject'),
                        'body': ticket_data.get('body', ''),
                        'status': 'New',
                        'priority': ticket_data.get('priority', 'Medium'),
                        'classification': ticket_data.get('classification', 'General'),
                        'is_important': False,
                        'has_unread_reply': False,
                        'has_warranty': ticket_data.get('has_warranty', False),
                        'has_attachments': ticket_data.get('has_attachments', False),
                        'warranty_forms_count': ticket_data.get('warranty_forms_count', 0),
                        'total_attachments': ticket_data.get('total_attachments', 0),
                        'attachment_total_size': ticket_data.get('attachment_total_size', 0),
                        'processing_method': 'n8n_tickets_api',
                        'created_at': datetime.now(),
                        'thread_id': f"THREAD_{ticket_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(100, 999)}"
                    }
                    
                    # Create ticket in database
                    created_id = db.create_ticket(db_ticket_data)
                    app.logger.info(f"[SUCCESS] âœ… Created ticket {ticket_id} in database with ID: {created_id}")
                    
                    # Process attachments if present
                    if ticket_data.get('attachments'):
                        for i, attachment in enumerate(ticket_data['attachments']):
                            try:
                                filename = attachment.get('filename', f'attachment_{i}')
                                file_data = attachment.get('data', '')
                                is_warranty = attachment.get('is_warranty', False)
                                
                                # Save file to disk
                                file_path = None
                                if file_data:
                                    try:
                                        decoded_data = base64.b64decode(file_data)
                                        safe_filename = secure_filename(filename)
                                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                        unique_filename = f"{timestamp}_{ticket_id}_{safe_filename}"
                                        
                                        file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                                        with open(file_path, 'wb') as f:
                                            f.write(decoded_data)
                                        
                                        app.logger.info(f"[SUCCESS] Saved attachment: {file_path}")
                                        
                                    except Exception as save_error:
                                        app.logger.error(f"Failed to save attachment {filename}: {save_error}")
                                        file_path = None
                                
                                # Store attachment metadata
                                attachment_metadata = {
                                    'key': f'attachment_{i}',
                                    'filename': filename,
                                    'file_path': file_path,
                                    'data': file_data,
                                    'is_warranty': is_warranty,
                                    'size': attachment.get('size', 0),
                                    'saved_to_disk': bool(file_path)
                                }
                                db.add_ticket_metadata(ticket_id, f'attachment_{i}', json.dumps(attachment_metadata))
                                
                            except Exception as att_error:
                                app.logger.error(f"Error processing attachment {i}: {att_error}")
                    
                    created_tickets.append({
                        'ticket_id': ticket_id,
                        'database_id': str(created_id),
                        'status': 'created',
                        'message': f'Ticket {ticket_id} created successfully in database'
                    })
                    
                    received_ticket_ids.append({
                        'ticket_id': ticket_id,
                        'status': 'created',
                        'message': f'Ticket ID {ticket_id} created successfully in database'
                    })
                    
                except Exception as ticket_error:
                    app.logger.error(f"Error creating ticket {ticket_data.get('ticket_id', 'unknown')}: {ticket_error}")
                    received_ticket_ids.append({
                        'ticket_id': ticket_data.get('ticket_id', 'unknown'),
                        'status': 'error',
                        'message': f'Failed to create ticket: {str(ticket_error)}'
                    })
            
            return jsonify({
                'success': True,
                'message': f'Successfully created {len(created_tickets)} ticket(s) in database',
                'tickets_created': len(created_tickets),
                'ticket_ids': received_ticket_ids,
                'note': 'Tickets are now created in database and will appear on frontend'
            }), 200
        else:
            return jsonify({
                'success': False,
                'message': 'No valid ticket data found in the provided data'
            }), 400

    except Exception as e:
        app.logger.error(f"[ERROR] Error in n8n_tickets_api: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Error processing request: {str(e)}'
        }), 500

def process_n8n_ticket_data(data):
    """
    Process n8n ticket data into database-ready format (based on working simple app)
    """
    try:
        app.logger.info(f"Processing ticket data: {data.get('ticket_id', 'no_id')} from {data.get('from', 'no_sender')}")
        
        # Extract name from email or use provided name
        name = data.get('name', '')
        if not name and data.get('from'):
            name = extract_name_from_email(data.get('from', ''))
        if not name:
            name = 'Unknown'
        
        # [CRITICAL FIX] Enhanced N8N ticket ID handling with better debugging
        # Check if we have a preserved N8N ticket ID from the main endpoint
        preserved_id = data.get('_preserved_n8n_ticket_id', None)
        if preserved_id:
            app.logger.info(f"[CRITICAL] Using preserved N8N ticket ID: {preserved_id}")
            n8n_ticket_id = preserved_id
        else:
            n8n_ticket_id = data.get('ticket_id', '').strip()
        
        app.logger.info(f"[DEBUG] N8N ticket ID extraction:")
        app.logger.info(f"  - Raw ticket_id field: '{data.get('ticket_id', 'NOT_FOUND')}'")
        app.logger.info(f"  - Stripped ticket_id: '{n8n_ticket_id}'")
        app.logger.info(f"  - Preserved ID: '{preserved_id}'")
        app.logger.info(f"  - Data keys available: {list(data.keys())}")
        app.logger.info(f"  - Data type: {type(data)}")
        
        if n8n_ticket_id:
            # Use n8n ticket ID EXACTLY as provided (no formatting, no prefixes)
            db = get_db()
            if not db.ticket_id_exists(n8n_ticket_id):
                ticket_id = n8n_ticket_id
                app.logger.info(f"[N8N_PROCESS] âœ… SUCCESS: Using n8n ticket ID exactly as provided: {ticket_id}")
            else:
                # If n8n ticket ID already exists, append a suffix to make it unique
                # This preserves the n8n ID while ensuring uniqueness
                suffix = 1
                while True:
                    unique_ticket_id = f"{n8n_ticket_id}_{suffix}"
                    if not db.ticket_id_exists(unique_ticket_id):
                        ticket_id = unique_ticket_id
                        app.logger.info(f"[N8N_PROCESS] âš ï¸ N8N ticket ID {n8n_ticket_id} already exists, using unique variant: {ticket_id}")
                        break
                    suffix += 1
                    if suffix > 999:  # Prevent infinite loops
                        app.logger.error(f"[N8N_PROCESS] âŒ Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
                        raise Exception(f"Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
        else:
            # [FALLBACK] Only generate new ID if no n8n ticket ID was provided
            app.logger.warning(f"[N8N_PROCESS] âš ï¸ No n8n ticket ID provided in data, falling back to generation")
            app.logger.warning(f"[N8N_PROCESS] âš ï¸ This should NOT happen if N8N is sending ticket_id: GS5160")
            
            # Generate new email ticket ID as fallback
            email = data.get('from', 'unknown@example.com')
            classification = data.get('Classification', 'General')
            
            # Use new email ticket ID generation (same format as manual tickets)
            db = get_db()
            ticket_id = generate_email_ticket_id(email, name, classification, db)
            app.logger.info(f"[N8N_PROCESS] ðŸ”„ Generated fallback email ticket ID: {ticket_id}")
        
        # [VERIFICATION] Log final ticket ID decision
        app.logger.info(f"[N8N_PROCESS] ðŸŽ¯ FINAL DECISION:")
        app.logger.info(f"  - Original N8N ID: '{n8n_ticket_id}'")
        app.logger.info(f"  - Final ticket ID: '{ticket_id}'")
        app.logger.info(f"  - ID preserved: {'âœ… YES' if ticket_id == n8n_ticket_id else 'âŒ NO - ID was modified!'}")
        
        # Process attachments
        attachments = []
        if 'attachments' in data and isinstance(data['attachments'], list):
            for att_data in data['attachments']:
                if isinstance(att_data, dict) and 'fileName' in att_data and 'fileData' in att_data:
                    attachments.append({
                        'filename': att_data['fileName'],
                        'data': att_data['fileData'],
                        'is_warranty': enhanced_detect_warranty_form(att_data['fileName']),
                        'size': len(base64.b64decode(att_data['fileData'])) if att_data['fileData'] else 0
                    })
        
        # Create simplified ticket data for acceptance (no database fields)
        ticket_data = {
            'ticket_id': ticket_id,
            'name': name,
            'email': data.get('from', 'unknown@example.com'),
            'subject': data.get('subject', f"Email from {name}"),
            'body': data.get('body', ''),
            'classification': data.get('Classification', 'Support'),
            'priority': data.get('Priority', 'Medium'),
            'has_attachments': len(attachments) > 0,
            'total_attachments': len(attachments),
            'has_warranty': any(att.get('is_warranty', False) for att in attachments),
            'attachments': attachments,
            'processing_method': 'n8n_acceptance',  # Track that this is just acceptance
            'n8n_original_id': n8n_ticket_id if n8n_ticket_id else None,  # Track original N8N ID for debugging
            'accepted_at': datetime.now().isoformat()
        }
        
        app.logger.info(f"[SUCCESS] âœ… ACCEPTED ticket ID {ticket_id} from N8N: {len(attachments)} attachments, warranty: {ticket_data['has_warranty']}")
        app.logger.info(f"[SUCCESS] âœ… Ticket ID {ticket_id} will be accepted in any format (GS5160, EO5267, TO3356, etc.)")
        return ticket_data
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error processing ticket data: {e}")
        import traceback
        app.logger.error(f"[ERROR] Full traceback: {traceback.format_exc()}")
        return None

def create_file_upload_ticket(data):
    """
    Create a ticket for file upload only (based on working simple app)
    """
    try:
        ticket_id = f"FILE{random.randint(100000, 999999)}"
        filename = data.get('fileName', 'unknown_file')
        
        # Create attachment
        attachment = {
            'filename': filename,
            'data': data.get('fileData', ''),
            'is_warranty': enhanced_detect_warranty_form(filename),
            'size': len(base64.b64decode(data['fileData'])) if data.get('fileData') else 0
        }
        
        ticket_data = {
            'ticket_id': ticket_id,
            'thread_id': f"THREAD_{ticket_id}",
            'name': 'File Upload User',
            'email': 'fileupload@system.com',
            'subject': f'File Upload: {filename}',
            'body': f'A file has been uploaded: {filename}',
            'draft_body': f'Thank you for uploading {filename}. We have received your file and will process it accordingly.\n\nBest regards,\nSupport Team',  # [FIX] Add draft response
            'status': 'Open',
            'priority': 'Medium',
            'classification': 'File Upload',
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'is_important': False,
            'has_unread_reply': False,
            'has_attachments': True,
            'total_attachments': 1,
            'has_warranty': attachment.get('is_warranty', False),
            'attachments': [attachment]
        }
        
        app.logger.info(f"[SUCCESS] Created file upload ticket {ticket_id}: {filename}")
        return ticket_data
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error creating file upload ticket: {e}")
        return None

def save_ticket_attachments(ticket_id, attachments, db):
    """
    Save ticket attachments to filesystem and add metadata to database
    """
    try:
        for i, attachment in enumerate(attachments):
            if attachment.get('data'):
                # Decode base64 data
                file_data = base64.b64decode(attachment.get('data', ''))
                filename = attachment.get('filename', 'unknown_file')
                safe_filename = secure_filename(filename)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                unique_filename = f"{timestamp}_{ticket_id}_{safe_filename}"
                
                # Save to uploads directory
                file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                with open(file_path, 'wb') as f:
                    f.write(file_data)
                
                # Add attachment metadata to database
                attachment_key = 'warranty_form' if attachment.get('is_warranty') else f'attachment_{i+1}'
                attachment_metadata = {
                    'key': attachment_key,
                    'file_path': unique_filename,
                    'original_name': filename,
                    'size': attachment.get('size', len(file_data)),
                    'is_warranty': attachment.get('is_warranty', False),
                    'uploaded_at': datetime.now().isoformat()
                }
                
                db.add_ticket_metadata(ticket_id, attachment_key, json.dumps(attachment_metadata))
                app.logger.info(f"[SUCCESS] Saved attachment: {filename} for ticket {ticket_id}")
                
    except Exception as e:
        app.logger.error(f"[ERROR] Error saving attachments for ticket {ticket_id}: {e}")

@app.route('/api/tickets/<ticket_id>/attachments/<attachment_id>/download')
def download_email_attachment(ticket_id, attachment_id):
    """Download email attachment by ticket ID and attachment ID"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        target_attachment = None
        
        # METHOD 1: Check for direct attachments in ticket (n8n email tickets)
        attachments = ticket.get('attachments', [])
        for i, att in enumerate(attachments):
            if f"{ticket_id}_{i}" == attachment_id:
                target_attachment = att
                break
        
        # METHOD 2: Check for metadata attachments (email attachments stored in metadata)
        if not target_attachment:
            metadata = db.get_ticket_metadata(ticket_id)
            for meta in metadata:
                if meta.get('key', '').startswith('attachment_'):
                    try:
                        attachment_data = json.loads(meta.get('value', '{}'))
                        if attachment_data and isinstance(attachment_data, dict):
                            # Check if this is the attachment we're looking for
                            metadata_index = meta.get('key', '').replace('attachment_', '')
                            if f"{ticket_id}_metadata_{metadata_index}" == attachment_id:
                                target_attachment = attachment_data
                                break
                    except (json.JSONDecodeError, TypeError):
                        continue
        
        if not target_attachment:
            return jsonify({'error': 'Attachment not found'}), 404
        
        # Decode base64 file data
        file_data = target_attachment.get('data', '')
        if not file_data:
            return jsonify({'error': 'No file data available'}), 404
        
        try:
            decoded_data = base64.b64decode(file_data)
        except Exception as e:
            app.logger.error(f"Failed to decode attachment data: {e}")
            return jsonify({'error': 'Failed to decode file data'}), 500
        
        filename = target_attachment.get('filename', target_attachment.get('original_name', 'attachment'))
        
        # Determine MIME type based on file extension
        mime_type = 'application/octet-stream'  # default
        if filename.lower().endswith('.pdf'):
            mime_type = 'application/pdf'
        elif filename.lower().endswith(('.jpg', '.jpeg')):
            mime_type = 'image/jpeg'
        elif filename.lower().endswith('.png'):
            mime_type = 'image/png'
        elif filename.lower().endswith('.gif'):
            mime_type = 'image/gif'
        elif filename.lower().endswith(('.doc', '.docx')):
            mime_type = 'application/msword'
        elif filename.lower().endswith(('.xls', '.xlsx')):
            mime_type = 'application/vnd.ms-excel'
        
        # Create response with proper headers for download
        response = make_response(decoded_data)
        response.headers['Content-Type'] = mime_type
        response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
        response.headers['Content-Length'] = len(decoded_data)
        
        # Add additional headers for better PDF handling
        if filename.lower().endswith('.pdf'):
            response.headers['Accept-Ranges'] = 'bytes'
            response.headers['Cache-Control'] = 'no-cache'
            response.headers['X-Content-Type-Options'] = 'nosniff'
            # Enhanced PDF validation for downloads
            pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
            is_valid_pdf = any(decoded_data.startswith(sig) for sig in pdf_signatures)
            
            # Also check for PDF content in the first 1024 bytes
            if not is_valid_pdf and len(decoded_data) > 100:
                first_kb = decoded_data[:1024]
                is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
            
            # Log warning but don't reject the file
            if not is_valid_pdf:
                app.logger.warning(f"PDF validation failed for download: {filename}, but serving anyway")
                app.logger.debug(f"First 100 bytes: {decoded_data[:100]}")
        
        app.logger.info(f"Download response for {filename}: {mime_type}, size: {len(decoded_data)} bytes")
        
        return response
        
    except Exception as e:
        app.logger.error(f"Error downloading attachment: {e}")
        return jsonify({'error': 'Internal server error'}), 500

@app.route('/api/tickets/<ticket_id>/attachments/<int:attachment_index>/preview')
def preview_attachment(ticket_id, attachment_index):
    """Preview attachment by ticket ID and attachment index from multiple sources"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        app.logger.info(f" Preview request for ticket {ticket_id}, attachment {attachment_index}")
        
        # METHOD 1: Check for direct attachments in ticket (n8n email tickets)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            attachments = ticket['attachments']
            app.logger.info(f"Found {len(attachments)} direct attachments in ticket")
            
            if attachment_index < len(attachments):
                attachment = attachments[attachment_index]
                filename = attachment.get('filename', 'unknown_file')
                file_data = attachment.get('data', '')
                
                if file_data:
                    app.logger.info(f" Previewing base64 attachment: {filename}")
                    try:
                        decoded_data = base64.b64decode(file_data)
                        return create_preview_response(decoded_data, filename)
                    except Exception as e:
                        app.logger.error(f"Failed to decode base64 data: {e}")
                        return jsonify({'error': 'Invalid attachment data'}), 500
        
        # METHOD 1.5: Check for simple_attachments (conversation section attachments)
        if ticket.get('simple_attachments'):
            simple_attachments = ticket['simple_attachments']
            app.logger.info(f"Found {len(simple_attachments)} simple attachments in ticket")
            
            if attachment_index < len(simple_attachments):
                attachment = simple_attachments[attachment_index]
                filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
                file_path = attachment.get('file_path', '')
                
                app.logger.info(f" Simple attachment for preview: {attachment}")
                
                # Try to read the file from the file_path
                if file_path and os.path.exists(file_path):
                    app.logger.info(f" FOUND SIMPLE ATTACHMENT FILE FOR PREVIEW: {file_path}")
                    try:
                        with open(file_path, 'rb') as f:
                            file_data = f.read()
                        return create_preview_response(file_data, filename)
                    except Exception as e:
                        app.logger.error(f"Failed to read simple attachment file: {e}")
                        return jsonify({'error': 'Failed to read file'}), 500
                else:
                    app.logger.warning(f" Simple attachment file not found for preview: {file_path}")
                    # Try to find the file in uploads directory
                    if filename:
                        upload_path = os.path.join('uploads', filename)
                        if os.path.exists(upload_path):
                            app.logger.info(f" FOUND SIMPLE ATTACHMENT IN UPLOADS FOR PREVIEW: {upload_path}")
                            try:
                                with open(upload_path, 'rb') as f:
                                    file_data = f.read()
                                return create_preview_response(file_data, filename)
                            except Exception as e:
                                app.logger.error(f"Failed to read simple attachment from uploads: {e}")
                                return jsonify({'error': 'Failed to read file'}), 500
                        else:
                            app.logger.warning(f" Simple attachment not found in uploads for preview: {upload_path}")
                            # List files in uploads directory for debugging
                            if os.path.exists('uploads'):
                                upload_files = os.listdir('uploads')
                                app.logger.info(f"FOLDER Files in uploads directory: {upload_files}")
                            else:
                                app.logger.warning(" Uploads directory does not exist")
        
        # METHOD 2: Check reply attachments (webhook files)
        replies = db.replies.find({'ticket_id': ticket_id}).sort('created_at', -1)
        all_reply_attachments = []
        
        for reply in replies:
            if reply.get('attachments'):
                for att in reply['attachments']:
                    if att.get('type') == 'file':
                        all_reply_attachments.append(att)
        
        app.logger.info(f"Found {len(all_reply_attachments)} reply attachments")
        
        if attachment_index < len(all_reply_attachments):
            attachment = all_reply_attachments[attachment_index]
            filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
            file_path = attachment.get('path', '')
            
            if file_path and os.path.exists(file_path):
                app.logger.info(f" FOUND REPLY FILE FOR PREVIEW: {file_path}")
                try:
                    with open(file_path, 'rb') as f:
                        file_data = f.read()
                    return create_preview_response(file_data, filename)
                except Exception as e:
                    app.logger.error(f"Failed to read reply file: {e}")
                    return jsonify({'error': 'Failed to read file'}), 500
            else:
                app.logger.warning(f" Reply file not found for preview: {file_path}")
        
        # METHOD 3: Check metadata collection for file attachments
        ticket_metadata = db.get_ticket_metadata(ticket_id)
        attachment_files = []
        
        for metadata_entry in ticket_metadata:
            if metadata_entry['key'].startswith('attachment_'):
                try:
                    attachment_data = json.loads(metadata_entry['value'])
                    attachment_files.append(attachment_data)
                except:
                    continue
        
        app.logger.info(f"Found {len(attachment_files)} metadata attachments")
        
        if attachment_index < len(attachment_files):
            attachment = attachment_files[attachment_index]
            filename = attachment.get('original_name', attachment.get('filename', 'unknown_file'))
            
            # Try saved file path first
            saved_file_path = attachment.get('file_path')
            if saved_file_path and os.path.exists(saved_file_path):
                app.logger.info(f" FOUND SAVED FILE FOR PREVIEW: {saved_file_path}")
                try:
                    with open(saved_file_path, 'rb') as f:
                        file_data = f.read()
                    return create_preview_response(file_data, filename)
                except Exception as e:
                    app.logger.error(f"Failed to read saved file: {e}")
                    return jsonify({'error': 'Failed to read file'}), 500
            
            # Try base64 data as fallback
            elif 'data' in attachment and attachment['data']:
                app.logger.info(f" FALLBACK TO BASE64 FOR PREVIEW: {filename}")
                try:
                    decoded_data = base64.b64decode(attachment.get('data', ''))
                    return create_preview_response(decoded_data, filename)
                except Exception as e:
                    app.logger.error(f"Failed to decode metadata base64: {e}")
                    return jsonify({'error': 'Invalid attachment data'}), 500
        
        # If we get here, attachment not found
        app.logger.warning(f" Attachment {attachment_index} not found for preview in ticket {ticket_id}")
        return jsonify({'error': 'Attachment not found'}), 404
        
    except Exception as e:
        app.logger.error(f"Error previewing attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Internal server error'}), 500

def create_preview_response(file_data, filename):
    """Helper function to create preview response with proper MIME type handling"""
    # Validate file data
    if not file_data or len(file_data) == 0:
        app.logger.error(f"Empty file data for {filename}")
        return jsonify({'error': 'Empty file data'}), 400
    
    # Determine MIME type based on file extension
    mime_type = 'application/octet-stream'  # default
    if filename.lower().endswith('.pdf'):
        mime_type = 'application/pdf'
        # Enhanced PDF validation - check multiple possible signatures
        pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
        is_valid_pdf = any(file_data.startswith(sig) for sig in pdf_signatures)
        
        # Also check for PDF content in the first 1024 bytes (some PDFs have headers)
        if not is_valid_pdf and len(file_data) > 100:
            # Look for PDF signature in first 1KB
            first_kb = file_data[:1024]
            is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
        
        # If still not valid, check if it might be a corrupted but recoverable PDF
        if not is_valid_pdf:
            app.logger.warning(f"PDF validation failed for {filename}, but attempting to serve anyway")
            app.logger.debug(f"First 100 bytes: {file_data[:100]}")
            # Don't reject the file - let the browser try to handle it
            # This prevents false positives from blocking valid PDFs with unusual headers
    elif filename.lower().endswith(('.jpg', '.jpeg')):
        mime_type = 'image/jpeg'
    elif filename.lower().endswith('.png'):
        mime_type = 'image/png'
    elif filename.lower().endswith('.gif'):
        mime_type = 'image/gif'
    elif filename.lower().endswith('.txt'):
        mime_type = 'text/plain'
    elif filename.lower().endswith('.md'):
        mime_type = 'text/markdown'
    elif filename.lower().endswith(('.doc', '.docx')):
        # For Word docs, show a message instead of trying to display
        return render_template_string('''
            <html><body style="font-family: Arial, sans-serif; padding: 20px;">
                <h3>Document Preview</h3>
                <p><strong>Filename:</strong> {{ filename }}</p>
                <p><strong>Type:</strong> Microsoft Word Document</p>
                <p>This document cannot be previewed in the browser. Please download it to view the contents.</p>
                <br>
                <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px;">Close</button>
            </body></html>
        ''', filename=filename)
    elif filename.lower().endswith(('.xls', '.xlsx')):
        # For Excel files, show a message instead of trying to display
        return render_template_string('''
            <html><body style="font-family: Arial, sans-serif; padding: 20px;">
                <h3>Spreadsheet Preview</h3>
                <p><strong>Filename:</strong> {{ filename }}</p>
                <p><strong>Type:</strong> Microsoft Excel Spreadsheet</p>
                <p>This spreadsheet cannot be previewed in the browser. Please download it to view the contents.</p>
                <br>
                <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px;">Close</button>
            </body></html>
        ''', filename=filename)
    
    # Create response with proper headers for inline display
    response = make_response(file_data)
    response.headers['Content-Type'] = mime_type
    response.headers['Content-Disposition'] = f'inline; filename="{filename}"'
    response.headers['Content-Length'] = len(file_data)
    
    # Add additional headers for better PDF handling
    if filename.lower().endswith('.pdf'):
        response.headers['Accept-Ranges'] = 'bytes'
        response.headers['Cache-Control'] = 'public, max-age=3600'
        response.headers['X-Content-Type-Options'] = 'nosniff'
    
    app.logger.info(f"Created preview response for {filename}: {mime_type}, size: {len(file_data)} bytes")
    
    return response

# ðŸš€ NEW: File System Attachment Routes (for metadata-stored files)
@app.route('/api/tickets/<ticket_id>/file-attachments/<attachment_key>/download')
def download_file_system_attachment(ticket_id, attachment_key):
    """Download file system attachment by ticket ID and attachment key (from metadata)"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Get ticket metadata to find file path
        metadata = db.get_ticket_metadata(ticket_id)
        file_path = None
        
        for meta in metadata:
            if meta['key'] == attachment_key:
                file_path = meta['value']
                break
        
        if not file_path:
            app.logger.error(f" No file path found for attachment key: {attachment_key}")
            return jsonify({'error': 'Attachment not found in metadata'}), 404
        
        # Check if file exists in uploads directory
        upload_path = os.path.join('uploads', os.path.basename(file_path))
        full_path = os.path.join(os.getcwd(), upload_path)
        
        app.logger.info(f" Looking for file at: {full_path}")
        
        if not os.path.exists(full_path):
            app.logger.error(f" File not found at path: {full_path}")
            return jsonify({'error': 'File not found on server'}), 404
        
        try:
            filename = os.path.basename(file_path)
            app.logger.info(f" Serving file: {filename}")
            
            # For PDFs, read and validate the file
            if filename.lower().endswith('.pdf'):
                try:
                    with open(full_path, 'rb') as f:
                        file_data = f.read()
                    
                    # Enhanced PDF validation - check multiple possible signatures
                    pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
                    is_valid_pdf = any(file_data.startswith(sig) for sig in pdf_signatures)
                    
                    # Also check for PDF content in the first 1024 bytes (some PDFs have headers)
                    if not is_valid_pdf and len(file_data) > 100:
                        first_kb = file_data[:1024]
                        is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
                    
                    # Log warning but don't reject the file - let browser try to handle it
                    if not is_valid_pdf:
                        app.logger.warning(f"PDF validation failed for download: {filename}, but serving anyway")
                        app.logger.debug(f"First 100 bytes: {file_data[:100]}")
                        # Don't reject the file - let the browser try to handle it
                        # This prevents false positives from blocking valid PDFs with unusual headers
                    
                    # Create custom response with proper headers
                    response = make_response(file_data)
                    response.headers['Content-Type'] = 'application/pdf'
                    response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
                    response.headers['Content-Length'] = len(file_data)
                    response.headers['Accept-Ranges'] = 'bytes'
                    response.headers['Cache-Control'] = 'no-cache'
                    response.headers['X-Content-Type-Options'] = 'nosniff'
                    
                    app.logger.info(f"PDF download response for {filename}: size: {len(file_data)} bytes")
                    return response
                    
                except Exception as e:
                    app.logger.error(f"Error reading PDF file for download: {e}")
                    return jsonify({'error': 'Failed to read PDF file'}), 500
            
            # For other files, use send_file
            return send_file(
                full_path,
                as_attachment=True,
                download_name=filename,
                mimetype='application/octet-stream'
            )
        except Exception as e:
            app.logger.error(f"ðŸ’¥ Error serving file: {e}")
            return jsonify({'error': 'Failed to serve file'}), 500
            
    except Exception as e:
        app.logger.error(f"ðŸ’¥ Error downloading file system attachment: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/file-attachments/<attachment_key>/preview')
def preview_file_system_attachment(ticket_id, attachment_key):
    """Preview file system attachment by ticket ID and attachment key (from metadata)"""
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Get ticket metadata to find file path
        metadata = db.get_ticket_metadata(ticket_id)
        file_path = None
        
        for meta in metadata:
            if meta['key'] == attachment_key:
                file_path = meta['value']
                break
        
        if not file_path:
            app.logger.error(f" No file path found for attachment key: {attachment_key}")
            return jsonify({'error': 'Attachment not found in metadata'}), 404
        
        # Check if file exists in uploads directory
        upload_path = os.path.join('uploads', os.path.basename(file_path))
        full_path = os.path.join(os.getcwd(), upload_path)
        
        app.logger.info(f"ðŸ‘€ Looking for preview file at: {full_path}")
        
        if not os.path.exists(full_path):
            app.logger.error(f" File not found at path: {full_path}")
            return jsonify({'error': 'File not found on server'}), 404
        
        try:
            filename = os.path.basename(file_path)
            
            # Determine content type for preview
            content_type = 'application/octet-stream'
            if filename.lower().endswith('.pdf'):
                content_type = 'application/pdf'
            elif filename.lower().endswith(('.jpg', '.jpeg')):
                content_type = 'image/jpeg'
            elif filename.lower().endswith('.png'):
                content_type = 'image/png'
            elif filename.lower().endswith('.gif'):
                content_type = 'image/gif'
            elif filename.lower().endswith(('.doc', '.docx')):
                # For Word docs, show message instead of trying to display
                return render_template_string('''
                    <html><body style="font-family: Arial, sans-serif; padding: 20px; text-align: center;">
                        <h3>ðŸ“„ Document Preview - File System</h3>
                        <p><strong>Filename:</strong> {{ filename }}</p>
                        <p><strong>Type:</strong> Microsoft Word Document</p>
                        <p>This document cannot be previewed in the browser. Please download it to view the contents.</p>
                        <br>
                        <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer;">Close</button>
                    </body></html>
                ''', filename=filename)
            elif filename.lower().endswith(('.xls', '.xlsx')):
                # For Excel files, show message instead of trying to display
                return render_template_string('''
                    <html><body style="font-family: Arial, sans-serif; padding: 20px; text-align: center;">
                        <h3>ðŸ“Š Spreadsheet Preview - File System</h3>
                        <p><strong>Filename:</strong> {{ filename }}</p>
                        <p><strong>Type:</strong> Microsoft Excel Spreadsheet</p>
                        <p>This spreadsheet cannot be previewed in the browser. Please download it to view the contents.</p>
                        <br>
                        <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer;">Close</button>
                    </body></html>
                ''', filename=filename)
            else:
                # For non-previewable files, force download instead
                app.logger.info(f"ðŸ”„ Non-previewable file, redirecting to download: {filename}")
                return download_file_system_attachment(ticket_id, attachment_key)
            
            app.logger.info(f"ðŸ‘€ Previewing file: {filename} as {content_type}")
            
            # For PDFs, read the file and validate it
            if filename.lower().endswith('.pdf'):
                try:
                    with open(full_path, 'rb') as f:
                        file_data = f.read()
                    
                    # Enhanced PDF validation - check multiple possible signatures
                    pdf_signatures = [b'%PDF', b'%PDF-', b'%PDF1.', b'%PDF2.', b'%PDF3.', b'%PDF4.', b'%PDF5.']
                    is_valid_pdf = any(file_data.startswith(sig) for sig in pdf_signatures)
                    
                    # Also check for PDF content in the first 1024 bytes (some PDFs have headers)
                    if not is_valid_pdf and len(file_data) > 100:
                        first_kb = file_data[:1024]
                        is_valid_pdf = any(sig in first_kb for sig in pdf_signatures)
                    
                    # Log warning but don't reject the file - let browser try to handle it
                    if not is_valid_pdf:
                        app.logger.warning(f"PDF validation failed for preview: {filename}, but serving anyway")
                        app.logger.debug(f"First 100 bytes: {file_data[:100]}")
                        # Don't reject the file - let the browser try to handle it
                        # This prevents false positives from blocking valid PDFs with unusual headers
                    
                    # Create custom response with proper headers
                    response = make_response(file_data)
                    response.headers['Content-Type'] = 'application/pdf'
                    response.headers['Content-Disposition'] = f'inline; filename="{filename}"'
                    response.headers['Content-Length'] = len(file_data)
                    response.headers['Accept-Ranges'] = 'bytes'
                    response.headers['Cache-Control'] = 'public, max-age=3600'
                    response.headers['X-Content-Type-Options'] = 'nosniff'
                    
                    app.logger.info(f"PDF preview response for {filename}: size: {len(file_data)} bytes")
                    return response
                    
                except Exception as e:
                    app.logger.error(f"Error reading PDF file: {e}")
                    return jsonify({'error': 'Failed to read PDF file'}), 500
            
            # For other files, use send_file
            return send_file(
                full_path,
                as_attachment=False,
                download_name=filename,
                mimetype=content_type
            )
        except Exception as e:
            app.logger.error(f"ðŸ’¥ Error serving preview file: {e}")
            return jsonify({'error': 'Failed to serve preview'}), 500
            
    except Exception as e:
        app.logger.error(f"ðŸ’¥ Error previewing file system attachment: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickets/test-n8n', methods=['POST'])
def test_n8n_integration():
    """
    Test endpoint for n8n integration - simulates your real data format
    """
    try:
        # Your real n8n data format for testing
        test_data = [
            {
                "complete": "{\"result\":false,\"fileName\":\"warranty_dashboard_report_20250726_112229.pdf\",\"fileData\":\"JVBERi0xLjQKJZOMi54gUmVwb3J0TGFiIEdlbmVyYXRlZCBQREYgZG9jdW1lbnQgaHR0cDovL3d3dy5yZXBvcnRsYWIuY29tCjEgMCBvYmoKPDwKL0YxIDIgMCBSIC9GMiAzIDAgUgo+PgplbmRvYmoKMiAwIG9iago8PAovQmFzZUZ4Kc3RhcnR4cmVmCjIyNDcKJSVFT0YK\"}"
            },
            {
                "complete": "{\"threadId\":\"AQQkADAwATM3ZmYBLTljMmQtMmQ5ZS0wMAItMDAKABAA62jpB7tOGUO0IrhdiiKqQg==\",\"name\":\"muhammad zeeshan liaqat\",\"body\":\"The mails\",\"Classification\":\"Others\",\"Priority\":\"Low\",\"ticket_id\":\"706393\",\"from\":\"fa22-bse-061@outlook.com\",\"date\":\"2025-08-07T20:52:53Z\",\"draft\":\"Dear muhammad zeeshan liaqat,\\\\n\\\\nThank you for your message regarding the test emails. We have noted your communication and will keep it on record.\\\\n\\\\nIf you have any specific inquiries or need further assistance, please feel free to reach out.\\\\n\\\\n(Ticket ID: 706393)\\\\n\\\\nSincerely,\\\\nCustomer Services\",\"messageid\":\"AQMkADAwATM3AAAADdI5CgAAAA==\",\"\":\"\"}"
            }
        ]
        
        # Create a test request context and call the main endpoint
        with app.test_request_context('/api/tickets', method='POST', json=test_data):
            response = n8n_tickets_api()
            return response
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Test failed: {str(e)}'
        }), 500

@app.route('/api/tickets/n8n-health', methods=['GET'])
def n8n_health_check():
    """
    Health check endpoint specifically for n8n integration
    """
    try:
        db = get_db()
        db.client.admin.command('ping')
        
        return jsonify({
            'status': 'healthy',
            'n8n_endpoint': '/api/tickets',
            'test_endpoint': '/api/tickets/test-n8n',
            'database': 'connected',
            'upload_folder_exists': os.path.exists(UPLOAD_FOLDER),
            'message': 'N8N integration ready for use',
            'supported_formats': [
                'Direct ticket data with attachments',
                'Array with complete JSON fields (your format)',
                'File upload only'
            ]
        }), 200
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'N8N integration health check failed: {str(e)}'
        }), 500

@app.route('/api/tickets/debug-n8n', methods=['POST'])
def debug_n8n_data():
    """
    Debug endpoint to analyze N8N data structure without creating tickets
    This will help identify why GS5160 is becoming EO5267
    """
    try:
        # Get request data
        raw_data = request.get_data()
        app.logger.info(f"[DEBUG-N8N] Debug endpoint received request: Content-Type={request.content_type}, Size={len(raw_data)}")
        
        # Parse JSON data
        try:
            if request.is_json:
                data = request.get_json()
            else:
                data = json.loads(raw_data.decode('utf-8'))
        except Exception as json_error:
            return jsonify({
                'status': 'error',
                'message': f'Invalid JSON format: {str(json_error)}',
                'raw_data': raw_data.decode('utf-8')[:500] + '...' if len(raw_data) > 500 else raw_data.decode('utf-8')
            }), 400
        
        # Analyze the data structure
        analysis = {
            'data_type': str(type(data)),
            'data_length': len(str(data)),
            'analysis': {}
        }
        
        if isinstance(data, dict):
            analysis['analysis']['top_level'] = {
                'keys': list(data.keys()),
                'has_ticket_id': 'ticket_id' in data,
                'ticket_id_value': data.get('ticket_id', 'NOT_FOUND'),
                'ticket_id_type': str(type(data.get('ticket_id')))
            }
        elif isinstance(data, list):
            analysis['analysis']['array'] = {
                'length': len(data),
                'items': []
            }
            
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    item_analysis = {
                        'index': i,
                        'keys': list(item.keys()),
                        'has_ticket_id': 'ticket_id' in item,
                        'ticket_id_value': item.get('ticket_id', 'NOT_FOUND'),
                        'has_complete': 'complete' in item
                    }
                    
                    if 'complete' in item:
                        try:
                            # Try to parse the complete field
                            clean_json = item['complete'].strip()
                            if clean_json.endswith(',}'):
                                clean_json = clean_json[:-2] + '}'
                            elif clean_json.endswith(',]'):
                                clean_json = clean_json[:-2] + ']'
                            
                            parsed_complete = json.loads(clean_json)
                            item_analysis['complete_parsed'] = {
                                'type': str(type(parsed_complete)),
                                'keys': list(parsed_complete.keys()) if isinstance(parsed_complete, dict) else 'Not a dict',
                                'has_ticket_id': 'ticket_id' in parsed_complete if isinstance(parsed_complete, dict) else 'N/A',
                                'ticket_id_value': parsed_complete.get('ticket_id', 'NOT_FOUND') if isinstance(parsed_complete, dict) else 'N/A'
                            }
                        except Exception as parse_error:
                            item_analysis['complete_parsed'] = {
                                'error': str(parse_error),
                                'raw_content': item['complete'][:200] + '...' if len(item['complete']) > 200 else item['complete']
                            }
                    
                    analysis['analysis']['array']['items'].append(item_analysis)
                else:
                    analysis['analysis']['array']['items'].append({
                        'index': i,
                        'type': str(type(item)),
                        'value': str(item)[:100] + '...' if len(str(item)) > 100 else str(item)
                    })
        
        # Return detailed analysis
        return jsonify({
            'status': 'success',
            'message': 'N8N data structure analyzed',
            'analysis': analysis,
            'recommendation': 'Check the analysis above to see where ticket_id is located in your data structure'
        })
        
    except Exception as e:
        app.logger.error(f"[DEBUG-N8N] Error in debug endpoint: {e}")
        import traceback
        return jsonify({
            'status': 'error',
            'message': f'Debug analysis failed: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/tickets/<ticket_id>/debug', methods=['GET'])
def debug_ticket_data(ticket_id):
    """
    Debug endpoint to check exactly what's stored for a ticket
    """
    try:
        db = get_db()
        
        # Get the ticket
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Get metadata
        metadata = db.get_ticket_metadata(ticket_id)
        
        # Parse the ticket data for debugging
        debug_info = {
            'ticket_id': ticket_id,
            'ticket_found': True,
            'has_attachments_flag': ticket.get('has_attachments', False),
            'total_attachments_count': ticket.get('total_attachments', 0),
            'attachments_in_ticket': ticket.get('attachments', []),
            'attachments_count_in_ticket': len(ticket.get('attachments', [])),
            'metadata_count': len(metadata),
            'metadata_items': []
        }
        
        # Check metadata for attachments
        for item in metadata:
            metadata_item = {
                'key': item['key'],
                'created_at': item.get('created_at', 'unknown')
            }
            
            # Try to parse the value if it's JSON
            try:
                if isinstance(item['value'], str) and item['value'].strip():
                    # Clean the JSON string before parsing
                    clean_value = item['value'].strip()
                    # Remove trailing commas and fix common JSON issues
                    if clean_value.endswith(',}'):
                        clean_value = clean_value[:-2] + '}'
                    elif clean_value.endswith(',]'):
                        clean_value = clean_value[:-2] + ']'
                    # Remove any leading/trailing whitespace and quotes
                    clean_value = clean_value.strip().strip('"\'')
                    # Skip if still empty after cleaning
                    if not clean_value or clean_value in ['{}', '[]', 'null', 'undefined']:
                        metadata_item['raw_value'] = 'empty'
                        metadata_item['is_attachment'] = False
                    else:
                        parsed_value = json.loads(clean_value)
                        metadata_item['parsed_value'] = parsed_value
                        metadata_item['is_attachment'] = 'file_path' in parsed_value or 'filename' in parsed_value
                else:
                    metadata_item['raw_value'] = str(item['value'])
                    metadata_item['is_attachment'] = False
            except json.JSONDecodeError as e:
                # Only log if it's actually malformed, not just empty
                if isinstance(item['value'], str) and item['value'].strip() and item['value'].strip() not in ['{}', '[]', 'null', 'undefined', '']:
                    app.logger.debug(f"JSON parse error in debug endpoint: {e} - Value: {item['value'][:50]}")
                metadata_item['raw_value'] = item['value'][:100] + '...' if len(str(item['value'])) > 100 else str(item['value'])
                metadata_item['is_attachment'] = False
                metadata_item['json_error'] = str(e)
            
            debug_info['metadata_items'].append(metadata_item)
        
        # Check for attachment files in metadata
        attachment_metadata = [item for item in metadata if item['key'].startswith('attachment_') or item['key'] == 'warranty_form']
        debug_info['attachment_metadata_count'] = len(attachment_metadata)
        
        # Check for direct attachments in ticket document
        if 'attachments' in ticket:
            debug_info['direct_attachments_details'] = []
            for i, att in enumerate(ticket['attachments']):
                att_info = {
                    'index': i,
                    'filename': att.get('filename', 'unknown'),
                    'has_data': bool(att.get('data', '')),
                    'data_length': len(att.get('data', '')),
                    'is_warranty': att.get('is_warranty', False),
                    'size': att.get('size', 0)
                }
                debug_info['direct_attachments_details'].append(att_info)
        
        return jsonify(debug_info), 200
        
    except Exception as e:
        return jsonify({
            'error': f'Debug failed: {str(e)}',
            'ticket_id': ticket_id
        }), 500

def process_n8n_item_for_tickets_api(item, item_index):
    """
    Process n8n data item and return the expected format for /api/tickets
    Returns list of items in the format: [attachments..., ticket_data]
    """
    result_items = []
    app.logger.info(f"[DEBUG] Processing n8n item {item_index}: type={type(item)}")
    
    try:
        # Initialize ticket data
        ticket_data = {
            'threadId': '',
            'name': 'Unknown',
            'body': '',
            'Classification': 'Others',
            'Priority': 'Low',
            'ticket_id': f"API{random.randint(100000, 999999)}",
            'from': '',
            'date': datetime.now().isoformat(),
            'draft': '',
            'messageid': ''
        }
        
        # Handle different data structures
        if isinstance(item, dict):
            # Check for direct email data
            if 'from' in item or 'subject' in item or 'body' in item:
                app.logger.info("? Found direct email data")
                ticket_data.update({
                    'threadId': item.get('threadI', item.get('threadId', f"THREAD_{ticket_data['ticket_id']}")),
                    'name': item.get('name', extract_name_from_email(item.get('from', ''))),
                    'subject': item.get('subject', 'No Subject'),  # Fix: Properly extract subject
                    'body': item.get('body', 'No content'),  # Fix: Don't use subject as fallback for body
                    'Classification': item.get('Classification', 'Others'),
                    'Priority': item.get('Priority', 'Low'),
                    'from': item.get('from', ''),
                    'date': item.get('date', datetime.now().isoformat()),
                    'draft': item.get('draft', ''),
                    'messageid': item.get('messageid', '')
                })
                
                # Extract and process attachments
                attachments = item.get('attachments', [])
                if attachments:
                    app.logger.info(f"? Found {len(attachments)} attachments")
                    for att in attachments:
                        if isinstance(att, dict):
                            # Handle different attachment data structures
                            file_name = att.get('fileName', att.get('filename', 'unknown_file'))
                            file_data = att.get('data', att.get('fileData', ''))
                            
                            if file_name and file_data:
                                attachment_item = {
                                    'result': True,
                                    'fileName': file_name,
                                    'fileData': file_data
                                }
                                result_items.append(attachment_item)
                                app.logger.info(f"[SUCCESS] Added attachment: {file_name}")
                            else:
                                app.logger.warning(f"[WARNING] Incomplete attachment data: fileName={file_name}, has_data={bool(file_data)}")
            
            # Check for nested data structures (common in n8n)
            elif 'data' in item:
                app.logger.info("[DEBUG] Found nested data structure")
                nested_data = item['data']
                
                if isinstance(nested_data, list):
                    # Process each item in the nested list
                    for nested_item in nested_data:
                        sub_results = process_n8n_item_for_tickets_api(nested_item, item_index)
                        result_items.extend(sub_results)
                elif isinstance(nested_data, dict):
                    # Process the nested object
                    sub_results = process_n8n_item_for_tickets_api(nested_data, item_index)
                    result_items.extend(sub_results)
                elif isinstance(nested_data, str):
                    # Try to parse as JSON
                    try:
                        # Clean JSON before parsing
                        clean_json = nested_data.strip()
                        if clean_json.endswith(',}'):
                            clean_json = clean_json[:-2] + '}'
                        elif clean_json.endswith(',]'):
                            clean_json = clean_json[:-2] + ']'
                        parsed_data = json.loads(clean_json)
                        sub_results = process_n8n_item_for_tickets_api(parsed_data, item_index)
                        result_items.extend(sub_results)
                    except:
                        app.logger.warning("Failed to parse nested string data as JSON")
            
            # Check for direct attachment data
            elif 'fileName' in item and 'fileData' in item:
                app.logger.info(f"? Found direct attachment: {item['fileName']}")
                attachment_item = {
                    'result': True,
                    'fileName': item['fileName'],
                    'fileData': item['fileData']
                }
                result_items.append(attachment_item)
        
        # If we found attachments, add the ticket data at the end
        if result_items or any(key in str(item) for key in ['from', 'subject', 'body', 'email']):
            result_items.append(ticket_data)
            app.logger.info(f"[SUCCESS] Added ticket data: {ticket_data['ticket_id']}")
        
        return result_items
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error processing n8n item {item_index}: {e}")
        # Return basic structure to prevent failure
        return [{
            'error': str(e),
            'item_index': item_index,
            'ticket_id': f"ERROR{random.randint(100000, 999999)}"
        }]

def extract_name_from_email(email_address):
    """Extract name from email address"""
    if not email_address:
        return 'Unknown'
    
    # Split by @ and take the part before
    local_part = email_address.split('@')[0]
    
    # Replace dots/underscores with spaces and title case
    name = local_part.replace('.', ' ').replace('_', ' ').title()
    
    return name if name else 'Unknown'

@app.route('/api/tickets/simple-test', methods=['POST'])
def simple_test_endpoint():
    """
    ? TEMPORARY TEST ENDPOINT - Works exactly like your simple app (no database)
    This will help us determine if the issue is Vercel caching or database-related
    """
    try:
        # Get raw data first (exactly like simple app)
        raw_data = request.get_data()
        app.logger.info(f"? Simple test endpoint - Raw request data: {raw_data}")
        
        # Try to get JSON data (exactly like simple app)
        try:
            data = request.get_json(force=True)  # Force JSON parsing
            app.logger.info(f"? Simple test - Parsed JSON data: {data}")
        except Exception as json_error:
            app.logger.error(f"? Simple test - JSON parsing error: {json_error}")
            # Try to parse raw data as JSON
            try:
                data = json.loads(raw_data.decode('utf-8'))
                app.logger.info(f"? Simple test - Parsed raw JSON data: {data}")
            except:
                return jsonify({'error': f'Invalid JSON format: {str(json_error)}'}), 400
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # Process the email data using simple app logic (NO DATABASE)
        processed_tickets = process_robust_email_data(data)
        app.logger.info(f"? Simple test - Processed tickets: {len(processed_tickets) if processed_tickets else 0}")
        
        if not processed_tickets:
            # Even if no tickets processed, return success to prevent hanging (like simple app)
            return jsonify({
                'success': True,
                'message': 'Request processed but no valid ticket data found (SIMPLE TEST)',
                'count': 0,
                'tickets': []
            }), 200
        
        # Format response exactly like simple app (NO DATABASE SAVING)
        response_tickets = []
        for ticket in processed_tickets:
            # Don't override ticket_id if it exists from n8n data (like simple app)
            if not ticket.get('ticket_id'):
                ticket['ticket_id'] = f"TEST{datetime.now().strftime('%H%M%S%f')[:-3]}"
            ticket.setdefault('date', datetime.now().isoformat())
            ticket.setdefault('Priority', 'Medium')
            ticket.setdefault('Classification', 'General')
            ticket.setdefault('name', 'Unknown')
            ticket.setdefault('from', '')
            ticket.setdefault('subject', 'No Subject')
            ticket.setdefault('body', '')
            ticket.setdefault('draft', '')
            
            response_tickets.append(ticket)
        
        # Return success response exactly like simple app
        response = jsonify({
            'success': True,
            'message': 'SIMPLE TEST: Tickets processed successfully (NO DATABASE)',
            'count': len(response_tickets),
            'tickets': response_tickets,
            'test_mode': True
        })
        response.status_code = 200
        response.headers['Content-Type'] = 'application/json'
        
        app.logger.info(f"? Simple test - Sending successful response: {len(response_tickets)} tickets")
        return response
        
    except Exception as e:
        app.logger.error(f"? Simple test - Error processing request: {str(e)}")
        import traceback
        app.logger.error(f"? Simple test - Stack trace: {traceback.format_exc()}")
        
        # Ensure we always return a response to prevent hanging (like simple app)
        error_response = jsonify({
            'success': True,  # Return success even on error to prevent n8n hanging
            'error': f'Simple test server error: {str(e)}',
            'message': 'SIMPLE TEST: Request failed but acknowledged (NO DATABASE)',
            'test_mode': True
        })
        error_response.status_code = 200  # Return 200 even on error
        error_response.headers['Content-Type'] = 'application/json'
        return error_response

def detect_warranty_form(filename, file_data=None):
    """
    Detect if attachment is a warranty form based on filename or content
    """
    warranty_keywords = ['warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante']
    filename_lower = filename.lower()
    
    for keyword in warranty_keywords:
        if keyword in filename_lower:
            return True
    
    # Additional logic can be added here to analyze file content
    return False

def process_robust_email_data(data):
    """
    Robust email data processing logic adapted from the working simple app
    """
    processed_tickets = []
    attachments_list = []
    main_ticket = None
    warranty_detected = False
    
    app.logger.info(f"[DEBUG] Processing robust email data: {type(data)}")
    app.logger.info(f"[DEBUG] DEBUG: Data content preview: {str(data)[:200]}...")
    
    # Handle case where data is a list
    if isinstance(data, list):
        app.logger.info(f"[DEBUG] DEBUG: Processing {len(data)} items in list")
        for i, item in enumerate(data):
            if isinstance(item, dict):
                # Check if this item has attachment data
                if 'data' in item and isinstance(item['data'], list):
                    # This is the attachments route data
                    for att_data in item['data']:
                        if isinstance(att_data, dict):
                            if 'data' in att_data and isinstance(att_data['data'], str):
                                # Parse JSON string data
                                try:
                                    parsed_att = json.loads(att_data['data'])
                                    if 'fileName' in parsed_att:
                                        attachments_list.append(parsed_att)
                                        # Check for warranty form
                                        if detect_warranty_form(parsed_att['fileName']):
                                            warranty_detected = True
                                except json.JSONDecodeError as e:
                                    app.logger.warning(f"JSON decode error in attachment: {e}")
                            elif 'fileName' in att_data:
                                # Direct attachment data
                                attachments_list.append(att_data)
                                if detect_warranty_form(att_data['fileName']):
                                    warranty_detected = True
                
                # Check if this is main ticket data (text route)
                elif 'ticket_id' in item or 'threadI' in item or 'body' in item:
                    main_ticket = item
                    
                # Check if item has direct data field with JSON
                elif 'data' in item and isinstance(item['data'], str):
                    try:
                        parsed_data = json.loads(item['data'])
                        if 'fileName' in parsed_data:
                            attachments_list.append(parsed_data)
                            if detect_warranty_form(parsed_data['fileName']):
                                warranty_detected = True
                        else:
                            main_ticket = parsed_data
                    except json.JSONDecodeError:
                        pass
                
                # [FIX] CRITICAL FIX: Check for flat attachment structure BEFORE treating as main ticket
                elif 'fileName' in item and 'fileData' in item:
                    # This is a flat attachment structure
                    app.logger.info(f"[TARGET] DEBUG: FLAT ATTACHMENT DETECTED! fileName: {item['fileName']}")
                    attachments_list.append(item)
                    if detect_warranty_form(item['fileName']):
                        warranty_detected = True
                        app.logger.info(f"Warranty detected in flat attachment: {item['fileName']}")
                    app.logger.info(f"Detected flat attachment: {item['fileName']}")
                        
                # Direct ticket data without nesting (fallback)
                else:
                    if not main_ticket:  # Only set if we don't have one yet
                        main_ticket = item
    else:
        # Single item case
        if isinstance(data, dict):
            if 'ticket_id' in data or 'threadI' in data or 'body' in data:
                main_ticket = data
    
    # Combine main ticket with attachments
    app.logger.info(f"[TARGET] DEBUG: Final processing results - Attachments found: {len(attachments_list)}, Main ticket: {main_ticket is not None}")
    if main_ticket:
        combined_ticket = main_ticket.copy()
        combined_ticket['attachments'] = []
        combined_ticket['has_attachments'] = len(attachments_list) > 0
        combined_ticket['has_warranty'] = warranty_detected
        app.logger.info(f"[TARGET] DEBUG: Setting has_attachments to: {combined_ticket['has_attachments']}")
        
        for att in attachments_list:
            attachment = {
                'filename': att.get('fileName', 'unknown_file'),
                'data': att.get('fileData', ''),
                'is_warranty': detect_warranty_form(att.get('fileName', '')),
                'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0
            }
            combined_ticket['attachments'].append(attachment)
        
        processed_tickets.append(combined_ticket)
    
    # If we have attachments but no main ticket, create a basic ticket
    elif attachments_list:
        for att in attachments_list:
            ticket = {
                'ticket_id': att.get('ticketNo', att.get('ticket_id', 'UNKNOWN')),
                'name': 'Unknown',
                'from': att.get('from', ''),
                'subject': att.get('subject', 'Attachment Only'),
                'body': f"Ticket created from attachment: {att.get('fileName', 'unknown')}",
                'date': datetime.now().isoformat(),
                'priority': 'Medium',
                'classification': 'General',
                'attachments': [{
                    'filename': att.get('fileName', 'unknown_file'),
                    'data': att.get('fileData', ''),
                    'is_warranty': detect_warranty_form(att.get('fileName', '')),
                    'size': len(base64.b64decode(att.get('fileData', ''))) if att.get('fileData') else 0
                }],
                'has_attachments': True,
                'has_warranty': detect_warranty_form(att.get('fileName', ''))
            }
            processed_tickets.append(ticket)
    
    return processed_tickets

def process_enhanced_email_ticket(raw_data):
    """Process enhanced email data from n8n with warranty detection"""
    try:
        # Test database connection first
        try:
            db = get_db()
        except ValueError as db_error:
            if "MONGODB_URI environment variable is required" in str(db_error):
                app.logger.error("[ERROR] Database configuration error: MONGODB_URI environment variable not set")
                return jsonify({
                    'status': 'error',
                    'error_type': 'DatabaseConfigurationError',
                    'message': 'Database connection failed. Please check server configuration.',
                    'details': 'MONGODB_URI environment variable is required'
                }), 500
            else:
                raise db_error
        except Exception as db_error:
            app.logger.error(f"[ERROR] Database connection failed: {str(db_error)}")
            return jsonify({
                'status': 'error',
                'error_type': 'DatabaseConnectionError',
                'message': 'Database connection failed. Please try again later.'
            }), 500
        
        # Use robust email processing adapted from working simple app
        processed_tickets = process_robust_email_data(raw_data)
        
        if not processed_tickets:
            return jsonify({
                'status': 'warning',
                'message': 'No valid ticket data found in email',
                'count': 0,
                'tickets': []
            }), 200
        
        created_tickets = []
        
        for ticket_data in processed_tickets:
            # [FIX] Use n8n provided ticket_id if available, otherwise generate one
            n8n_ticket_id = ticket_data.get('ticket_id', '').strip()
            
            if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
                # Use n8n provided ticket ID if it doesn't exist in database
                ticket_id = n8n_ticket_id
                app.logger.info(f"[ENHANCED_EMAIL] Using n8n provided ticket ID: {ticket_id}")
                
                # Prepare enhanced ticket data
                enhanced_ticket = {
                    'ticket_id': ticket_id,
                    'name': ticket_data.get('name', 'Unknown'),
                    'email': ticket_data.get('from', ''),
                    'subject': ticket_data.get('subject', 'Email Ticket'),
                    'body': ticket_data.get('body', ''),
                    'priority': ticket_data.get('Priority', 'High' if ticket_data.get('has_warranty') else 'Medium'),
                    'classification': 'Warranty Claim' if ticket_data.get('has_warranty') else ticket_data.get('Classification', 'General'),
                    'status': 'New',
                    'creation_method': 'email',
                    
                    # Enhanced warranty & attachment data
                    'has_warranty': ticket_data.get('has_warranty', False),
                    'has_attachments': ticket_data.get('has_attachments', False),
                    'warranty_forms_count': ticket_data.get('warranty_forms_count', 0),
                    'total_attachments': ticket_data.get('total_attachments', 0),
                    'attachment_total_size': ticket_data.get('attachment_total_size', 0),
                    'processing_method': ticket_data.get('processing_method', 'enhanced_email_processor'),
                    'attachments': ticket_data.get('attachments', []),
                    
                    # Threading data - Generate completely unique thread_id to prevent attachment collisions
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                    'message_id': ticket_data.get('messageid', ''),
                    'processed_at': datetime.now().isoformat()
                }
                
                try:
                    # Create in database
                    db.create_ticket(enhanced_ticket)
                    app.logger.info(f"[SUCCESS] Enhanced email ticket created using n8n ID: {ticket_id} | Warranty: {enhanced_ticket['has_warranty']} | Attachments: {enhanced_ticket['total_attachments']}")
                    
                    created_tickets.append({
                        'ticket_id': ticket_id,
                        'has_warranty': enhanced_ticket['has_warranty'],
                        'warranty_forms_count': enhanced_ticket['warranty_forms_count'],
                        'has_attachments': enhanced_ticket['has_attachments'],
                        'total_attachments': enhanced_ticket['total_attachments'],
                        'priority': enhanced_ticket['priority']
                    })
                except ValueError as e:
                    app.logger.error(f"Failed to create enhanced email ticket with n8n ID {ticket_id}: {e}")
            else:
                # Generate unique ticket ID with enhanced collision protection as fallback
                timestamp = datetime.now()
                base_prefix = "EMAIL"  # Changed from "OL" to be more specific
                
                base_ticket_id = f"{base_prefix}{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
                
                max_attempts = 20  # Increased attempts for busy periods
                ticket_id = None
                
                if n8n_ticket_id:
                    app.logger.warning(f"[ENHANCED_EMAIL] N8N ticket ID {n8n_ticket_id} already exists, generating new ID")
                else:
                    app.logger.info(f"[ENHANCED_EMAIL] No n8n ticket ID provided, generating new ID")
                
                for attempt in range(max_attempts):
                    potential_id = f"{base_ticket_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                    
                    try:
                        # Prepare enhanced ticket data
                        enhanced_ticket = {
                            'ticket_id': potential_id,
                            'name': ticket_data.get('name', 'Unknown'),
                            'email': ticket_data.get('from', ''),
                            'subject': ticket_data.get('subject', 'Email Ticket'),
                            'body': ticket_data.get('body', ''),
                            'priority': ticket_data.get('Priority', 'High' if ticket_data.get('has_warranty') else 'Medium'),
                            'classification': 'Warranty Claim' if ticket_data.get('has_warranty') else ticket_data.get('Classification', 'General'),
                            'status': 'New',
                            'creation_method': 'email',
                            
                            # Enhanced warranty & attachment data
                            'has_warranty': ticket_data.get('has_warranty', False),
                            'has_attachments': ticket_data.get('has_attachments', False),
                            'warranty_forms_count': ticket_data.get('warranty_forms_count', 0),
                            'total_attachments': ticket_data.get('total_attachments', 0),
                            'attachment_total_size': ticket_data.get('attachment_total_size', 0),
                            'processing_method': ticket_data.get('processing_method', 'enhanced_email_processor'),
                            'attachments': ticket_data.get('attachments', []),
                            
                            # Threading data - Generate completely unique thread_id to prevent attachment collisions
                            'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}",
                            'message_id': ticket_data.get('messageid', ''),
                            'processed_at': datetime.now().isoformat()
                        }
                        
                        # Log warranty classification for debugging
                        if enhanced_ticket.get('has_warranty'):
                            app.logger.info(f" ENHANCED EMAIL WARRANTY: Ticket {potential_id} created with classification '{enhanced_ticket['classification']}' (has_warranty: {enhanced_ticket.get('has_warranty')})")
                        
                        # Create in database
                        db.create_ticket(enhanced_ticket)
                        ticket_id = potential_id
                        
                        # Log successful creation
                        app.logger.info(f"[SUCCESS] Email ticket created: {ticket_id} | Warranty: {enhanced_ticket['has_warranty']} | Attachments: {enhanced_ticket['total_attachments']}")
                        
                        created_tickets.append({
                            'ticket_id': ticket_id,
                            'has_warranty': enhanced_ticket['has_warranty'],
                            'warranty_forms_count': enhanced_ticket['warranty_forms_count'],
                            'has_attachments': enhanced_ticket['has_attachments'],
                            'total_attachments': enhanced_ticket['total_attachments'],
                            'priority': enhanced_ticket['priority']
                        })
                        break
                        
                    except ValueError as e:
                        if "Ticket ID already exists" in str(e):
                            app.logger.debug(f"[RETRY] Email ticket ID collision: {potential_id}, retrying (attempt {attempt + 1})")
                            continue
                        else:
                            raise e
            
            if not ticket_id:
                app.logger.error(f"[ERROR] Failed to generate unique ticket ID after {max_attempts} attempts")
                return jsonify({
                    'status': 'error',
                    'message': 'Failed to generate unique ticket ID. Please try again.'
                }), 500
        
        return jsonify({
            'status': 'success',
            'message': f'Successfully created {len(created_tickets)} email ticket(s) with enhanced processing',
            'count': len(created_tickets),
            'tickets': created_tickets,
            'warranty_forms_detected': sum(1 for t in created_tickets if t['has_warranty']),
            'total_attachments': sum(t['total_attachments'] for t in created_tickets)
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] Enhanced email processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Email processing failed: {str(e)}'
        }), 500

def process_simple_json_ticket(data):
    """Process simple JSON ticket data"""
    try:
        # Test database connection first
        try:
            db = get_db()
        except ValueError as db_error:
            if "MONGODB_URI environment variable is required" in str(db_error):
                app.logger.error("[ERROR] Database configuration error: MONGODB_URI environment variable not set")
                return jsonify({
                    'status': 'error',
                    'error_type': 'DatabaseConfigurationError',
                    'message': 'Database connection failed. Please check server configuration.',
                    'details': 'MONGODB_URI environment variable is required'
                }), 500
            else:
                raise db_error
        except Exception as db_error:
            app.logger.error(f"[ERROR] Database connection failed: {str(db_error)}")
            return jsonify({
                'status': 'error',
                'error_type': 'DatabaseConnectionError',
                'message': 'Database connection failed. Please try again later.'
            }), 500
        
        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
        n8n_ticket_id = data.get('ticket_id', '').strip() if isinstance(data, dict) else ''
        
        if n8n_ticket_id and not db.ticket_id_exists(n8n_ticket_id):
            # Use n8n provided ticket ID if it doesn't exist in database
            ticket_id = n8n_ticket_id
            app.logger.info(f"[JSAPI_PROCESS] Using n8n provided ticket ID: {ticket_id}")
            
            try:
                # Create basic ticket with unique thread_id (CRITICAL FIX for attachment collisions)
                ticket = {
                    'ticket_id': ticket_id,
                    'name': data.get('name', 'Unknown'),
                    'email': data.get('email', ''),
                    'subject': data.get('subject', 'API Ticket'),
                    'body': data.get('body', ''),
                    'priority': data.get('priority', 'Medium'),
                    'classification': data.get('classification', 'General'),
                    'status': 'New',
                    'creation_method': 'simple_json_api',
                    'has_warranty': False,
                    'has_attachments': False,
                    'warranty_forms_count': 0,
                    'total_attachments': 0,
                    'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"  # CRITICAL: Added missing thread_id
                }
                
                db.create_ticket(ticket)
                app.logger.info(f"[SUCCESS] Simple JSON ticket created using n8n ID: {ticket_id}")
                
            except ValueError as e:
                app.logger.error(f"Failed to create simple JSON ticket with n8n ID {ticket_id}: {e}")
                # Fall through to generate new ID
                ticket_id = None
        
        if not ticket_id:
            # Generate collision-resistant ticket ID as fallback
            timestamp = datetime.now()
            base_id = f"JSAPI{timestamp.strftime('%H%M%S')}{timestamp.microsecond:06d}{random.randint(10,99)}"[:12]
            
            # Collision protection loop
            max_attempts = 20
            
            if n8n_ticket_id:
                app.logger.warning(f"[JSAPI_PROCESS] N8N ticket ID {n8n_ticket_id} already exists or failed, generating new ID")
            else:
                app.logger.info(f"[JSAPI_PROCESS] No n8n ticket ID provided, generating new ID")
            
            for attempt in range(max_attempts):
                potential_id = f"{base_id}{f'_{attempt+1}' if attempt > 0 else ''}"
                
                try:
                    # Create basic ticket with unique thread_id
                    ticket = {
                        'ticket_id': potential_id,
                        'name': data.get('name', 'Unknown'),
                        'email': data.get('email', ''),
                        'subject': data.get('subject', 'API Ticket'),
                        'body': data.get('body', ''),
                        'priority': data.get('priority', 'Medium'),
                        'classification': data.get('classification', 'General'),
                        'status': 'New',
                        'creation_method': 'simple_json_api',
                        'has_warranty': False,
                        'has_attachments': False,
                        'warranty_forms_count': 0,
                        'total_attachments': 0,
                        'thread_id': f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                    }
                    
                    db.create_ticket(ticket)
                    ticket_id = potential_id
                    break
                    
                except ValueError as e:
                    if "Ticket ID already exists" in str(e):
                        app.logger.debug(f"[RETRY] Simple JSON ticket ID collision: {potential_id}, retrying (attempt {attempt + 1})")
                        continue
                    else:
                        raise e
        
        if not ticket_id:
            app.logger.error(f"[ERROR] Failed to generate unique simple JSON ticket ID after {max_attempts} attempts")
            return jsonify({
                'status': 'error',
                'message': 'Failed to generate unique ticket ID. Please try again.'
            }), 500
        
        app.logger.info(f"[SUCCESS] Simple JSON ticket created: {ticket_id}")
        
        return jsonify({
            'status': 'success',
            'message': 'Simple JSON ticket created successfully',
            'ticket_id': ticket_id,
            'creation_method': 'simple_json_api'
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] Simple JSON processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Ticket creation failed: {str(e)}'
        }), 500

def process_manual_form_ticket():
    """Process manual form data from UI (redirect to existing create endpoint)"""
    app.logger.info("[RETRY] Redirecting manual form to existing /api/tickets/create endpoint")
    return api_create_ticket()

@app.route('/api/tickets/n8n-create', methods=['POST'])
def n8n_create_ticket():
    """Dedicated endpoint for n8n ticket creation without authentication - WITH DATABASE"""
    app.logger.info("? N8N dedicated endpoint called - processing WITH database (fixed thread_id)")
    return process_n8n_form_ticket()

def process_n8n_form_ticket():
    """Process form data from n8n without authentication requirements"""
    try:
        # Test database connection first
        try:
            db = get_db()
            # Test database connectivity with a simple operation
            test_count = db.tickets.count_documents({})
            app.logger.info(f"?? Database connection successful for n8n form. Current ticket count: {test_count}")
        except Exception as db_error:
            app.logger.error(f"[ERROR] CRITICAL: Database connection failed for n8n form: {db_error}")
            return jsonify({
                'status': 'error',
                'message': 'Database connection failed. Please try again later.',
                'error_type': 'DatabaseConnectionError'
            }), 500
        
        app.logger.info("? Processing n8n form data without authentication")
        
        # Extract form data (similar to manual processing but without auth)
        name = request.form.get('name', request.form.get('customer_name', 'Unknown')).strip()
        email = request.form.get('email', request.form.get('from', '')).strip()
        subject = request.form.get('subject', 'N8N Form Ticket').strip()
        body = request.form.get('body', request.form.get('message', '')).strip()
        priority = request.form.get('priority', 'Medium').strip()
        classification = request.form.get('classification', 'General').strip()
        
        app.logger.info(f"[NOTE] N8N Form Data: name='{name}', email='{email}', subject='{subject[:50]}...'")
        
        # Check for warranty indicators in form data
        has_warranty = False
        warranty_keywords = ['warranty', 'guarantee', 'claim', 'dpf', 'emission', 'defect']
        search_text = f"{subject} {body}".lower()
        
        for keyword in warranty_keywords:
            if keyword in search_text:
                has_warranty = True
                break
        
        # [FIX] Use n8n provided ticket_id if available, otherwise generate one
        # Upgrade classification for warranty claims
        final_classification = 'Warranty Claim' if has_warranty else classification
        
        if has_warranty:
            app.logger.info(f" WARRANTY EMAIL DETECTED: Setting classification from '{classification}' to 'Warranty Claim' for {name} ({email})")
        
        # Check for n8n provided ticket_id first
        n8n_ticket_id = request.form.get('ticket_id', '').strip()
        
        if n8n_ticket_id:
            # Use n8n ticket ID EXACTLY as provided (no formatting, no prefixes)
            if not db.ticket_id_exists(n8n_ticket_id):
                # Use n8n ticket ID exactly as-is
                ticket_id = n8n_ticket_id
                app.logger.info(f"[N8N_FORM] Using n8n ticket ID exactly as provided: {ticket_id}")
            else:
                # If n8n ticket ID already exists, append a suffix to make it unique
                # This preserves the n8n ID while ensuring uniqueness
                suffix = 1
                while True:
                    unique_ticket_id = f"{n8n_ticket_id}_{suffix}"
                    if not db.ticket_id_exists(unique_ticket_id):
                        ticket_id = unique_ticket_id
                        app.logger.info(f"[N8N_FORM] N8N ticket ID {n8n_ticket_id} already exists, using unique variant: {ticket_id}")
                        break
                    suffix += 1
                    if suffix > 999:  # Prevent infinite loops
                        app.logger.error(f"[N8N_FORM] Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
                        raise Exception(f"Could not create unique variant of n8n ticket ID {n8n_ticket_id}")
        else:
            # No n8n ticket ID provided, generate new one
            app.logger.info(f"[N8N_FORM] No n8n ticket ID provided, generating new ID")
            ticket_id = generate_email_ticket_id(email, name, final_classification, db)
        
        # Generate unique thread_id to prevent attachment collisions
        thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
        
        app.logger.info(f"[SUCCESS] Using ticket ID: {ticket_id}")
        
        # Create ticket data
        ticket_data = {
            'ticket_id': ticket_id,
            'name': name,
            'email': email,
            'subject': subject,
            'body': body,
            'draft_body': '',  # Will be generated below
            'priority': 'High' if has_warranty else priority,
            'classification': final_classification,
            'status': 'New',
            'creation_method': 'n8n_form',
            'has_warranty': has_warranty,
            'has_attachments': False,  # Form data typically doesn't have attachments
            'warranty_forms_count': 1 if has_warranty else 0,
            'total_attachments': 0,
            'processing_method': 'n8n_form_processor',
            'thread_id': thread_id
        }
        
        # ðŸš€ GENERATE SMART DRAFT RESPONSE for N8N form tickets
        app.logger.info(f"ðŸ¤– GENERATING SMART DRAFT for N8N form ticket {ticket_id}")
        app.logger.info(f"ðŸ” DEBUG: ticket_data['ticket_id'] = {ticket_data.get('ticket_id')} (should be formatted like EO980494)")
        draft_response = generate_email_draft_response(ticket_data)
        ticket_data['draft_body'] = draft_response
        app.logger.info(f"ðŸ“ DRAFT GENERATED: {draft_response[:200]}..." if len(draft_response) > 200 else f"ðŸ“ DRAFT GENERATED: {draft_response}")
        app.logger.info(f" SMART DRAFT GENERATED for N8N form ticket {ticket_id} - Length: {len(draft_response)} chars")
        
        # Create ticket (collision protection is handled by generate_email_ticket_id)
        db.create_ticket(ticket_data)
        app.logger.info(f"[SUCCESS] N8N form ticket created: {ticket_id} | Warranty: {has_warranty} | Priority: {ticket_data['priority']}")
        
        # Success - return result
        return jsonify({
            'status': 'success',
            'message': 'N8N form ticket created successfully',
            'ticket_id': ticket_id,
            'has_warranty': has_warranty
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] N8N form processing error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'N8N form ticket creation failed: {str(e)}'
        }), 500

@app.route('/api/tickets/create', methods=['POST'])
def api_create_ticket():
    """
    Create a ticket with new structured fields and attachments
    """
    app.logger.info("=== STARTING TICKET CREATION ===")
    app.logger.info(f"Request method: {request.method}")
    app.logger.info(f"Request form data: {dict(request.form)}")
    app.logger.info(f"Request files: {dict(request.files)}")
    app.logger.info(f"Request files keys: {list(request.files.keys())}")
    app.logger.info(f"Session data: {dict(session)}")
    
    """
    
    TICKET NUMBERING SYSTEM (All tickets are 6 characters):
    - Manual tickets: M{type}{4 random} (e.g., MP1A2B for Premium DPF, MK3F8E for Workshop)
    - Email tickets: {class}{priority}{4 random} (e.g., TM3F8E for Technical Medium, XU9A2B for Spam Urgent)
    - Warranty tickets: W{5 random} (e.g., W7K9L2)
    
    Type codes for manual tickets:
    - P = DPF Clean - Premium
    - S = DPF Clean - Standard  
    - J = Part Job
    - O = Other
    - K = Workshop Job (worKshop)
    
    Duplicate checking ensures unique ticket IDs across all types.
    """
    # Check if this is an unauthenticated request
    if 'member_id' not in session:
        # Process dynamic email JSON instead of redirecting to form handler
        app.logger.info("? Unauthenticated request to /api/tickets/create - processing dynamic email JSON")
        try:
            incoming_data = request.get_json(silent=True)
            if incoming_data is None and 'data' in request.form:
                try:
                    incoming_data = json.loads(request.form.get('data', '{}'))
                except Exception:
                    incoming_data = None

            # If incoming_data is a list, try to find a dict with typical email keys
            if isinstance(incoming_data, list):
                candidate = None
                for item in incoming_data:
                    if isinstance(item, dict) and (('body' in item) or ('from' in item) or ('subject' in item) or ('ticket_id' in item)):
                        candidate = item
                        break
                incoming_data = candidate if candidate else (incoming_data[0] if incoming_data else None)

            if isinstance(incoming_data, dict):
                ticket_data = process_n8n_ticket_data(incoming_data)
                if ticket_data:
                    # Ensure required fields for DB insert
                    if 'thread_id' not in ticket_data or not ticket_data.get('thread_id'):
                        ticket_data['thread_id'] = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                    ticket_data['status'] = ticket_data.get('status', 'New')
                    ticket_data['creation_method'] = ticket_data.get('creation_method', 'email_ingest')

                    # Generate draft response if not present
                    try:
                        if not ticket_data.get('draft_body'):
                            draft_response = generate_email_draft_response(ticket_data)
                            ticket_data['draft_body'] = draft_response
                    except Exception as draft_err:
                        app.logger.error(f"[ERROR] Failed generating draft response: {draft_err}")

                    # Persist ticket
                    try:
                        db = get_db()
                        db.create_ticket(ticket_data)
                        app.logger.info(f"[SUCCESS] Email JSON ticket created: {ticket_data.get('ticket_id')}")
                        return jsonify({
                            'status': 'success',
                            'message': 'Email JSON ticket created successfully',
                            'ticket_id': ticket_data.get('ticket_id'),
                            'creation_method': ticket_data.get('creation_method')
                        }), 200
                    except Exception as db_err:
                        app.logger.error(f"[ERROR] Failed to create email JSON ticket: {db_err}")
                        return jsonify({'status': 'error', 'message': 'Failed to create ticket from email JSON'}), 500

            # If we reach here, we couldn't parse dynamic data; fail rather than creating default form ticket
            return jsonify({'status': 'error', 'message': 'No valid email JSON provided for unauthenticated request'}), 400
        except Exception as e:
            app.logger.error(f"[ERROR] Unauthenticated email JSON processing failed: {e}")
            return jsonify({'status': 'error', 'message': 'Unauthenticated email JSON processing failed'}), 500
    
    try:
        # Extract required form data
        customer_title = request.form.get('customer_title', '').strip()
        customer_first_name = request.form.get('customer_first_name', '').strip()
        customer_surname = request.form.get('customer_surname', '').strip()
        email = request.form.get('email', '').strip()
        vehicle_registration = request.form.get('vehicle_registration', '').strip().upper()
        type_of_claim = request.form.get('type_of_claim', '').strip()
        priority = request.form.get('priority', '').strip()
        technician = request.form.get('technician', '').strip()
        subject = request.form.get('subject', '').strip()
        description = request.form.get('description', '').strip()
        service_date = request.form.get('service_date', '').strip()
        claim_date = request.form.get('claim_date', '').strip()
        vhc_link = request.form.get('vhc_link', '').strip()
        
        # Validate required fields
        required_fields = {
            'customer_title': customer_title,
            'customer_first_name': customer_first_name,
            'customer_surname': customer_surname,
            'email': email,
            'vehicle_registration': vehicle_registration,
            'type_of_claim': type_of_claim,
            'priority': priority,
            'technician': technician,
            'subject': subject,
            'description': description,
            'service_date': service_date,
            'claim_date': claim_date
        }
        
        for field_name, field_value in required_fields.items():
            if not field_value:
                return jsonify({'status': 'error', 'message': f'Missing required field: {field_name.replace("_", " ").title()}'}), 400
        
        # Validate email format
        if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', email):
            return jsonify({'status': 'error', 'message': 'Invalid email format'}), 400
        
        # Validate dates
        try:
            service_date_obj = datetime.strptime(service_date, '%Y-%m-%d')
            claim_date_obj = datetime.strptime(claim_date, '%Y-%m-%d')
            if claim_date_obj < service_date_obj:
                return jsonify({'status': 'error', 'message': 'Claim date cannot be before service date'}), 400
        except ValueError:
            return jsonify({'status': 'error', 'message': 'Invalid date format'}), 400
        
        # Create combined customer name for compatibility
        customer_full_name = f"{customer_title} {customer_first_name} {customer_surname}"
        
        # Connect to database early (needed for duplicate checking)
        try:
            db = get_db()
            # Test database connectivity
            test_count = db.tickets.count_documents({})
            app.logger.info(f"?? Database connection successful. Current ticket count: {test_count}")
        except Exception as db_error:
            app.logger.error(f"[ERROR] CRITICAL: Database connection failed: {db_error}")
            return jsonify({
                'status': 'error',
                'message': 'Database connection failed. Please try again later.',
                'error_type': 'DatabaseConnectionError'
            }), 500
        
        # Generate automatic ticket ID for manual tickets (6 chars total: M + type + 4 random)
        type_code_mapping = {
            'DPF Clean - Premium': 'P',  # Premium
            'DPF Clean-Standard': 'S',   # Standard
            'Part Job': 'J',             # Job
            'Other': 'O',                # Other
            'Workshop Job': 'K'          # worKshop (changed from 'W' to avoid conflict with Warranty tickets)
        }
        
        type_code = type_code_mapping.get(type_of_claim, 'O')
        
        # Generate unique ticket ID with improved collision detection
        import random
        import string
        import time
        import uuid
        
        ticket_id = None
        max_attempts = 100
        
        # Log current ticket statistics for debugging
        try:
            manual_ticket_count = db.tickets.count_documents({'ticket_id': {'$regex': f'^M{type_code}'}})
            total_ticket_count = db.tickets.count_documents({})
            app.logger.info(f"Current database state: {total_ticket_count} total tickets, {manual_ticket_count} with prefix M{type_code}")
        except Exception as e:
            app.logger.warning(f"Could not get ticket statistics: {e}")
        
        for attempt in range(max_attempts):
            try:
                # Generate 4-digit code using same logic as email tickets (deterministic based on customer data)
                # Use customer email + timestamp to create unique seed for calculation
                seed_string = f"{email}{customer_full_name}{datetime.now().isoformat()}"
                
                # Calculate sum of character codes (same logic as email system)
                sum_chars = 0
                for char in seed_string:
                    sum_chars += ord(char)
                
                # Generate 4-digit number (same as email system: sum % 10000)
                four_digit_code = sum_chars % 10000
                four_digit_str = f"{four_digit_code:04d}"  # Ensure 4 digits with leading zeros
                
                potential_id = f"M{type_code}{four_digit_str}"  # Exactly 6 chars: M + 1 + 4 digits
                
                app.logger.info(f"Attempting ticket ID: {potential_id} (attempt {attempt + 1}/{max_attempts})")
                app.logger.debug(f"? Calculation details: seed='{seed_string[:50]}...', sum_chars={sum_chars}, 4-digit={four_digit_code}")
                
                # Use dedicated ticket_id_exists method for faster checking
                app.logger.debug(f"[DEBUG] Checking if ticket ID {potential_id} exists...")
                
                try:
                    exists = db.ticket_id_exists(potential_id)
                    app.logger.debug(f"[SUCCESS] Database check complete: {potential_id} exists = {exists}")
                except Exception as db_check_error:
                    app.logger.error(f"[ERROR] Database check failed for {potential_id}: {db_check_error}")
                    # On database connectivity issues, wait briefly and retry the same ID
                    import time
                    time.sleep(0.1)  # Brief pause to allow for database recovery
                    try:
                        # Retry the database check once more
                        exists = db.ticket_id_exists(potential_id)
                        app.logger.info(f"[SUCCESS] Database check retry successful: {potential_id} exists = {exists}")
                    except Exception as retry_error:
                        app.logger.error(f"[ERROR] Database check retry also failed: {retry_error}")
                        # Skip this attempt and try the next ID
                        continue
                
                if not exists:
                    # ID is unique, create the ticket
                    # Generate unique thread_id for manual tickets (required due to unique index)
                    # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
                    thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                    
                    ticket_data = {
                        'ticket_id': potential_id,
                        'email': email,
                        'name': customer_full_name,
                        'subject': subject,
                        'body': description,
                        'status': 'Open',
                        'priority': priority,
                        'classification': type_of_claim,
                        'technician': technician,
                        'vehicle_registration': vehicle_registration,
                        'service_date': service_date,
                        'claim_date': claim_date,
                        'creation_method': 'manual',
                        'thread_id': thread_id,  # CRITICAL: Must be unique due to database constraint
                        'created_at': datetime.now(),
                        'updated_at': datetime.now()
                    }
                    
                    # Add created_by only if we have a session
                    if session.get('member_id'):
                        ticket_data['created_by'] = session.get('member_id')
                    
                    try:
                        app.logger.debug(f"? Attempting to create ticket with ID {potential_id}, thread_id {thread_id}")
                        result = db.create_ticket(ticket_data)
                        ticket_id = potential_id
                        app.logger.info(f"[SUCCESS] Successfully created manual ticket with ID: {ticket_id} on attempt {attempt + 1}")
                        app.logger.info(f"? Ticket data: email={email}, name={customer_full_name[:20]}..., thread_id={thread_id}")
                        break
                        
                    except ValueError as e:
                        error_str = str(e)
                        if "Ticket ID already exists" in error_str:
                            app.logger.warning(f"[WARNING] Race condition detected for ticket ID {potential_id}, retrying (attempt {attempt + 1})")
                            continue  # Race condition, try again
                        elif "Thread ID already exists" in error_str:
                            app.logger.warning(f"[WARNING] Thread ID collision detected, generating new thread_id and retrying (attempt {attempt + 1})")
                            # Generate a new thread_id and try again with the same ticket_id
                            # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
                            thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                            continue
                        else:
                            # Different ValueError, log and re-raise
                            app.logger.error(f"[ERROR] ValueError creating ticket {potential_id}: {e}")
                            raise e
                    except Exception as e:
                        app.logger.error(f"[ERROR] Unexpected error creating ticket with ID {potential_id}: {e}")
                        app.logger.error(f"[DEBUG] Full error details: {type(e).__name__}: {str(e)}")
                        import traceback
                        app.logger.error(f"? Stack trace: {traceback.format_exc()}")
                        raise e
                else:
                    # ID already exists
                    app.logger.debug(f"[RETRY] Ticket ID {potential_id} already exists, retrying (attempt {attempt + 1})")
                    continue
                        
            except Exception as e:
                app.logger.error(f"[ERROR] Error during ticket ID generation attempt {attempt + 1}: {str(e)}")
                continue
        
        if not ticket_id:
            # Last resort: Try fallback ID generation with UUID
            app.logger.warning(f"[WARNING] Primary ID generation failed, attempting fallback method...")
            
            fallback_attempts = 5
            for fallback_attempt in range(fallback_attempts):
                try:
                    # Generate a completely different style ID using UUID
                    import uuid
                    short_uuid = str(uuid.uuid4()).replace('-', '')[:8].upper()
                    fallback_id = f"M{type_code}{short_uuid}"[:12]  # Limit to 12 chars max
                    
                    app.logger.info(f"? Fallback attempt {fallback_attempt + 1}: trying ID {fallback_id}")
                    
                    # Check if this fallback ID exists
                    try:
                        exists = db.ticket_id_exists(fallback_id)
                        if not exists:
                            # Create ticket with fallback ID
                            # Generate completely unique thread_id to prevent attachment collisions (same as enhanced email processor)
                            thread_id = f"TH_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{uuid.uuid4().hex[:8]}_{random.randint(10000,99999)}"
                            ticket_data = {
                                'ticket_id': fallback_id,
                                'email': email,
                                'name': customer_full_name,
                                'subject': subject,
                                'body': description,
                                'status': 'Open',
                                'priority': priority,
                                'classification': type_of_claim,
                                'technician': technician,
                                'vehicle_registration': vehicle_registration,
                                'service_date': service_date,
                                'claim_date': claim_date,
                                'creation_method': 'manual_fallback',
                                'thread_id': thread_id,
                                'created_at': datetime.now(),
                                'updated_at': datetime.now()
                            }
                            
                            if session.get('member_id'):
                                ticket_data['created_by'] = session.get('member_id')
                            
                            result = db.create_ticket(ticket_data)
                            ticket_id = fallback_id
                            app.logger.info(f"[TARGET] SUCCESS: Fallback ticket created with ID {ticket_id}")
                            break
                            
                    except Exception as fallback_db_error:
                        app.logger.error(f"[ERROR] Fallback database error: {fallback_db_error}")
                        continue
                        
                except Exception as fallback_error:
                    app.logger.error(f"[ERROR] Fallback generation error: {fallback_error}")
                    continue
            
            if not ticket_id:
                error_msg = f'Failed to generate unique ticket ID after {max_attempts} attempts and {fallback_attempts} fallback attempts. Type code: M{type_code}. This may indicate severe database connectivity issues or extremely high collision rate. Please contact system administrator.'
                app.logger.error(f"[ERROR] CRITICAL: {error_msg}")
                return jsonify({
                    'status': 'error', 
                    'message': error_msg,
                    'debug_info': {
                        'type_code': type_code,
                        'max_attempts': max_attempts,
                        'fallback_attempts': fallback_attempts,
                        'suggested_action': 'Contact system administrator - severe database issues detected'
                    }
                }), 500
        
        app.logger.info(f"Ticket created successfully with ID: {ticket_id}")
        
        # Handle file uploads - FIXED: Store files in database as base64p
        uploaded_files = []
        app.logger.info(f"Starting file upload processing for ticket {ticket_id}")
        
        # ENHANCED DEBUGGING: Check what's in request.files
        app.logger.info(f"DEBUG: request.files keys: {list(request.files.keys())}")
        app.logger.info(f"DEBUG: request.files content: {dict(request.files)}")
        app.logger.info(f"DEBUG: request.content_type: {request.content_type}")
        app.logger.info(f"DEBUG: request.content_length: {request.content_length}")
        
        try:
            # Create uploads directory for this ticket
            upload_dir = os.path.join(UPLOAD_FOLDER, ticket_id)
            os.makedirs(upload_dir, exist_ok=True)
            app.logger.info(f"Created upload directory: {upload_dir}")
            
            # Process each attachment type
            attachment_fields = {
                'dpf_report': 'DPF Report',
                'warranty_form': 'Warranty Form',
                'other_attachments': 'Other Documents'
            }
            
            for field_name, display_name in attachment_fields.items():
                app.logger.info(f"DEBUG: Checking field '{field_name}'")
                
                # Get files using getlist (handles both single and multiple files)
                files = request.files.getlist(field_name)
                app.logger.info(f"DEBUG: getlist('{field_name}') returned {len(files)} files")
                
                # Filter out empty files and duplicates
                valid_files = []
                seen_filenames = set()
                
                for file in files:
                    if file and hasattr(file, 'filename') and file.filename and file.filename.strip():
                        # Check for duplicate filenames
                        if file.filename not in seen_filenames:
                            valid_files.append(file)
                            seen_filenames.add(file.filename)
                            app.logger.info(f"DEBUG: Added valid file: {file.filename}")
                        else:
                            app.logger.warning(f"DEBUG: Skipping duplicate file: {file.filename}")
                    else:
                        app.logger.warning(f"DEBUG: Skipping invalid file object for field '{field_name}'")
                
                app.logger.info(f"Processing field '{field_name}' - found {len(valid_files)} valid files after deduplication")
                
                # Use the deduplicated files list
                files = valid_files
                
                for file in files:
                    app.logger.info(f"DEBUG: Processing file object: {file}")
                    app.logger.info(f"DEBUG: File type: {type(file)}")
                    app.logger.info(f"DEBUG: File has filename attr: {hasattr(file, 'filename')}")
                    
                    # ENHANCED FILE VALIDATION
                    if file and hasattr(file, 'filename') and file.filename and file.filename.strip():
                        app.logger.info(f"Processing file: {file.filename} (field: {field_name})")
                        
                        # Generate safe filename
                        filename = secure_filename(file.filename)
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        safe_filename = f"{timestamp}_{filename}"
                        file_path = os.path.join(upload_dir, safe_filename)
                        
                        # Save file to disk (for backup and compatibility)
                        file.save(file_path)
                        app.logger.info(f"File saved to disk: {file_path}")
                        
                        # Get file size
                        file_size = os.path.getsize(file_path)
                        
                        # FIXED: Read file content and convert to base64 for database storage
                        try:
                            with open(file_path, 'rb') as f:
                                file_content = f.read()
                                file_data = base64.b64encode(file_content).decode('utf-8')
                            app.logger.info(f"SUCCESS: Converted file to base64: {filename} ({len(file_data)} chars)")
                        except Exception as e:
                            app.logger.error(f"ERROR: Failed to read file for base64 conversion: {e}")
                            file_data = ''
                        
                        file_info = {
                            'type': display_name,
                            'filename': safe_filename,
                            'original_name': filename,
                            'path': file_path,  # Keep path for fallback
                            'size': file_size,
                            'data': file_data,  # FIXED: Add base64 data for database storage
                            'is_warranty': field_name == 'warranty_form',
                            'file_type_info': 'document'
                        }
                        uploaded_files.append(file_info)
                        app.logger.info(f"SUCCESS: Added file to uploaded_files: {filename} (size: {file_size} bytes, base64: {len(file_data)} chars)")
                    else:
                        app.logger.warning(f"DEBUG: File object is empty or has no filename for field '{field_name}'")
                        app.logger.warning(f"DEBUG: File object: {file}")
                        app.logger.warning(f"DEBUG: File type: {type(file)}")
                        app.logger.warning(f"DEBUG: File has filename attr: {hasattr(file, 'filename')}")
                        if hasattr(file, 'filename'):
                            app.logger.warning(f"DEBUG: File filename: '{file.filename}'")
                            app.logger.warning(f"DEBUG: File filename stripped: '{file.filename.strip() if file.filename else 'None'}'")
                        
        except Exception as e:
            app.logger.error(f"Error processing file uploads: {e}")
            app.logger.error(f"Full traceback: {traceback.format_exc()}")
            uploaded_files = []
        
        # Store structured metadata
        metadata_entries = [
            {'ticket_id': ticket_id, 'key': 'customer_title', 'value': customer_title},
            {'ticket_id': ticket_id, 'key': 'customer_first_name', 'value': customer_first_name},
            {'ticket_id': ticket_id, 'key': 'customer_surname', 'value': customer_surname},
            {'ticket_id': ticket_id, 'key': 'vehicle_registration', 'value': vehicle_registration},
            {'ticket_id': ticket_id, 'key': 'type_of_claim', 'value': type_of_claim},
            {'ticket_id': ticket_id, 'key': 'technician', 'value': technician},
            {'ticket_id': ticket_id, 'key': 'service_date', 'value': service_date},
            {'ticket_id': ticket_id, 'key': 'claim_date', 'value': claim_date}
        ]
        
        # Add VHC link if provided
        if vhc_link:
            metadata_entries.append({'ticket_id': ticket_id, 'key': 'vhc_link', 'value': vhc_link})
        
        # Add attachment metadata
        for i, file_info in enumerate(uploaded_files):
            metadata_entries.append({
                'ticket_id': ticket_id, 
                'key': f'attachment_{i+1}', 
                'value': json.dumps(file_info)
            })
        
        # Store all metadata
        for metadata in metadata_entries:
            db.add_ticket_metadata(metadata['ticket_id'], metadata['key'], metadata['value'])
        
        # Update the ticket document with attachment information
        app.logger.info(f"DEBUG: Final uploaded_files count: {len(uploaded_files)}")
        app.logger.info(f"DEBUG: Final uploaded_files details:")
        for i, file_info in enumerate(uploaded_files):
            app.logger.info(f"  File {i+1}: {file_info['original_name']} -> {file_info['filename']} (size: {file_info['size']} bytes)")
        
        if uploaded_files:
            app.logger.info(f"DEBUG: Creating attachments array for {len(uploaded_files)} files")
            
            # Create attachments array for the ticket - FIXED: Include base64 data
            attachments_array = []
            for file_info in uploaded_files:
                attachment_data = {
                    'filename': file_info['filename'],
                    'original_name': file_info['original_name'],
                    'name': file_info['original_name'],  # Add 'name' field for template compatibility
                    'size': file_info['size'],
                    'is_warranty': file_info['is_warranty'],
                    'file_type': file_info['file_type_info'],
                    'uploaded_at': datetime.now().isoformat(),
                    'source': 'manual_upload',
                    'path': file_info['path'],  # Full path for file operations
                    'type': 'file',  # Ensure type is set for template compatibility
                    'data': file_info['data']  # FIXED: Include base64 data for database storage
                }
                attachments_array.append(attachment_data)
                app.logger.info(f"DEBUG: Added attachment to array: {file_info['original_name']} (base64: {len(file_info['data'])} chars)")
            
            # Update ticket with attachment information - ENHANCED UPDATE
            update_data = {
                'has_attachments': True,
                'total_attachments': len(uploaded_files),
                'attachments': attachments_array,
                'has_warranty': any(f.get('is_warranty') for f in uploaded_files)
            }
            
            app.logger.info(f"DEBUG: Updating ticket {ticket_id} with data: {update_data}")
            
            try:
                # First update the ticket document
                db.update_ticket(ticket_id, update_data)
                app.logger.info(f"SUCCESS: Updated ticket {ticket_id} with attachment information: {len(uploaded_files)} attachments")
                
                # Also ensure the attachments are properly indexed in the database
                # This helps with search and retrieval
                for i, attachment in enumerate(attachments_array):
                    # Store each attachment as individual metadata for better retrieval
                    # FIXED: Include base64 data in metadata for complete storage
                    attachment_metadata = {
                        'ticket_id': ticket_id,
                        'key': f'file_attachment_{i+1}',
                        'value': json.dumps(attachment)
                    }
                    db.add_ticket_metadata(ticket_id, f'file_attachment_{i+1}', json.dumps(attachment))
                    app.logger.info(f"SUCCESS: Stored attachment {i+1} metadata for ticket {ticket_id} (base64: {len(attachment.get('data', ''))} chars)")
                
            except Exception as update_error:
                app.logger.error(f"ERROR: Failed to update ticket {ticket_id} with attachment info: {update_error}")
                app.logger.error(f"ERROR: Update data was: {update_data}")
        else:
            app.logger.warning(f"WARNING: No uploaded files to process for ticket {ticket_id}")
        
        # Save additional metadata for the ticket
        try:
            # Save technician information to metadata
            if technician:
                db.add_ticket_metadata(ticket_id, 'technician_name', technician)
                app.logger.info(f"Saved technician name to metadata: {technician}")
                
                # Also get and save technician ID for proper assignment
                technician_data = db.get_technician_by_name(technician)
                if technician_data:
                    db.add_ticket_metadata(ticket_id, 'technician_id', str(technician_data['_id']))
                    app.logger.info(f"Saved technician ID to metadata: {technician_data['_id']}")
                else:
                    app.logger.warning(f"Technician '{technician}' not found in database")
            
            # Save other form fields to metadata
            db.add_ticket_metadata(ticket_id, 'customer_title', customer_title)
            db.add_ticket_metadata(ticket_id, 'customer_first_name', customer_first_name)
            db.add_ticket_metadata(ticket_id, 'customer_surname', customer_surname)
            db.add_ticket_metadata(ticket_id, 'type_of_claim', type_of_claim)
            db.add_ticket_metadata(ticket_id, 'vehicle_registration', vehicle_registration)
            db.add_ticket_metadata(ticket_id, 'service_date', service_date)
            db.add_ticket_metadata(ticket_id, 'claim_date', claim_date)
            db.add_ticket_metadata(ticket_id, 'vhc_link', vhc_link)
            
            app.logger.info(f"Successfully saved all metadata for ticket {ticket_id}")
        except Exception as metadata_error:
            app.logger.error(f"Warning: Failed to save metadata for ticket {ticket_id}: {metadata_error}")
            # Don't fail the ticket creation if metadata saving fails
        
        app.logger.info(f"Ticket {ticket_id} created successfully by user {session.get('member_name')}")
        
        return jsonify({
            'status': 'success',
            'message': f'Ticket created successfully! Customer Number: {ticket_id}',
            'ticket_id': ticket_id,
            'customer_number': ticket_id,
            'reference_message': f'Please reference Customer Number {ticket_id} for all inquiries about this ticket.',
            'attachments_uploaded': len(uploaded_files)
        })
        
    except Exception as e:
        app.logger.error(f"Error creating ticket: {str(e)}")
        import traceback
        app.logger.error(f"Full traceback: {traceback.format_exc()}")
        # Return more detailed error for debugging (without non-serializable objects)
        return jsonify({
            'status': 'error', 
            'message': f'Error creating ticket: {str(e)}',
            'error_type': type(e).__name__
        }), 500

# Email Template System with Placeholders
DEFAULT_WARRANTY_TEMPLATE = {
    'name': 'Warranty Claim Template',
    'subject': 'Warranty Claim - <Vehicle Registration>| <Ticket Number> | Auto Assist Group',
    'body': '''Dear <First Name> <Surname> (TicketID: <Ticket Number>),

Thank you for contacting us regarding your recent DPF service with Auto Assist Group.

To begin your warranty claim process, please follow the steps below:

Click the link below to access the warranty claim form:

https://autoassistgroup.com/report/claims

The form will ask you to provide:

- Your vehicle registration number
- Current mileage (with a photo of the dashboard as proof)
- New OBD-II fault codes
- Confirmation and proof of any advisory work completed
- Driving habits since the clean (e.g. short trips, motorway usage, etc.)

Your original DPF service report is attached for your reference.

Once we receive your completed form, our Aftercare Team will review the information and update your warranty ticket. If any further information is required, we will contact you directly.

If you have any questions in the meantime, please reply to this email.

Kind regards,

Auto Assist Group - Aftercare Team'''
}

def replace_email_placeholders(template_text, ticket_id):
    """Replace email template placeholders with actual ticket data"""
    try:
        app.logger.info(f"ðŸ” REPLACING EMAIL PLACEHOLDERS - Input Ticket ID: {ticket_id}")
        
        db = get_db()
        
        # Get ticket metadata
        metadata = db.get_ticket_metadata(ticket_id)
        metadata_dict = {meta['key']: meta['value'] for meta in metadata}
        
        # Get ticket data for additional placeholders
        ticket = db.get_ticket_by_id(ticket_id)
        customer_name = ticket.get('name', '') if ticket else ''
        first_name = customer_name.split()[0] if customer_name else 'Customer'
        
        # Define placeholder mappings (support both formats)
        placeholders = {
            # Original format
            '<First Name>': metadata_dict.get('customer_first_name', first_name),
            '<Surname>': metadata_dict.get('customer_surname', ''),
            '<Customer Title>': metadata_dict.get('customer_title', ''),
            '<Vehicle Registration>': metadata_dict.get('vehicle_registration', ''),
            '<Ticket Number>': ticket_id,
            '<Type of Claim>': metadata_dict.get('type_of_claim', ''),
            '<Technician>': metadata_dict.get('technician', ''),
            '<Service Date>': metadata_dict.get('service_date', ''),
            '<Claim Date>': metadata_dict.get('claim_date', ''),
            
            # New format for generate_email_draft_response
            '{first_name}': first_name,
            '{customer_name}': customer_name,
            '{ticket_id}': ticket_id,
            '{ticket_data.get(\'ticket_id\', \'N/A\')}': ticket_id
        }
        
        app.logger.info(f"ðŸ” PLACEHOLDER MAPPINGS - <Ticket Number> will be replaced with: {ticket_id}")
        
        # Replace all placeholders
        result = template_text
        for placeholder, value in placeholders.items():
            result = result.replace(placeholder, value)
        
        return result
        
    except Exception as e:
        app.logger.error(f"Error replacing email placeholders: {str(e)}")
        return template_text

@app.route('/api/email/send-template', methods=['POST'])
def send_template_email():
    """Send email using template with placeholders"""
    app.logger.info(f"ðŸš€ EMAIL TEMPLATE ENDPOINT CALLED")
    if 'member_id' not in session:
        app.logger.error(f"ðŸ’¥ UNAUTHORIZED - No member_id in session")
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        app.logger.info(f"ðŸš€ EMAIL TEMPLATE TRY BLOCK ENTERED")
        data = request.json
        ticket_id = data.get('ticket_id')
        template_type = data.get('template_type', 'warranty')
        custom_subject = data.get('custom_subject', '')
        custom_body = data.get('custom_body', '')
        attachments = data.get('attachments', [])
        
        if not ticket_id:
            return jsonify({'status': 'error', 'message': 'Ticket ID required'}), 400

        # ANTI-SPAM: Check for duplicate email template submissions
        member_id = session['member_id']
        current_time = datetime.now()
        cache_key = f"email_template_spam_{ticket_id}_{member_id}_{custom_subject[:30]}"
        
        # Use the same cache as reply anti-spam
        if not hasattr(app, '_reply_cache'):
            app._reply_cache = {}
        
        # Clean old entries (older than 10 seconds for email templates)
        app._reply_cache = {k: v for k, v in app._reply_cache.items() 
                           if (current_time - v).total_seconds() < 10}
        
        if cache_key in app._reply_cache:
            app.logger.warning(f"ðŸš« EMAIL TEMPLATE SPAM BLOCKED - Duplicate email attempt for ticket {ticket_id} by member {member_id}")
            return jsonify({'status': 'error', 'message': 'Duplicate email submission detected. Please wait before sending again.'}), 429
        
        # Record this submission to prevent duplicates
        app._reply_cache[cache_key] = current_time
        
        app.logger.info(f" PROCESSING EMAIL TEMPLATE - Ticket: {ticket_id}, Member: {member_id}, Subject: {custom_subject[:50]}...")
        
        # Get ticket information
        try:
            db = get_db()
            app.logger.info(f" DEBUG: Got database connection for ticket {ticket_id}")
            ticket = db.get_ticket_by_id(ticket_id)
            app.logger.info(f" DEBUG: Retrieved ticket data: {ticket is not None}")
            if not ticket:
                return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        except Exception as e:
            app.logger.error(f"ðŸ’¥ DATABASE ERROR - Failed to get ticket {ticket_id}: {str(e)}")
            return jsonify({'status': 'error', 'message': 'Database error'}), 500
        
        # Use template or custom content
        try:
            if custom_subject and custom_body:
                # Use custom content
                app.logger.info(f" DEBUG: Using custom template content for ticket {ticket_id}")
                subject = replace_email_placeholders(custom_subject, ticket_id)
                body = replace_email_placeholders(custom_body, ticket_id)
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF CUSTOM EMAIL BODY
                ticket_id_header = f""
                enhanced_body = ticket_id_header + body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO CUSTOM EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            else:
                # Use default warranty template
                app.logger.info(f" DEBUG: Using default warranty template for ticket {ticket_id}")
                subject = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['subject'], ticket_id)
                body = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['body'], ticket_id)
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
                ticket_id_header = f""
                enhanced_body = ticket_id_header + body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
                
                app.logger.info(f" DEBUG: Template processing complete - Subject: {subject[:50]}...")
        except Exception as e:
            app.logger.error(f"ðŸ’¥ TEMPLATE ERROR - Failed to process template for ticket {ticket_id}: {str(e)}")
            return jsonify({'status': 'error', 'message': 'Template processing error'}), 500
        
        # INTEGRATE EMAIL SERVICE - Send actual email with attachments
        recipient_email = ticket.get('email', '')
        if not recipient_email:
            app.logger.error(f" No email address found for ticket {ticket_id}")
            return jsonify({'status': 'error', 'message': 'No recipient email address found'}), 400
        
        app.logger.info(f"ðŸ“§ PREPARING TO SEND EMAIL to {recipient_email}")
        app.logger.info(f"ðŸ“§ Subject: {subject}")
        app.logger.info(f"ðŸ“§ Body length: {len(body)} chars")
        app.logger.info(f"ðŸ“Ž RECEIVED ATTACHMENTS FROM FRONTEND: {len(attachments)} attachments")
        
        # Prepare attachments in the format expected by EmailService
        email_attachments = []
        
        # Process each attachment to prepare for email sending
        if attachments:
            app.logger.info(f"ðŸ”„ PROCESSING {len(attachments)} ATTACHMENTS for email sending")
        
        # FIXED: Enhanced original ticket attachment processing for manual tickets
        original_ticket_attachments = []
        if ticket.get('attachments'):
            app.logger.info(f"ðŸ“Ž PROCESSING {len(ticket['attachments'])} ORIGINAL TICKET ATTACHMENTS")
            for i, att in enumerate(ticket['attachments']):
                filename = att.get('filename', att.get('original_name', f'original_attachment_{i}'))
                # Include all attachments without filtering by name prefix
                if filename:
                    # FIXED: Handle both email tickets (with data) and manual tickets (with data)
                    if att.get('data'):  # Base64 data available
                        app.logger.info(f"ðŸ“Ž USING BASE64 DATA FOR EMAIL: {filename} ({len(att.get('data'))} chars)")
                        original_ticket_attachments.append({
                            'name': filename,
                            'data': att.get('data'),
                            'size': att.get('size', 0),
                            'is_warranty': att.get('is_warranty', False),
                            'is_manual_ticket_attachment': att.get('is_manual_ticket_attachment', False)
                        })
                    else:
                        app.logger.warning(f"ðŸ“Ž NO BASE64 DATA FOR EMAIL: {filename}")
                else:
                    app.logger.info(f"ðŸ“Ž SKIPPING ATTACHMENT: {filename} (no filename)")
        else:
            app.logger.info(f"ðŸ“Ž NO ORIGINAL TICKET ATTACHMENTS FOUND")
        
        # Only add metadata attachments for manually created tickets (not email-created tickets)
        # Check if this is an email-created ticket by looking for email-specific fields
        is_email_ticket = ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id')
        
        if not is_email_ticket:
            # Only process metadata attachments for manually created tickets
            metadata = db.get_ticket_metadata(ticket_id)
            for meta in metadata:
                if meta.get('key', '').startswith('attachment_'):
                    try:
                        attachment_data = json.loads(meta.get('value', '{}'))
                        if attachment_data and isinstance(attachment_data, dict):
                            # Read file from disk and convert to base64
                            file_path = attachment_data.get('path', '')
                            if file_path:
                                full_path = os.path.join(UPLOAD_FOLDER, file_path)
                                if os.path.exists(full_path):
                                    with open(full_path, 'rb') as f:
                                        file_data = base64.b64encode(f.read()).decode('utf-8')
                                    attachment_name = attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File'))
                                    # Include all metadata attachments without filtering by name prefix
                                    if attachment_name:
                                        original_ticket_attachments.append({
                                            'name': attachment_name,
                                            'data': file_data,
                                            'size': attachment_data.get('size', 0),
                                            'is_warranty': attachment_data.get('is_warranty', False),
                                            'is_manual_ticket_attachment': True  # FIXED: Flag for manual ticket attachments
                                        })
                                        app.logger.info(f"ðŸ“Ž ADDED METADATA ATTACHMENT TO EMAIL: {attachment_data.get('original_name')} (data: {len(file_data)} chars)")
                    except (json.JSONDecodeError, TypeError, IOError) as e:
                        app.logger.warning(f"Failed to process metadata attachment for email: {e}")
                        continue
        
        # Combine reply attachments with original ticket attachments - PREVENT DUPLICATES
        # Only include original ticket attachments if they're not already in reply attachments
        all_attachments = attachments.copy()  # Start with reply attachments
        
        # Add original ticket attachments only if they're not duplicates
        if original_ticket_attachments:
            for orig_att in original_ticket_attachments:
                orig_name = orig_att.get('name', '')
                # Check if this original attachment is already in reply attachments
                is_duplicate = False
                for reply_att in attachments:
                    if reply_att.get('name', '') == orig_name:
                        is_duplicate = True
                        app.logger.info(f"ðŸ“Ž SKIPPING DUPLICATE: {orig_name} already exists in reply attachments")
                        break
                
                if not is_duplicate:
                    all_attachments.append(orig_att)
                    app.logger.info(f"ðŸ“Ž ADDED ORIGINAL: {orig_name} (not a duplicate)")
                else:
                    app.logger.info(f"ðŸ“Ž SKIPPED DUPLICATE: {orig_name}")
        
        app.logger.info(f"ðŸ“Ž TOTAL ATTACHMENTS FOR EMAIL: {len(all_attachments)} (reply: {len(attachments)}, original added: {len(all_attachments) - len(attachments)})")
        
        # FIXED: Prepare email attachments with proper file data for manual tickets
        email_attachments = []
        for attachment in all_attachments:
            attachment_name = attachment.get('name', 'Unknown File')
            attachment_data = attachment.get('data', '')
            
            if attachment_data and len(attachment_data) > 10:  # Valid base64 data
                try:
                    # Decode base64 to get binary data
                    file_content = base64.b64decode(attachment_data)
                    
                    # Create email attachment object
                    email_attachment = {
                        'filename': attachment_name,
                        'content': file_content,
                        'content_type': get_mime_type(attachment_name),
                        'is_warranty': attachment.get('is_warranty', False),
                        'is_manual_ticket_attachment': attachment.get('is_manual_ticket_attachment', False)
                    }
                    
                    email_attachments.append(email_attachment)
                    app.logger.info(f"ðŸ“Ž PREPARED EMAIL ATTACHMENT: {attachment_name} ({len(file_content)} bytes, type: {email_attachment['content_type']})")
                    
                except Exception as e:
                    app.logger.error(f"ðŸ“Ž ERROR PREPARING EMAIL ATTACHMENT {attachment_name}: {e}")
                    continue
            else:
                app.logger.warning(f"ðŸ“Ž SKIPPING ATTACHMENT WITHOUT DATA: {attachment_name}")
        
        app.logger.info(f"ðŸ“Ž FINAL EMAIL ATTACHMENTS: {len(email_attachments)} attachments ready for sending")
        
        # Process each attachment to prepare for email sending
        for i, attachment in enumerate(attachments):
            if isinstance(attachment, dict):
                attachment_name = attachment.get('name', 'unknown_file')
                file_path = attachment.get('file_path', '')
                attachment_key = attachment.get('key', '')
                ticket_index = attachment.get('ticket_index')
                
                app.logger.info(f"ðŸ“Ž Processing attachment {i+1}/{len(attachments)}: {attachment_name} (ticket_index: {ticket_index})")
                
                # Try to get file data - PRIORITIZE FRONTEND fileData FIRST!
                file_data = ""
                try:
                    # ðŸš€ PRIORITY 0: Use fileData from frontend if available (MOST RELIABLE)
                    if attachment.get('fileData'):
                        file_data = attachment.get('fileData')
                        app.logger.info(f"ðŸŽ¯ FRONTEND fileData: Found data for {attachment_name} from frontend ({len(file_data)} chars)")
                        
                        # ðŸš€ CRITICAL VALIDATION: Ensure the fileData is valid base64
                        if file_data and len(file_data) > 10:
                            try:
                                # Validate base64 data by attempting to decode it
                                decoded_data = base64.b64decode(file_data)
                                app.logger.info(f"âœ… VALIDATED BASE64 DATA: {attachment_name} ({len(file_data)} chars, decoded to {len(decoded_data)} bytes)")
                                
                                # Add frontend attachment with validated fileData to email attachments
                                email_attachments.append({
                                    'filename': attachment_name,
                                    'fileData': file_data,
                                    'data': file_data,  # Support both keys for compatibility
                                    'size': len(decoded_data),  # Use actual decoded size
                                    'type': attachment.get('type', 'file'),
                                    'content': decoded_data,  # Include decoded binary content for email service
                                    'content_type': get_mime_type(attachment_name)
                                })
                                app.logger.info(f"âœ… ADDED VALIDATED FRONTEND ATTACHMENT: {attachment_name} with {len(file_data)} chars base64 ({len(decoded_data)} bytes)")
                                continue  # Skip further processing since we already have the data
                                
                            except Exception as e:
                                app.logger.error(f"âŒ INVALID BASE64 DATA for {attachment_name}: {e}")
                                file_data = ""  # Reset to empty to try other methods
                        else:
                            app.logger.warning(f"âš ï¸ FRONTEND fileData too short or empty for {attachment_name}: {len(file_data) if file_data else 0} chars")
                            file_data = ""  # Reset to empty to try other methods
                        
                    # PRIORITY 1: Use ticket_index to get data directly (FASTEST METHOD)
                    elif ticket_index is not None and ticket.get('attachments') and ticket_index < len(ticket['attachments']):
                        ticket_att = ticket['attachments'][ticket_index]
                        if ticket_att.get('data'):
                            file_data = ticket_att.get('data')
                            app.logger.info(f"ðŸŽ¯ DIRECT ACCESS: Found data for {attachment_name} using ticket_index {ticket_index} ({len(file_data)} chars)")
                        else:
                            app.logger.warning(f" No data at ticket_index {ticket_index} for {attachment_name}")
                    
                    # PRIORITY 2: If no ticket_index, go straight to metadata (for metadata attachments)
                    elif ticket_index is None and attachment_key:
                        app.logger.info(f" METADATA ATTACHMENT: Searching metadata directly for key: {attachment_key}")
                        db = get_db()
                        metadata = db.get_ticket_metadata(ticket_id)
                        
                        # DEBUG: Log all available metadata for debugging
                        app.logger.info(f" DEBUG METADATA: Found {len(metadata)} metadata entries:")
                        for idx, meta in enumerate(metadata):
                            meta_key = meta.get('key', 'NO_KEY')
                            meta_value_type = type(meta.get('value', None)).__name__
                            meta_value_preview = str(meta.get('value', ''))[:100] + ('...' if len(str(meta.get('value', ''))) > 100 else '')
                            app.logger.info(f"  [{idx}] key='{meta_key}', value_type={meta_value_type}, preview='{meta_value_preview}'")
                        
                        for meta in metadata:
                            if meta.get('key') == attachment_key:
                                app.logger.info(f" FOUND MATCHING KEY: {attachment_key}")
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                        app.logger.info(f" PARSED JSON METADATA: keys={list(meta_data.keys())}")
                                    else:
                                        meta_data = meta.get('value', {})
                                        app.logger.info(f" DIRECT METADATA: type={type(meta_data)}, keys={list(meta_data.keys()) if isinstance(meta_data, dict) else 'NOT_DICT'}")
                                    
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        app.logger.info(f" Found metadata attachment data for {attachment_name} ({len(file_data)} chars)")
                                        break
                                    else:
                                        app.logger.warning(f" METADATA HAS NO DATA: {attachment_key} - available keys: {list(meta_data.keys()) if isinstance(meta_data, dict) else 'NOT_DICT'}")
                                except (json.JSONDecodeError, TypeError) as e:
                                    app.logger.error(f" METADATA PARSE ERROR for {attachment_key}: {e}")
                                    continue
                        
                        if not file_data:
                            app.logger.error(f" METADATA ATTACHMENT NOT FOUND: Could not find data for key '{attachment_key}' in {len(metadata)} metadata entries")
                    
                    # PRIORITY 3: Fallback - search ticket attachments by filename if direct access failed
                    elif ticket.get('attachments'):
                        app.logger.info(f" FALLBACK: Searching ticket attachments by name for {attachment_name}")
                        for ticket_att in ticket['attachments']:
                            if isinstance(ticket_att, dict):
                                # Check various filename fields
                                ticket_filename = ticket_att.get('filename', ticket_att.get('fileName', ''))
                                
                                if ticket_filename and (
                                    ticket_filename == attachment_name or 
                                    attachment_name in ticket_filename or 
                                    ticket_filename in attachment_name
                                ):
                                    # Found matching filename, now get the data
                                    if ticket_att.get('data'):
                                        file_data = ticket_att.get('data')
                                        app.logger.info(f" Found base64 data in ticket attachments: {attachment_name} ({len(file_data)} chars)")
                                        break
                    
                    # PRIORITY 4: Final metadata search if still not found
                    if not file_data:
                        app.logger.info(f" Checking metadata for {attachment_name}")
                        db = get_db()
                        metadata = db.get_ticket_metadata(ticket_id)
                        
                        # Try to match by key first
                        if attachment_key:
                            for meta in metadata:
                                if meta.get('key') == attachment_key:
                                    try:
                                        if isinstance(meta.get('value'), str):
                                            meta_data = json.loads(meta.get('value'))
                                        else:
                                            meta_data = meta.get('value', {})
                                        
                                        if meta_data.get('data'):
                                            file_data = meta_data.get('data')
                                            app.logger.info(f" Found base64 data in metadata via key {attachment_key}")
                                            break
                                    except (json.JSONDecodeError, TypeError):
                                        continue
                            
                            # If no data found by key, try name matching in metadata
                            if not file_data:
                                for meta in metadata:
                                    try:
                                        if isinstance(meta.get('value'), str):
                                            meta_data = json.loads(meta.get('value'))
                                        else:
                                            meta_data = meta.get('value', {})
                                        
                                        # Check filename matches
                                        meta_filename = meta_data.get('filename', meta_data.get('fileName', ''))
                                        if meta_filename and (meta_filename == attachment_name or attachment_name in meta_filename):
                                            if meta_data.get('data'):
                                                file_data = meta_data.get('data')
                                                app.logger.info(f" Found base64 data in metadata via filename match")
                                                break
                                    except (json.JSONDecodeError, TypeError):
                                        continue
                        
                        # Add to email attachments list if data found
                        if file_data:
                            email_attachments.append({
                                'filename': attachment_name,
                                'fileData': file_data,
                                'data': file_data  # Support both keys for compatibility
                            })
                            app.logger.info(f" Added {attachment_name} to email attachments ({len(file_data)} chars base64)")
                        else:
                            app.logger.warning(f" No data found for attachment: {attachment_name}")
                    
                except Exception as e:
                    app.logger.error(f" Error processing attachment {attachment_name}: {e}")
        
        # Send the actual email using EmailService
        try:
            app.logger.info(f"ðŸ“§ SENDING EMAIL via EmailService to {recipient_email} with {len(email_attachments)} attachments")
            
            # Convert all attachments to the format expected by EmailService
            final_email_attachments = []
            for attachment in all_attachments:
                if attachment.get('data'):  # Base64 data
                    final_email_attachments.append({
                        'filename': attachment.get('name', 'attachment'),
                        'data': attachment.get('data'),
                        'content_type': 'application/octet-stream'
                    })
                elif attachment.get('file_path'):  # File path
                    try:
                        with open(attachment['file_path'], 'rb') as f:
                            file_data = base64.b64encode(f.read()).decode('utf-8')
                        final_email_attachments.append({
                            'filename': attachment.get('name', 'attachment'),
                            'data': file_data,
                            'content_type': 'application/octet-stream'
                        })
                    except IOError as e:
                        app.logger.warning(f"Failed to read attachment file: {e}")
                        continue
            
            # Create HTML body for better formatting
            # Use enhanced_body if available, otherwise fall back to body
            email_body = enhanced_body if 'enhanced_body' in locals() else body
            
            html_body = """
            <html>
                <body>
                    <p>{email_body.replace(chr(10), '<br>')}</p>
                    <br>
                    <hr>
                    <p style="font-size: 12px; color: #666;">
                        Ticket ID: {ticket_id}<br>
                        Sent via Email Template System
                    </p>
                </body>
            </html>
            """
            
            # Send email with attachments
            # Use enhanced_body if available, otherwise fall back to body
            email_body = enhanced_body if 'enhanced_body' in locals() else body
            
            email_success = email_service.send_email(
                to_email=recipient_email,
                subject=subject,
                body=email_body,
                html_body=html_body,
                attachments=final_email_attachments if final_email_attachments else None
            )
            
            if email_success:
                app.logger.info(f" EMAIL SENT SUCCESSFULLY to {recipient_email}")
            else:
                app.logger.error(f" EMAIL SENDING FAILED to {recipient_email}")
                
        except Exception as email_error:
            app.logger.error(f"ðŸ’¥ EMAIL SERVICE ERROR: {email_error}")
            email_success = False
        
        # Add email record to ticket history/replies
        try:
            # Create detailed message about email status
            email_status_msg = " Successfully sent" if email_success else " Failed to send"
            attachment_info = f" with {len(email_attachments)} attachments" if email_attachments else " with no attachments"
            
            reply_data = {
                'ticket_id': ticket_id,
                'thread_id': ticket.get('thread_id', ''),
                'message': f"ðŸ“§ **Email {email_status_msg} via Template{attachment_info}**\n\n**To:** {recipient_email}\n**Subject:** {subject}\n\n**Message:**\n{email_body}",
                'sender': 'support',
                'is_email': True,
                'email_subject': subject,
                'email_body': email_body,
                'email_status': 'sent' if email_success else 'failed',
                'email_recipient': recipient_email,
                'attachments': attachments,
                'email_attachments_count': len(email_attachments)
            }
            
            app.logger.info(f" DEBUG: Adding reply record for ticket {ticket_id}")
            db.create_reply(reply_data)
            app.logger.info(f" DEBUG: Reply record added successfully for ticket {ticket_id}")
        except Exception as e:
            app.logger.error(f"ðŸ’¥ REPLY ERROR - Failed to add reply for ticket {ticket_id}: {str(e)}")
            return jsonify({'status': 'error', 'message': 'Database reply error'}), 500
        
        # WEBHOOK INTEGRATION: Trigger webhook for email template sends - Enhanced format
        current_timestamp = datetime.now().isoformat()
        
        # ðŸ”§ FIX: Format attachments with actual file data for email templates
        formatted_attachments = []
        
        if not attachments:
            app.logger.warning(f" NO ATTACHMENTS TO PROCESS for ticket {ticket_id}")
        
        for i, attachment in enumerate(attachments):
            app.logger.info(f"ðŸ“Ž PROCESSING ATTACHMENT {i}: {attachment}")
            
            if isinstance(attachment, dict):
                attachment_name = attachment.get('name', 'unknown_file')
                file_path = attachment.get('file_path', '')
                attachment_key = attachment.get('key', '')
                ticket_index = attachment.get('ticket_index')
                
                app.logger.info(f"ðŸ“Ž ATTACHMENT DETAILS: name='{attachment_name}', file_path='{file_path}', key='{attachment_key}', ticket_index='{ticket_index}'")
                
                # Try to read actual file content
                file_data = ""
                file_size = 0
                
                try:
                    # PRIORITY 1: Use ticket_index for direct access (SAME AS EMAIL PROCESSING)
                    app.logger.info(f" SEARCHING FOR WEBHOOK ATTACHMENT: {attachment_name} (ticket_index: {ticket_index})")
                    
                    if ticket_index is not None and ticket.get('attachments') and ticket_index < len(ticket['attachments']):
                        ticket_att = ticket['attachments'][ticket_index]
                        if ticket_att.get('data'):
                            file_data = ticket_att.get('data')
                            file_size = ticket_att.get('size', 0)
                            app.logger.info(f"ðŸŽ¯ WEBHOOK DIRECT ACCESS: Found data for {attachment_name} using ticket_index {ticket_index} ({len(file_data)} chars)")
                        else:
                            app.logger.warning(f" No data at webhook ticket_index {ticket_index} for {attachment_name}")
                    
                    # PRIORITY 1.5: Fallback to filename search in ticket attachments
                    elif ticket.get('attachments'):
                        app.logger.info(f" WEBHOOK FALLBACK: Searching ticket attachments by name for {attachment_name}")
                        for ticket_att in ticket['attachments']:
                            if isinstance(ticket_att, dict):
                                # Check various filename fields
                                ticket_filename = ticket_att.get('filename', ticket_att.get('fileName', ''))
                                
                                if ticket_filename and (
                                    ticket_filename == attachment_name or 
                                    attachment_name in ticket_filename or 
                                    ticket_filename in attachment_name
                                ):
                                    # Found matching filename, now get the data
                                    if ticket_att.get('data'):
                                        file_data = ticket_att.get('data')
                                        file_size = ticket_att.get('size', 0)
                                        app.logger.info(f" Found attachment data in ticket for webhook: {attachment_name} ({len(file_data)} chars)")
                                        break
                    
                    # PRIORITY 2: If no ticket_index, check metadata directly (for metadata attachments)
                    if not file_data and ticket_index is None and attachment_key:
                        app.logger.info(f" METADATA ATTACHMENT FOR WEBHOOK: Searching metadata directly for key: {attachment_key}")
                        metadata = db.get_ticket_metadata(ticket_id)
                        
                        for meta in metadata:
                            if meta.get('key') == attachment_key:
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                    else:
                                        meta_data = meta.get('value', {})
                                    
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        file_size = meta_data.get('size', 0)
                                        app.logger.info(f" Found metadata attachment data for webhook {attachment_name} ({len(file_data)} chars)")
                                        break
                                except (json.JSONDecodeError, TypeError):
                                    continue
                    
                    # PRIORITY 3: Full metadata search if still not found
                    if not file_data:
                        app.logger.info(f" Checking metadata for webhook: {attachment_name}")
                    metadata = db.get_ticket_metadata(ticket_id)
                    app.logger.info(f" FOUND {len(metadata)} metadata entries for ticket {ticket_id}")
                    
                    # Try to match by key first (most reliable)
                    if attachment_key:
                        for idx, meta in enumerate(metadata):
                            if meta.get('key') == attachment_key:
                                app.logger.info(f" FOUND ATTACHMENT BY KEY: {attachment_key}")
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                    else:
                                        meta_data = meta.get('value', {})
                                    
                                    # Get file data directly from metadata
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        file_size = meta_data.get('size', 0)
                                        app.logger.info(f"ðŸ“§ USING BASE64 DATA FROM KEY: {attachment_name} ({file_size} bytes)")
                                        break
                                    
                                    # Try file path if available
                                    elif meta_data.get('file_path'):
                                        file_path_from_meta = meta_data.get('file_path')
                                        # Try multiple path combinations
                                        possible_paths = [
                                            os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                            os.path.join(os.getcwd(), file_path_from_meta),
                                            file_path_from_meta
                                        ]
                                        
                                        for path_attempt in possible_paths:
                                            if os.path.exists(path_attempt):
                                                with open(path_attempt, 'rb') as f:
                                                    file_content = f.read()
                                                    file_data = base64.b64encode(file_content).decode('utf-8')
                                                    file_size = len(file_content)
                                                    app.logger.info(f"FOLDER READ FILE BY KEY: {path_attempt} ({file_size} bytes)")
                                                    break
                                        
                                        if file_data:
                                            break
                                            
                                except (json.JSONDecodeError, TypeError) as e:
                                    app.logger.error(f"ðŸ’¥ METADATA PARSE ERROR for key {attachment_key}: {e}")
                                    continue
                    
                    # If not found by key, try by name matching
                    if not file_data:
                        for idx, meta in enumerate(metadata):
                            try:
                                if isinstance(meta.get('value'), str):
                                    meta_data = json.loads(meta.get('value'))
                                else:
                                    meta_data = meta.get('value', {})
                                
                                # Get all possible names from metadata
                                meta_filename = meta_data.get('filename', '')
                                meta_name = meta_data.get('name', '')
                                meta_fileName = meta_data.get('fileName', '')
                                
                                # Check for exact matches first, then partial matches
                                exact_matches = [
                                    meta_filename == attachment_name,
                                    meta_name == attachment_name,
                                    meta_fileName == attachment_name
                                ]
                                
                                partial_matches = [
                                    attachment_name in meta_filename and meta_filename != '',
                                    attachment_name in meta_name and meta_name != '',
                                    attachment_name in meta_fileName and meta_fileName != '',
                                    meta_filename in attachment_name and meta_filename != '',
                                    meta_name in attachment_name and meta_name != '',
                                    meta_fileName in attachment_name and meta_fileName != ''
                                ]
                                
                                if any(exact_matches) or any(partial_matches):
                                    match_type = "EXACT" if any(exact_matches) else "PARTIAL"
                                    app.logger.info(f" FOUND {match_type} MATCH: {attachment_name} matches metadata {idx}")
                                    
                                    # Try base64 data first
                                    if meta_data.get('data'):
                                        file_data = meta_data.get('data')
                                        file_size = meta_data.get('size', 0)
                                        app.logger.info(f"ðŸ“§ USING BASE64 DATA: {attachment_name} ({file_size} bytes)")
                                        break
                                    
                                    # Try file path
                                    elif meta_data.get('file_path'):
                                        file_path_from_meta = meta_data.get('file_path')
                                        possible_paths = [
                                            os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                            os.path.join(os.getcwd(), file_path_from_meta),
                                            file_path_from_meta
                                        ]
                                        
                                        for path_attempt in possible_paths:
                                            if os.path.exists(path_attempt):
                                                with open(path_attempt, 'rb') as f:
                                                    file_content = f.read()
                                                    file_data = base64.b64encode(file_content).decode('utf-8')
                                                    file_size = len(file_content)
                                                    app.logger.info(f"FOLDER READ FILE BY NAME: {path_attempt} ({file_size} bytes)")
                                                    break
                                        
                                        if file_data:
                                            break
                                        
                            except (json.JSONDecodeError, TypeError) as e:
                                app.logger.error(f"ðŸ’¥ METADATA PARSE ERROR {idx}: {e}")
                                continue
                    
                    # Final fallback: try direct file path from frontend
                    if not file_data and file_path:
                        possible_paths = [
                            os.path.join(os.getcwd(), 'uploads', file_path),
                            os.path.join(os.getcwd(), file_path),
                            file_path
                        ]
                        
                        for path_attempt in possible_paths:
                            if os.path.exists(path_attempt):
                                with open(path_attempt, 'rb') as f:
                                    file_content = f.read()
                                    file_data = base64.b64encode(file_content).decode('utf-8')
                                    file_size = len(file_content)
                                    app.logger.info(f"FOLDER READ FILE BY DIRECT PATH: {path_attempt} ({file_size} bytes)")
                                    break
                    
                    # FINAL DESPERATE ATTEMPT: Try to find ANY matching attachment data
                    if not file_data:
                        app.logger.warning(f"ðŸ”„ FINAL ATTEMPT: Searching ALL metadata for ANY file with similar name...")
                        
                        # Try partial name matches with more flexible matching
                        for idx, meta in enumerate(metadata):
                            try:
                                if isinstance(meta.get('value'), str):
                                    meta_data = json.loads(meta.get('value'))
                                else:
                                    meta_data = meta.get('value', {})
                                
                                # Get all name variations
                                name_variants = [
                                    meta_data.get('filename', ''),
                                    meta_data.get('name', ''),
                                    meta_data.get('fileName', ''),
                                    meta.get('key', '')
                                ]
                                
                                # Very flexible matching - any partial match
                                for variant in name_variants:
                                    if variant and (
                                        variant.lower() in attachment_name.lower() or 
                                        attachment_name.lower() in variant.lower() or
                                        variant.split('.')[0].lower() in attachment_name.lower() or
                                        attachment_name.split('.')[0].lower() in variant.lower()
                                    ):
                                        app.logger.warning(f"ðŸ”„ FOUND PARTIAL MATCH: '{attachment_name}' ~= '{variant}' in metadata {idx}")
                                        
                                        if meta_data.get('data'):
                                            file_data = meta_data.get('data')
                                            file_size = meta_data.get('size', len(file_data) if file_data else 0)
                                            app.logger.info(f" SUCCESS WITH PARTIAL MATCH: {attachment_name} ({file_size} bytes)")
                                            break
                                            
                                if file_data:  # Break outer loop if found
                                    break
                                    
                            except Exception as e:
                                continue
                        
                        # Log failure details if STILL no data found
                        if not file_data:
                            app.logger.error(f" ATTACHMENT NOT FOUND: {attachment_name}")
                            # Log available attachment names for debugging
                            available_names = []
                            available_keys = []
                            for meta in metadata:
                                try:
                                    if isinstance(meta.get('value'), str):
                                        meta_data = json.loads(meta.get('value'))
                                    else:
                                        meta_data = meta.get('value', {})
                                    
                                    names = [meta_data.get('filename'), meta_data.get('name'), meta_data.get('fileName')]
                                    available_names.extend([n for n in names if n])
                                    if meta.get('key'):
                                        available_keys.append(meta.get('key'))
                                except:
                                    pass
                            app.logger.error(f" AVAILABLE NAMES: {available_names}")
                            app.logger.error(f" AVAILABLE KEYS: {available_keys}")
                            app.logger.error(f" REQUESTED: name='{attachment_name}', key='{attachment_key}', file_path='{file_path}'")
                
                except Exception as e:
                    app.logger.error(f"ðŸ’¥ EMAIL TEMPLATE ATTACHMENT ERROR for {attachment_name}: {str(e)}")
                    file_data = ""
                    file_size = 0
                
                # Create the formatted attachment entry
                formatted_attachment = {
                    "fileName": attachment_name,
                    "fileData": file_data,
                    "id": str(uuid.uuid4().hex[:8]),
                    "size": file_size,
                    "isWarranty": 'warranty' in attachment_name.lower()
                }
                
                formatted_attachments.append(formatted_attachment)
                
                # Enhanced result logging
                if file_data and len(file_data) > 0:
                    app.logger.info(f" ATTACHMENT SUCCESS: {attachment_name} -> {len(file_data)} chars base64, {file_size} bytes")
                else:
                    app.logger.error(f" ATTACHMENT FAILED: {attachment_name} -> NO FILE DATA")
                    app.logger.error(f"   ðŸ“ Debug Info:")
                    app.logger.error(f"   - Original attachment object: {attachment}")
                    app.logger.error(f"   - Attachment name: '{attachment_name}'")
                    app.logger.error(f"   - File path: '{file_path}'")
                    app.logger.error(f"   - Attachment key: '{attachment_key}'")
                    app.logger.error(f"   - Searched: uploads/{file_path}")
                    app.logger.error(f"   - Searched: metadata for names matching '{attachment_name}'")
                    
                    # ENHANCED DEBUG: Let's see what's actually available
                    try:
                        app.logger.error(f"    DEBUG: Available ticket data keys: {list(ticket.keys()) if ticket else 'No ticket data'}")
                        if ticket and 'attachments' in ticket:
                            app.logger.error(f"    DEBUG: Ticket has {len(ticket['attachments'])} attachments")
                            for idx, att in enumerate(ticket['attachments']):
                                att_keys = list(att.keys()) if isinstance(att, dict) else []
                                att_filename = att.get('filename') if isinstance(att, dict) else 'N/A'
                                att_data = bool(att.get('data')) if isinstance(att, dict) else False
                                att_file_path = att.get('file_path') if isinstance(att, dict) else 'N/A'
                                app.logger.error(f"     Attachment {idx}: {att_keys} -> filename: {att_filename}, data: {att_data}, file_path: {att_file_path}")
                        else:
                            app.logger.error(f"    DEBUG: No attachments in ticket data")
                        
                        # Check what metadata keys exist
                        metadata = db.get_ticket_metadata(ticket_id)
                        metadata_keys = [meta.get('key') for meta in metadata]
                        app.logger.error(f"    DEBUG: Available metadata keys: {metadata_keys}")
                        
                        # Show first few metadata entries
                        for idx, meta in enumerate(metadata[:3]):
                            app.logger.error(f"     Metadata {idx}: key='{meta.get('key')}', value_type={type(meta.get('value'))}")
                            
                    except Exception as debug_e:
                        app.logger.error(f"    DEBUG ERROR: Could not get debug info: {debug_e}")
                        
                    app.logger.warning(f"    SENDING EMPTY ATTACHMENT to n8n for debugging")
                    
            else:
                app.logger.error(f"ðŸ’¥ INVALID ATTACHMENT FORMAT: {attachment} (type: {type(attachment)})")
        
        # Final summary with critical alerts
        total_attachments = len(formatted_attachments)
        working_attachments = sum(1 for att in formatted_attachments if att['fileData'])
        failed_attachments = total_attachments - working_attachments
        
        app.logger.info(f"ðŸ“Ž EMAIL TEMPLATE FINAL SUMMARY:")
        app.logger.info(f"  - Total requested: {len(attachments)}")
        app.logger.info(f"  - Total processed: {total_attachments}")
        app.logger.info(f"  - With file data: {working_attachments}")
        app.logger.info(f"  - Failed/empty: {failed_attachments}")
        
        if failed_attachments > 0:
            app.logger.error(f"ðŸš¨ CRITICAL: {failed_attachments} attachments have NO FILE DATA - emails will be missing attachments!")
        
        if total_attachments == 0:
            app.logger.error(f"ðŸš¨ CRITICAL: NO ATTACHMENTS will be sent - webhook payload will have empty attachments array!")
        
        # Convert base64 attachments to n8n binary format
        binary_data = {}
        for i, attachment in enumerate(formatted_attachments):
            if attachment.get('fileData'):  # Only process attachments with data
                # Decode base64 to get actual file size
                try:
                    decoded_data = base64.b64decode(attachment['fileData'])
                    
                    # Determine MIME type
                    filename = attachment.get('fileName', 'attachment')
                    import mimetypes
                    mime_type, _ = mimetypes.guess_type(filename)
                    if not mime_type:
                        # Default MIME types based on extension
                        ext = filename.lower().split('.')[-1] if '.' in filename else ''
                        mime_types_map = {
                            'pdf': 'application/pdf',
                            'doc': 'application/msword',
                            'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                            'jpg': 'image/jpeg',
                            'jpeg': 'image/jpeg',
                            'png': 'image/png',
                            'txt': 'text/plain'
                        }
                        mime_type = mime_types_map.get(ext, 'application/octet-stream')
                    
                    # Create n8n binary data entry
                    binary_key = f"attachment_{i}" if len(formatted_attachments) > 1 else "data"
                    binary_data[binary_key] = {
                        "data": attachment['fileData'],  # Keep as base64 for n8n
                        "mimeType": mime_type,
                        "fileName": filename,
                        "fileSize": len(decoded_data)
                    }
                    
                    app.logger.info(f"ðŸ“¦ Created binary data for n8n: {binary_key} -> {filename} ({mime_type}, {len(decoded_data)} bytes)")
                    
                except Exception as e:
                    app.logger.error(f" Failed to process binary data for {attachment.get('fileName')}: {e}")
        
        # Create the webhook payload as an array with the exact same structure as reply webhook
        # Include multiple field names for n8n Microsoft Outlook node compatibility
        webhook_payload = [
            {
            "id": ticket_id,
            "threadId": ticket.get('thread_id', ''),
            "name": ticket.get('name', ''),
            "email": ticket.get('email', ''),
            "subject": subject,  # Use processed email subject  
            "body": email_body,        # Use enhanced email body with ticket ID
            "draft": f"Email sent via template - Subject: {subject}",
            "message": email_body,  # Email template body with ticket ID
            "replyMessage": email_body,
            "content": email_body,
            "classification": ticket.get('classification', 'General'),
            "priority": ticket.get('priority', 'Medium'),
            "date": current_timestamp,
            "messageId": ticket.get('message_id', f"email-template-{ticket_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}"),
            "attachments": formatted_attachments,  # Keep original format for compatibility
            "created_at": current_timestamp,
                # Email template specific fields - keeping same keys but different values
            "isEmailTemplate": True,
            "templateType": template_type,
            "emailSubject": subject,
            "emailBody": email_body,
            "canReplyToEmail": False,  # Email templates are outbound
            "isEmailOriginated": False,
            "ticketSource": "email_template",
            "recommendedOperation": "send"
        }
        ]
        # Send to BOTH webhooks for complete functionality:
        # 1. Original email template webhook for actual email sending
        # 2. Main webhook for data consistency with reply conversations
        
        # Original Email Template Webhook (for email sending functionality)
        EMAIL_TEMPLATE_WEBHOOK = "https://ffxtrading.app.n8n.cloud/webhook/fb4af014-26e6-4477-821f-917fc9b3ee96"
        
        # Create original format payload for email sending webhook
        email_sending_payload = {
            "json": webhook_payload[0],  # Use the same data structure
            "binary": binary_data
        }
        
        try:
            app.logger.info(f"ðŸš€ SENDING EMAIL TEMPLATE WEBHOOK (Email Sending) - Ticket: {ticket_id}, URL: {EMAIL_TEMPLATE_WEBHOOK}")
            
            # Send to original email template webhook for email sending
            response = requests.post(EMAIL_TEMPLATE_WEBHOOK, json=email_sending_payload, timeout=10)
            response.raise_for_status()
            
            app.logger.info(f" EMAIL TEMPLATE WEBHOOK (Email Sending) SUCCESS - Ticket: {ticket_id}, Status: {response.status_code}")
            
        except requests.exceptions.RequestException as e:
            app.logger.error(f" EMAIL TEMPLATE WEBHOOK (Email Sending) FAILED - Ticket: {ticket_id}, Error: {e}")
            if hasattr(e, 'response') and e.response is not None:
                app.logger.error(f" Email sending webhook response status: {e.response.status_code}")
                app.logger.error(f" Email sending webhook response content: {e.response.text}")
        except Exception as e:
            app.logger.error(f"ðŸ’¥ EMAIL TEMPLATE WEBHOOK (Email Sending) UNEXPECTED ERROR - Ticket: {ticket_id}, Error: {e}")
        
        # Main Webhook - REMOVED TO PREVENT DUPLICATE WEBHOOKS
        # Only EMAIL_TEMPLATE_WEBHOOK is needed for email template functionality
        app.logger.info(f"ðŸš€ DUPLICATE WEBHOOK REMOVED - Using only EMAIL_TEMPLATE_WEBHOOK for ticket: {ticket_id}")
        app.logger.info(f"ðŸ“§ Email template webhook sent successfully, no duplicate webhook needed")
        
        app.logger.info(f"ðŸŽ‰ EMAIL TEMPLATE COMPLETED - Ticket: {ticket_id}, Member: {member_id}")
        
        # Return status based on actual email sending result
        if email_success:
            return jsonify({
                'status': 'success',
                'message': f'Email sent successfully to {recipient_email}',
                'subject': subject,
                'preview_body': body[:200] + '...' if len(body) > 200 else body,
                'attachments_sent': len(email_attachments),
                'recipient': recipient_email
            })
        else:
            return jsonify({
                'status': 'warning',
                'message': f'Email processing completed but sending failed to {recipient_email}. Please check email configuration.',
                'subject': subject,
                'preview_body': body[:200] + '...' if len(body) > 200 else body,
                'attachments_prepared': len(email_attachments),
                'recipient': recipient_email
            }), 207  # 207 Multi-Status - partial success
        
    except Exception as e:
        import traceback
        app.logger.error(f"ðŸ’¥ CRITICAL EMAIL TEMPLATE ERROR - Ticket: {ticket_id}")
        app.logger.error(f"ðŸ’¥ Error: {str(e)}")
        app.logger.error(f"ðŸ’¥ Traceback: {traceback.format_exc()}")
        return jsonify({'status': 'error', 'message': f'Email template error: {str(e)}'}), 500

@app.route('/api/email-template/<template_type>/<ticket_id>')
def load_email_template(template_type, ticket_id):
    """Load email template - Check for n8n draft first, fallback to default template"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        # Import base64 for file encoding
        import base64
        app.logger.info(f"ðŸ” LOADING EMAIL TEMPLATE - Type: {template_type}, URL Ticket ID: {ticket_id}")
        
        # Get ticket data
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            app.logger.error(f"âŒ TICKET NOT FOUND - URL Ticket ID: {ticket_id}")
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Debug: Log the actual ticket data retrieved
        actual_ticket_id = ticket.get('ticket_id', 'NO_TICKET_ID_FIELD')
        app.logger.info(f"ðŸ” TICKET DATA RETRIEVED - URL Ticket ID: {ticket_id}, Actual Ticket ID: {actual_ticket_id}")
        
        # Check for mismatch
        if str(ticket_id) != str(actual_ticket_id):
            app.logger.warning(f"âš ï¸ TICKET ID MISMATCH DETECTED - URL: {ticket_id}, Database: {actual_ticket_id}")
            app.logger.warning(f"âš ï¸ This explains why email template shows different ticket ID than portal!")
            
            # FIX: Use the actual ticket ID from database for email templates
            app.logger.info(f"ðŸ”§ FIXING TICKET ID MISMATCH - Using database ticket ID: {actual_ticket_id} instead of URL: {ticket_id}")
            ticket_id = actual_ticket_id  # Update ticket_id to use the correct one from database
        
        # Check if n8n-generated draft exists
        # Try multiple possible draft fields: 'draft_body', 'draft', 'n8n_draft'
        n8n_draft = ticket.get('draft_body', '').strip()
        if not n8n_draft:
            n8n_draft = ticket.get('draft', '').strip()
        if not n8n_draft:
            n8n_draft = ticket.get('n8n_draft', '').strip()
        
        # Log draft detection for debugging
        app.logger.info(f"ðŸ” DRAFT DETECTION - Ticket: {ticket_id}")
        app.logger.info(f"   - draft_body: {ticket.get('draft_body', 'NOT_FOUND')}")
        app.logger.info(f"   - draft: {ticket.get('draft', 'NOT_FOUND')}")
        app.logger.info(f"   - n8n_draft: {ticket.get('n8n_draft', 'NOT_FOUND')}")
        app.logger.info(f"   - Final n8n_draft: {n8n_draft[:100] if n8n_draft else 'EMPTY'}")
        ticket_subject = ticket.get('subject', '')
        
        # Check if this is an email-created ticket by looking for email-specific fields
        is_email_ticket = ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id')
        
        # Get ticket attachments for template
        ticket_attachments = []
        
        # FIXED: Enhanced main ticket attachment processing for both email and manual tickets
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            app.logger.info(f"ðŸ“Ž FOUND {len(ticket['attachments'])} MAIN TICKET ATTACHMENTS")
            for i, att in enumerate(ticket['attachments']):
                filename = att.get('filename', att.get('original_name', 'unknown_file'))
                app.logger.info(f"ðŸ“Ž MAIN ATTACHMENT {i}: {filename}")
                
                # Include all attachments without filtering by name prefix
                if filename:
                    # Get the actual file data for the attachment
                    file_data = ""
                    file_size = 0
                    try:
                        # ðŸš€ ENHANCED: Better file data extraction with multiple fallback methods
                        app.logger.info(f"ðŸ“Ž ðŸ” ANALYZING ATTACHMENT STRUCTURE for {filename}:")
                        app.logger.info(f"ðŸ“Ž   - Has 'data' field: {bool(att.get('data'))}")
                        app.logger.info(f"ðŸ“Ž   - Has 'file_path' field: {bool(att.get('file_path'))}")
                        app.logger.info(f"ðŸ“Ž   - Has 'path' field: {bool(att.get('path'))}")
                        app.logger.info(f"ðŸ“Ž   - Has 'url' field: {bool(att.get('url'))}")
                        app.logger.info(f"ðŸ“Ž   - All attachment keys: {list(att.keys())}")
                        
                        if att.get('data'):  # If attachment already has base64 data
                            file_data = att.get('data')
                            file_size = len(base64.b64decode(file_data)) if file_data else 0
                            app.logger.info(f"ðŸ“Ž âœ… USING EXISTING BASE64 DATA: {filename} ({len(file_data)} chars, {file_size} bytes)")
                        else:
                            # ðŸš€ ENHANCED: Try multiple possible file path fields
                            possible_file_paths = [
                                att.get('file_path'),
                                att.get('path'),
                                att.get('url'),
                                att.get('filename'),  # Sometimes filename contains the path
                                os.path.join(UPLOAD_FOLDER, filename)  # Try with upload folder
                            ]
                            
                            file_data = ""
                            file_size = 0
                            
                            for file_path in possible_file_paths:
                                if not file_path:
                                    continue
                                    
                            app.logger.info(f"ðŸ“Ž ðŸ” ATTEMPTING TO READ FROM FILE PATH: {file_path}")
                            
                            # Try multiple possible path combinations
                            possible_paths = [
                                file_path,
                                os.path.join(os.getcwd(), file_path),
                                os.path.join(UPLOAD_FOLDER, file_path),
                                    os.path.join(os.getcwd(), 'uploads', file_path),
                                    os.path.join(UPLOAD_FOLDER, os.path.basename(file_path))  # Try just filename in upload folder
                            ]
                            
                            for path_attempt in possible_paths:
                                app.logger.info(f"ðŸ“Ž ðŸ” TRYING PATH: {path_attempt}")
                                if os.path.exists(path_attempt):
                                    try:
                                        with open(path_attempt, 'rb') as f:
                                            file_content = f.read()
                                            file_data = base64.b64encode(file_content).decode('utf-8')
                                            file_size = len(file_content)
                                        app.logger.info(f"ðŸ“Ž âœ… SUCCESSFULLY READ FILE FROM PATH: {filename} ({len(file_data)} chars, {file_size} bytes)")
                                        break
                                    except Exception as e:
                                        app.logger.warning(f"ðŸ“Ž âš ï¸ FAILED TO READ FILE FROM {path_attempt}: {e}")
                                        continue
                                else:
                                    app.logger.info(f"ðŸ“Ž ðŸ” PATH NOT FOUND: {path_attempt}")
                                
                                if file_data:  # If we successfully read the file, break out of the file path loop
                                    break
                            
                            if not file_data:
                                app.logger.warning(f"ðŸ“Ž âŒ ALL FILE PATH ATTEMPTS FAILED FOR: {filename}")
                                app.logger.warning(f"ðŸ“Ž   - Tried paths: {possible_file_paths}")
                                app.logger.warning(f"ðŸ“Ž   - UPLOAD_FOLDER: {UPLOAD_FOLDER}")
                                app.logger.warning(f"ðŸ“Ž   - Current working directory: {os.getcwd()}")
                    except Exception as e:
                        app.logger.error(f"ðŸ“Ž âŒ ERROR READING FILE DATA FOR {filename}: {e}")
                    
                    # Determine if this is a manual ticket attachment
                    is_manual = not is_email_ticket or att.get('is_manual_ticket_attachment', False)
                    
                    ticket_attachments.append({
                        'name': filename,
                        'file_path': f"/api/tickets/{ticket_id}/attachments/{i}/download",
                        'key': str(i),
                        'fileData': file_data,  # Include actual file data
                        'size': file_size,
                        'type': 'file',
                        'has_data': bool(file_data),  # FIXED: Flag to indicate if file has real data
                        'is_manual_ticket_attachment': is_manual,  # FIXED: Flag to identify manual ticket attachments
                        'ticket_index': i  # FIXED: Add ticket index for proper download URL generation
                    })
                    
                    if file_data:
                        app.logger.info(f"ðŸ“Ž âœ… ADDED MAIN ATTACHMENT WITH DATA: {filename} (data: {len(file_data)} chars, size: {file_size} bytes, manual: {is_manual})")
                    else:
                        app.logger.warning(f"ðŸ“Ž âš ï¸ ADDED MAIN ATTACHMENT WITHOUT DATA: {filename} (manual: {is_manual})")
                else:
                    app.logger.info(f"ðŸ“Ž SKIPPING MAIN ATTACHMENT: {filename} (no filename)")
        else:
            app.logger.info(f"ðŸ“Ž NO MAIN TICKET ATTACHMENTS FOUND")
        
        # ENHANCED DUPLICATE REMOVAL: Remove any duplicate attachments by name, path, and content to prevent showing the same file twice
        seen_names = set()
        seen_paths = set()
        seen_content_hashes = set()
        unique_attachments = []
        
        app.logger.info(f"ðŸ“Ž PROCESSING {len(ticket_attachments)} ATTACHMENTS FOR ENHANCED DUPLICATE REMOVAL")
        
        for att in ticket_attachments:
            name = att['name']
            path = att['file_path']
            file_data = att.get('fileData', '')
            
            # Create a content hash for duplicate detection
            content_hash = f"{len(file_data)}_{att.get('size', 0)}"
            
            # Check for exact name duplicates
            if name in seen_names:
                app.logger.info(f"ðŸ“Ž REMOVING DUPLICATE BY NAME: {name} (already exists)")
                continue
                
            # Check for path duplicates (same file, different name)
            if path in seen_paths:
                app.logger.info(f"ðŸ“Ž REMOVING DUPLICATE BY PATH: {name} (path already exists: {path})")
                continue
                
            # Check for content duplicates (same file content, different name/path)
            if content_hash in seen_content_hashes and file_data:
                app.logger.info(f"ðŸ“Ž REMOVING DUPLICATE BY CONTENT: {name} (same content as existing file)")
                continue
                
            # Check for similar names (e.g., "image.jpg" vs "image (1).jpg")
            is_similar = False
            for seen_name in seen_names:
                # Remove common suffixes like (1), (2), _copy, etc.
                base_name = seen_name.lower().replace(' (1)', '').replace(' (2)', '').replace('_copy', '').replace('_copy1', '').replace('_copy2', '')
                current_base = name.lower().replace(' (1)', '').replace(' (2)', '').replace('_copy', '').replace('_copy1', '').replace('_copy2', '')
                
                # Check if base names are similar (allowing for small differences)
                if base_name == current_base or base_name in current_base or current_base in base_name:
                    app.logger.info(f"ðŸ“Ž REMOVING SIMILAR DUPLICATE: {name} (similar to: {seen_name})")
                    is_similar = True
                    break
            
            if is_similar:
                continue
                
            # Add to unique attachments
            seen_names.add(name)
            seen_paths.add(path)
            if file_data:
                seen_content_hashes.add(content_hash)
            unique_attachments.append(att)
            app.logger.info(f"ðŸ“Ž ADDING UNIQUE ATTACHMENT: {name}")
        
        app.logger.info(f"ðŸ“Ž ENHANCED DUPLICATE REMOVAL COMPLETE: {len(unique_attachments)}/{len(ticket_attachments)} attachments kept")
        ticket_attachments = unique_attachments
        
        # Only add metadata attachments for manually created tickets (not email-created tickets)
        if not is_email_ticket:
            # FIXED: Enhanced metadata attachment processing for manual tickets
            app.logger.info(f"ðŸ“Ž PROCESSING METADATA ATTACHMENTS FOR MANUAL TICKET {ticket_id}")
            metadata = db.get_ticket_metadata(ticket_id)
            app.logger.info(f"ðŸ“Ž FOUND {len(metadata)} METADATA ENTRIES")
            
            for meta in metadata:
                if meta.get('key', '').startswith('attachment_'):
                    try:
                        app.logger.info(f"ðŸ“Ž PROCESSING METADATA KEY: {meta.get('key')}")
                        attachment_data = json.loads(meta.get('value', '{}'))
                        if attachment_data and isinstance(attachment_data, dict):
                            app.logger.info(f"ðŸ“Ž ATTACHMENT DATA KEYS: {list(attachment_data.keys())}")
                            
                            # FIXED: Enhanced file data retrieval with multiple fallback methods
                            file_data = ""
                            file_size = 0
                            attachment_name = attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File'))
                            
                            # PRIORITY 1: Use base64 data if available in metadata
                            if attachment_data.get('data'):
                                file_data = attachment_data.get('data')
                                try:
                                    file_size = len(base64.b64decode(file_data)) if file_data else 0
                                    app.logger.info(f"ðŸ“Ž âœ… USING METADATA BASE64 DATA: {attachment_name} ({len(file_data)} chars, {file_size} bytes)")
                                except Exception as e:
                                    app.logger.warning(f"ðŸ“Ž âš ï¸ INVALID BASE64 DATA FOR {attachment_name}: {e}")
                                    file_data = ""
                                    file_size = 0
                            
                            # PRIORITY 2: If no base64 data, try to read from file path
                            if not file_data and attachment_data.get('path'):
                                file_path_from_meta = attachment_data.get('path')
                                app.logger.info(f"ðŸ“Ž ðŸ” ATTEMPTING TO READ FILE FROM PATH: {file_path_from_meta}")
                                
                                # Try multiple possible path combinations
                                possible_paths = [
                                    os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                    os.path.join(os.getcwd(), file_path_from_meta),
                                    file_path_from_meta,
                                    os.path.join(UPLOAD_FOLDER, file_path_from_meta)
                                ]
                                
                                for path_attempt in possible_paths:
                                    app.logger.info(f"ðŸ“Ž ðŸ” TRYING PATH: {path_attempt}")
                                    if os.path.exists(path_attempt):
                                        try:
                                            with open(path_attempt, 'rb') as f:
                                                file_content = f.read()
                                                file_data = base64.b64encode(file_content).decode('utf-8')
                                                file_size = len(file_content)
                                            app.logger.info(f"ðŸ“Ž âœ… SUCCESSFULLY READ FILE FROM PATH: {attachment_name} ({len(file_data)} chars, {file_size} bytes)")
                                            break
                                        except Exception as e:
                                            app.logger.warning(f"ðŸ“Ž âš ï¸ FAILED TO READ FILE FROM {path_attempt}: {e}")
                                            continue
                                    else:
                                        app.logger.info(f"ðŸ“Ž ðŸ” PATH NOT FOUND: {path_attempt}")
                                else:
                                    app.logger.warning(f"ðŸ“Ž âŒ ALL FILE PATHS FAILED FOR: {attachment_name}")
                            
                            # PRIORITY 3: If still no data, try to find in main ticket attachments
                            if not file_data and ticket.get('has_attachments', False) and 'attachments' in ticket:
                                app.logger.info(f"ðŸ“Ž ðŸ” SEARCHING MAIN TICKET ATTACHMENTS FOR: {attachment_name}")
                                for i, att in enumerate(ticket['attachments']):
                                    if (att.get('filename') == attachment_data.get('filename') or 
                                        att.get('original_name') == attachment_data.get('original_name') or
                                        att.get('filename') == attachment_name or
                                        att.get('original_name') == attachment_name):
                                        
                                        if att.get('data'):
                                            file_data = att.get('data')
                                            try:
                                                file_size = len(base64.b64decode(file_data)) if file_data else 0
                                                app.logger.info(f"ðŸ“Ž âœ… FOUND DATA IN MAIN ATTACHMENTS: {attachment_name} ({len(file_data)} chars, {file_size} bytes)")
                                                break
                                            except Exception as e:
                                                app.logger.warning(f"ðŸ“Ž âš ï¸ INVALID DATA IN MAIN ATTACHMENTS FOR {attachment_name}: {e}")
                                                continue
                            
                            # Include all metadata attachments without filtering by name prefix
                            if attachment_name:
                                # Determine the correct file path for the attachment
                                attachment_index = None
                                if ticket.get('has_attachments', False) and 'attachments' in ticket:
                                    for i, att in enumerate(ticket['attachments']):
                                        if (att.get('filename') == attachment_data.get('filename') or 
                                            att.get('original_name') == attachment_data.get('original_name')):
                                            attachment_index = i
                                            break
                                
                                if attachment_index is not None:
                                    file_path = f"/api/tickets/{ticket_id}/attachments/{attachment_index}/download"
                                else:
                                    # Fallback: use the metadata key as index
                                    file_path = f"/api/tickets/{ticket_id}/attachments/{len(ticket_attachments)}/download"
                                
                                # Add attachment to the list
                                ticket_attachments.append({
                                    'name': attachment_name,
                                    'file_path': file_path,
                                    'key': str(attachment_index) if attachment_index is not None else str(len(ticket_attachments)),
                                    'fileData': file_data,  # Include actual file data
                                    'size': file_size,
                                    'type': 'file',
                                    'has_data': bool(file_data),  # FIXED: Flag to indicate if file has real data
                                    'is_manual_ticket_attachment': True  # FIXED: Flag to identify manual ticket attachments
                                })
                                
                                if file_data:
                                    app.logger.info(f"ðŸ“Ž âœ… ADDED METADATA ATTACHMENT WITH DATA: {attachment_name} (data: {len(file_data)} chars, size: {file_size} bytes)")
                                else:
                                    app.logger.warning(f"ðŸ“Ž âš ï¸ ADDED METADATA ATTACHMENT WITHOUT DATA: {attachment_name}")
                            else:
                                app.logger.info(f"ðŸ“Ž SKIPPING METADATA ATTACHMENT: {attachment_name} (no attachment name)")
                    except (json.JSONDecodeError, TypeError) as e:
                        app.logger.warning(f"ðŸ“Ž âŒ FAILED TO PARSE METADATA FOR KEY {meta.get('key')}: {e}")
                        continue
            
            # ðŸš€ FIXED: REMOVED COMMON DOCUMENTS FROM EMAIL TEMPLATE
            # Common documents are ONLY for conversation module drag & drop
            # Email template should ONLY show original ticket attachments
            app.logger.info(f"ðŸ“„ SKIPPING COMMON DOCUMENTS FOR EMAIL TEMPLATE - They are only for conversation module")
        
        if n8n_draft:
            # Use n8n-generated draft
            app.logger.info(f" USING N8N DRAFT - Ticket: {ticket_id}, Draft length: {len(n8n_draft)}")
            
            # Create subject from ticket subject or generate one
            if ticket_subject:
                draft_subject = f"Re: {ticket_subject}"
            else:
                draft_subject = replace_email_placeholders(
                    f"Response to your inquiry - <Ticket Number> | Auto Assist Group", 
                    ticket_id
                )
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
            ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
            enhanced_draft_body = ticket_id_header + n8n_draft
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            
                    # FINAL COMPREHENSIVE DUPLICATE CHECK: Ensure no duplicates remain before returning
        final_attachments = []
        final_seen_names = set()
        final_seen_paths = set()
        final_seen_content = set()
        
        app.logger.info(f"ðŸ“Ž FINAL COMPREHENSIVE DUPLICATE CHECK: Processing {len(ticket_attachments)} attachments")
        
        for att in ticket_attachments:
            name = att['name']
            path = att['file_path']
            file_data = att.get('fileData', '')
            content_hash = f"{len(file_data)}_{att.get('size', 0)}"
            
            # Check for any type of duplicate
            is_duplicate = False
            
            if name in final_seen_names:
                app.logger.warning(f"ðŸš¨ FINAL DUPLICATE REMOVAL: {name} - duplicate name detected!")
                is_duplicate = True
            elif path in final_seen_paths:
                app.logger.warning(f"ðŸš¨ FINAL DUPLICATE REMOVAL: {name} - duplicate path detected: {path}")
                is_duplicate = True
            elif file_data and content_hash in final_seen_content:
                app.logger.warning(f"ðŸš¨ FINAL DUPLICATE REMOVAL: {name} - duplicate content detected!")
                is_duplicate = True
            
            if not is_duplicate:
                final_attachments.append(att)
                final_seen_names.add(name)
                final_seen_paths.add(path)
                if file_data:
                    final_seen_content.add(content_hash)
                app.logger.info(f"ðŸ“Ž FINAL CHECK PASSED: {name}")
            else:
                app.logger.warning(f"ðŸš¨ FINAL CHECK FAILED: {name} - removed as duplicate")
        
        app.logger.info(f"ðŸ“Ž FINAL COMPREHENSIVE CHECK COMPLETE: {len(final_attachments)}/{len(ticket_attachments)} attachments kept")
        
        # ðŸš€ CRITICAL DEBUGGING: Log exactly what we're returning
        app.logger.info(f"ðŸš€ CRITICAL DEBUG: About to return {len(final_attachments)} attachments to frontend")
        for i, att in enumerate(final_attachments):
            app.logger.info(f"ðŸš€ CRITICAL DEBUG - Attachment {i}: {att}")
            app.logger.info(f"  - Name: {att.get('name')}")
            app.logger.info(f"  - Type: {att.get('type')}")
            app.logger.info(f"  - File Path: {att.get('file_path')}")
            app.logger.info(f"  - Has Data: {att.get('has_data')}")
            app.logger.info(f"  - File Data Length: {len(att.get('fileData', ''))}")
            app.logger.info(f"  - All Keys: {list(att.keys())}")
        
        # Enhanced logging for debugging ticket attachments
        for i, att in enumerate(final_attachments):
            app.logger.info(f"ðŸ“Ž FINAL ATTACHMENT {i}: {att.get('name')} (has_data: {att.get('has_data', False)}, size: {att.get('size', 0)}, type: {att.get('type', 'unknown')})")
            if att.get('is_manual_ticket_attachment'):
                app.logger.info(f"ðŸ“Ž   -> MANUAL TICKET ATTACHMENT: {att.get('name')}")
        
        if n8n_draft:
            # Use n8n-generated draft
            app.logger.info(f"ðŸ“ USING N8N DRAFT - Ticket: {ticket_id}, Draft length: {len(n8n_draft)}")
            
            # Create subject from ticket subject or generate one
            if ticket_subject:
                draft_subject = f"Re: {ticket_subject}"
            else:
                draft_subject = replace_email_placeholders(
                    f"Response to your inquiry - <Ticket Number> | Auto Assist Group", 
                    ticket_id
                )
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
            ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
            enhanced_draft_body = ticket_id_header + n8n_draft
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            
            return jsonify({
                'status': 'success',
                'template': {
                    'subject': draft_subject,
                    'body': enhanced_draft_body,
                    'attachments': final_attachments,
                    'has_draft': True,
                    'content_source': 'draft',
                    'source_info': 'n8n-generated draft response (with ticket ID header)'
                }
            })
        
        # ðŸš€ ENHANCED: If no draft found, try to generate one based on ticket data
        elif ticket.get('processing_method') == 'n8n_tickets_api' or ticket.get('processing_method') == 'n8n_email_processor':
            app.logger.info(f"ðŸ“ NO DRAFT FOUND - Generating contextual draft for N8N ticket {ticket_id}")
            
            # Generate contextual draft based on ticket data
            contextual_draft = generate_email_draft_response(ticket)
            
            if contextual_draft and contextual_draft.strip():
                app.logger.info(f"ðŸ“ GENERATED CONTEXTUAL DRAFT for ticket {ticket_id}: {contextual_draft[:200]}...")
                
                # ðŸ”§ REPLACE PLACEHOLDERS in the contextual draft
                contextual_draft = replace_email_placeholders(contextual_draft, ticket_id)
                app.logger.info(f"ðŸ”§ REPLACED PLACEHOLDERS in contextual draft for ticket {ticket_id}")
                
                # Create subject from ticket subject or generate one
                if ticket_subject:
                    draft_subject = f"Re: {ticket_subject}"
                else:
                    draft_subject = replace_email_placeholders(
                        f"Response to your inquiry - <Ticket Number> | Auto Assist Group", 
                        ticket_id
                    )
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
                ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
                enhanced_draft_body = ticket_id_header + contextual_draft
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO CONTEXTUAL DRAFT - Ticket: {ticket_id}")
                
                return jsonify({
                    'status': 'success',
                    'template': {
                        'subject': draft_subject,
                        'body': enhanced_draft_body,
                        'attachments': final_attachments,
                        'has_draft': True,
                        'content_source': 'generated_contextual',
                        'source_info': 'contextual draft generated for N8N ticket (with ticket ID header)'
                    }
                })
        
        else:
            # Fallback to default template with same schema
            app.logger.info(f"ðŸ“ USING FALLBACK TEMPLATE - Ticket: {ticket_id} (no n8n draft found)")
            app.logger.error(f"ðŸš¨ DEBUG: Why is no draft found?")
            app.logger.error(f"ðŸš¨ DEBUG: n8n_draft = '{n8n_draft}'")
            app.logger.error(f"ðŸš¨ DEBUG: ticket.get('draft') = '{ticket.get('draft', 'NOT_FOUND')}'")
            app.logger.error(f"ðŸš¨ DEBUG: ticket.get('draft_body') = '{ticket.get('draft_body', 'NOT_FOUND')}'")
            app.logger.error(f"ðŸš¨ DEBUG: ticket.get('n8n_draft') = '{ticket.get('n8n_draft', 'NOT_FOUND')}'")
            app.logger.error(f"ðŸš¨ DEBUG: processing_method = '{ticket.get('processing_method', 'NOT_FOUND')}'")
            
            # Generate fallback template matching n8n draft schema
            if template_type == 'warranty_claim':
                # Use warranty template
                subject = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['subject'], ticket_id)
                body = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['body'], ticket_id)
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF WARRANTY EMAIL BODY
                ticket_id_header = f"Ticket ID: {ticket_id}\n\n"
                enhanced_body = ticket_id_header + body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO WARRANTY EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
                
                return jsonify({
                    'status': 'success',
                    'template': {
                        'subject': subject,
                        'body': enhanced_body,
                        'attachments': final_attachments,
                        'has_draft': False,
                        'content_source': 'default_warranty',
                        'source_info': 'default warranty template (with ticket ID header)'
                    }
                })
            else:
                # Generate smart fallback based on ticket data
                customer_name = ticket.get('name', 'Valued Customer')
                first_name = customer_name.split()[0] if customer_name else 'Customer'
                
                subject = replace_email_placeholders(
                    f"Your inquiry - <Ticket Number> | Auto Assist Group", 
                    ticket_id
                )
                
                # Generate contextual response using the same logic as n8n
                body = generate_email_draft_response(ticket)
                if not body.strip():
                    # Ultimate fallback
                    body = """Dear {first_name},

Thank you for contacting Auto Assist Group.

We have received your inquiry and our team is reviewing the details. We will respond to your request within 1-2 business days.

If you have any urgent questions in the meantime, please don't hesitate to contact us.

Best regards,
Auto Assist Group - Customer Service Team

(Ticket ID: {ticket_id})"""
                
                # ðŸ”§ ADD TICKET ID TO BEGINNING OF EMAIL BODY
                ticket_id_header = f""
                enhanced_body =  body
                app.logger.info(f"ðŸ”§ ADDED TICKET ID TO FALLBACK EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
            
            return jsonify({
                'status': 'success',
                'template': {
                    'subject': subject,
                    'body': enhanced_body,
                    'attachments': final_attachments,
                    'has_draft': False,
                    'content_source': 'template',
                    'source_info': 'Auto-generated template with ticket ID header (no n8n draft available)'
                }
            })
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR LOADING EMAIL TEMPLATE - Ticket: {ticket_id}, Error: {str(e)}")
        return jsonify({'status': 'error', 'message': f'Error loading template: {str(e)}'}), 500

@app.route('/api/debug/attachments/<ticket_id>')
def debug_attachments(ticket_id):
    """Debug endpoint to inspect attachment processing for a specific ticket"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Get all attachment sources
        main_attachments = ticket.get('attachments', [])
        metadata = db.get_ticket_metadata(ticket_id)
        metadata_attachments = []
        
        for meta in metadata:
            if meta.get('key', '').startswith('attachment_'):
                try:
                    attachment_data = json.loads(meta.get('value', '{}'))
                    if attachment_data and isinstance(attachment_data, dict):
                        metadata_attachments.append({
                            'key': meta.get('key'),
                            'data': attachment_data,
                            'parsed_successfully': True
                        })
                except (json.JSONDecodeError, TypeError):
                    metadata_attachments.append({
                        'key': meta.get('key'),
                        'data': meta.get('value'),
                        'parsed_successfully': False
                    })
        
        # Get replies and their attachments
        replies = db.get_replies_by_ticket(ticket_id)
        reply_attachments = []
        for reply in replies:
            reply_attachments.append({
                'reply_id': str(reply.get('_id', '')),
                'attachments_count': len(reply.get('attachments', [])),
                'attachments': reply.get('attachments', []),
                'created_at': reply.get('created_at', ''),
                'source': reply.get('source', 'unknown')
            })
        
        # Get common documents
        common_documents = []
        try:
            common_docs = db.get_all_common_documents()
            for doc in common_docs:
                common_documents.append({
                    'id': str(doc.get('_id', '')),
                    'name': doc.get('name', 'Unknown'),
                    'filename': doc.get('file_name', doc.get('filename', 'unknown'))
                })
        except Exception as e:
            common_documents = [{'error': str(e)}]
        
        debug_info = {
            'ticket_id': ticket_id,
            'ticket_has_attachments': ticket.get('has_attachments', False),
            'main_attachments_count': len(main_attachments),
            'main_attachments': main_attachments,
            'metadata_attachments_count': len(metadata_attachments),
            'metadata_attachments': metadata_attachments,
            'replies_count': len(replies),
            'reply_attachments': reply_attachments,
            'common_documents_count': len(common_documents),
            'common_documents': common_documents,
            'ticket_source': {
                'is_email_ticket': ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id'),
                'processing_method': ticket.get('processing_method', 'unknown'),
                'has_warranty': ticket.get('has_warranty', False)
            }
        }
        
        return jsonify({
            'status': 'success',
            'debug_info': debug_info
        })
        
    except Exception as e:
        app.logger.error(f"Debug attachments error: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500





@app.route('/api/email/preview-template', methods=['POST'])
def preview_template():
    """Preview email template with placeholders replaced"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        data = request.json
        ticket_id = data.get('ticket_id')
        template_type = data.get('template_type', 'warranty')
        
        if not ticket_id:
            return jsonify({'status': 'error', 'message': 'Ticket ID required'}), 400
        
        # Get template and replace placeholders
        if template_type == 'warranty':
            subject = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['subject'], ticket_id)
            body = replace_email_placeholders(DEFAULT_WARRANTY_TEMPLATE['body'], ticket_id)
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF PREVIEW EMAIL BODY
            ticket_id_header = f""
            enhanced_body = ticket_id_header + body
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO PREVIEW EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
        else:
            subject = replace_email_placeholders('<Ticket Number> - Follow Up', ticket_id)
            body = replace_email_placeholders('Dear <First Name> <Surname>,\n\nRegarding your ticket <Ticket Number>...\n\nBest regards,\nAuto Assist Group', ticket_id)
            
            # ðŸ”§ ADD TICKET ID TO BEGINNING OF PREVIEW EMAIL BODY
            ticket_id_header = f""
            enhanced_body = ticket_id_header + body
            app.logger.info(f"ðŸ”§ ADDED TICKET ID TO PREVIEW EMAIL BODY - Ticket: {ticket_id}, Body now starts with: {ticket_id_header.strip()}")
        
        return jsonify({
            'status': 'success',
            'subject': subject,
            'body': enhanced_body,
            'template_name': DEFAULT_WARRANTY_TEMPLATE['name']
        })
        
    except Exception as e:
        app.logger.error(f"Error previewing template: {str(e)}")
        return jsonify({'status': 'error', 'message': 'Error previewing template'}), 500

# ============ ROLES MANAGEMENT API ENDPOINTS ============

@app.route('/api/roles', methods=['GET', 'POST'])
def handle_roles():
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 403
    
    if request.method == 'GET':
        try:
            roles = db.get_all_roles()
            # Convert ObjectIds to strings for JSON serialization
            for role in roles:
                role['_id'] = str(role['_id'])
                role['id'] = role['_id']  # Add 'id' field for frontend compatibility
            return jsonify({'status': 'success', 'roles': roles})
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500
    
    elif request.method == 'POST':
        try:
            data = request.json
            required_fields = ['name', 'description']
            
            if not all(field in data for field in required_fields):
                return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400
            
            role_data = {
                'name': data['name'],
                'description': data['description'],
                'permissions': data.get('permissions', []),
                'level': data.get('level', 3),
                'color': data.get('color', '#6b7280'),
                'is_default': False
            }
            
            db.create_role(role_data)
            return jsonify({'status': 'success', 'message': 'Role created successfully'})
        except ValueError as e:
            return jsonify({'status': 'error', 'message': str(e)}), 400
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500

# Status Management API Endpoints (Missing from original)
@app.route('/api/admin/statuses', methods=['GET', 'POST'])
def manage_statuses():
    """Manage ticket statuses (GET all statuses, POST new status)"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        
        if request.method == 'GET':
            # Get all statuses
            statuses = db.get_all_ticket_statuses()
            
            # Convert ObjectId to string for JSON serialization
            for status in statuses:
                status['_id'] = str(status['_id'])
            
            return jsonify({
                'status': 'success',
                'statuses': statuses
            })
        
        elif request.method == 'POST':
            # Create new status
            data = request.get_json()
            
            # Validate required fields
            if not data.get('name'):
                return jsonify({'status': 'error', 'message': 'Status name is required'}), 400
            
            status_data = {
                'name': data['name'],
                'color': data.get('color', '#6b7280'),
                'description': data.get('description', ''),
                'is_active': True
            }
            
            status_id = db.create_ticket_status(status_data)
            return jsonify({
                'status': 'success',
                'message': 'Status created successfully',
                'status_id': str(status_id)
            })
            
    except Exception as e:
        logging.error(f"Error managing statuses: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/statuses/<status_id>', methods=['PUT', 'DELETE'])
def manage_status(status_id):
    """Update or delete specific status"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        
        if request.method == 'PUT':
            # Update status
            data = request.get_json()
            update_data = {}
            
            if 'name' in data:
                update_data['name'] = data['name']
            if 'color' in data:
                update_data['color'] = data['color']
            if 'description' in data:
                update_data['description'] = data['description']
            
            result = db.update_ticket_status_config(status_id, update_data)
            
            if result.modified_count > 0:
                return jsonify({'status': 'success', 'message': 'Status updated successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Status not found or no changes made'}), 404
                
        elif request.method == 'DELETE':
            # Deactivate status (soft delete)
            result = db.deactivate_ticket_status(status_id)
            
            if result.modified_count > 0:
                return jsonify({'status': 'success', 'message': 'Status deactivated successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Status not found'}), 404
                
    except Exception as e:
        logging.error(f"Error managing status {status_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/roles/<role_id>', methods=['PUT', 'DELETE'])
def manage_role(role_id):
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
        
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member['role'].lower() != 'administrator':
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 403
    
    if request.method == 'PUT':
        try:
            data = request.json
            update_data = {}
            
            if 'name' in data:
                update_data['name'] = data['name']
            if 'description' in data:
                update_data['description'] = data['description']
            if 'permissions' in data:
                update_data['permissions'] = data['permissions']
            if 'level' in data:
                update_data['level'] = data['level']
            if 'color' in data:
                update_data['color'] = data['color']
            
            if db.update_role(role_id, update_data):
                return jsonify({'status': 'success', 'message': 'Role updated successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Role not found or no changes made'}), 404
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500
    
    elif request.method == 'DELETE':
        try:
            if db.delete_role(role_id):
                return jsonify({'status': 'success', 'message': 'Role deleted successfully'})
            else:
                return jsonify({'status': 'error', 'message': 'Role not found'}), 404
        except ValueError as e:
            return jsonify({'status': 'error', 'message': str(e)}), 400
        except Exception as e:
            return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/replies/<reply_id>/attachments/<int:attachment_index>/download')
def download_reply_attachment(reply_id, attachment_index):
    """Download attachment from a specific reply"""
    try:
        # Check authentication
        if 'member_id' not in session:
            return jsonify({'error': 'Authentication required'}), 401
        
        db = get_db()
        
        # Get the reply
        reply = db.replies.find_one({'_id': ObjectId(reply_id)})
        if not reply:
            return jsonify({'error': 'Reply not found'}), 404
        
        # Check if user has access to this ticket
        ticket = db.tickets.find_one({'ticket_id': reply['ticket_id']})
        if not ticket:
            return jsonify({'error': 'Associated ticket not found'}), 404
        
        # Get attachments from reply
        attachments = reply.get('attachments', [])
        
        # FIXED: Map filtered index to actual attachment index
        # The frontend passes filtered indices, but we need to find the actual downloadable attachment
        downloadable_attachments = []
        for i, att in enumerate(attachments):
            # Enhanced detection: check for type, source, or fileData presence
            is_downloadable = (
                att.get('type') == 'file' or 
                att.get('source') in ['webhook_base64', 'webhook', 'simple_attachments'] or 
                att.get('fileData') or  # Check for fileData (base64 content)
                att.get('data') or      # Check for data field
                not att.get('type')     # Fallback for attachments without type
            )
            
            if is_downloadable:
                downloadable_attachments.append((i, att))  # Store (original_index, attachment)
        
        # Check if the requested filtered index is valid
        if attachment_index >= len(downloadable_attachments):
            app.logger.error(f" FILTERED ATTACHMENT INDEX OUT OF RANGE: Requested {attachment_index}, but only {len(downloadable_attachments)} downloadable attachments exist")
            available_filtered_indices = list(range(len(downloadable_attachments)))
            app.logger.error(f" Available filtered indices: {available_filtered_indices}")
            return jsonify({
                'error': 'Filtered attachment index out of range',
                'requested_index': attachment_index,
                'total_downloadable_attachments': len(downloadable_attachments),
                'total_attachments': len(attachments),
                'available_filtered_indices': available_filtered_indices,
                'attachment_types': [att.get('type') for att in attachments],
                'attachment_sources': [att.get('source') for att in attachments]
            }), 404
        
        # Get the actual attachment using the filtered index
        original_index, attachment = downloadable_attachments[attachment_index]
        
        # Enhanced attachment type checking for webhook attachments
        attachment_type = attachment.get('type')
        if attachment_type == 'text_reference':
            # Handle text reference attachments - these are not downloadable files
            return jsonify({
                'error': 'This is a text reference attachment, not a downloadable file',
                'attachment_info': {
                    'type': 'text_reference',
                    'name': attachment.get('name', 'Document Reference'),
                    'description': attachment.get('description', '')
                }
            }), 400
        elif attachment_type not in ['file', 'webhook_base64'] and not attachment.get('fileData') and not attachment.get('data'):
            # Only reject if no fileData or data is present
            app.logger.error(f" Invalid attachment type: {attachment_type}. Expected 'file' or 'webhook_base64' or attachment with fileData")
            app.logger.error(f" Full attachment data: {attachment}")
            return jsonify({'error': f'Invalid attachment type: {attachment_type}'}), 400
        
        # Get file information - handle both webhook and regular attachments
        filename = attachment.get('filename') or attachment.get('name', 'unknown_file')
        file_path = attachment.get('path', '')
        # Check for base64 data in multiple possible fields
        base64_data = attachment.get('data', '') or attachment.get('fileData', '')
        

        
        # FIXED: Priority 1 - Use base64 data if available (most reliable)
        if base64_data and len(base64_data) > 10:
            try:
                app.logger.info(f"ðŸ“Ž Using base64 data for reply attachment: {filename} ({len(base64_data)} chars)")
                file_content = base64.b64decode(base64_data)
                
                # Create response with file content
                response = make_response(file_content)
                response.headers['Content-Type'] = get_mime_type(filename)
                response.headers['Content-Disposition'] = f'attachment; filename="{filename}"'
                response.headers['Content-Length'] = str(len(file_content))
                return response
                
            except Exception as e:
                app.logger.error(f"ðŸ“Ž Error decoding base64 data for {filename}: {e}")
                # Fall back to file path method
        
        # FIXED: Priority 2 - Try to serve the file from disk
        if file_path and os.path.exists(file_path):
            # File exists at original path
            app.logger.info(f" Serving file from original path: {file_path}")
            return send_file(
                file_path,
                as_attachment=True,
                download_name=filename,
                mimetype=get_mime_type(filename)
            )
        else:
            # Try uploads directory
            upload_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path) if file_path else filename)
            app.logger.info(f" Trying uploads directory: {upload_path}")
            
            if os.path.exists(upload_path):
                app.logger.info(f" Serving file from uploads: {upload_path}")
                return send_file(
                    upload_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            else:
                app.logger.error(f"ðŸ“Ž Reply attachment file not found: {file_path} or {upload_path}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER: {UPLOAD_FOLDER}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER exists: {os.path.exists(UPLOAD_FOLDER)}")
                if os.path.exists(UPLOAD_FOLDER):
                    app.logger.error(f"ðŸ“Ž Files in UPLOAD_FOLDER: {os.listdir(UPLOAD_FOLDER)}")
                
                # FIXED: Enhanced error response with attachment details
                return jsonify({
                    'error': 'File not found on server',
                    'attachment_info': {
                        'filename': filename,
                        'type': attachment_type,
                        'has_base64_data': bool(base64_data),
                        'file_path': file_path,
                        'upload_path': upload_path
                    }
                }), 404
        
    except Exception as e:
        app.logger.error(f" Error downloading reply attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Failed to download attachment'}), 500

@app.route('/api/replies/<reply_id>/attachments/<int:attachment_index>/preview')
def preview_reply_attachment(reply_id, attachment_index):
    """Preview attachment from a specific reply (for images, PDFs, etc.)"""
    try:
        # Check authentication
        if 'member_id' not in session:
            return jsonify({'error': 'Authentication required'}), 401
        
        db = get_db()
        
        # Get the reply
        reply = db.replies.find_one({'_id': ObjectId(reply_id)})
        if not reply:
            return jsonify({'error': 'Reply not found'}), 404
        
        # Check if user has access to this ticket
        ticket = db.tickets.find_one({'ticket_id': reply['ticket_id']})
        if not ticket:
            return jsonify({'error': 'Associated ticket not found'}), 404
        
        # Get attachments from reply
        attachments = reply.get('attachments', [])
        
        # FIXED: Map filtered index to actual attachment index
        # The frontend passes filtered indices, but we need to find the actual downloadable attachment
        downloadable_attachments = []
        for i, att in enumerate(attachments):
            # Enhanced detection: check for type, source, or fileData presence
            is_downloadable = (
                att.get('type') == 'file' or 
                att.get('source') in ['webhook_base64', 'webhook', 'simple_attachments'] or 
                att.get('fileData') or  # Check for fileData (base64 content)
                att.get('data') or      # Check for data field
                not att.get('type')     # Fallback for attachments without type
            )
            
            if is_downloadable:
                downloadable_attachments.append((i, att))  # Store (original_index, attachment)
        
        # Check if the requested filtered index is valid
        if attachment_index >= len(downloadable_attachments):
            app.logger.error(f" PREVIEW FILTERED ATTACHMENT INDEX OUT OF RANGE: Requested {attachment_index}, but only {len(downloadable_attachments)} downloadable attachments exist")
            available_filtered_indices = list(range(len(downloadable_attachments)))
            app.logger.error(f" Available filtered indices: {available_filtered_indices}")
            return jsonify({
                'error': 'Filtered attachment index out of range',
                'requested_index': attachment_index,
                'total_downloadable_attachments': len(downloadable_attachments),
                'total_attachments': len(attachments),
                'available_filtered_indices': available_filtered_indices,
                'attachment_types': [att.get('type') for att in attachments],
                'attachment_sources': [att.get('source') for att in attachments]
            }), 404
        
        # Get the actual attachment using the filtered index
        original_index, attachment = downloadable_attachments[attachment_index]
        
        # Enhanced attachment type checking for webhook attachments
        attachment_type = attachment.get('type')
        if attachment_type == 'text_reference':
            # Handle text reference attachments - these are not previewable files
            return jsonify({
                'error': 'This is a text reference attachment, not a previewable file',
                'attachment_info': {
                    'type': 'text_reference',
                    'name': attachment.get('name', 'Document Reference'),
                    'description': attachment.get('description', '')
                }
            }), 400
        elif attachment_type not in ['file', 'webhook_base64'] and not attachment.get('fileData') and not attachment.get('data'):
            # Only reject if no fileData or data is present
            app.logger.error(f" Invalid attachment type: {attachment_type}. Expected 'file' or 'webhook_base64' or attachment with fileData")
            app.logger.error(f" Full attachment data: {attachment}")
            return jsonify({'error': f'Invalid attachment type: {attachment_type}'}), 400
        
        # Get file information - handle both webhook and regular attachments
        filename = attachment.get('filename') or attachment.get('name', 'unknown_file')
        file_path = attachment.get('path', '')
        # Check for base64 data in multiple possible fields
        base64_data = attachment.get('data', '') or attachment.get('fileData', '')
        
        # Check if file is previewable
        preview_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.txt', '.md']
        file_ext = os.path.splitext(filename.lower())[1]
        
        if file_ext not in preview_extensions:
            app.logger.error(f"ðŸ“Ž File type not previewable: {file_ext}")
            return jsonify({'error': f'File type {file_ext} not previewable'}), 400
        

        
        # FIXED: Priority 1 - Use base64 data if available (most reliable)
        if base64_data and len(base64_data) > 10:
            try:
                app.logger.info(f"ðŸ“Ž Using base64 data for reply attachment preview: {filename} ({len(base64_data)} chars)")
                file_content = base64.b64decode(base64_data)
                
                # Create response with file content for preview
                response = make_response(file_content)
                response.headers['Content-Type'] = get_mime_type(filename)
                response.headers['Content-Length'] = str(len(file_content))
                return response
                
            except Exception as e:
                app.logger.error(f"ðŸ“Ž Error decoding base64 data for preview {filename}: {e}")
                # Fall back to file path method
        
        # FIXED: Priority 2 - Try to serve the file from disk for preview
        if file_path and os.path.exists(file_path):
            # File exists at original path
            app.logger.info(f" Serving preview from original path: {file_path}")
            return send_file(
                file_path,
                as_attachment=False,  # Display inline for preview
                mimetype=get_mime_type(filename)
            )
        else:
            # Try uploads directory
            upload_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path) if file_path else filename)
            app.logger.info(f" Trying uploads directory for preview: {upload_path}")
            
            if os.path.exists(upload_path):
                app.logger.info(f" Serving preview from uploads: {upload_path}")
                return send_file(
                    upload_path,
                    as_attachment=False,  # Display inline for preview
                    mimetype=get_mime_type(filename)
                )
            else:
                app.logger.error(f"ðŸ“Ž Reply attachment file not found for preview: {file_path} or {upload_path}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER: {UPLOAD_FOLDER}")
                app.logger.error(f"ðŸ“Ž UPLOAD_FOLDER exists: {os.path.exists(UPLOAD_FOLDER)}")
                if os.path.exists(UPLOAD_FOLDER):
                    app.logger.error(f"ðŸ“Ž Files in UPLOAD_FOLDER: {os.listdir(UPLOAD_FOLDER)}")
                
                # FIXED: Enhanced error response with attachment details
                return jsonify({
                    'error': 'File not found on server',
                    'attachment_info': {
                        'filename': filename,
                        'type': attachment_type,
                        'has_base64_data': bool(base64_data),
                        'file_path': file_path,
                        'upload_path': upload_path
                    }
                }), 404
        
    except Exception as e:
        app.logger.error(f" Error previewing reply attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Failed to preview attachment'}), 500

@app.route('/api/tickets/<ticket_id>/reply-count', methods=['GET'])
def get_reply_count(ticket_id):
    """Get the current reply count for a ticket (for auto-refresh functionality)"""
    try:
        db = get_db()
        
        # Get ticket to verify it exists
        ticket = db.tickets.find_one({'ticket_id': ticket_id})
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Count replies for this ticket
        reply_count = db.replies.count_documents({'ticket_id': ticket_id})
        
        return jsonify({
            'status': 'success',
            'ticket_id': ticket_id,
            'reply_count': reply_count
        })
        
    except Exception as e:
        app.logger.error(f"Error getting reply count for ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': 'Failed to get reply count'}), 500



@app.route('/webhook/reply', methods=['POST'])
def webhook_reply():
    """Webhook endpoint for external systems (like n8n) to send ticket replies"""
    try:
        # Get data for processing
        raw_data = request.get_data()
        
        if not raw_data:
            response = jsonify({
                'success': False,
                'message': 'No data received',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        # Handle both JSON and form data
        if request.is_json:
            data = request.get_json()
            if isinstance(data, list) and len(data) > 0:
                data = data[0]
            
            ticket_id = data.get('ticket_id', '').strip()
            response_text = data.get('response', '').strip() or data.get('message', '').strip()
            attachments_data = data.get('attachments', {})
        else:
            ticket_id = request.form.get('ticket_id', '').strip()
            response_text = request.form.get('response', '').strip() or request.form.get('message', '').strip()
            attachments_data = {}
        
        # Validation
        if not ticket_id:
            response = jsonify({
                'success': False,
                'message': 'Missing ticket_id',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        if not response_text:
            response = jsonify({
                'success': False,
                'message': 'Missing response text',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        if len(response_text) > 10000:
            response = jsonify({
                'success': False,
                'message': 'Response text too long (max 10000 characters)',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 400
        
        try:
            db = get_db()
            ticket = db.tickets.find_one({'ticket_id': ticket_id})
            
            if not ticket:
                response = jsonify({
                    'success': False,
                    'message': f'Ticket {ticket_id} not found',
                    'timestamp': datetime.now().isoformat(),
                    'status': 'error'
                })
                response.headers['Content-Type'] = 'application/json'
                response.headers['Access-Control-Allow-Origin'] = '*'
                return response, 404
            
            # Save reply to database
            reply_data = {
                'ticket_id': ticket_id,
                'thread_id': ticket['thread_id'],
                'message': response_text,
                'sender': 'customer'
            }
            
            reply_id = db.create_reply(reply_data)
            
            # Process attachments
            attachments = []
            file_attachments = []
            
            # Process JSON attachments from webhook data
            if attachments_data and isinstance(attachments_data, dict):
                for attachment_key, attachment_info in attachments_data.items():
                    if isinstance(attachment_info, dict):
                        filename = attachment_info.get('fileName', 'unknown_file')
                        base64_data = attachment_info.get('data', '')
                        mime_type = attachment_info.get('mimeType', 'application/octet-stream')
                        
                        if base64_data and filename:
                            try:
                                # Create attachment object with proper structure
                                attachment = {
                                    'type': 'file',  # âœ… Set as file type
                                    'name': filename,
                                    'filename': filename,
                                    'data': base64_data,  # âœ… Store base64 data
                                    'has_data': True,
                                    'mime_type': mime_type,
                                    'source': 'webhook_base64',  # âœ… Mark source
                                    'size': len(base64_data) * 3 // 4,  # Approximate size
                                    'uploaded_at': datetime.now()
                                }
                                attachments.append(attachment)
                                
                                app.logger.info(f"âœ… Processed webhook attachment: {filename} ({len(base64_data)} chars)")
                                
                            except Exception as e:
                                app.logger.error(f"âŒ Error processing webhook attachment {filename}: {e}")
                                # Add as text reference if processing fails
                                attachments.append({
                                    'type': 'text_reference',
                                    'name': filename,
                                    'description': f'Error processing: {str(e)}'
                                })
            
            # Handle file uploads
            if request.files:
                for file_key, file_obj in request.files.items():
                    if file_obj and file_obj.filename:
                        try:
                            if not UPLOAD_FOLDER:
                                attachments.append({
                                    'type': 'text_reference',
                                    'name': file_obj.filename,
                                    'description': 'Upload folder not configured'
                                })
                                continue
                            
                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                            safe_filename = secure_filename(file_obj.filename)
                            unique_filename = f"{timestamp}_{safe_filename}"
                            
                            try:
                                if not os.path.exists(UPLOAD_FOLDER):
                                    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
                                
                                upload_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                                file_obj.save(upload_path)
                                
                                with open(upload_path, 'rb') as f:
                                    file_content = f.read()
                                    base64_data = base64.b64encode(file_content).decode('utf-8')
                                
                                file_attachment = {
                                    'type': 'file',
                                    'name': file_obj.filename,
                                    'path': upload_path,
                                    'size': os.path.getsize(upload_path),
                                    'uploaded_at': datetime.now(),
                                    'data': base64_data,
                                    'has_data': True,
                                    'filename': file_obj.filename,
                                    'source': 'file_upload'  # Add source for better identification
                                }
                                file_attachments.append(file_attachment)
                                
                            except OSError as e:
                                if 'Read-only file system' in str(e) or 'Permission denied' in str(e):
                                    attachments.append({
                                        'type': 'text_reference',
                                        'name': file_obj.filename,
                                        'description': 'File system is read-only'
                                    })
                                else:
                                    raise
                                    
                        except Exception as e:
                            app.logger.error(f"Error processing file {file_obj.filename}: {e}")
                            attachments.append({
                                'type': 'text_reference',
                                'name': file_obj.filename,
                                'description': f'Error: {str(e)}'
                            })
            
            # Save attachments to reply
            all_attachments = attachments + file_attachments
            if all_attachments:
                db.replies.update_one(
                    {'_id': reply_id},
                    {'$set': {'attachments': all_attachments}}
                )
            
            # Update ticket status
            update_data = {
                'status': 'Open',
                'draft_body': '',
                'updated_at': datetime.now(),
                'has_unread_reply': True
            }
            db.update_ticket(ticket_id, update_data)
            
            app.logger.info(f"Webhook reply processed successfully for ticket: {ticket_id}")
            app.logger.info(f"Total attachments processed: {len(attachments)} (Files: {len(file_attachments)})")
            
            # Return the actual processed data in the format expected
            response = jsonify([{
                'ticket_id': ticket_id,
                'response': response_text,
                'attachments': attachments_data
            }])
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response
            
        except Exception as bg_error:
            app.logger.error(f"Background processing error: {bg_error}")
            response = jsonify({
                'success': False,
                'message': f'Error processing webhook data: {str(bg_error)}',
                'timestamp': datetime.now().isoformat(),
                'status': 'error'
            })
            response.headers['Content-Type'] = 'application/json'
            response.headers['Access-Control-Allow-Origin'] = '*'
            return response, 500
        
    except Exception as e:
        app.logger.error(f"Webhook endpoint error: {str(e)}")
        response = jsonify({
            'success': False,
            'message': f'Error processing webhook: {str(e)}',
            'timestamp': datetime.now().isoformat(),
            'status': 'error'
        })
        response.headers['Content-Type'] = 'application/json'
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response, 500

@app.route('/api/attachment/<attachment_id>')
def get_simple_attachment(attachment_id):
    """
    [TARGET] SIMPLE APP STYLE: Serve attachment file exactly like the simple app
    attachment_id format: "ticket_id_index" (e.g., "706393_R122412_0")
    """
    try:
        app.logger.info(f"? Attachment request: {attachment_id}")
        
        # Parse attachment_id to get ticket_id and index
        parts = attachment_id.rsplit('_', 1)
        if len(parts) != 2:
            app.logger.error(f"Invalid attachment ID format: {attachment_id}")
            return jsonify({'error': 'Invalid attachment ID format'}), 400
        
        ticket_id = parts[0]
        try:
            attachment_index = int(parts[1])
        except ValueError:
            app.logger.error(f"Invalid attachment index: {parts[1]}")
            return jsonify({'error': 'Invalid attachment index'}), 400
        
        app.logger.info(f"? Looking for ticket: {ticket_id}, attachment: {attachment_index}")
        
        db = get_db()
        
        # Get ticket data
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            app.logger.error(f"Ticket not found: {ticket_id}")
            return jsonify({'error': 'Ticket not found'}), 404
        
        app.logger.info(f"[SUCCESS] Found ticket, has_attachments: {ticket.get('has_attachments', False)}")
        
        # Get attachments from ticket (same as simple app logic)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            attachments = ticket['attachments']
            app.logger.info(f"? Found {len(attachments)} attachments")
            
            if attachment_index < len(attachments):
                attachment = attachments[attachment_index]
                filename = attachment.get('filename', 'unknown_file')
                file_data = attachment.get('data', '')
                
                app.logger.info(f"? Processing attachment: {filename}, data length: {len(file_data)}")
                
                if file_data:
                    try:
                        # [FIX] ENHANCED: Fix base64 padding if needed
                        # Add padding if missing (base64 strings must be multiple of 4)
                        missing_padding = len(file_data) % 4
                        if missing_padding:
                            file_data += '=' * (4 - missing_padding)
                            app.logger.info(f"Added {4 - missing_padding} padding characters")
                        
                        # Validate base64 before decoding
                        if not file_data.replace('+', '').replace('/', '').replace('=', '').isalnum():
                            app.logger.error("Base64 data contains invalid characters")
                            return jsonify({'error': 'Invalid base64 data format'}), 500
                        
                        # Decode base64 data
                        decoded_data = base64.b64decode(file_data, validate=True)
                        app.logger.info(f"[SUCCESS] Successfully decoded {len(decoded_data)} bytes")
                        
                        # Create a BytesIO object
                        file_stream = io.BytesIO(decoded_data)
                        
                        # Guess MIME type from filename
                        mime_type, _ = mimetypes.guess_type(filename)
                        if not mime_type:
                            # Try to detect from data headers
                            if decoded_data.startswith(b'\xFF\xD8\xFF'):
                                mime_type = 'image/jpeg'
                            elif decoded_data.startswith(b'\x89PNG'):
                                mime_type = 'image/png'
                            elif decoded_data.startswith(b'%PDF'):
                                mime_type = 'application/pdf'
                            else:
                                mime_type = 'application/octet-stream'
                        
                        app.logger.info(f"[TARGET] Serving file: {filename}, MIME: {mime_type}")
                        
                        # For preview, don't force download
                        if request.args.get('preview') == 'true':
                            return send_file(
                                file_stream,
                                mimetype=mime_type
                            )
                        else:
                            return send_file(
                                file_stream,
                                mimetype=mime_type,
                                as_attachment=True,
                                download_name=filename
                            )
                            
                    except base64.binascii.Error as e:
                        app.logger.error(f"Base64 decoding error: {e}")
                        return jsonify({'error': f'Base64 decode error: {str(e)}'}), 500
                    except Exception as e:
                        app.logger.error(f"Failed to process attachment data: {e}")
                        return jsonify({'error': f'Attachment processing error: {str(e)}'}), 500
                else:
                    app.logger.error("No file data found in attachment")
                    return jsonify({'error': 'No file data available'}), 404
            else:
                app.logger.error(f"Attachment index {attachment_index} out of range (max: {len(attachments)-1})")
                return jsonify({'error': f'Attachment index out of range'}), 404
        else:
            app.logger.error("No attachments found in ticket")
            return jsonify({'error': 'No attachments found'}), 404
        
    except Exception as e:
        app.logger.error(f"Error serving attachment: {str(e)}")
        import traceback
        app.logger.error(f"Full traceback: {traceback.format_exc()}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickets/<ticket_id>/attachments/<int:attachment_index>/download')
def download_attachment(ticket_id, attachment_index):
    """
    [ENHANCED] Download attachments from multiple sources:
    1. Direct ticket attachments (base64 data)
    2. Reply attachments (webhook files)
    3. Metadata attachments (file uploads)
    """
    try:
        db = get_db()
        
        # Get ticket data
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        app.logger.info(f" Download request for ticket {ticket_id}, attachment {attachment_index}")
        
        # METHOD 1: Check for direct attachments in ticket (n8n email tickets and manual tickets)
        if ticket.get('has_attachments', False) and 'attachments' in ticket:
            attachments = ticket['attachments']
            app.logger.info(f"Found {len(attachments)} direct attachments in ticket")
            
            if attachment_index < len(attachments):
                attachment = attachments[attachment_index]
                filename = attachment.get('filename', attachment.get('original_name', 'unknown_file'))
                
                # FIXED: PRIORITY 1 - Check for base64 data first (most reliable)
                file_data = attachment.get('data', '')
                if file_data:
                    app.logger.info(f" Downloading base64 attachment: {filename} (base64: {len(file_data)} chars)")
                    try:
                        decoded_data = base64.b64decode(file_data)
                        return send_file(
                            io.BytesIO(decoded_data),
                            as_attachment=True,
                            download_name=filename,
                            mimetype=get_mime_type(filename)
                        )
                    except Exception as e:
                        app.logger.error(f"Failed to decode base64 data: {e}")
                        # Fall back to file path method
                        app.logger.warning(f"Falling back to file path method for {filename}")
                
                # FIXED: PRIORITY 2 - Check if this is a manual ticket attachment (has file path)
                if attachment.get('path') and os.path.exists(attachment['path']):
                    app.logger.info(f" Downloading manual ticket attachment from disk: {filename} from {attachment['path']}")
                    return send_file(
                        attachment['path'],
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                
                # FIXED: PRIORITY 3 - Try to find file in uploads directory for manual tickets
                if filename:
                    upload_path = os.path.join(UPLOAD_FOLDER, ticket_id, filename)
                    if os.path.exists(upload_path):
                        app.logger.info(f" Found manual ticket attachment in uploads: {upload_path}")
                        return send_file(
                            upload_path,
                            as_attachment=True,
                            download_name=filename,
                            mimetype=get_mime_type(filename)
                        )
                    else:
                        app.logger.warning(f" Manual ticket attachment not found: {upload_path}")
                        # List files in uploads directory for debugging
                        upload_dir = os.path.join(UPLOAD_FOLDER, ticket_id)
                        if os.path.exists(upload_dir):
                            upload_files = os.listdir(upload_dir)
                            app.logger.info(f"FOLDER Files in uploads/{ticket_id}: {upload_files}")
                        else:
                            app.logger.warning(f" Uploads directory for ticket {ticket_id} does not exist")
        
        # METHOD 1.5: Check for simple_attachments (conversation section attachments)
        if ticket.get('simple_attachments'):
            simple_attachments = ticket['simple_attachments']
            app.logger.info(f"Found {len(simple_attachments)} simple attachments in ticket")
            
            if attachment_index < len(simple_attachments):
                attachment = simple_attachments[attachment_index]
                filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
                file_path = attachment.get('file_path', '')
                
                app.logger.info(f" Simple attachment: {attachment}")
                
                # Try to serve the file from the file_path
                if file_path and os.path.exists(file_path):
                    app.logger.info(f" FOUND SIMPLE ATTACHMENT FILE: {file_path}")
                    return send_file(
                        file_path,
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                else:
                    app.logger.warning(f" Simple attachment file not found: {file_path}")
                    # Try to find the file in uploads directory
                    if filename:
                        upload_path = os.path.join(UPLOAD_FOLDER, filename)
                        if os.path.exists(upload_path):
                            app.logger.info(f" FOUND SIMPLE ATTACHMENT IN UPLOADS: {upload_path}")
                            return send_file(
                                upload_path,
                                as_attachment=True,
                                download_name=filename,
                                mimetype=get_mime_type(filename)
                            )
                        else:
                            app.logger.warning(f" Simple attachment not found in uploads: {upload_path}")
                            # List files in uploads directory for debugging
                            if os.path.exists(UPLOAD_FOLDER):
                                upload_files = os.listdir(UPLOAD_FOLDER)
                                app.logger.info(f"FOLDER Files in uploads directory: {upload_files}")
                            else:
                                app.logger.warning(f" Uploads directory {UPLOAD_FOLDER} does not exist")
        
        # METHOD 2: Check reply attachments (webhook files)
        replies = db.replies.find({'ticket_id': ticket_id}).sort('created_at', -1)
        all_reply_attachments = []
        
        for reply in replies:
            if reply.get('attachments'):
                for att in reply['attachments']:
                    if att.get('type') == 'file':
                        all_reply_attachments.append(att)
        
        app.logger.info(f"Found {len(all_reply_attachments)} reply attachments")
        
        if attachment_index < len(all_reply_attachments):
            attachment = all_reply_attachments[attachment_index]
            filename = attachment.get('name', attachment.get('filename', 'unknown_file'))
            file_path = attachment.get('path', '')
            
            if file_path and os.path.exists(file_path):
                app.logger.info(f" FOUND REPLY FILE: {file_path}")
                return send_file(
                    file_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            else:
                app.logger.warning(f" Reply file not found: {file_path}")
        
        # METHOD 3: Check metadata collection for file attachments (both email and manual tickets)
        ticket_metadata = db.get_ticket_metadata(ticket_id)
        attachment_files = []
        
        for metadata_entry in ticket_metadata:
            if metadata_entry['key'].startswith('attachment_'):
                try:
                    attachment_data = json.loads(metadata_entry['value'])
                    attachment_files.append(attachment_data)
                except:
                    continue
        
        app.logger.info(f"Found {len(attachment_files)} metadata attachments")
        
        if attachment_index < len(attachment_files):
            attachment = attachment_files[attachment_index]
            filename = attachment.get('original_name', attachment.get('filename', 'unknown_file'))
            
            # FIXED: PRIORITY 1 - Check for base64 data first (most reliable for manual tickets)
            file_data = attachment.get('data', '')
            if file_data:
                app.logger.info(f" FOUND BASE64 DATA: {filename} (base64: {len(file_data)} chars)")
                try:
                    decoded_data = base64.b64decode(file_data)
                    return send_file(
                        io.BytesIO(decoded_data),
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                except Exception as e:
                    app.logger.error(f"Failed to decode base64 data from metadata: {e}")
                    # Fall back to file path method
                    app.logger.warning(f"Falling back to file path method for {filename}")
            
            # FIXED: PRIORITY 2 - Try saved file path (EMAIL TICKETS with disk saves)
            saved_file_path = attachment.get('file_path')
            if saved_file_path and os.path.exists(saved_file_path):
                app.logger.info(f" FOUND SAVED FILE: {saved_file_path}")
                return send_file(
                    saved_file_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            
            # FIXED: PRIORITY 3 - Try uploads directory (MANUAL TICKETS)
            file_path = os.path.join('uploads', filename)
            if os.path.exists(file_path):
                app.logger.info(f" FOUND UPLOAD FILE: {filename}")
                return send_file(
                    file_path,
                    as_attachment=True,
                    download_name=filename,
                    mimetype=get_mime_type(filename)
                )
            
            # FIXED: PRIORITY 4 - Try base64 data from metadata (FALLBACK - moved to top priority)
            elif 'data' in attachment and attachment['data']:
                app.logger.info(f" FALLBACK TO BASE64: {filename}")
                try:
                    decoded_data = base64.b64decode(attachment.get('data', ''))
                    return send_file(
                        io.BytesIO(decoded_data),
                        as_attachment=True,
                        download_name=filename,
                        mimetype=get_mime_type(filename)
                    )
                except Exception as e:
                    app.logger.error(f"Failed to decode metadata base64: {e}")
                    return jsonify({'error': 'Invalid attachment data'}), 500
            else:
                app.logger.warning(f" NO DATA SOURCE for attachment {filename}")
                app.logger.warning(f"   - file_path: {saved_file_path}")
                app.logger.warning(f"   - upload_path: {file_path}")
                app.logger.warning(f"   - has_base64: {bool(attachment.get('data'))}")
        
        # If we get here, attachment not found
        app.logger.warning(f" Attachment {attachment_index} not found for ticket {ticket_id}")
        app.logger.warning(f"   - Direct attachments: {len(ticket.get('attachments', []))}")
        app.logger.warning(f"   - Reply attachments: {len(all_reply_attachments)}")
        app.logger.warning(f"   - Metadata attachments: {len(attachment_files)}")
        
        # FIXED: Enhanced error response with debugging information
        return jsonify({
            'error': 'Attachment not found',
            'ticket_id': ticket_id,
            'attachment_index': attachment_index,
            'debug_info': {
                'ticket_has_attachments': ticket.get('has_attachments', False),
                'ticket_attachments_count': len(ticket.get('attachments', [])),
                'simple_attachments_count': len(ticket.get('simple_attachments', [])),
                'metadata_attachments_count': len(attachment_files),
                'reply_attachments_count': len(all_reply_attachments),
                'suggestion': 'Check if manual ticket attachments have base64 data stored in database'
            }
        }), 404
        
    except Exception as e:
        app.logger.error(f"Error downloading attachment: {str(e)}")
        import traceback
        app.logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': 'Failed to download attachment'}), 500

def get_mime_type(filename):
    """Get MIME type based on file extension"""
    ext = filename.lower().split('.')[-1] if '.' in filename else ''
    
    mime_types = {
        'pdf': 'application/pdf',
        'jpg': 'image/jpeg',
        'jpeg': 'image/jpeg', 
        'png': 'image/png',
        'gif': 'image/gif',
        'txt': 'text/plain',
        'doc': 'application/msword',
        'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        'xls': 'application/vnd.ms-excel',
        'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
        'zip': 'application/zip',
        'rar': 'application/x-rar-compressed'
    }
    
    return mime_types.get(ext, 'application/octet-stream')

@app.route('/api/tickets/<ticket_id>/attachments')
def get_ticket_attachments(ticket_id):
    """
    Get all attachments for a ticket with enhanced metadata
    """
    try:
        db = get_db()
        
        # Get ticket with attachments
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        # Return attachment information
        attachments = ticket.get('attachments', [])
        
        # Enhanced attachment metadata
        enhanced_attachments = []
        for i, att in enumerate(attachments):
            enhanced_att = {
                'index': i,
                'filename': att.get('filename', 'unknown_file'),
                'size': att.get('size', 0),
                'size_formatted': att.get('size_formatted', format_file_size(att.get('size', 0))),
                'is_warranty': att.get('is_warranty', False),
                'file_type': att.get('file_type', 'unknown'),
                'file_category': att.get('file_category', 'unknown'),
                'file_extension': att.get('file_extension', ''),
                'from': att.get('from', ''),
                'processed_at': att.get('processed_at', ''),
                'download_url': f'/api/tickets/{ticket_id}/attachments/{i}/download'
            }
            enhanced_attachments.append(enhanced_att)
        
        return jsonify({
            'ticket_id': ticket_id,
            'has_attachments': len(enhanced_attachments) > 0,
            'total_attachments': len(enhanced_attachments),
            'warranty_forms_count': sum(1 for att in enhanced_attachments if att.get('is_warranty', False)),
            'total_size': sum(att.get('size', 0) for att in enhanced_attachments),
            'total_size_formatted': format_file_size(sum(att.get('size', 0) for att in enhanced_attachments)),
            'attachments': enhanced_attachments
        })
        
    except Exception as e:
        app.logger.error(f"Error getting ticket attachments: {str(e)}")
        return jsonify({'error': 'Failed to get attachments'}), 500

@app.route('/api/tickets/<ticket_id>/attachments/warranty-analysis')
def analyze_warranty_attachments(ticket_id):
    """
    Analyze attachments for warranty-related content
    """
    try:
        db = get_db()
        
        # Get ticket with attachments
        ticket = db.get_ticket_by_id(ticket_id)
        if not ticket:
            return jsonify({'error': 'Ticket not found'}), 404
        
        attachments = ticket.get('attachments', [])
        
        # Analyze warranty attachments
        warranty_analysis = {
            'total_attachments': len(attachments),
            'warranty_forms_detected': 0,
            'warranty_confidence': 0,
            'detected_keywords': [],
            'warranty_attachments': [],
            'non_warranty_attachments': []
        }
        
        all_keywords = set()
        warranty_attachments = []
        
        for i, att in enumerate(attachments):
            filename = att.get('filename', '')
            is_warranty = att.get('is_warranty', False)
            
            if is_warranty:
                warranty_analysis['warranty_forms_detected'] += 1
                
                # Extract keywords that were detected
                warranty_keywords = [
                    'warranty', 'guarantee', 'warrantee', 'warrenty', 'guarante', 'warrantie',
                    'dpf', 'diesel', 'emission', 'claim', 'form', 'customer',
                    'repair', 'service', 'defect', 'malfunction', 'issue', 'fault'
                ]
                
                filename_lower = filename.lower()
                detected_in_file = [kw for kw in warranty_keywords if kw in filename_lower]
                all_keywords.update(detected_in_file)
                
                warranty_info = {
                    'index': i,
                    'filename': filename,
                    'size_formatted': att.get('size_formatted', ''),
                    'detected_keywords': detected_in_file,
                    'download_url': f'/api/tickets/{ticket_id}/attachments/{i}/download'
                }
                warranty_analysis['warranty_attachments'].append(warranty_info)
                warranty_attachments.append(att)
            else:
                non_warranty_info = {
                    'index': i,
                    'filename': filename,
                    'size_formatted': att.get('size_formatted', ''),
                    'file_type': att.get('file_type', 'unknown'),
                    'download_url': f'/api/tickets/{ticket_id}/attachments/{i}/download'
                }
                warranty_analysis['non_warranty_attachments'].append(non_warranty_info)
        
        # Calculate confidence
        if len(attachments) > 0:
            warranty_analysis['warranty_confidence'] = min(
                (warranty_analysis['warranty_forms_detected'] / len(attachments)) * 100, 
                95
            )
        
        warranty_analysis['detected_keywords'] = sorted(list(all_keywords))
        warranty_analysis['recommendation'] = (
            'High Priority - Warranty forms detected' if warranty_analysis['warranty_forms_detected'] > 0 
            else 'Standard Priority - No warranty forms detected'
        )
        
        return jsonify(warranty_analysis)
        
    except Exception as e:
        app.logger.error(f"Error analyzing warranty attachments: {str(e)}")
        return jsonify({'error': 'Failed to analyze attachments'}), 500

@app.route('/api/tickets/<ticket_id>', methods=['GET'])
def get_single_ticket(ticket_id):
    """Get a single ticket by ID for admin panel and frontend"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            return jsonify({'status': 'error', 'message': 'Ticket not found'}), 404
        
        # Convert ObjectId to string for JSON serialization
        ticket['_id'] = str(ticket['_id'])
        
        # Get ticket metadata for additional info
        ticket_metadata = db.get_ticket_metadata(ticket_id)
        if ticket_metadata:
            ticket['metadata'] = ticket_metadata
        
        return jsonify({
            'status': 'success',
            'ticket': ticket
        })
        
    except Exception as e:
        app.logger.error(f"Error fetching ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Failed to fetch ticket: {str(e)}'}), 500

@app.route('/api/tickets', methods=['GET'])
def get_all_tickets():
    """
    [TARGET] GET ALL TICKETS ENDPOINT - For frontend display
    Returns all tickets with attachment data for dashboard
    """
    try:
        db = get_db()
        
        # Get all tickets with attachment info
        tickets = list(db.tickets.find({}).sort([('_id', -1)]).limit(50))
        
        # Convert to frontend-friendly format
        formatted_tickets = []
        for ticket in tickets:
            # Convert ObjectId to string
            ticket['_id'] = str(ticket['_id'])
            
            # [FIX] ENHANCED FIX: Handle both email attachments (stored in ticket) and manual attachments (in metadata)
            attachments = []
            
            # METHOD 1: Check for direct attachments in ticket (n8n email tickets)
            if ticket.get('has_attachments', False) and 'attachments' in ticket:
                direct_attachments = ticket['attachments']
                app.logger.info(f"Found {len(direct_attachments)} direct attachments in ticket {ticket['ticket_id']}")
                
                for i, att in enumerate(direct_attachments):
                    attachment = {
                        'index': i,
                        'filename': att.get('filename', 'unknown_file'),
                        'size': att.get('size', 0),
                        'is_warranty': att.get('is_warranty', False),
                        'file_type': att.get('file_type', 'unknown'),
                        'download_url': f"/api/tickets/{ticket['ticket_id']}/attachments/{i}/download",
                        'source': 'email'  # Mark as email attachment
                    }
                    attachments.append(attachment)
            
            # METHOD 2: Also check metadata collection (manual tickets)
            ticket_metadata = db.get_ticket_metadata(ticket['ticket_id'])
            metadata_attachments = []
            
            for metadata_entry in ticket_metadata:
                if metadata_entry['key'].startswith('attachment_'):
                    try:
                        attachment_data = json.loads(metadata_entry['value'])
                        # Convert metadata back to attachment format
                        attachment = {
                            'index': len(attachments) + len(metadata_attachments),
                            'filename': attachment_data.get('original_name', attachment_data.get('filename', 'unknown')),
                            'size': attachment_data.get('size', 0),
                            'is_warranty': attachment_data.get('is_warranty', False),
                            'file_path': attachment_data.get('file_path', ''),
                            'key': attachment_data.get('key', ''),
                            'download_url': f"/api/tickets/{ticket['ticket_id']}/attachments/{len(attachments) + len(metadata_attachments)}/download",
                            'source': 'manual'  # Mark as manual attachment
                        }
                        metadata_attachments.append(attachment)
                    except (json.JSONDecodeError, KeyError) as e:
                        app.logger.warning(f"Failed to parse attachment metadata for {ticket['ticket_id']}: {e}")
            
            # Combine both types of attachments
            attachments.extend(metadata_attachments)
            
            # Set proper attachment fields
            ticket['attachments'] = attachments
            ticket['has_attachments'] = len(attachments) > 0
            ticket['has_warranty'] = any(att.get('is_warranty', False) for att in attachments)
            ticket['total_attachments'] = len(attachments)
            ticket['email_attachments'] = len([a for a in attachments if a.get('source') == 'email'])
            ticket['manual_attachments'] = len([a for a in attachments if a.get('source') == 'manual'])
            
            # Format created date
            if 'created_at' in ticket and ticket['created_at']:
                try:
                    if isinstance(ticket['created_at'], datetime):
                        ticket['formatted_date'] = ticket['created_at'].strftime("%b %d, %I:%M %p")
                    else:
                        created_at = datetime.strptime(str(ticket['created_at']), "%Y-%m-%d %H:%M:%S")
                        ticket['formatted_date'] = created_at.strftime("%b %d, %I:%M %p")
                except:
                    ticket['formatted_date'] = 'Unknown'
            else:
                ticket['formatted_date'] = 'Unknown'
            
            formatted_tickets.append(ticket)
        
        return jsonify({
            'success': True,
            'tickets': formatted_tickets,
            'total': len(formatted_tickets),
            'attachments_summary': {
                'total_with_attachments': len([t for t in formatted_tickets if t.get('has_attachments')]),
                'total_with_warranty': len([t for t in formatted_tickets if t.get('has_warranty')])
            }
        })
        
    except Exception as e:
        app.logger.error(f"[ERROR] Error getting tickets: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'tickets': []
        }), 500



# AI Response Display API Endpoint
@app.route('/api/ai/display-response', methods=['POST'])
def display_ai_response():
    """
    Display AI response in ticket reply conversation textarea
    Accepts POST request with ticket_id and ai_response from n8n
    """
    try:
        data = request.get_json()
        
        # Extract only required fields
        ticket_id = data.get('ticket_id', '')
        ai_response = data.get('ai_response', '')
        
        # Validate required fields
        if not ticket_id:
            return jsonify({
                'success': False,
                'error': 'ticket_id is required'
            }), 400
            
        if not ai_response:
            return jsonify({
                'success': False,
                'error': 'ai_response is required'
            }), 400
        
        # Store AI response in database for retrieval
        try:
            db = get_db()
            # Store in ticket metadata for easy retrieval
            db.set_ticket_metadata(ticket_id, 'ai_response', ai_response)
            db.set_ticket_metadata(ticket_id, 'ai_response_timestamp', datetime.now().isoformat())
        except Exception as e:
            app.logger.warning(f"Could not store AI response in metadata: {e}")
        
        # Create URL for displaying the AI response
        import urllib.parse
        encoded_response = urllib.parse.quote(ai_response)
        # Use the actual domain from the request
        base_url = request.host_url.rstrip('/')
        display_url = f"{base_url}/ai-response/{ticket_id}?response={encoded_response}"
        
        # Return the AI response ready for textarea display
        return jsonify({
            'success': True,
            'ticket_id': ticket_id,
            'ai_response': ai_response,
            'display_url': display_url,
            'message': 'AI response ready for textarea display. Use display_url to show in textarea.',
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error displaying AI response: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e),
            'ai_response': 'I apologize, but I encountered an error while processing your request. Please try again or contact support directly.'
        }), 500

# AI Response Display Frontend Endpoint
@app.route('/ai-response/<ticket_id>')
def show_ai_response(ticket_id):
    """
    Frontend endpoint to display AI response in textarea
    This will redirect to the ticket detail page with AI response pre-filled
    """
    try:
        # Get the AI response from the request parameters
        ai_response = request.args.get('response', '')
        
        if not ai_response:
            return "No AI response provided", 400
        
        # Create a simple HTML page that will populate the textarea
        html_content = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>AI Response - Ticket {ticket_id}</title>
            <script>
                console.log('ðŸ¤– AI Response Debug - Page loaded');
                console.log('ðŸŽ« Ticket ID:', '{ticket_id}');
                console.log('ðŸ’¬ AI Response Length:', {len(ai_response)});
                
                function populateTextarea() {{
                    console.log('ðŸ”§ Attempting to populate textarea...');
                    
                    // Method 1: Try parent window
                    if (window.opener) {{
                        console.log('ðŸ‘† Found parent window, looking for textarea...');
                        const textarea = window.opener.document.getElementById('response');
                        if (textarea) {{
                            console.log('âœ… Found textarea in parent window!');
                            textarea.value = `{ai_response.replace('`', '\\`')}`;
                            console.log('ðŸ“ Textarea populated with:', textarea.value.substring(0, 100) + '...');
                            
                            // Trigger auto-expand
                            if (window.opener.autoExpandTextarea) {{
                                window.opener.autoExpandTextarea(textarea);
                            }}
                            
                            // Trigger input event
                            textarea.dispatchEvent(new Event('input', {{ bubbles: true }}));
                            
                            console.log('ðŸŽ‰ Success! Closing window...');
                            window.close();
                            return;
                        }}
                    }}
                    
                    // Method 2: Try current window
                    console.log('ðŸ” Trying current window...');
                    const textarea = document.getElementById('response');
                    if (textarea) {{
                        console.log('âœ… Found textarea in current window!');
                        textarea.value = `{ai_response.replace('`', '\\`')}`;
                        console.log('ðŸ“ Textarea populated with:', textarea.value.substring(0, 100) + '...');
                        
                        if (window.autoExpandTextarea) {{
                            window.autoExpandTextarea(textarea);
                        }}
                        
                        textarea.dispatchEvent(new Event('input', {{ bubbles: true }}));
                        console.log('ðŸŽ‰ Success!');
                        return;
                    }}
                    
                    // Method 3: Redirect to ticket page
                    console.log('ðŸ”„ No textarea found, redirecting to ticket page...');
                    window.location.href = '/ticket/{ticket_id}?ai_response={ai_response.replace(' ', '%20')}';
                }}
                
                // Run immediately
                populateTextarea();
            </script>
        </head>
        <body style="font-family: Arial, sans-serif; padding: 20px; text-align: center;">
            <h2>ðŸ¤– AI Response Ready</h2>
            <p>Ticket: {ticket_id}</p>
            <p>Loading AI response into textarea...</p>
            <button onclick="populateTextarea()" style="padding: 10px 20px; margin: 10px;">Retry</button>
            <button onclick="window.close()" style="padding: 10px 20px; margin: 10px;">Close</button>
        </body>
        </html>
        """
        
        return html_content
        
    except Exception as e:
        app.logger.error(f"Error showing AI response: {str(e)}")
        return f"Error: {str(e)}", 500

# AI Response API Endpoint for JavaScript
@app.route('/api/ai/get-response/<ticket_id>')
def get_ai_response(ticket_id):
    """
    Get AI response for a ticket (for JavaScript to use)
    """
    try:
        db = get_db()
        metadata = db.get_ticket_metadata(ticket_id)
        
        ai_response = None
        for meta in metadata:
            if meta.get('key') == 'ai_response':
                ai_response = meta.get('value')
                break
        
        if ai_response:
            return jsonify({
                'success': True,
                'ai_response': ai_response,
                'ticket_id': ticket_id
            })
        else:
            return jsonify({
                'success': False,
                'message': 'No AI response found for this ticket'
            })
            
    except Exception as e:
        app.logger.error(f"Error getting AI response: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def generate_support_response(ticket_id, subject, body, customer_name, customer_email, status, priority):
    """
    Generate AI-powered support response based on ticket content
    """
    try:
        # Basic AI response generation logic
        response_parts = []
        
        # Greeting
        if customer_name:
            response_parts.append(f"Hello {customer_name},")
        else:
            response_parts.append("Hello,")
        
        response_parts.append("")
        response_parts.append("Thank you for contacting AutoAssistGroup support.")
        response_parts.append("")
        
        # Analyze ticket content for appropriate response
        if 'warranty' in body.lower() or 'warranty' in subject.lower():
            response_parts.append("I can see you're inquiring about a warranty claim. Let me help you with that.")
            response_parts.append("")
            response_parts.append("To process your warranty claim efficiently, I'll need the following information:")
            response_parts.append("â€¢ Original purchase receipt or invoice")
            response_parts.append("â€¢ Warranty registration details")
            response_parts.append("â€¢ Clear photos of the issue/defect")
            response_parts.append("â€¢ Description of when the problem first occurred")
            response_parts.append("")
            response_parts.append("Once I receive this information, I'll review your claim and provide you with the next steps.")
            
        elif 'repair' in body.lower() or 'fix' in body.lower() or 'broken' in body.lower():
            response_parts.append("I understand you're experiencing issues that require repair assistance.")
            response_parts.append("")
            response_parts.append("To better assist you, could you please provide:")
            response_parts.append("â€¢ A detailed description of the problem")
            response_parts.append("â€¢ When the issue first started")
            response_parts.append("â€¢ Any error messages or symptoms you've noticed")
            response_parts.append("â€¢ Photos or videos if applicable")
            response_parts.append("")
            response_parts.append("I'll review this information and coordinate with our technical team to resolve your issue.")
            
        elif 'appointment' in body.lower() or 'schedule' in body.lower() or 'visit' in body.lower():
            response_parts.append("I can help you schedule an appointment with our technical team.")
            response_parts.append("")
            response_parts.append("Please let me know:")
            response_parts.append("â€¢ Your preferred date and time")
            response_parts.append("â€¢ The nature of the service required")
            response_parts.append("â€¢ Your location/address")
            response_parts.append("â€¢ Any specific requirements or notes")
            response_parts.append("")
            response_parts.append("I'll check our availability and confirm your appointment.")
            
        elif 'status' in body.lower() or 'update' in body.lower():
            response_parts.append("I'll check the current status of your ticket and provide you with an update.")
            response_parts.append("")
            response_parts.append(f"Current Status: {status}")
            response_parts.append(f"Priority: {priority}")
            response_parts.append("")
            response_parts.append("I'm reviewing your case and will provide you with detailed information shortly.")
            
        else:
            # Generic helpful response
            response_parts.append("I've received your message and I'm here to help you.")
            response_parts.append("")
            response_parts.append("To provide you with the best assistance, I may need some additional information:")
            response_parts.append("â€¢ More details about your specific concern")
            response_parts.append("â€¢ Any relevant documentation or photos")
            response_parts.append("â€¢ Your preferred method of contact")
            response_parts.append("")
            response_parts.append("I'll work to resolve your inquiry as quickly as possible.")
        
        # Add closing
        response_parts.append("")
        response_parts.append("If you have any questions or need immediate assistance, please don't hesitate to contact us.")
        response_parts.append("")
        response_parts.append("Best regards,")
        response_parts.append("AutoAssistGroup Support Team")
        
        # Join all parts with newlines
        ai_response = "\n".join(response_parts)
        
        return ai_response
        
    except Exception as e:
        app.logger.error(f"Error in AI response generation: {str(e)}")
        return "Thank you for contacting AutoAssistGroup support. I'm currently reviewing your request and will provide you with a detailed response shortly. If you need immediate assistance, please contact our support team directly."

# Ticket Deletion API Endpoints  
@app.route('/api/tickets/<ticket_id>', methods=['DELETE'])
def delete_ticket(ticket_id):
    """Delete a ticket completely (hard delete) - Admin only"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can delete tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        result = db.delete_ticket(ticket_id)
        
        if result['success']:
            return jsonify({
                'status': 'success',
                'message': result['message']
            })
        else:
            return jsonify({
                'status': 'error', 
                'message': result['message']
            }), 404
            
    except Exception as e:
        logging.error(f"Error deleting ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/ticket/<ticket_id>/delete', methods=['POST', 'GET'])
def delete_ticket_html(ticket_id):
    """HTML-friendly delete that redirects after deletion (Admin only)."""
    if 'member_id' not in session:
        return redirect(url_for('portal'))

    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

    try:
        db = get_db()
        result = db.delete_ticket(ticket_id)
        if result.get('success'):
            return redirect(url_for('dashboard'))
        else:
            return redirect(url_for('ticket_detail', ticket_id=ticket_id))
    except Exception as e:
        logging.error(f"HTML delete error for ticket {ticket_id}: {e}")
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

@app.route('/api/tickets/<ticket_id>/soft-delete', methods=['POST'])
def soft_delete_ticket(ticket_id):
    """Soft delete a ticket (mark as deleted) - Admin only"""  
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can soft delete tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        deleted_by = session.get('member_id')
        result = db.soft_delete_ticket(ticket_id, deleted_by)
        
        if result['success']:
            return jsonify({
                'status': 'success',
                'message': result['message']
            })
        else:
            return jsonify({
                'status': 'error',
                'message': result['message']
            }), 404
            
    except Exception as e:
        logging.error(f"Error soft deleting ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/ticket/<ticket_id>/archive', methods=['POST', 'GET'])
def archive_ticket_html(ticket_id):
    """HTML-friendly soft delete that redirects (Admin only)."""
    if 'member_id' not in session:
        return redirect(url_for('portal'))

    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

    try:
        db = get_db()
        deleted_by = session.get('member_id')
        result = db.soft_delete_ticket(ticket_id, deleted_by)
        if result.get('success'):
            return redirect(url_for('dashboard'))
        else:
            return redirect(url_for('ticket_detail', ticket_id=ticket_id))
    except Exception as e:
        logging.error(f"HTML soft delete error for ticket {ticket_id}: {e}")
        return redirect(url_for('ticket_detail', ticket_id=ticket_id))

@app.route('/api/tickets/<ticket_id>/restore', methods=['POST'])
def restore_ticket(ticket_id):
    """Restore a soft-deleted ticket - Admin only"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can restore tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        result = db.restore_ticket(ticket_id)
        
        if result['success']:
            return jsonify({
                'status': 'success',
                'message': result['message']
            })
        else:
            return jsonify({
                'status': 'error',
                'message': result['message']
            }), 404
            
    except Exception as e:
        logging.error(f"Error restoring ticket {ticket_id}: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/tickets/deleted', methods=['GET'])
def get_deleted_tickets():
    """Get all soft-deleted tickets - Admin only"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Only administrators can view deleted tickets
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        deleted_tickets = db.get_deleted_tickets()
        
        # Convert ObjectId to string for JSON serialization
        for ticket in deleted_tickets:
            ticket['_id'] = str(ticket['_id'])
        
        return jsonify({
            'status': 'success',
            'tickets': deleted_tickets
        })
        
    except Exception as e:
        logging.error(f"Error getting deleted tickets: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# System Settings API Endpoints
@app.route('/api/admin/settings', methods=['GET', 'POST'])
def manage_system_settings():
    """Manage system settings"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        
        if request.method == 'GET':
            # Get system settings
            settings = db.db.system_settings.find_one({'type': 'general'})
            if not settings:
                # Create default settings if none exist
                default_settings = {
                    'type': 'general',
                    'auto_assign_enabled': False,
                    'email_notifications': True,
                    'webhook_notifications': True,
                    'max_file_size': '10MB',
                    'allowed_file_types': ['pdf', 'doc', 'docx', 'jpg', 'png', 'xlsx'],
                    'created_at': datetime.now()
                }
                db.db.system_settings.insert_one(default_settings)
                settings = default_settings
            
            # Convert ObjectId to string
            if '_id' in settings:
                settings['_id'] = str(settings['_id'])
            
            return jsonify({
                'status': 'success',
                'settings': settings
            })
        
        elif request.method == 'POST':
            # Update system settings
            data = request.get_json()
            
            update_data = {
                'updated_at': datetime.now(),
                'updated_by': session.get('member_id')
            }
            
            # Update allowed settings
            allowed_keys = ['auto_assign_enabled', 'email_notifications', 'webhook_notifications', 
                          'max_file_size', 'allowed_file_types']
            for key in allowed_keys:
                if key in data:
                    update_data[key] = data[key]
            
            result = db.db.system_settings.update_one(
                {'type': 'general'},
                {'$set': update_data},
                upsert=True
            )
            
            return jsonify({
                'status': 'success',
                'message': 'System settings updated successfully'
            })
            
    except Exception as e:
        logging.error(f"Error managing system settings: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/cleanup', methods=['POST'])
def cleanup_old_data():
    """Cleanup old data from the system"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        db = get_db()
        data = request.get_json()
        days = data.get('days', 365)
        
        # Calculate cutoff date
        cutoff_date = datetime.now() - timedelta(days=days)
        
        deleted_count = 0
        
        # Clean up old ticket metadata
        result = db.ticket_metadata.delete_many({
            'created_at': {'$lt': cutoff_date}
        })
        deleted_count += result.deleted_count
        
        # Clean up old replies for deleted tickets
        result = db.replies.delete_many({
            'created_at': {'$lt': cutoff_date},
            'ticket_id': {'$regex': '^deleted_'}
        })
        deleted_count += result.deleted_count
        
        # Clean up old session data (if any)
        # This is just a placeholder - implement as needed
        
        logging.info(f"Cleanup completed - removed {deleted_count} old records")
        
        return jsonify({
            'status': 'success',
            'message': f'Cleanup completed successfully',
            'deleted_count': deleted_count
        })
        
    except Exception as e:
        logging.error(f"Error during cleanup: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/admin/export', methods=['POST'])
def export_system_data():
    """Export system data to CSV files"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    # Check admin access
    member_role = session.get('member_role', '')
    if member_role != 'Administrator':
        return jsonify({'status': 'error', 'message': 'Administrator access required'}), 403
    
    try:
        import csv
        import io
        import zipfile
        
        db = get_db()
        
        # Create a zip file in memory
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            
            # Export tickets
            tickets = list(db.get_all_tickets())
            if tickets:
                csv_buffer = io.StringIO()
                if tickets:  # Check if we have tickets
                    fieldnames = tickets[0].keys()
                    writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
                    writer.writeheader()
                    for ticket in tickets:
                        # Convert ObjectId to string for CSV
                        clean_ticket = {}
                        for key, value in ticket.items():
                            if hasattr(value, '__str__'):
                                clean_ticket[key] = str(value)
                            else:
                                clean_ticket[key] = value
                        writer.writerow(clean_ticket)
                zip_file.writestr('tickets.csv', csv_buffer.getvalue())
            
            # Export members
            members = list(db.get_all_members())
            if members:
                csv_buffer = io.StringIO()
                if members:
                    fieldnames = ['name', 'user_id', 'role', 'gender', 'created_at']
                    writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
                    writer.writeheader()
                    for member in members:
                        clean_member = {key: str(member.get(key, '')) for key in fieldnames}
                        writer.writerow(clean_member)
                zip_file.writestr('members.csv', csv_buffer.getvalue())
            
            # Export technicians
            technicians = list(db.get_all_technicians())
            if technicians:
                csv_buffer = io.StringIO()
                if technicians:
                    fieldnames = ['name', 'role', 'is_active', 'created_at']
                    writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
                    writer.writeheader()
                    for tech in technicians:
                        clean_tech = {key: str(tech.get(key, '')) for key in fieldnames}
                        writer.writerow(clean_tech)
                zip_file.writestr('technicians.csv', csv_buffer.getvalue())
        
        zip_buffer.seek(0)
        
        # Return the zip file
        return send_file(
            io.BytesIO(zip_buffer.getvalue()),
            mimetype='application/zip',
            as_attachment=True,
            download_name=f'system-export-{datetime.now().strftime("%Y-%m-%d")}.zip'
        )
        
    except Exception as e:
        logging.error(f"Error during data export: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/debug/assignment/<ticket_id>')
def debug_assignment_status(ticket_id):
    """DEBUG: Check assignment status for JavaScript verification"""
    try:
        db = get_db()
        
        # Get assignment data directly
        assignment = db.get_assignment_by_ticket(ticket_id)
        
        # Get dashboard ticket data
        tickets_with_assignments = db.get_tickets_with_assignments()
        target_ticket = None
        for t in tickets_with_assignments:
            if t.get('ticket_id') == ticket_id:
                target_ticket = t
                break
        
        debug_data = {
            'ticket_id': ticket_id,
            'assignment_exists': assignment is not None,
            'assignment_data': str(assignment) if assignment else None,
            'dashboard_shows_assignment': target_ticket is not None and len(target_ticket.get('assignment', [])) > 0,
            'assigned_to': target_ticket.get('assigned_to') if target_ticket else None,
            'assigned_member_data': target_ticket.get('assigned_member', []) if target_ticket else [],
            'assignment_count': len(target_ticket.get('assignment', [])) if target_ticket else 0,
            'member_count': len(target_ticket.get('assigned_member', [])) if target_ticket else 0,
            'timestamp': datetime.now().isoformat(),
            'badge_will_show': target_ticket is not None and target_ticket.get('assigned_to') is not None
        }
        
        app.logger.info(f"[DEBUG] Assignment check for {ticket_id}: exists={assignment is not None}, dashboard={debug_data['dashboard_shows_assignment']}")
        return jsonify(debug_data)
        
    except Exception as e:
        app.logger.error(f"[DEBUG] Error checking assignment: {e}")
        return jsonify({
            'error': str(e),
            'assignment_exists': False,
            'ticket_id': ticket_id
        }), 500

# Add debug endpoint for technicians
@app.route('/debug/technicians')
def debug_technicians():
    """Debug endpoint to check technicians in database"""
    try:
        import traceback
        db = get_db()
        
        # Get all technicians (including inactive)
        all_technicians = list(db.technicians.find({}))
        active_technicians = list(db.technicians.find({"is_active": True}))
        
        # Get technicians using the function
        function_technicians = db.get_all_technicians()
        
        debug_info = {
            'total_technicians_in_collection': len(all_technicians),
            'active_technicians_in_collection': len(active_technicians),
            'function_technicians_count': len(function_technicians),
            'all_technicians': [],
            'active_technicians': [],
            'function_technicians': []
        }
        
        # Format all technicians
        for tech in all_technicians:
            debug_info['all_technicians'].append({
                'id': str(tech['_id']),
                'name': tech.get('name', 'No Name'),
                'role': tech.get('role', 'No Role'),
                'email': tech.get('email', 'No Email'),
                'is_active': tech.get('is_active', False),
                'created_at': str(tech.get('created_at', 'No Date'))
            })
        
        # Format active technicians
        for tech in active_technicians:
            debug_info['active_technicians'].append({
                'id': str(tech['_id']),
                'name': tech.get('name', 'No Name'),
                'role': tech.get('role', 'No Role'),
                'email': tech.get('email', 'No Email'),
                'is_active': tech.get('is_active', False),
                'created_at': str(tech.get('created_at', 'No Date'))
            })
        
        # Format function technicians
        for tech in function_technicians:
            debug_info['function_technicians'].append({
                'id': str(tech['_id']),
                'name': tech.get('name', 'No Name'),
                'role': tech.get('role', 'No Role'),
                'email': tech.get('email', 'No Email'),
                'is_active': tech.get('is_active', False),
                'created_at': str(tech.get('created_at', 'No Date'))
            })
        
        return jsonify(debug_info)
        
    except Exception as e:
        return jsonify({'error': str(e), 'traceback': traceback.format_exc()}), 500

@app.route('/debug/warranty-tickets')
def debug_warranty_tickets():
    """
    Debug endpoint to check warranty tickets
    """
    try:
        db = get_db()
        tickets = db.get_tickets_with_assignments()
        
        warranty_tickets = []
        all_classifications = {}
        
        for ticket in tickets:
            classification = ticket.get('classification', 'Unknown')
            has_warranty = ticket.get('has_warranty', False)
            
            # Count all classifications
            all_classifications[classification] = all_classifications.get(classification, 0) + 1
            
            # Check if this is a warranty ticket
            is_warranty_related = (
                has_warranty or 
                'warranty' in classification.lower() or
                'warranty' in ticket.get('subject', '').lower()
            )
            
            if is_warranty_related:
                warranty_tickets.append({
                    'ticket_id': ticket.get('ticket_id'),
                    'classification': classification,
                    'has_warranty': has_warranty,
                    'priority': ticket.get('priority'),
                    'subject': ticket.get('subject', '')[:100]
                })
        
        return """
        <h1> Warranty Tickets Debug</h1>
        <h2>ðŸ“Š Summary</h2>
        <p><strong>Total tickets:</strong> {len(tickets)}</p>
        <p><strong>Warranty tickets found:</strong> {len(warranty_tickets)}</p>
        
        <h2> Warranty Tickets</h2>
        {'<p> No warranty tickets found!</p>' if not warranty_tickets else ''}
        {''.join([f'''
        <div style="border: 1px solid #ccc; margin: 10px 0; padding: 10px;">
            <strong>ID:</strong> {t['ticket_id']}<br>
            <strong>ID:</strong> {t['ticket_id']}<br>
            <strong>Classification:</strong> "{t['classification']}"<br>
            <strong>Has Warranty:</strong> {t['has_warranty']}<br>
            <strong>Priority:</strong> {t['priority']}<br>
            <strong>Subject:</strong> {t['subject']}<br>
        </div>
        ''' for t in warranty_tickets])}
        
        <h2>ðŸ“‹ All Classifications</h2>
        {''.join([f'<p><strong>{cls}:</strong> {count} tickets</p>' for cls, count in sorted(all_classifications.items())])}
        """
        
    except Exception as e:
        return f" Error: {e}"

@app.route('/debug/ticket-ids')
def debug_ticket_ids_page():
    """Debug page for ticket ID mismatches"""
    if 'member_id' not in session:
        return redirect(url_for('portal'))
    
    # Check if user is admin or has debug access
    db = get_db()
    current_member = db.get_member_by_id(session['member_id'])
    if not current_member or current_member.get('role') not in ['Administrator', 'IT']:
        flash('Access denied. Only administrators and IT staff can access debug tools.', 'error')
        return redirect(url_for('dashboard'))
    
    return render_template('debug_ticket_ids.html')

@app.route('/api/debug/ticket-id-mismatches')
def debug_ticket_id_mismatches():
    """Debug endpoint to identify and fix ticket ID mismatches"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Find all tickets and check for mismatches
        all_tickets = list(db.tickets.find({}))
        mismatches = []
        fixed_count = 0
        
        for ticket in all_tickets:
            ticket_id = ticket.get('_id')
            ticket_id_field = ticket.get('ticket_id')
            
            if ticket_id and ticket_id_field:
                # Check if there's a mismatch between _id and ticket_id
                if str(ticket_id) != str(ticket_id_field):
                    mismatches.append({
                        'ticket_id': str(ticket_id),
                        'ticket_id_field': ticket_id_field,
                        'subject': ticket.get('subject', 'No Subject'),
                        'status': ticket.get('status', 'Unknown'),
                        'created_at': str(ticket.get('created_at', 'Unknown'))
                    })
                    
                    # Fix the mismatch by updating the ticket_id field
                    try:
                        db.tickets.update_one(
                            {'_id': ticket_id},
                            {'$set': {'ticket_id': str(ticket_id)}}
                        )
                        fixed_count += 1
                        app.logger.info(f"ðŸ”§ FIXED TICKET ID MISMATCH - Ticket {ticket_id}: updated ticket_id field to {ticket_id}")
                    except Exception as e:
                        app.logger.error(f"âŒ FAILED TO FIX TICKET ID MISMATCH - Ticket {ticket_id}: {e}")
        
        return jsonify({
            'status': 'success',
            'total_tickets_checked': len(all_tickets),
            'mismatches_found': len(mismatches),
            'mismatches_fixed': fixed_count,
            'mismatch_details': mismatches,
            'message': f'Found {len(mismatches)} mismatches and fixed {fixed_count}'
        })
        
    except Exception as e:
        app.logger.error(f"Error in debug_ticket_id_mismatches: {e}")
        return jsonify({'status': 'error', 'message': f'Error: {str(e)}'}), 500

def regenerate_attachment_base64_data(ticket_id):
    """Utility function to regenerate base64 data for existing manual ticket attachments"""
    try:
        app.logger.info(f"ðŸ”„ REGENERATING BASE64 DATA FOR TICKET {ticket_id}")
        db = get_db()
        ticket = db.get_ticket_by_id(ticket_id)
        
        if not ticket:
            app.logger.error(f"âŒ TICKET NOT FOUND: {ticket_id}")
            return False
        
        # Check if this is a manual ticket
        is_email_ticket = ticket.get('ticketSource') == 'email' or ticket.get('isEmailOriginated') or ticket.get('message_id')
        if is_email_ticket:
            app.logger.info(f"ðŸ“§ SKIPPING EMAIL TICKET: {ticket_id}")
            return False
        
        app.logger.info(f"ðŸ“Ž PROCESSING MANUAL TICKET ATTACHMENTS: {ticket_id}")
        
        # Get metadata attachments
        metadata = db.get_ticket_metadata(ticket_id)
        updated_count = 0
        
        for meta in metadata:
            if meta.get('key', '').startswith('attachment_'):
                try:
                    attachment_data = json.loads(meta.get('value', '{}'))
                    if attachment_data and isinstance(attachment_data, dict):
                        attachment_name = attachment_data.get('original_name', attachment_data.get('filename', 'Unknown File'))
                        
                        # Skip if already has base64 data
                        if attachment_data.get('data'):
                            app.logger.info(f"ðŸ“Ž SKIPPING {attachment_name} - already has base64 data")
                            continue
                        
                        # Try to read file from path and regenerate base64 data
                        if attachment_data.get('path'):
                            file_path_from_meta = attachment_data.get('path')
                            app.logger.info(f"ðŸ“Ž ðŸ”„ REGENERATING BASE64 FOR: {attachment_name} from {file_path_from_meta}")
                            
                            # Try multiple possible path combinations
                            possible_paths = [
                                os.path.join(os.getcwd(), 'uploads', file_path_from_meta),
                                os.path.join(os.getcwd(), file_path_from_meta),
                                file_path_from_meta,
                                os.path.join(UPLOAD_FOLDER, file_path_from_meta)
                            ]
                            
                            for path_attempt in possible_paths:
                                if os.path.exists(path_attempt):
                                    try:
                                        with open(path_attempt, 'rb') as f:
                                            file_content = f.read()
                                            base64_data = base64.b64encode(file_content).decode('utf-8')
                                        
                                        # Update the attachment data with base64
                                        attachment_data['data'] = base64_data
                                        attachment_data['size'] = len(file_content)
                                        
                                        # Update metadata in database
                                        db.add_ticket_metadata(ticket_id, meta['key'], json.dumps(attachment_data))
                                        
                                        app.logger.info(f"ðŸ“Ž âœ… REGENERATED BASE64 FOR: {attachment_name} ({len(base64_data)} chars)")
                                        updated_count += 1
                                        break
                                        
                                    except Exception as e:
                                        app.logger.warning(f"ðŸ“Ž âš ï¸ FAILED TO READ FILE FROM {path_attempt}: {e}")
                                        continue
                                else:
                                    app.logger.info(f"ðŸ“Ž ðŸ” PATH NOT FOUND: {path_attempt}")
                            else:
                                app.logger.warning(f"ðŸ“Ž âŒ COULD NOT REGENERATE BASE64 FOR: {attachment_name}")
                        else:
                            app.logger.warning(f"ðŸ“Ž âš ï¸ NO FILE PATH FOR: {attachment_name}")
                            
                except (json.JSONDecodeError, TypeError) as e:
                    app.logger.warning(f"ðŸ“Ž âŒ FAILED TO PARSE METADATA FOR KEY {meta.get('key')}: {e}")
                    continue
        
        app.logger.info(f"ðŸ”„ COMPLETED: Regenerated base64 data for {updated_count} attachments in ticket {ticket_id}")
        return updated_count > 0
        
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR REGENERATING BASE64 DATA FOR TICKET {ticket_id}: {e}")
        return False

@app.route('/api/tickets/<ticket_id>/regenerate-attachments', methods=['POST'])
def regenerate_ticket_attachments(ticket_id):
    """API endpoint to regenerate base64 data for existing manual ticket attachments"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        success = regenerate_attachment_base64_data(ticket_id)
        if success:
            return jsonify({
                'status': 'success', 
                'message': f'Successfully regenerated attachment data for ticket {ticket_id}'
            })
        else:
            return jsonify({
                'status': 'warning', 
                'message': f'No attachments needed regeneration for ticket {ticket_id}'
            })
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR IN REGENERATE ATTACHMENTS API: {e}")
        return jsonify({
            'status': 'error', 
            'message': f'Failed to regenerate attachments: {str(e)}'
        }), 500

def fix_malformed_base64_data(base64_string):
    """Utility function to fix common base64 encoding issues"""
    try:
        if not base64_string:
            return None, "Empty base64 string"
        
        # Clean the string
        cleaned = base64_string.strip()
        
        # Remove any non-base64 characters
        import re
        cleaned = re.sub(r'[^A-Za-z0-9+/=]', '', cleaned)
        
        # Check if padding is needed
        padding_needed = len(cleaned) % 4
        if padding_needed:
            cleaned += '=' * (4 - padding_needed)
        
        # Test decode
        try:
            decoded = base64.b64decode(cleaned)
            return cleaned, None  # Return cleaned string and no error
        except Exception as e:
            return None, f"Base64 decode failed: {str(e)}"
            
    except Exception as e:
        return None, f"Error fixing base64: {str(e)}"

@app.route('/api/tickets/<ticket_id>/regenerate-webhook-attachments', methods=['POST'])
def regenerate_webhook_attachments(ticket_id):
    """API endpoint to regenerate missing webhook attachments for existing replies"""
    if 'member_id' not in session:
        return jsonify({'status': 'error', 'message': 'Unauthorized'}), 401
    
    try:
        db = get_db()
        
        # Get all replies for this ticket
        replies = list(db.replies.find({'ticket_id': ticket_id}))
        app.logger.info(f"ðŸ”„ Found {len(replies)} replies for ticket {ticket_id}")
        
        regenerated_count = 0
        
        for reply in replies:
            reply_id = reply['_id']
            attachments = reply.get('attachments', [])
            
            # Check if this reply has attachments but they're missing data
            if attachments:
                app.logger.info(f"ðŸ”„ Checking reply {reply_id} with {len(attachments)} attachments")
                
                for i, attachment in enumerate(attachments):
                    if attachment.get('type') == 'file':
                        # Check if attachment has malformed base64 data or is missing data
                        existing_data = attachment.get('data', '')
                        file_path = attachment.get('path', '')
                        
                        if existing_data:
                            # Try to fix malformed base64 data
                            try:
                                # Test if existing data is valid
                                base64.b64decode(existing_data)
                                app.logger.info(f"âœ… Attachment {i} in reply {reply_id} has valid base64 data")
                            except Exception as base64_error:
                                app.logger.warning(f"âš ï¸ Attachment {i} in reply {reply_id} has malformed base64 data: {base64_error}")
                                
                                # Try to fix the malformed data
                                fixed_data, error = fix_malformed_base64_data(existing_data)
                                if fixed_data:
                                    # Update with fixed base64 data
                                    db.replies.update_one(
                                        {'_id': reply_id, f'attachments.{i}.path': file_path},
                                        {'$set': {
                                            f'attachments.{i}.data': fixed_data,
                                            f'attachments.{i}.has_data': True
                                        }}
                                    )
                                    app.logger.info(f"âœ… Fixed malformed base64 data for attachment {i} in reply {reply_id}")
                                    regenerated_count += 1
                                else:
                                    app.logger.error(f"âŒ Could not fix malformed base64 data for attachment {i}: {error}")
                        
                        elif file_path and os.path.exists(file_path):
                            # This attachment is missing base64 data, try to regenerate it
                            try:
                                # Read file and convert to base64
                                with open(file_path, 'rb') as f:
                                    file_content = f.read()
                                    base64_data = base64.b64encode(file_content).decode('utf-8')
                                
                                # Update attachment with base64 data
                                db.replies.update_one(
                                    {'_id': reply_id, f'attachments.{i}.path': file_path},
                                    {'$set': {
                                        f'attachments.{i}.data': base64_data,
                                        f'attachments.{i}.has_data': True,
                                        f'attachments.{i}.size': len(file_content)
                                    }}
                                )
                                
                                app.logger.info(f"âœ… Regenerated base64 data for attachment {i} in reply {reply_id}")
                                regenerated_count += 1
                                
                            except Exception as e:
                                app.logger.error(f"âŒ Failed to regenerate attachment {i} in reply {reply_id}: {e}")
                        else:
                            app.logger.warning(f"âš ï¸ File not found for attachment {i} in reply {reply_id}: {file_path}")
        
        if regenerated_count > 0:
            return jsonify({
                'status': 'success',
                'message': f'Successfully regenerated {regenerated_count} webhook attachments for ticket {ticket_id}'
            })
        else:
            return jsonify({
                'status': 'warning',
                'message': f'No webhook attachments needed regeneration for ticket {ticket_id}'
            })
            
    except Exception as e:
        app.logger.error(f"ðŸ’¥ ERROR IN REGENERATE WEBHOOK ATTACHMENTS API: {e}")
        import traceback
        app.logger.error(f"ðŸ’¥ Full traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Failed to regenerate webhook attachments: {str(e)}'
        }), 500

@app.route('/api/debug/fix-base64', methods=['POST'])
def debug_fix_base64():
    """Debug endpoint to test and fix base64 data"""
    try:
        data = request.get_json()
        base64_string = data.get('base64_data', '')
        
        if not base64_string:
            return jsonify({'status': 'error', 'message': 'No base64 data provided'}), 400
        
        app.logger.info(f"ðŸ”§ Testing base64 data: length={len(base64_string)}")
        app.logger.info(f"ðŸ”§ First 50 chars: {base64_string[:50]}...")
        app.logger.info(f"ðŸ”§ Last 50 chars: {base64_string[-50:]}...")
        app.logger.info(f"ðŸ”§ Length % 4: {len(base64_string) % 4}")
        
        # Check for common issues
        has_invalid_chars = any(c not in 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=' for c in base64_string)
        has_padding = '=' in base64_string
        app.logger.info(f"ðŸ”§ Has invalid chars: {has_invalid_chars}")
        app.logger.info(f"ðŸ”§ Has padding: {has_padding}")
        
        # Try to fix the base64 data
        fixed_data, error = fix_malformed_base64_data(base64_string)
        
        if fixed_data:
            try:
                # Test decode the fixed data
                decoded = base64.b64decode(fixed_data)
                app.logger.info(f"ðŸ”§ Successfully decoded {len(decoded)} bytes")
                
                response_data = {
                    'status': 'success',
                    'message': 'Base64 data fixed successfully',
                    'original_length': len(base64_string),
                    'fixed_length': len(fixed_data),
                    'decoded_bytes': len(decoded),
                    'original_data_preview': base64_string[:100] + '...' if len(base64_string) > 100 else base64_string,
                    'fixed_data_preview': fixed_data[:100] + '...' if len(fixed_data) > 100 else fixed_data,
                    'analysis': {
                        'original_length_mod_4': len(base64_string) % 4,
                        'fixed_length_mod_4': len(fixed_data) % 4,
                        'has_invalid_chars': has_invalid_chars,
                        'has_padding': has_padding
                    }
                }
                
                app.logger.info(f"ðŸ”§ Returning success response: {response_data}")
                return jsonify(response_data)
                
            except Exception as e:
                app.logger.error(f"ðŸ”§ Fixed data still invalid: {e}")
                return jsonify({
                    'status': 'error',
                    'message': f'Fixed data still invalid: {str(e)}',
                    'error': str(e),
                    'original_length': len(base64_string),
                    'fixed_length': len(fixed_data) if fixed_data else 0
                }), 400
        else:
            app.logger.error(f"ðŸ”§ Could not fix base64 data: {error}")
            return jsonify({
                'status': 'error',
                'message': f'Could not fix base64 data: {error}',
                'error': error,
                'original_length': len(base64_string),
                'analysis': {
                    'length_mod_4': len(base64_string) % 4,
                    'has_invalid_chars': has_invalid_chars,
                    'has_padding': has_padding
                }
            }), 400
            
    except Exception as e:
        app.logger.error(f"ðŸ”§ Error in debug fix base64: {e}")
        import traceback
        app.logger.error(f"ðŸ”§ Full traceback: {traceback.format_exc()}")
        return jsonify({
            'status': 'error',
            'message': f'Internal error: {str(e)}',
            'traceback': traceback.format_exc()
        }), 500


# Webhook cleanup and maintenance functions
def cleanup_old_webhook_metadata():
    """
    Clean up old webhook metadata to prevent database bloat
    Removes webhook records older than 30 days
    """
    try:
        db = get_db()
        cutoff_date = datetime.now() - timedelta(days=30)
        
        # Get all webhook metadata
        all_metadata = db.get_all_ticket_metadata()
        cleaned_count = 0
        
        for meta in all_metadata:
            if meta['key'] in ['webhook_triggered', 'webhook_url', 'webhook_method', 'referred_by']:
                # Check if this is old metadata
                if 'created_at' in meta and meta['created_at'] < cutoff_date:
                    # Remove old webhook metadata
                    db.remove_ticket_metadata(meta['ticket_id'], meta['key'])
                    cleaned_count += 1
        
        if cleaned_count > 0:
            app.logger.info(f"[CLEANUP] Cleaned up {cleaned_count} old webhook metadata records")
        
        return cleaned_count
        
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to cleanup webhook metadata: {e}")
        return 0


def get_webhook_health_status():
    """
    Get overall health status of the webhook system
    Returns statistics and any issues found
    """
    try:
        db = get_db()
        
        # Count active reminders
        active_reminders = 0
        cancelled_reminders = 0
        failed_webhooks = 0
        
        all_metadata = db.get_all_ticket_metadata()
        
        for meta in all_metadata:
            if meta['key'] == 'webhook_triggered':
                active_reminders += 1
            elif meta['key'] == 'reminder_cancelled':
                cancelled_reminders += 1
            elif meta['key'] == 'webhook_error':
                failed_webhooks += 1
        
        return {
            'active_reminders': active_reminders,
            'cancelled_reminders': cancelled_reminders,
            'failed_webhooks': failed_webhooks,
            'total_webhook_operations': active_reminders + cancelled_reminders + failed_webhooks,
            'health_score': 'good' if failed_webhooks < active_reminders * 0.1 else 'warning'
        }
        
    except Exception as e:
        app.logger.error(f"[ERROR] Failed to get webhook health status: {e}")
        return {'error': str(e)}


if __name__ == '__main__':
    # Development server configuration
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
